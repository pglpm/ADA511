<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ADA511 0.1 Data science and data-driven engineering - 7&nbsp; Probability inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./1st_connection_ML.html" rel="next">
<link href="./truth_inference.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="ada511styles.css">
</head>

<body class="nav-sidebar docked slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./inference.html">Inference I</a></li><li class="breadcrumb-item"><a href="./probability_inference.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Probability inference</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./ada511logo8_small.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">ADA511 <span class="small grey">0.1</span> <br>Data science and data-driven engineering</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dear student<br> and aspiring data engineer</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">An invitation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Accept or discard?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./framework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Framework</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basic_decisions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Basic decision problems</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Inference I</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">What is an inference?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sentences.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Sentences</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./truth_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Truth inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability_inference.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Probability inference</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1st_connection_ML.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">A first connection with machine learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Data I</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./quantities_types.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Quantities and data types</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./quantities_types_multi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Joint quantities and complex data types</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Inference II</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probability distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./joint_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Joint probability distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./marginal_conditional_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Marginal and conditional probabilities</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2nd_connection_ML.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">A second connection with machine learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Data II</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./populations_variates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Populations and variates</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./subpopulations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Subpopulations and conditional frequencies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Infinite populations and samples</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Population inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./recap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">A general inference problem</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./population_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Inference and populations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./exchangeability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Exchangeability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference_exchangeability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Inference under exchangeability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glass_application_R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">The universal exchangeable-inference machine in action</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Decision theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./making_decisions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Making decisions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Machine learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./machine_learning_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Machine learning - an introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./decision_trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Decision trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./neural_networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Neural networks</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-probability-def" id="toc-sec-probability-def" class="nav-link active" data-scroll-target="#sec-probability-def"><span class="header-section-number">7.1</span> When truth isn’t known: probability</a></li>
  <li><a href="#sec-uncertain-inference" id="toc-sec-uncertain-inference" class="nav-link" data-scroll-target="#sec-uncertain-inference"><span class="header-section-number">7.2</span> An unsure inference</a></li>
  <li><a href="#probability-notation" id="toc-probability-notation" class="nav-link" data-scroll-target="#probability-notation"><span class="header-section-number">7.3</span> Probability notation</a></li>
  <li><a href="#sec-fundamental" id="toc-sec-fundamental" class="nav-link" data-scroll-target="#sec-fundamental"><span class="header-section-number">7.4</span> Inference rules</a></li>
  <li><a href="#solution-of-the-uncertain-inference-example" id="toc-solution-of-the-uncertain-inference-example" class="nav-link" data-scroll-target="#solution-of-the-uncertain-inference-example"><span class="header-section-number">7.5</span> Solution of the uncertain-inference example</a>
  <ul class="collapse">
  <li><a href="#atomic-sentences" id="toc-atomic-sentences" class="nav-link" data-scroll-target="#atomic-sentences">Atomic sentences</a></li>
  <li><a href="#proposal-conditional-and-target-inference" id="toc-proposal-conditional-and-target-inference" class="nav-link" data-scroll-target="#proposal-conditional-and-target-inference">Proposal, conditional, and target inference</a></li>
  <li><a href="#starting-inferences" id="toc-starting-inferences" class="nav-link" data-scroll-target="#starting-inferences">Starting inferences</a></li>
  <li><a href="#final-inference" id="toc-final-inference" class="nav-link" data-scroll-target="#final-inference">Final inference</a></li>
  </ul></li>
  <li><a href="#how-the-inference-rules-are-used" id="toc-how-the-inference-rules-are-used" class="nav-link" data-scroll-target="#how-the-inference-rules-are-used"><span class="header-section-number">7.6</span> How the inference rules are used</a></li>
  <li><a href="#derived-rules" id="toc-derived-rules" class="nav-link" data-scroll-target="#derived-rules"><span class="header-section-number">7.7</span> Derived rules</a>
  <ul class="collapse">
  <li><a href="#sec-boolean" id="toc-sec-boolean" class="nav-link" data-scroll-target="#sec-boolean">Boolean algebra</a></li>
  <li><a href="#sec-extension-conversation" id="toc-sec-extension-conversation" class="nav-link" data-scroll-target="#sec-extension-conversation">Law of total probability or “extension of the conversation”</a></li>
  </ul></li>
  <li><a href="#sec-bayes-theorem" id="toc-sec-bayes-theorem" class="nav-link" data-scroll-target="#sec-bayes-theorem"><span class="header-section-number">7.8</span> Bayes’s theorem</a>
  <ul class="collapse">
  <li><a href="#combining-with-the-extension-of-the-conversation" id="toc-combining-with-the-extension-of-the-conversation" class="nav-link" data-scroll-target="#combining-with-the-extension-of-the-conversation">Combining with the extension of the conversation</a></li>
  <li><a href="#many-facets" id="toc-many-facets" class="nav-link" data-scroll-target="#many-facets">Many facets</a></li>
  </ul></li>
  <li><a href="#consequences-of-not-following-the-rules" id="toc-consequences-of-not-following-the-rules" class="nav-link" data-scroll-target="#consequences-of-not-following-the-rules"><span class="header-section-number">7.9</span> Consequences of not following the rules</a></li>
  <li><a href="#remarks-on-terminology-and-notation" id="toc-remarks-on-terminology-and-notation" class="nav-link" data-scroll-target="#remarks-on-terminology-and-notation"><span class="header-section-number">7.10</span> Remarks on terminology and notation</a>
  <ul class="collapse">
  <li><a href="#likelihood" id="toc-likelihood" class="nav-link" data-scroll-target="#likelihood">Likelihood</a></li>
  <li><a href="#omitting-background-information" id="toc-omitting-background-information" class="nav-link" data-scroll-target="#omitting-background-information">Omitting background information</a></li>
  <li><a href="#random-variables" id="toc-random-variables" class="nav-link" data-scroll-target="#random-variables">“Random variables”</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-probability" class="quarto-section-identifier"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Probability inference</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="hidden">
<p><span class="math display">\[
\DeclarePairedDelimiters{\set}{\{}{\}}
\]</span></p>
</div>
<div class="hidden">

</div>
<p>In most engineering and data-science problems we don’t know the truth or falsity of outcomes and hypotheses that interest us. But this doesn’t mean that nothing can be said or done in such situations. Now we shall finally see how to draw <em>uncertain</em> inferences, that is, how to calculate the <em>probability</em> of something that interests us, given particular data, information, and assumptions.</p>
<p>So far we have used the term “probability” somewhat informally and intuitively. It is time to make it more precise and to emphasize some of its most important aspects. Then we’ll dive into the rules of probability-inference.</p>
<section id="sec-probability-def" class="level2 page-columns page-full" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="sec-probability-def"><span class="header-section-number">7.1</span> When truth isn’t known: probability</h2>
<p>When we cross a busy city street we look left and right to check whether any cars are approaching. We typically don’t look <em>up</em> to check whether something is falling from the sky. Yet, couldn’t it be <code>false</code> that cars are approaching at that moment? and couldn’t it be <code>true</code> that <a href="https://www.aerotime.aero/articles/32818-cessna-door-falls-off-lands-in-parking-lot">some object is falling from the sky</a>? Of course both events are possible. Then why do we look left and right, but not up?</p>
<p>The main reason is that we <em>believe strongly</em> that cars might be approaching, and <em>believe very weakly</em> that some object might be falling from the sky. In other words, we consider the first occurrence to be <em>very probable</em>, and the second extremely <em>improbable</em>.</p>
<p>We shall take the notion of <span class="blue"><strong>probability</strong></span> as intuitively understood (just as we did with the notion of truth). Terms equivalent for “probability” are <span class="blue"><em>degree of belief</em></span>, <span class="blue"><em>plausibility</em></span>, <span class="blue"><em>credibility</em></span>.</p>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="fa-solid fa-exclamation-circle" aria-label="exclamation-circle"></i> Beware of <em>likelihood</em> as a synonym for <em>probability</em>
</div>
</div>
<div class="callout-body-container callout-body">
<p>In technical discourse, “likelihood” means something different and is <em>not</em> a synonym of “probability”, as we’ll explain later.</p>
</div>
</div>
<p>Probabilities are quantified between <span style="display:inline-block;"><span class="math inline">\(0\)</span></span> and <span style="display:inline-block;"><span class="math inline">\(1\)</span>,</span> or equivalently between <span style="display:inline-block;"><span class="math inline">\(0\%\)</span></span> and <span style="display:inline-block;"><span class="math inline">\(100\%\)</span>.</span> Assigning to a sentence a probability <code>1</code> is the same as saying that it is <code>true</code>; and a probability <code>0</code>, that it is <code>false</code>. A probability of <span style="display:inline-block;"><span class="math inline">\(0.5\)</span></span> represents a belief completely symmetric with respect to truth and falsity.</p>
<p>Let’s emphasize and agree on some important facts about probabilities:</p>
<ul>
<li><p><span class="blue"><strong><i class="fa-solid fa-hand-point-right" aria-label="hand-point-right"></i> Probabilities are assigned to <em>sentences</em></strong></span>. We already discussed this point in <a href="sentences.html#sec-sentence-notation">§&nbsp;<span>5.3</span></a>, but let’s reiterate it. Consider an engineer working on a problem of electric-power distribution in a specific geographical region. At a given moment the engineer may believe with <span style="display:inline-block;"><span class="math inline">\(75\%\)</span></span> probability that the measured average power output in the next hour will be 100 MW. The <span style="display:inline-block;"><span class="math inline">\(75\%\)</span></span> probability is assigned not to the quantity “100 MW”, but to the <em>sentence</em></p>
<p><span class="math display">\[
\textsf{\small`The measured average power output in the next hour will be 100\,MW'}
\]</span></p>
<p>This difference is extremely important. Consider the alternative sentence</p>
<p><span class="math display">\[
\textsf{\small`The average power output in the next hour will be \emph{set} to 100\,MW'}
\]</span></p>
<p>the numerical quantity is the same, but the meaning is very different. The probability can therefore be very different (if the engineer is the person deciding how to set that output, the probability is <span style="display:inline-block;"><span class="math inline">\(100\%\)</span>).</span> The probability depends not only on a number, but on what it’s being done with that number – measuring, setting, third-party reporting, and so on. Often we write simply <span style="display:inline-block;">“<span class="math inline">\(O = \mathrm{100\,W}\)</span>”</span> provided that the full sentence behind this kind of shorthand is understood.</p></li>
<li><p><span class="blue"><strong><i class="fa-solid fa-hand-point-right" aria-label="hand-point-right"></i> Probabilities are agent- and context-dependent</strong></span>. A coin is tossed, comes down heads, and is quickly hidden from view. Alice sees that it landed heads-up. Bob instead doesn’t manage to see the outcome and has no clue. Alice considers the sentence <span style="display:inline-block;"><span class="math inline">\(\textsf{\small`Coin came down heads'}\)</span></span> to be <code>true</code>, that is, to have <span style="display:inline-block;"><span class="math inline">\(100\%\)</span></span> probability. Bob considers the same sentence to have <span style="display:inline-block;"><span class="math inline">\(50\%\)</span></span> probability.</p>
<p>Note how Alice and Bob assign two different probabilities to the same sentence; yet both assignments are completely rational. If Bob assigned <span style="display:inline-block;"><span class="math inline">\(100\%\)</span></span> to <span style="display:inline-block;"><span class="math inline">\(\textsf{\small`heads'}\)</span>,</span> we would suspect that he had seen the outcome after all; if he assigned <span style="display:inline-block;"><span class="math inline">\(0\%\)</span></span> to <span style="display:inline-block;"><span class="math inline">\(\textsf{\small`heads'}\)</span>,</span> we would consider that groundless and silly. We would be baffled if Alice assigned <span style="display:inline-block;"><span class="math inline">\(50\%\)</span></span> to <span style="display:inline-block;"><span class="math inline">\(\textsf{\small`heads'}\)</span>,</span> because she saw the outcome was actually heads; we would hypothesize that she feels unsure about what she saw.</p>
<p>An omniscient agent would know the truth or falsity of every sentence, and assign only probabilities <code>0</code> or <code>1</code>. Some authors speak of “<em>actual</em> (but unknown) probabilities”. But if there were “actual” probabilities, they would be all <code>0</code> or <code>1</code>, and it would be pointless to speak about probabilities at all – every inference would be a truth-inference.</p></li>
<li><p><span class="blue"><strong><i class="fa-solid fa-hand-point-right" aria-label="hand-point-right"></i> Probabilities are not frequencies</strong></span>. Consider the fraction of defective mechanical components to total components produced per year in some factory. This quantity can be physically measured and, once measured, would be agreed upon by every agent. It is a <em>frequency</em>, not a degree of belief or probability.</p>
<p>It is important to understand the difference between <em>probability</em> and <em>frequency</em>: mixing them up may lead to sub-optimal decisions. Later we shall say more about the difference and the precise relations between probability and frequency.</p>
<p>Frequencies can be unknown to some agents. Probabilities cannot be “unknown”: they can only be difficult to calculate. Be careful when you read authors speaking of an “unknown probability”: they actually mean either “unknown frequency”, or a probability that has to be calculated (it’s “unknown” in the same sense that the value of <span style="display:inline-block;"><span class="math inline">\(1-0.7 \cdot 0.2/(1-0.3)\)</span></span> is “unknown” to you right now).</p></li>
<li><p><span class="blue"><strong><i class="fa-solid fa-hand-point-right" aria-label="hand-point-right"></i> Probabilities are not physical properties</strong></span>. Whether a tossed coin lands heads up or tails up is fully determined by the initial conditions (position, orientation, momentum, rotational momentum) of the toss and the boundary conditions (air velocity and pressure) during the flight. The same is true for all macroscopic engineering phenomena (even quantum phenomena have never been proved to be non-deterministic, and there are <a href="https://doi.org/10.48550/arXiv.quant-ph/9504010">deterministic and experimentally consistent</a> mathematical representations of quantum theory). So we cannot measure a probability using some physical apparatus; and the mechanisms underlying any engineering problem boil down to physical laws, not to probabilities.</p></li>
</ul>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="fa-solid fa-book" aria-label="book"></i> Reading
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="https://hvl.instructure.com/courses/25074/modules/items/661553"><em>Dynamical Bias in the Coin Toss</em></a>. </p>
</div>
</div>
<p><br>
</p>
<div class="page-columns page-full"><p>These points listed above are not just a matter of principle. They have important practical consequences. A data scientist who is not attentive to the source of the data (measured? set? reported, and so maybe less trustworthy?), or who does not carefully assess the context of a probability, or who mixes a probability with a frequency, or who does not take advantage (when possible) of the physics involved in the a problem – such data scientist will design systems with sub-optimal performance<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> – or even cause deaths.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;This fact can be mathematically proven.</p></li></div></div>
</section>
<section id="sec-uncertain-inference" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="sec-uncertain-inference"><span class="header-section-number">7.2</span> An unsure inference</h2>
<p>Consider now the following variation of the trivial inference problem of <a href="truth_inference.html#sec-trivial-inference">§&nbsp;<span>6.1</span></a>.</p>
<blockquote class="blockquote">
<p>This electric component had an early failure. If an electric component fails early, then at production it either didn’t pass the heating test or didn’t pass the shock test. The probability that it didn’t pass both tests is 10%. There’s no reason to believe that the component passed the heating test, more than it passed the shock test.</p>
</blockquote>
<p>The inspector wants to assess, also in this case, whether the component did not pass the heating test.</p>
<p>From the data and information given, what would you say is the probability that the component didn’t pass the heating test?</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="fa-solid fa-user-edit" aria-label="user-edit"></i> Exercises
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Try to argue why a conclusion cannot drawn with certainty in this case. One way to argue this is to present two different scenarios that fit the data given but have opposite conclusions.</li>
<li>Try to reason intuitively and assess the probability that the component didn’t pass the heating test. Should it be larger or smaller than 50%? Why?</li>
</ul>
</div>
</div>
</section>
<section id="probability-notation" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="probability-notation"><span class="header-section-number">7.3</span> Probability notation</h2>
<p>For this inference problem we can’t find a <code>true</code> or <code>false</code> final value. The truth-inference rules (<a href="truth_inference.html#eq-t-not"><span>6.1</span></a>)–(<a href="truth_inference.html#eq-t-unity"><span>6.4</span></a>) therefore cannot help us here. In fact even the <span style="display:inline-block;">“<span class="math inline">\(\mathrm{T}(\dotso \nonscript\:\vert\nonscript\:\mathopen{} \dotso)\)</span>”</span> notation is unsuitable, because it only admits the values <span style="display:inline-block;"><span class="math inline">\(1\)</span></span> (<code>true</code>) and <span style="display:inline-block;"><span class="math inline">\(0\)</span></span> (<code>false</code>).</p>
<p>Let us first generalize this notation in a straightforward way:</p>
<p>First, let’s represent the probability or degree of belief of a sentence by a number in the range <span class="m"><span class="math inline">\([0,1]\)</span>,</span> that is, between <span style="display:inline-block;"><span class="math inline">\(\mathbf{1}\)</span></span> (certainty or <code>true</code>) and <span style="display:inline-block;"><span class="math inline">\(\mathbf{0}\)</span></span> (impossibility or <code>false</code>). The value <span style="display:inline-block;"><span class="math inline">\(0.5\)</span></span> represents that the belief in the truth of the sentence is as strong as that in its falsity.</p>
<p>Second, let’s symbolically write that the probability of a proposal <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Y}\)</span>,</span> given a conditional <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X}\)</span>,</span> is some number <span style="display:inline-block;"><span class="math inline">\(p\)</span>,</span> as follows:</p>
<p><span class="math display">\[
\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}) = p
\]</span></p>
<p>Note that this notation includes the notation for truth-values as a special case:</p>
<p><span class="math display">\[
\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}) = 0\text{ or }1
\quad\Longleftrightarrow\quad
\mathrm{T}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}) = 0\text{ or }1
\]</span></p>
</section>
<section id="sec-fundamental" class="level2 page-columns page-full" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="sec-fundamental"><span class="header-section-number">7.4</span> Inference rules</h2>
<p>Extending our truth-inference notation to probability-inference notation has been straightforward. But which rules should we use for drawing inferences when probabilities are involved?</p>
<p>The amazing result is that <em>the rules for truth-inference, formulae (<a href="truth_inference.html#eq-t-not"><span>6.1</span></a>)–(<a href="truth_inference.html#eq-t-unity"><span>6.4</span></a>), extend also to probability-inference</em>. The only difference is that they now hold for all values in the range <span style="display:inline-block;"><span class="math inline">\([0,1]\)</span>,</span> rather than for <span style="display:inline-block;"><span class="math inline">\(0\)</span></span> and <span style="display:inline-block;"><span class="math inline">\(1\)</span></span> only.</p>
<p>This important result was taken more or less for granted at least since Laplace in the 1700s. But was formally proven for the first time in the 1946 by R.&nbsp;T.&nbsp;Cox. The proof has been refined since then. What kind of proof is it? It shows that if we don’t follow the rules we are doomed to arrive at illogical conclusions; we’ll show some examples later.</p>
<p><br>
</p>
<p>Finally, here are the fundamental rules of all inference. They are encoded by the following equations, which must always hold for any atomic or complex sentences <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X},\mathsfit{Y},\mathsfit{Z}\)</span>:</span></p>
<div class="column-page-right">
<div class="callout callout-style-default callout-note no-icon callout-titled" style="text-align:center;font-size:125%">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="blue" style="font-size:150%"><strong><i class="fa-solid fa-landmark" aria-label="landmark"></i>&nbsp;&nbsp;&nbsp;THE FUNDAMENTAL LAWS OF INFERENCE&nbsp;&nbsp;&nbsp;<i class="fa-solid fa-landmark" aria-label="landmark"></i></strong></span>
</div>
</div>
<div class="callout-body-container callout-body">
<div style="font-size:165%">
<dl>
<dt>“Not” <span class="math inline">\(\boldsymbol{\lnot}\)</span> rule</dt>
<dd>
<span class="math display">\[\mathrm{P}(\lnot \mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
+ \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
= 1\]</span><br>

</dd>
<dt>“And” <span class="math inline">\(\boldsymbol{\land}\)</span> rule</dt>
<dd>
<span class="math display">\[
\mathrm{P}(\mathsfit{X}\land \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
= \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}\land \mathsfit{Z}) \cdot
\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
= \mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land \mathsfit{Z}) \cdot
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
\]</span><br>

</dd>
<dt>“Or” <span class="math inline">\(\boldsymbol{\lor}\)</span> rule</dt>
<dd>
<span class="math display">\[\mathrm{P}(\mathsfit{X}\lor \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
= \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) +
\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
- \mathrm{P}(\mathsfit{X}\land \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
\]</span><br>

</dd>
<dt>Self-consistency rule</dt>
<dd>
<span class="math display">\[\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land \mathsfit{Z})
= 1
\]</span>
</dd>
</dl>
</div>
</div>
</div>
</div>
<p>It is amazing that <strong>ALL</strong> inference is nothing else but a repeated application of these four rules – billions of times or more in some cases. All machine-learning algorithms are just applications or approximations of these rules. Methods that you may have heard about in statistics are just specific applications of these rules. Truth inferences are also special applications of these rules. Most of this course is, at bottom, just a study of how to apply these rules in particular kinds of problems.</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="fa-solid fa-book" aria-label="book"></i> Reading
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="https://hvl.instructure.com/courses/25074/modules/items/660094"><em>Probability, Frequency and Reasonable Expectation</em></a></p></li>
<li><p>Ch.&nbsp;2 of <a href="https://hvl.instructure.com/courses/25074/modules/items/660390"><em>Bayesian Logical Data Analysis for the Physical Sciences</em></a></p></li>
<li><p>Ch.&nbsp;1 of <a href="https://hvl.instructure.com/courses/25074/modules/items/675505"><em>Probability</em></a></p></li>
<li><p>§§&nbsp;1.0–1.2 of <a href="https://hvl.instructure.com/courses/25074/modules/items/661040"><em>Data Analysis</em></a></p></li>
<li><p>Feel free to skim through §§&nbsp;2.0–2.4 of <a href="https://hvl.instructure.com/courses/25074/modules/items/660090"><em>Probability Theory</em></a></p></li>
</ul>
</div>
</div>
<p>&nbsp;</p>
<p>The fundamental inference rules are used in the same way as their truth-inference special case: Each equality can be rewritten in different ways according to the usual rules of algebra. Then left and right side of the equality thus obtained can replace each other in a proof.</p>
</section>
<section id="solution-of-the-uncertain-inference-example" class="level2 page-columns page-full" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="solution-of-the-uncertain-inference-example"><span class="header-section-number">7.5</span> Solution of the uncertain-inference example</h2>
<p>Armed with the fundamental rules of inference, let’s solve our earlier inference problem. As usual we first analyse it, find what are its proposal and conditional, and which starting inferences are given in the problem.</p>
<section id="atomic-sentences" class="level3">
<h3 class="anchored" data-anchor-id="atomic-sentences">Atomic sentences</h3>
<p><span class="math display">\[
\begin{aligned}
\mathsfit{h}&amp;\coloneqq\textsf{\small`The component passed the heating test'}
\\
\mathsfit{s}&amp;\coloneqq\textsf{\small`The component passed the shock test'}
\\
\mathsfit{f}&amp;\coloneqq\textsf{\small`The component had an early failure'}
\\
\mathsfit{J}&amp;\coloneqq\textsf{\small (all other implicit background information)}
\end{aligned}
\]</span></p>
<p>The background information in this example is different from the previous, truth-inference one, so we use the different symbol <span style="display:inline-block;"><span class="math inline">\(\mathsfit{J}\)</span></span> for it.</p>
</section>
<section id="proposal-conditional-and-target-inference" class="level3">
<h3 class="anchored" data-anchor-id="proposal-conditional-and-target-inference">Proposal, conditional, and target inference</h3>
<p>The proposal is <span style="display:inline-block;"><span class="math inline">\(\lnot\mathsfit{h}\)</span>,</span> just like in the truth-inference example.</p>
<p>The conditional is different now. We know that the component failed early, but we don’t know whether it passed the shock test. Hence the conditional is <span style="display:inline-block;"><span class="math inline">\(\mathsfit{f}\land \mathsfit{J}\)</span>.</span></p>
<p>The target inference is therefore</p>
<p><span class="math display">\[
\color[RGB]{238,102,119}\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
\]</span></p>
</section>
<section id="starting-inferences" class="level3">
<h3 class="anchored" data-anchor-id="starting-inferences">Starting inferences</h3>
<p>We are told that if an electric component fails early, then at production it didn’t pass either the heating test or the shock test. Let’s write this as</p>
<p><span class="math display">\[
\color[RGB]{34,136,51}\mathrm{P}(\lnot\mathsfit{h}\lor \lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J}) = 1
\]</span></p>
<p>We are also told that there is a <span style="display:inline-block;"><span class="math inline">\(10\%\)</span></span> probability that both tests fail</p>
<p><span class="math display">\[
\color[RGB]{34,136,51}\mathrm{P}(\lnot\mathsfit{h}\land \lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J}) = 0.1
\]</span></p>
<p>Finally the problem says that there’s no reason to believe that the component didn’t pass the heating test, more than it didn’t pass the shock test. This can be written as follows:</p>
<p><span class="math display">\[
\color[RGB]{34,136,51}\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J}) = \mathrm{P}(\lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
\]</span></p>
<p>Note this interesting situation: we are not given the numerical values of these two probabilities, we are only told that they are equal. This is an example of application of the <em>principle of indifference</em>, which we’ll discuss more in detail later.</p>
</section>
<section id="final-inference" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="final-inference">Final inference</h3>
<p>Also in this case there is no unique way of applying the rules to reach our target inference, but all ways lead to the same result. Let’s try to proceed backwards:</p>
<div class="column-page-inset-right">
<p><span class="math display">\[
\begin{aligned}
&amp;\color[RGB]{238,102,119}\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})&amp;&amp;
\\[1ex]
&amp;\qquad= {\color[RGB]{34,136,51}\mathrm{P}(\lnot\mathsfit{s}\lor \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})}
+ {\color[RGB]{34,136,51}\mathrm{P}(\lnot\mathsfit{s}\land \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})}
- \mathrm{P}(\lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
&amp;&amp;\text{\small ∨-rule}
\\[1ex]
&amp;\qquad= {\color[RGB]{34,136,51}1}
+ {\color[RGB]{34,136,51}0.1}
- \mathrm{P}(\lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
&amp;&amp;\text{\small starting inferences}
\\[1ex]
&amp;\qquad= 0.1 + \color[RGB]{34,136,51}\mathrm{P}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
&amp;&amp;\text{\small ¬-rule}
\\[1ex]
&amp;\qquad= 0.1 + \mathrm{P}(\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
&amp;&amp;\text{\small starting inference}
\\[1ex]
&amp;\qquad= 0.1 + 1 -\color[RGB]{238,102,119}\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
&amp;&amp;\text{\small ¬-rule}
\end{aligned}
\]</span></p>
</div>
<p>The target probability appears on the left and right side with opposite signs. We can solve for it:</p>
<p><span class="math display">\[
\begin{aligned}
2\,{\color[RGB]{238,102,119}\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})} &amp;= 0.1 + 1
\\[1ex]
{\color[RGB]{238,102,119}\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})} &amp;= 0.55
\end{aligned}
\]</span></p>
<p>So the probability that the component didn’t pass the heating test is <span style="display:inline-block;"><span class="math inline">\(55\%\)</span>.</span></p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="fa-solid fa-user-edit" aria-label="user-edit"></i> Exercises
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Try to find an intuitive explanation of why the probability is 55%, slightly larger than 50%. If your intuition says this probability is wrong, then</p>
<ul>
<li>Check the proof of the inference for mistakes, or try to find a proof with a different path.</li>
<li>Examine your intuition critically and educate it.</li>
</ul></li>
<li><p>Check how the target probability <span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})\)</span></span> changes if we change the value of the probability <span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\lnot\mathsfit{s}\land \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})\)</span></span> from <span style="display:inline-block;"><span class="math inline">\(0.1\)</span>.</span></p>
<ul>
<li>What result do we obtain if <span class="math inline">\(\mathrm{P}(\lnot\mathsfit{s}\land \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})=0\)</span>? Can it be intuitively explained?</li>
<li>What if <span class="math inline">\(\mathrm{P}(\lnot\mathsfit{s}\land \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})=1\)</span>? Does the result make sense?</li>
</ul></li>
</ul>
</div>
</div>
</section>
</section>
<section id="how-the-inference-rules-are-used" class="level2 page-columns page-full" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="how-the-inference-rules-are-used"><span class="header-section-number">7.6</span> How the inference rules are used</h2>
<p>In the solution above you noticed that the equations of the fundamental rules are not only used to obtain some of the probabilities appearing in them from the remaining probabilities.</p>
<div class="page-columns page-full"><p>The rules represent, first of all, <span class="blue"><em>constraints of logical consistency</em></span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> among probabilities. For instance, if we have probabilities&nbsp;&nbsp;<span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X}\land \mathsfit{Z})=0.1\)</span>,&nbsp;&nbsp;</span><span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z})=0.7\)</span>,&nbsp;&nbsp;and</span> <span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\mathsfit{X}\land \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z})=0.2\)</span>,&nbsp;&nbsp;then</span> there’s an inconsistency somewhere, because these values violate the and-rule:&nbsp;&nbsp;<span style="display:inline-block;"><span class="math inline">\(0.2 \ne 0.1 \cdot 0.7\)</span>.&nbsp;&nbsp;In</span> this case we must find the inconsistency and solve it. However, since probabilities are quantified by real numbers, it’s possible and acceptable to have slight discrepancies within numerical round-off errors.</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;The technical term is <span class="blue"><strong>coherence</strong></span>.</p></li></div></div>
<p>The rules also imply more general constraints. For example we must <em>always</em> have</p>
<p><span class="math display">\[
\begin{gathered}
\mathrm{P}(\mathsfit{X}\land \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}) \le \min\set[\big]{\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}),\  \mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z})}
\\
\mathrm{P}(\mathsfit{X}\lor \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}) \ge \max \set[\big]{\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}),\  \mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z})}
\end{gathered}
\]</span></p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="fa-solid fa-user-edit" aria-label="user-edit"></i> Exercise
</div>
</div>
<div class="callout-body-container callout-body">
<p>Try to prove the two constraints above.</p>
</div>
</div>
</section>
<section id="derived-rules" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="derived-rules"><span class="header-section-number">7.7</span> Derived rules</h2>
<p>The fundamental rules above are in principle all we need to use to draw inferences from other inferences. But from them it is possible to derive some “shortcut” rules.</p>
<section id="sec-boolean" class="level3">
<h3 class="anchored" data-anchor-id="sec-boolean">Boolean algebra</h3>
<p>First, it is possible to show that all rules you may know from Boolean algebra <em>are a consequence of the fundamental rules</em>. So we can always make the following convenient replacements anywhere in a probability expression:</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Boolean algebra
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{gathered}
\lnot\lnot \mathsfit{X}= \mathsfit{X}
\qquad
\mathsfit{X}\land \mathsfit{X}= \mathsfit{X}\lor \mathsfit{X}= \mathsfit{X}
\\[1ex]
\mathsfit{X}\land \mathsfit{Y}= \mathsfit{Y}\land \mathsfit{X}
\qquad
\mathsfit{X}\lor \mathsfit{Y}= \mathsfit{Y}\lor \mathsfit{X}
\\[1ex]
\mathsfit{X}\land (\mathsfit{Y}\lor \mathsfit{Z}) = (\mathsfit{X}\land \mathsfit{Y}) \lor (\mathsfit{X}\land \mathsfit{Z})
\\[1ex]
\mathsfit{X}\lor (\mathsfit{Y}\land \mathsfit{Z}) = (\mathsfit{X}\lor \mathsfit{Y}) \land (\mathsfit{X}\lor \mathsfit{Z})
\\[1ex]
\lnot (\mathsfit{X}\land \mathsfit{Y}) = \lnot \mathsfit{X}\lor \lnot \mathsfit{Y}
\qquad
\lnot (\mathsfit{X}\lor \mathsfit{Y}) = \lnot \mathsfit{X}\land \lnot \mathsfit{Y}
\end{gathered}
\]</span></p>
</div>
</div>
<p><br>
</p>
</section>
<section id="sec-extension-conversation" class="level3">
<h3 class="anchored" data-anchor-id="sec-extension-conversation">Law of total probability or “extension of the conversation”</h3>
<p>Suppose we have a set of <span style="display:inline-block;"><span class="math inline">\(n\)</span></span> sentences <span style="display:inline-block;"><span class="math inline">\(set{\mathsfit{Y}_1, \mathsfit{Y}_2, \dotsc, \mathsfit{Y}_n}\)</span></span> having these two properties:</p>
<ul>
<li><p>They are <span class="blue"><strong>mutually exclusive</strong></span>, meaning that the “and” of any two of them is false, given a conditional <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Z}\)</span>:</span></p>
<p><span class="math display">\[
  \mathrm{P}(\mathsfit{Y}_1\land\mathsfit{Y}_2\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}) = 0\ , \quad
  \mathrm{P}(\mathsfit{Y}_1\land\mathsfit{Y}_3\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}) = 0\ , \quad
\dotsc \ , \quad
  \mathrm{P}(\mathsfit{Y}_{n-1}\land\mathsfit{Y}_n\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}) = 0
  \]</span></p></li>
<li><p>They are <span class="blue"><strong>exhaustive</strong></span>, meaning that the “or” of all of them is true, given a conditional <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Z}\)</span>:</span></p>
<p><span class="math display">\[
  \mathrm{P}(\mathsfit{Y}_1\lor \mathsfit{Y}_2 \lor \dotsb \lor \mathsfit{Y}_n \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}) = 1
  \]</span></p></li>
</ul>
<p>Then the probability of a sentence <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X}\)</span>,</span> conditional on <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Z}\)</span>,</span> is equal to a combination of probabilities conditional on <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Y}_1,\mathsfit{Y}_2,\dotsc\)</span>:</span></p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span style="font-size:110%">Derived rule: extension of the conversation</span>
</div>
</div>
<div class="callout-body-container callout-body">
<div style="font-size:110%">
<p><span class="math display">\[
\begin{aligned}
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) =
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}_1 \land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{Y}_1 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) +
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}_2 \land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{Y}_2 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) +{}&amp;
\\[2ex]
\dotsb + \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}_n \land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{Y}_n \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})&amp;
\end{aligned}
\]</span></p>
</div>
</div>
</div>
<p>This rule is useful when it is difficult to assess the probability of a sentence conditional on the background information, but it is easier to assess the probabilities of that sentence conditional on several auxiliary sentences – often representing hypotheses that exclude one another, and of which we know at least one is true. The name <span class="blue"><strong>extension of the conversation</strong></span> for this derived rule comes from the fact that we are able to call the additional sentences into play.</p>
<p>This situation occurs very often in concrete applications, especially in problems where the probabilities of several competing hypotheses have to be assessed.</p>
<p>The next derived rule is used extremely often, so we discuss it separately.</p>
</section>
</section>
<section id="sec-bayes-theorem" class="level2 page-columns page-full" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="sec-bayes-theorem"><span class="header-section-number">7.8</span> Bayes’s theorem</h2>
<p>The probably most famous – or infamous – rule derived from the laws of inference is <span class="blue"><strong>Bayes’s theorem</strong></span>. It allows us to relate the probability where two sentences <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Y},\mathsfit{X}\)</span></span> appear in the proposal and the conditional, with one where they are exchanged:</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="bayes_big-bang.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Bayes’s theorem guest-starring in <a href="https://www.imdb.com/title/tt0898266/"><em>The Big Bang Theory</em></a></figcaption>
</figure>
</div>
</div></div><div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span style="font-size:110%">Derived rule: Bayes’s theorem</span>
</div>
</div>
<div class="callout-body-container callout-body">
<div style="font-size:110%">
<p><span class="math display">\[
\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land \mathsfit{Z}) =
\frac{\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}\land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})}{\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})}
\]</span></p>
</div>
</div>
</div>
<p>Obviously this rule can only be used if <span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) &gt; 0\)</span>,</span> that is, if the sentence <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X}\)</span></span> is not false conditional on <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Z}\)</span>.</span></p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="fa-solid fa-user-edit" aria-label="user-edit"></i> Exercise
</div>
</div>
<div class="callout-body-container callout-body">
<p>Prove Bayes’s theorem from the fundamental rules of inference.</p>
</div>
</div>
<p>Bayes’s theorem is extremely useful when we want to assess the probability of a sentence, typically a hypothesis, given some conditional, typically data; and we can easily assess the probability of the data conditional on the hypothesis. Note, however, that the sentences <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Y}\)</span></span> and <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X}\)</span></span> in the theorem can be about anything whatsoever: <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Y}\)</span></span> does not always need to be a “hypothesis”, and <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X}\)</span></span> “data”.</p>
<section id="combining-with-the-extension-of-the-conversation" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="combining-with-the-extension-of-the-conversation">Combining with the extension of the conversation</h3>
<p>Bayes’s theorem is often with several sentences <span style="display:inline-block;"><span class="math inline">\(\set{\mathsfit{Y}_1, \mathsfit{Y}_2, \dotsc, \mathsfit{Y}_n}\)</span></span> that are mutually exclusive and exhaustive. Typically these represent competing hypotheses. In this case the probability of the sentence <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X}\)</span></span> in the denominator can be expressed using the rule of extension of the conversation:</p>
<div class="column-page-inset-right">
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span style="font-size:110%">Derived rule: Bayes’s theorem with extension of the conversation</span>
</div>
</div>
<div class="callout-body-container callout-body">
<div style="font-size:110%">
<p><span class="math display">\[
\mathrm{P}(\mathsfit{Y}_1 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land \mathsfit{Z}) =
\frac{\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}_1 \land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{Y}_1 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})}{
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}_1 \land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{Y}_1 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) +
\dotsb + \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}_n \land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{Y}_n \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
}
\]</span></p>
</div>
<p>and similarly for <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Y}_2\)</span></span> and so on.</p>
</div>
</div>
</div>
<p>We will use this form of Bayes’s theorem very frequently.</p>
</section>
<section id="many-facets" class="level3">
<h3 class="anchored" data-anchor-id="many-facets">Many facets</h3>
<p>Bayes’s theorem is a very general result of the fundamental rules of inference, valid for any sentences <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X},\mathsfit{Y},\mathsfit{Z}\)</span>.</span> This generality leads to many uses and interpretations.</p>
<p>The theorem is often proclaimed to be the rule according to which we “update our beliefs”. The meaning of this proclamation is the following. Let’s say that at some point <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Z}\)</span></span> represents all your knowledge. Your degree of belief about some sentence <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Y}\)</span></span> is then (at least in theory) the value of <span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})\)</span>.</span> At some later point, let’s say that you get to know – maybe thanks to an observation you made – that the sentence <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X}\)</span></span> is true. Your whole knowledge at that point is represented no longer by <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Z}\)</span>,</span> but by <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X}\land \mathsfit{Z}\)</span>.</span> Your degree of belief about <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Y}\)</span></span> is then given by the value of <span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land\mathsfit{Z})\)</span>.</span> Bayes’s theorem allows you to find your degree of belief about <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Y}\)</span></span> conditional on your new state of knowledge, from the one conditional on your old state of knowledge.</p>
<p>This chronological element, however, comes only from this particular way of using Bayes’s theorem. The theorem can more generally be used to connect any two states of knowledge <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Z}\)</span></span> and <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X}\land\mathsfit{Z}\)</span>,</span> no matter their temporal order, even if they happen simultaneously, and even if they belong to two different agents.</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="fa-solid fa-user-edit" aria-label="user-edit"></i> Exercise
</div>
</div>
<div class="callout-body-container callout-body">
<p>Using Bayes’s theorem and the fundamental laws of inference, prove that if <span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})=1\)</span>,</span> that is, if you already know that <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X}\)</span></span> is true in your current state of knowledge <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Z}\)</span>,</span> then</p>
<p><span class="math display">\[
\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land \mathsfit{Z}) = \mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
\]</span></p>
<p>that is, your degree of belief about <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Y}\)</span></span> doesn’t change.</p>
<p>Is this result reasonable?</p>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="fa-solid fa-book" aria-label="book"></i> Reading
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>§§ 4.1–4.3 in <a href="https://hvl.instructure.com/courses/25074/modules/items/671397"><em>Medical Decision Making</em></a> give one more point of view on Bayes’s theorem.</p></li>
<li><p>Ch.&nbsp;3 of <a href="https://hvl.instructure.com/courses/25074/modules/items/675505"><em>Probability</em></a></p></li>
<li><p>A graphical explanation of how Bayes’s theorem works mathematically (using a specific interpretation of the theorem):</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/HZGCoVF3YvM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p></p></li>
</ul>
</div>
</div>
</section>
</section>
<section id="consequences-of-not-following-the-rules" class="level2" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="consequences-of-not-following-the-rules"><span class="header-section-number">7.9</span> Consequences of not following the rules</h2>
<p>@@ §12.2.3 of AI</p>
<ul>
<li><p><em>Exercise: <a href="The_Monty_Hall_problem-exercise.pdf">Monty-Hall problem &amp; variations</a></em></p></li>
<li><p><em>Exercise: clinical test &amp; diagnosis</em></p></li>
</ul>
</section>
<section id="remarks-on-terminology-and-notation" class="level2 page-columns page-full" data-number="7.10">
<h2 data-number="7.10" class="anchored" data-anchor-id="remarks-on-terminology-and-notation"><span class="header-section-number">7.10</span> Remarks on terminology and notation</h2>
<section id="likelihood" class="level3">
<h3 class="anchored" data-anchor-id="likelihood">Likelihood</h3>
<p>In everyday language, “likely” is often a synonym of “probable”; and “likelihood”, of “probability”. But in technical writings about probability, inference, and decision-making, “likelihood” has a very different meaning. Beware of this important difference in definition:</p>
<p><span class="math inline">\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X})\)</span> is:</p>
<ul>
<li><p>the <span class="blue"><strong>probability of <span class="math inline">\(\mathsfit{Y}\)</span> given <span class="math inline">\(\mathsfit{X}\)</span></strong></span> (or <strong>conditional on <span class="math inline">\(\mathsfit{X}\)</span></strong>),</p></li>
<li><p>the <span class="blue"><strong>likelihood of <span class="math inline">\(\mathsfit{X}\)</span> in view of <span class="math inline">\(\mathsfit{Y}\)</span></strong></span>.</p></li>
</ul>
<p>Let’s express this also in a different way:</p>
<ul>
<li><p>the <span class="blue"><strong>probability of <span class="math inline">\(\mathsfit{Y}\)</span></strong></span> given <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X}\)</span>,</span> is <span style="display:inline-block;"><span class="math inline">\(\mathrm{P}({\color[RGB]{68,119,170}\mathsfit{Y}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X})\)</span>.</span></p></li>
<li><p>the <span class="blue"><strong>likelihood of <span class="math inline">\(\mathsfit{Y}\)</span></strong></span> in view of <span style="display:inline-block;"><span class="math inline">\(\mathsfit{X}\)</span>,</span> is <span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{}{\color[RGB]{68,119,170}\mathsfit{Y}})\)</span>.</span></p></li>
</ul>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="fa-solid fa-exclamation-circle" aria-label="exclamation-circle"></i>
</div>
</div>
<div class="callout-body-container callout-body">
<p>A priori there is no relation between the probability and the likelihood of a sentence <span style="display:inline-block;"><span class="math inline">\(\mathsfit{Y}\)</span>:</span> this sentence could have very high probability and very low likelihood, and vice versa.</p>
</div>
</div>
<p>In these notes we’ll avoid the possibly confusing term “likelihood”. All we need to express can be phrased in terms of “probability”.</p>
</section>
<section id="omitting-background-information" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="omitting-background-information">Omitting background information</h3>
<p>In the analyses of the inference examples of <a href="truth_inference.html#sec-trivial-inference">§&nbsp;<span>6.1</span></a> and <a href="#sec-uncertain-inference">§&nbsp;<span>7.2</span></a> we defined sentences (<span style="display:inline-block;"><span class="math inline">\(\mathsfit{I}\)</span></span> and <span style="display:inline-block;"><span class="math inline">\(\mathsfit{J}\)</span>)</span> expressing all background information, and always included these sentences in the conditionals of the inferences – because those inferences obviously depended on that background information.</p>
<p>In many concrete inference problems the background information usually stays there in the conditional from beginning to end, while the other sentences jump around between conditional and proposal as we apply the rules of inference. For this reason the background information is often omitted from the notation, being implicitly understood. For instance, if the background information is denoted <span style="display:inline-block;"><span class="math inline">\(\mathsfit{I}\)</span>,</span> one writes</p>
<ul>
<li><p><span style="display:inline-block;">“<span class="math inline">\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X})\)</span>”</span>&nbsp;&nbsp;instead of&nbsp;&nbsp;<span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X}\land \mathsfit{I})\)</span></span></p></li>
<li><p><span style="display:inline-block;">“<span class="math inline">\(\mathrm{P}(\mathsfit{Y})\)</span>”</span>&nbsp;&nbsp;instead of&nbsp;&nbsp;<span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})\)</span></span></p></li>
</ul>
<p>This is what’s happening when you see in books probabilities <span style="display:inline-block;">“<span class="math inline">\(P(x)\)</span>”</span> without conditional.</p>
<p>Such practice may be convenient, but be wary of it, especially in particular situations:</p>
<ul>
<li><p>In some inference problems we suddenly realize that we must distinguish between cases that depend on hypotheses, say <span style="display:inline-block;"><span class="math inline">\(\mathsfit{H}_1\)</span></span> and <span style="display:inline-block;"><span class="math inline">\(\mathsfit{H}_2\)</span>,</span> that were buried in the background information <span style="display:inline-block;"><span class="math inline">\(\mathsfit{I}\)</span>.</span> If the background information <span style="display:inline-block;"><span class="math inline">\(\mathsfit{I}\)</span></span> is explicitly reported in the notation, this is no problem: we can rewrite it as</p>
<p><span class="math display">\[ \mathsfit{I}= (\mathsfit{H}_1 \lor \mathsfit{H}_2) \land \mathsfit{I}'\]</span></p>
<p>and proceed, for example using the rule of extension of the conversation. If the background information was not explicitly written, this may lead to confusion and mistakes. For instance there may suddenly appear two instances of <span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\mathsfit{X})\)</span></span> with <em>different</em> values, just because one of them is invisibly conditional on <span style="display:inline-block;"><span class="math inline">\(\mathsfit{I}\)</span>,</span> the other on <span style="display:inline-block;"><span class="math inline">\(\mathsfit{I}'\)</span>.</span></p></li>
<li><p>In some inference problems we are considering <em>several different</em> instances of background information – for example because more than one agent is involved. It’s then extremely important to write the background information explicitly, lest we mix up the different agents’s degrees of belief.</p></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="fa-solid fa-rocket" aria-label="rocket"></i> For the extra curious
</div>
</div>
<div class="callout-body-container callout-body">
<p>A once-famous <a href="https://hvl.instructure.com/courses/25074/modules/items/672178">paper published in the quantum-theory literature</a> arrived at completely wrong results simply by omitting background information, mixing up probabilities having different conditionals.</p>
</div>
</div>
</div></div><p>This kind of confusion from poor notation happens more often than one thinks, and even appears in scientific literature.</p>
</section>
<section id="random-variables" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="random-variables">“Random variables”</h3>
<p>Some texts speak of the probability of a “random variable”, or more precisely of the probability “that a random variable takes on a particular value”. As you notice, we have just expressed that idea by means of a <em>sentence</em>. The viewpoint and terminology of random variables is therefore a special case of that based on sentences, which we use here.</p>
<p>The dialect of “random variables” does not offer any advantages in concepts, notation, terminology, or calculations, but it has several shortcomings:</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="maxwell1.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption"><a href="https://clerkmaxwellfoundation.org/html/about_maxwell.html">James&nbsp;Clerk&nbsp;Maxwell</a> is one of the main founders of statistical mechanics and kinetic theory (and electromagnetism). Yet he never used the word “random” in his technical writings. Maxwell is known for being very clear and meticulous with explanations and terminology.</figcaption>
</figure>
</div>
</div></div><ul>
<li><p>As discussed in <a href="#sec-probability-def">§&nbsp;<span>7.1</span></a>, in concrete applications it is important to know how a quantity “takes on” a value: for example it could be directly measured, indirectly reported, or purposely set to that specific value. Thinking and working in terms of sentences, rather than of random variables, allows us to account for these important differences.</p></li>
<li><p>Very often the object (proposal) of a probability is not a “variable”: it is actually a <em>constant</em> value that is simply unknown.</p></li>
<li><p>What does “random” (or “chance”) mean? Good luck finding an understandable and non-circular definition in texts that use that word; strangely enough, they never define it. In these notes, if the word “random” is ever used, it stands for “unpredictable” or “unsystematic”.</p></li>
</ul>
<p>It’s a question for sociology of science why some people keep on using less flexible points of view or terminologies. Probably they just memorize them as students and then a fossilization process sets in.</p>
<p><br>
</p>
<p>Finally, some texts speak of the probability of an “event”. For all purposes an “event” is just what’s expressed in a sentence.</p>


</section>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./truth_inference.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Truth inference</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./1st_connection_ML.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">A first connection with machine learning</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>