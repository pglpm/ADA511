<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-11-01">

<title>24&nbsp; A categorization of inferences – ADA511 0.4</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./exchangeable_probabilities.html" rel="next">
<link href="./samples.html" rel="prev">
<link href="./favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-6fc7f9edc9275b1be4df9d56d9e5af00.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/quarto-contrib/fontawesome6-1.2.0/all.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/fontawesome6-1.2.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="ada511styles.css">
</head>

<body class="nav-sidebar docked slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title"><span id="sec-kinds-inferences" class="quarto-section-identifier"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title"><span class="green">A categorization of inferences</span></span></span></h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./ada511logo8_small.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">ADA511 <span class="small grey">0.4</span><br><span class="small grey">2025-11-01</span><br></a><a href="http://creativecommons.org/licenses/by-sa/4.0"><img src="cc_by_sa.png" class="img-fluid" style="width:3em" alt="CC BY-SA 4.0"> <span class="small grey">licence</span></a><br> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dear student<br> and aspiring data- &amp; AI-engineer</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text"><span class="lightblue"><strong>An invitation</strong></span></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title"><span class="lightblue">Accept or discard?</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./framework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title"><span class="lightblue">Framework</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basic_decisions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title"><span class="lightblue">Basic decision problems</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./connection-1-ML.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title"><span class="midgrey">Connection with machine learning and AI</span></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text"><span class="green"><strong>Inference I</strong></span></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Rintro1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="lightblue">Working with R, I</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title"><span class="green">What is an inference?</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sentences.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title"><span class="green">Sentences</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./truth_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title"><span class="green">Truth inference</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title"><span class="green">Probability inference</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./derived_rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title"><span class="green">Shortcut rules</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./monty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title"><span class="green">Monty Hall and related inference problems</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./connection-2-ML.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title"><span class="midgrey">Second connection with machine learning</span></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text"><span class="yellow"><strong>Data I</strong></span></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./quantities_types.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title"><span class="yellow">Quantities and data types</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./quantities_types_multi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title"><span class="yellow">Joint quantities and complex data types</span></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text"><span class="green"><strong>Inference II</strong></span></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title"><span class="green">Probability distributions</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Rintro2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="lightblue">Working with R, II</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./joint_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title"><span class="green">Joint probability distributions</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Rintro3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="lightblue">Working with R, III</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./marginal_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title"><span class="green">Marginal probability distributions</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conditional_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title"><span class="green">Conditional probability and learning</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conditional_summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="green">Learning and conditional probability: a summary</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./information.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title"><span class="green">Information, relevance, independence, association</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./connection-3-ML.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title"><span class="midgrey">Third connection with machine learning</span></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text"><span class="yellow"><strong>Data II</strong></span></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./populations_variates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title"><span class="yellow">Populations and variates</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title"><span class="yellow">Statistics</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./subpopulations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title"><span class="yellow">Subpopulations and conditional frequencies</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title"><span class="yellow">Infinite populations and samples</span></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text"><span class="green"><strong>Inference III</strong></span></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./categorization-inferences.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title"><span class="green">A categorization of inferences</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./exchangeable_probabilities.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title"><span class="green">Exchangeable beliefs</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference_from_freqs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title"><span class="green">Inferences from frequencies</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference_about_freqs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title"><span class="green">Inference about frequencies</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dirichlet-mixture.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title"><span class="green">Example of belief over frequencies: the Dirichlet-mixture distribution</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary_formulae.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title"><span class="green">Final inference formulae for exchangeable beliefs</span></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text"><span class="red"><strong>A prototype Optimal Predictor Machine</strong></span></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./look_behind.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title"><span class="red">A look behind</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./code_design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title"><span class="red">Implementing an OPM</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prototype_code.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title"><span class="red">Prototype code and workflow</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example_opm1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title"><span class="red">Example application: adult-income task</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./slm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title"><span class="red">Example application: “small language model”</span></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text"><span class="blue"><strong>Decision-making</strong></span></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./utilities.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title"><span class="blue">Utilities</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./making_decisions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title"><span class="blue">Making decisions</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example_opm2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title"><span class="red">The prototype Optimal Predictor Machine makes decisions</span></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text"><span class="midgrey"><strong>Approximations: machine learning</strong></span></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./machine_learning_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Introduction to machine learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./decision_trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Decision trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./neural_networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Neural networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./llms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Large Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./limitations_ML.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title"><span class="darkgrey">Decisions: limitations of present-day machine-learning algorithms</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./utilities_evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title"><span class="darkgrey">Evaluation practices and utilities</span></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text"><span class="lightblue"><strong>Conclusion</strong></span></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./whither.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="lightblue">What next?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bibliography.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="lightblue">Further reading</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./thanks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="lightblue">Thanks</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="lightblue">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-cat-problems" id="toc-sec-cat-problems" class="nav-link active" data-scroll-target="#sec-cat-problems"><span class="header-section-number">24.1</span> A task- and information-oriented categorization of some inference problems</a></li>
  <li><a href="#sec-categ-probtheory" id="toc-sec-categ-probtheory" class="nav-link" data-scroll-target="#sec-categ-probtheory"><span class="header-section-number">24.2</span> Flexible categorization using probability notation</a>
  <ul class="collapse">
  <li><a href="#notation" id="toc-notation" class="nav-link" data-scroll-target="#notation">Notation</a></li>
  </ul></li>
  <li><a href="#sec-example-inference-categories" id="toc-sec-example-inference-categories" class="nav-link" data-scroll-target="#sec-example-inference-categories"><span class="header-section-number">24.3</span> Examples of inference tasks</a>
  <ul class="collapse">
  <li><a href="#new-unit-given-vs-generated" id="toc-new-unit-given-vs-generated" class="nav-link" data-scroll-target="#new-unit-given-vs-generated">New unit: given vs generated</a></li>
  <li><a href="#guessing-variates-all-or-some" id="toc-guessing-variates-all-or-some" class="nav-link" data-scroll-target="#guessing-variates-all-or-some">Guessing variates: all or some</a></li>
  <li><a href="#information-available-in-previous-units" id="toc-information-available-in-previous-units" class="nav-link" data-scroll-target="#information-available-in-previous-units">Information available in previous units</a></li>
  </ul></li>
  <li><a href="#sec-underlying-distribution" id="toc-sec-underlying-distribution" class="nav-link" data-scroll-target="#sec-underlying-distribution"><span class="header-section-number">24.4</span> The underlying distribution</a></li>
  <li><a href="#plan-for-the-next-few-chapters" id="toc-plan-for-the-next-few-chapters" class="nav-link" data-scroll-target="#plan-for-the-next-few-chapters"><span class="header-section-number">24.5</span> Plan for the next few chapters</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span id="sec-kinds-inferences" class="quarto-section-identifier"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title"><span class="green">A categorization of inferences</span></span></span></h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">2025-11-01</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="hidden">
<p><span class="math inline">\(\DeclarePairedDelimiter{\set}{\{}{\}}\)</span> </p>
</div>
<div class="hidden">

</div>
<div class="hidden">

</div>
<p>In this and the next few chapters we shall focus on particular kinds of inferences and predictions, and on how an AI agent should do them. Later on we shall also explore ways to make our agent faster, at the expense of optimality; most present-day machine-learning algorithms are examples of such fast, sub-optimal approximations.</p>
<section id="sec-cat-problems" class="level2 page-columns page-full" data-number="24.1">
<h2 data-number="24.1" class="anchored" data-anchor-id="sec-cat-problems"><span class="header-section-number">24.1</span> A task- and information-oriented categorization of some inference problems</h2>
<p>All sorts of inferences must be faced in everyday life and in highly technological applications; in situations without serious consequences and in others, like medicine, where lives may be at stake.</p>
<p>Such variety of inferences cannot be separated into clear-cut categories. But an informal categorization can provide a starting point to examine some new kind of inference that we may have to face. Many inference tasks will fall in between categories; every data-engineering or data-science problem is unique.</p>
<p>The important questions for us are these:</p>
<ul>
<li><strong>What do we need or want to infer?</strong></li>
<li><strong>From which kind of information?</strong></li>
</ul>
<p>So let’s focus on a categorization based on the types of desired information and of available information. For simplicity here we <em>exclude</em> all tasks that require an agent to continuously and actively interact with its environment for acquiring information, making choices, getting feedback, and so on. These tasks are the domain of Decision Theory in its most complex form, with ramified decisions, <em>strategies</em>, and possibly with the interaction among several decision-making agents. To explore and analyse this complex kind of tasks is beyond the purpose of this course.</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="fa-solid fa-rocket" aria-label="rocket"></i> For the extra curious
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="references.html"><em>Decision Analysis</em></a></p></li>
<li><p>Chapters 16–18 in <a href="references.html"><em>Artificial Intelligence</em></a></p></li>
<li><p><a href="references.html"><em>Games and Decisions</em></a></p></li>
</ul>
</div>
</div>
</div></div><p>We focus on tasks where multiple “instances” with similar characteristics are involved, and the agent has some question related to a “new instance”. According to the conceptual framework developed in the <span class="yellow">Data&nbsp;II</span> part (chapters&nbsp;<a href="populations_variates.html" class="quarto-xref"><span>20</span></a>–<a href="samples.html" class="quarto-xref"><span>23</span></a>), we can view these “instances” as <em>units</em> of a practically infinite population. The “characteristics” that the agent observed or must guess are <em>variates</em> common to all these units.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Remember that you can adopt any terminology you like. If you prefer “instance” and “characteristics” or some other words to “unit” and “variate”, then use them. What’s important is that you understand the ideas and methods behind these words, and that you can exactly explain what you mean to others.</p>
</div></div></section>
<section id="sec-categ-probtheory" class="level2 page-columns page-full" data-number="24.2">
<h2 data-number="24.2" class="anchored" data-anchor-id="sec-categ-probtheory"><span class="header-section-number">24.2</span> Flexible categorization using probability notation</h2>
<p>An extremely useful way to express an inference task is directly through probability notation <span style="display:inline-block;">“<span class="math inline">\(\mathrm{P}(\dotso \nonscript\:\vert\nonscript\:\mathopen{} \dotso)\)</span>”</span>, once the relevant variates – or more generally the relevant <em>sentences</em> (<a href="sentences.html" class="quarto-xref">ch.&nbsp;&nbsp;<span>6</span></a>) – have been defined. It has two main advantages:</p>
<ul>
<li>It directly gives us the probability or probabilities that the agent eventually needs to calculate.</li>
<li>It often eliminates <strong>ambiguity</strong> or <strong>vagueness</strong> in the inference task.</li>
</ul>
<p>This latter advantage is often highly underestimated. As was briefly mentioned in <a href="sentences.html#sec-identify-sentences" class="quarto-xref">§&nbsp;<span>6.2</span></a>, many apparent difficulties in inference tasks arise not because of computational difficulties, but because it isn’t clear what the inference is about. You can witness, for example, different conclusions and debates in trying to determine “which model ois better” – which is not a clear inference at all, until it is precisely stated what “better” means, how it is measured, and by which variate it is represented.</p>
<p>It is therefore to your advantage if you learn and practice to translate an inference and its information into probability notation, and vice versa to read from probability notation what type of inference is being drawn.</p>
<p>We shall use this probability-notation method for delineating approximate categories of inference. Recall (<a href="inference.html#sec-basic-elements-inference" class="quarto-xref">§&nbsp;<span>5.3</span></a>) that in probability notation</p>
<p><span class="math display">\[\mathrm{P}(\text{\color[RGB]{238,102,119}\small[proposal]}\nonscript\:\vert\nonscript\:\mathopen{}\text{\color[RGB]{34,136,51}\small[conditional]} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\]</span></p>
<p>the <span class="red">proposal</span> contains what the agent’s belief is about, and the <span class="green">conditional</span> contains what’s supposed to be known to the agent, together with the background <span class="m">information <span class="math inline">\(\mathsfit{I}\)</span>.</span></p>
<section id="notation" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="notation">Notation</h3>
<p>First let’s introduce some symbol conventions to be used in this and the next chapters. We consider a population, its units being the instances where an agent learned or guessed something. Denote the variates involved in the inferences by letters like&nbsp;&nbsp;<span style="display:inline-block;"><span class="math inline">\(X\)</span>,</span> <span style="display:inline-block;"><span class="math inline">\(Y\)</span>,&nbsp;&nbsp;etc;</span> keep in mind that each of these variates might itself be a composite one, for instance <span style="display:inline-block;"><span class="math inline">\(X = (A, B)\)</span>.&nbsp;&nbsp;Subscripts,</span> usually&nbsp;&nbsp;<span style="display:inline-block;"><span class="math inline">\({}_1\)</span> ,</span> <span style="display:inline-block;"><span class="math inline">\({}_2\)</span> ,</span> <span style="display:inline-block;"><span class="math inline">\({}_n\)</span> ,&nbsp;&nbsp;etc.,</span> identify the individual instances; each subscript might be associated to the time or place of the instance.</p>
<p>Focus on the inference that the agent is currently making, let’s say on unit <span style="display:inline-block;"><span class="math inline">\(N+1\)</span>.</span> We can then divide all population variates intro three roles:</p>
<ul>
<li><p>The <span class="blue"><strong>predictands</strong></span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> are the variates that the agent must guess for this unit, because it doesn’t know their values. We shall usually denote the predictands, jointly, with the symbol <span style="display:inline-block;"><span class="math inline">\(Y\)</span>.</span> <em>An inference always has a predictand.</em></p></li>
<li><p>The <span class="blue"><strong>predictors</strong></span> are variates that the agent has observed in this unit; it knows their value. We shall usually denote the predictors, jointly, with the symbol <span style="display:inline-block;"><span class="math inline">\(X\)</span>.</span> <em>An inference may not have any predictors.</em></p></li>
<li><p>The <span class="blue"><strong>nuisance variates</strong></span> are the remaining ones, which the agent neither needs to guess nor has observed in unit; it doesn’t know their values, and is not interested in their values. Nuisance variates, jointly, shall usually be denoted by <span style="display:inline-block;"><span class="math inline">\(W\)</span>.</span> <em>An inference may not have any nuisance variates.</em></p></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;literally “what has to be predicted”</p></div></div><p>In probability notation these roles are clear as we write</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{\small population variates: }\ Y, X, W
\\[1ex]
&amp;\mathrm{P}(Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1} \nonscript\:\vert\nonscript\:\mathopen{} X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotso)
\end{aligned}
\]</span></p>
<p>where the dots <span style="display:inline-block;"><span class="math inline">\(\dotso\)</span></span> do not refer to the present unit. You see that, for this <span style="display:inline-block;"><span class="math inline">\((N+1)\)</span>th</span> unit, the predictand <span style="display:inline-block;">“<span class="math inline">\(Y\)</span>”</span> is in the proposal, at the left of the conditional bar; this is what the agent’s belief is about. In the conditional, at the right of the conditional bar, we see there’s a predictor <span style="display:inline-block;">“<span class="math inline">\(X\)</span>”</span>; this means that its value is assumed to be known to the agent. We don’t see the variate <span style="display:inline-block;">“<span class="math inline">\(W\)</span>”</span>: not on the left of the conditional bar, because this is not what the belief is about; and not on the right, because its value is unknown. But we know this is a population variate; thus it is a nuisance variate. Note that the variate <span style="display:inline-block;"><span class="math inline">\(W\)</span></span> might be known to the agent for <em>other</em> units.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;In machine learning, instead of “predictand” the terms “dependent variable”, “class” or “label” (for nominal variates) are often; instead of “predictor”, the terms “independent variable” or “feature” are often used.</p></div></div><div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>The roles of “predictand”, “predictor”, “nuisance variate” do not need to be fixed once and for all.</strong>&nbsp;&nbsp;Take the hospital example (<a href="joint_probability.html#sec-repr-joint-prob" class="quarto-xref">§&nbsp;<span>15.2</span></a>): for the present inference the predictand might be <span style="display:inline-block;"><span class="math inline">\(\mathit{Urgency}\)</span>:</span></p>
<p><span class="math display">\[
\mathrm{P}(U_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \nonscript\:\vert\nonscript\:\mathopen{} \dotso) \ ,
\]</span></p>
<p>but in the next inference the predictand might be <span style="display:inline-block;"><span class="math inline">\(\mathit{Transportation}\)</span>:</span></p>
<p><span class="math display">\[
\mathrm{P}(T_{N+2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \nonscript\:\vert\nonscript\:\mathopen{} \dotso) \ .
\]</span></p>
<p>There are some inference tasks where the predictand and predictor are always the same. An example is image classification: an agent designed for it always takes an image as predictor, and tries to guess the image’s label as predictand:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\mathrm{P}(\mathit{Label}_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \nonscript\:\vert\nonscript\:\mathopen{}\mathit{Image}_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso) \ ,
\\[1ex]
&amp;\mathrm{P}(\mathit{Label}_{N+2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \nonscript\:\vert\nonscript\:\mathopen{}\mathit{Image}_{N+2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso) \ ,
\\[1ex]
&amp;\dotso
\end{aligned}
\]</span></p>
<p>In other inference tasks the predictand and predictor may be different from time to time, and even be exchanged. Examples occur in medicine: for a patient we may need to infer the disease given the observed symptoms, and for another patient we may need to forecast the symptoms, say to reduce their severity, given the patient’s known disease:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\mathrm{P}(\mathit{Disease}_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \nonscript\:\vert\nonscript\:\mathopen{}\mathit{Symptom}_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso) \ ,
\\[1ex]
&amp;\mathrm{P}(\mathit{Symptom}_{N+2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \nonscript\:\vert\nonscript\:\mathopen{}\mathit{Disease}_{N+2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso) \ .
\\[1ex]
&amp;\dotso
\end{aligned}
\]</span></p>
</div>
</div>
<p>The agent generally has mixed information about the three groups of variates for other units <span style="display:inline-block;"><span class="math inline">\(1, 2, \dotsc, N\)</span>,</span> usually called the <em>training data</em>. It may know <span style="display:inline-block;"><span class="math inline">\(Y\)</span></span> for one unit, <span style="display:inline-block;"><span class="math inline">\(X\)</span></span> for another, <span style="display:inline-block;"><span class="math inline">\(W\)</span></span> for another, <span style="display:inline-block;"><span class="math inline">\((Y,X)\)</span></span> for another still, and so on. Consider for example this expression:</p>
<p><span class="math display">\[
\mathrm{P}(Y_{5}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{5}  \nonscript\:\vert\nonscript\:\mathopen{} X_{5}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{5}  \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{4}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{4}  \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{3}  \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{3}  \mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{2}  \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}  \mathbin{\mkern-0.5mu,\mkern-0.5mu}W_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}w_{1}  \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I})
\]</span></p>
<p>This agent, having background information <span style="display:inline-block;"><span class="math inline">\(\mathsfit{I}\)</span>,</span> is calculating its belief that the predictand <span style="display:inline-block;"><span class="math inline">\(Y\)</span></span> has value <span style="display:inline-block;"><span class="math inline">\(y_{5}\)</span></span> for unit #5. It knows the predictor <span style="display:inline-block;"><span class="math inline">\(X\)</span></span> for this unit. The agent also knows the variate <span style="display:inline-block;"><span class="math inline">\(Y\)</span>,</span> but not <span style="display:inline-block;"><span class="math inline">\(X\)</span>,</span> for unit #4; it knows both <span style="display:inline-block;"><span class="math inline">\(Y\)</span></span> and <span style="display:inline-block;"><span class="math inline">\(X\)</span></span> for unit #3; it knows only <span style="display:inline-block;"><span class="math inline">\(X\)</span></span> for unit #2; finally it knows <span style="display:inline-block;"><span class="math inline">\(Y\)</span></span> and <span style="display:inline-block;"><span class="math inline">\(W\)</span></span> for unit #1. This task might have additional variates, whose values are unknown to the agent for all units so far – but which may come into play for future units.</p>
<p>In fact, if any of these variate is composite, say <span style="display:inline-block;"><span class="math inline">\(Y = (A,B)\)</span>,</span> the agent may have information only about component variate <span style="display:inline-block;"><span class="math inline">\(A\)</span></span> rather than for all <span style="display:inline-block;"><span class="math inline">\(Y\)</span>.</span> As already remarked, the number of possibilities is endless.</p>
</section>
</section>
<section id="sec-example-inference-categories" class="level2 page-columns page-full" data-number="24.3">
<h2 data-number="24.3" class="anchored" data-anchor-id="sec-example-inference-categories"><span class="header-section-number">24.3</span> Examples of inference tasks</h2>
<p>Let’s have an overview of some common inference tasks</p>
<section id="new-unit-given-vs-generated" class="level3">
<h3 class="anchored" data-anchor-id="new-unit-given-vs-generated">New unit: given vs generated</h3>
<p>A first important distinction can be made between</p>
<ul>
<li><p><span class="green">Tasks where an agent is given a new unit, of which it must <em>guess</em> some or all variates.</span></p></li>
<li><p><span class="green">Tasks where an agent must <em>generate</em> a new unit, with all its variates.</span></p></li>
</ul>
<p>Examples of the first type of task are <em>image generation</em> and <em>word generation</em>, which Large Language Models do. An algorithm is given a collection of images or a corpus of texts, and is asked to generate a new image or text based on, or “inspired” by, them.</p>
<p>It’s very important to keep in mind that despite the use of the words “generate” and “guess”, both tasks above require the computation of probabilities; that is, the agent must assess its beliefs. They are both <em>inference</em> tasks. In generation, the agent needs to assess what’s best to generate; in guessing, it needs to assess the possible guesses.</p>
<p>Indeed we shall see that these two types of task are actually quite close to each other from the point of view of Decision Theory &amp; Probability Theory.</p>
<div class="small midgrey">
<p>In machine learning, the terms “generative” and “discriminative” are sometimes associated with the two types of task above.</p>
</div>
</section>
<section id="guessing-variates-all-or-some" class="level3">
<h3 class="anchored" data-anchor-id="guessing-variates-all-or-some">Guessing variates: all or some</h3>
<p>Focusing on the second type of task above – the agent must make guesses about a unit given to it – we can further divide it into two subtypes:</p>
<ul>
<li><span class="green">The agent must guess <em>all</em> variates of the new unit</span>:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{\small population variates: }\ Y
\\[1ex]
&amp;\mathrm{P}(Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1} \nonscript\:\vert\nonscript\:\mathopen{} \dotso)
\end{aligned}
\]</span></p>
<ul>
<li><span class="green">The agent must guess <em>some</em> variates of the new unit, but can observe all others</span>:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{\small population variates: }\ Y, X
\\[1ex]
&amp;\mathrm{P}(Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1} \nonscript\:\vert\nonscript\:\mathopen{} X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotso)
\end{aligned}
\]</span></p>
<p>An example of the first subtype of task is the “urgent vs non-urgent” problem of <a href="conditional_probability.html#sec-conditional-joint-sim" class="quarto-xref">§&nbsp;<span>17.4</span></a>: having observed incoming patients, some of which where urgent and some non-urgent, the agent must guess whether the next incoming patient will be urgent or not. No other kinds of information (transport, patient characteristics, or others) are available.</p>
<div class="small midgrey">
<p>In machine learning, the terms “unsupervised learning” and “supervised learning” are sometimes associated with these two subtypes of task. But the association is loose. “Clustering” tasks for example, discussed below, are usually called “unsupervised” but they are examples of the second subtype above, where the agent has some predictors.</p>
</div>
</section>
<section id="information-available-in-previous-units" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="information-available-in-previous-units">Information available in previous units</h3>
<p>Finally we can further divide the second subtype above into two or three subsubtypes, depending on the information available to the agent about <em>previous units</em>:</p>
<ul>
<li><span class="green">Predictor and predictand are known for all previous units <span class="math inline">\(N,\dotsc,1\)</span></span>:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{\small population variates: }\ Y, X
\\[1ex]
&amp;\mathrm{P}(Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1} \nonscript\:\vert\nonscript\:\mathopen{} X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{N} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N} \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotso
Y_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I})
\end{aligned}
\]</span><br>
</p>
<ul>
<li><span class="green">The predictor variate, but not the predictand one, is known for all previous units <span class="math inline">\(N,\dotsc,1\)</span></span>:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{\small population variates: }\ Y, X
\\[1ex]
&amp;\mathrm{P}(Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1} \nonscript\:\vert\nonscript\:\mathopen{} X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotso
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I})
\end{aligned}
\]</span><br>
</p>
<ul>
<li><span class="green">The predictand variate, but not the predictor one, is known for all previous units <span class="math inline">\(N,\dotsc,1\)</span></span>:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{\small population variates: }\ Y, X
\\[1ex]
&amp;\mathrm{P}(Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1} \nonscript\:\vert\nonscript\:\mathopen{} X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotso
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I})
\end{aligned}
\]</span><br>
</p>
<p>An example of the first subsubtype of task above is image classification. The agent is for example given the following 128 × 128-pixel images (predictor) and character-labels (predictand) from the <a href="https://onepunchman.fandom.com">One Punch Man</a> series:</p>
<p><img src="saitama_images.png" class="img-fluid" style="width:100.0%"></p>
<p>and is then given one new 128 × 128-pixel image:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="saitama_new.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="128"></p>
</figure>
</div>
<p>of which it must guess the character-label.</p>
<p>A pictorial representation of the probability notation for this case could be as follows:</p>
<p><img src="saitama_example2.png" class="img-fluid" style="width:100.0%"></p>
<p>where <span style="display:inline-block;"><span class="math inline">\({\color[RGB]{238,102,119}y} \in \set{\color[RGB]{238,102,119}{\small\verb;Saitama;}, {\small\verb;Fubuki;}, {\small\verb;Genos;}, {\small\verb;MetalBat;}, \dotsc \color[RGB]{0,0,0}}\)</span>.</span></p>
<p><br>
</p>
<p>An example similar to the second subtype is <em>clustering</em>. The agent is for example given the following set of points in <span style="display:inline-block;"><span class="math inline">\((\alpha, \beta)\)</span></span> coordinates:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="clusters_nolabels.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%"></p>
</figure>
</div>
<p>Each point is a unit, and the predictor variate is the pair of coordinates <span style="display:inline-block;"><span class="math inline">\((\alpha, \beta)\)</span>.</span></p>
<p>The agent must now guess the <em>label</em> of each point: this is the predictand. One possible guess could be the following:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="clusters_labels.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%"></p>
</figure>
</div>
<p>This kind of inference can be expressed as follows:</p>
<div class="column-page-inset-right">
<p><span class="math display">\[
\begin{aligned}
&amp;\text{\small population variates: }\ \mathit{label}, \alpha, \beta
\\[1ex]
&amp;\mathrm{P}(
\mathit{label}_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso
\,\mathbin{\mkern-0.5mu,\mkern-0.5mu}\, \dotso \,\mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
\mathit{label}_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso
\nonscript\:\vert\nonscript\:\mathopen{}
\alpha_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \,\mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
\beta_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso
\,\mathbin{\mkern-0.5mu,\mkern-0.5mu}\, \dotso \,\mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
\alpha_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \,\mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
\beta_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso
\,\mathbin{\mkern-0.5mu,\mkern-0.5mu}\, \mathsfit{I})
\end{aligned}
\]</span></p>
</div>
<div class="small midgrey">
<p>In machine learning, the term “supervised learning” typically refer to the first subsubtype above.</p>
<p>The term “unsupervised learning” can refer to the second subsubtype.</p>
<p>The third subsubtype is very rarely considered in machine learning, yet it is not an unrealistic task.</p>
</div>
<p><br>
</p>
<p>The types, subtypes, subsubtypes described above are obviously not mutually exclusive or comprehensive. Consider for instance the following task, which doesn’t fit into any of the types discussed above. The agent must guess the predictand <span style="display:inline-block;"><span class="math inline">\(Y\)</span></span> for the new unit #3, observing that its predictor <span style="display:inline-block;"><span class="math inline">\(X\)</span></span> has value <span style="display:inline-block;"><span class="math inline">\(x_3\)</span>.</span> Of two previous units, the agent knows the predictor value <span style="display:inline-block;"><span class="math inline">\(x_1\)</span></span> of the first, and the predictand value <span style="display:inline-block;"><span class="math inline">\(y_2\)</span></span> of the second. This task is expressed by</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{\small population variates: }\ Y, X
\\[1ex]
&amp;\mathrm{P}(Y_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_3
\nonscript\:\vert\nonscript\:\mathopen{}
X_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_3
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
Y_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{2}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\end{aligned}
\]</span></p>
<div class="small midgrey">
<p>In machine learning, hybrid situations like these are categorized as “missing data” or “imputation”.</p>
</div>
<div class="column-page-inset-right">
<div id="cau-unique1" class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise&nbsp;24.1
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Find an example, invented or realistic, for the last type of task discussed above:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{\small population variates: }\ Y, X
\\[1ex]
&amp;\mathrm{P}(Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1} \nonscript\:\vert\nonscript\:\mathopen{} X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotso
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I})
\end{aligned}
\]</span></p></li>
<li><p>What kind of task does the following probability express? what kind of peculiarities does it have?</p>
<p><span class="math display">\[
\mathrm{P}(
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1}
\nonscript\:\vert\nonscript\:\mathopen{}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1} \,\mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
W_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}w_{N} \,\mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
W_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}w_{1} \,\mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
\mathsfit{I})
\]</span></p></li>
</ul>
</div>
</div>
</div>
</section>
</section>
<section id="sec-underlying-distribution" class="level2 page-columns page-full" data-number="24.4">
<h2 data-number="24.4" class="anchored" data-anchor-id="sec-underlying-distribution"><span class="header-section-number">24.4</span> The underlying distribution</h2>
<p>From the discussion and all examples above we can draw the following conclusion:</p>
<div class="callout callout-style-default callout-note no-icon callout-titled" style="font-size:120%">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
&nbsp;
</div>
</div>
<div class="callout-body-container callout-body">
<div style="font-size:120%">
<p>Probability distribution such as those discussed above intrinsically enter all types of inference algorithms, including machine-learning algorithms.</p>
</div>
</div>
</div>
<p>This is the condition for any inference algorithm to be optimal and self-consistent. The less an algorithm satisfies that condition, the less optimal and the less consistent it is.</p>
<p>A remarkable feature of all the probabilities discussed in the above task categorization is that they can all be calculated from <em>one</em> and the same probability distribution. We briefly discussed and used this feature in <a href="conditional_probability.html" class="quarto-xref">chapter&nbsp;&nbsp;<span>17</span></a>.</p>
<p>A conditional probability such as <span style="display:inline-block;"><span class="math inline">\(\mathrm{P}(\mathsfit{\color[RGB]{238,102,119}A}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{\color[RGB]{34,136,51}B} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\)</span></span> can always be written, by the <code>and</code>-rule, as the ratio of two probabilities:</p>
<p><span class="math display">\[
\mathrm{P}(\mathsfit{\color[RGB]{238,102,119}A}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{\color[RGB]{34,136,51}B} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
=
\frac{
\mathrm{P}(\mathsfit{\color[RGB]{238,102,119}A}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}B} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\mathrm{P}(\mathsfit{\color[RGB]{34,136,51}B} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\]</span></p>
<p>Therefore we have, for the probabilities of some of the tasks above,</p>
<div class="column-page-inset-right">
<p><span class="math display">\[
\begin{aligned}
&amp;\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&amp;\qquad{}=
\frac{
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\mathrm{P}(
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\\[2em]
&amp;\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&amp;\qquad{}=
\frac{
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\mathrm{P}(
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\end{aligned}
\]</span></p>
</div>
<p><br>
</p>
<p>We also know the marginalization rule (<a href="marginal_probability.html#sec-marginal-probs" class="quarto-xref">chapter&nbsp;&nbsp;<span>16.1</span></a>): any quantity <span style="display:inline-block;"><span class="math inline">\(\color[RGB]{204,187,68}C\)</span></span> with values <span style="display:inline-block;"><span class="math inline">\(\color[RGB]{204,187,68}c\)</span></span> can be introduced into the proposal of a probability via the <code>or</code>-rule:</p>
<p><span class="math display">\[
\mathrm{P}( {\color[RGB]{34,136,51}\boldsymbol{\dotsb}} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) =
\sum_{\color[RGB]{204,187,68}c}\mathrm{P}({\color[RGB]{204,187,68}C\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}c} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}\boldsymbol{\dotsb}} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]</span></p>
<p>Using the marginalization rule we find these final expressions of the probabilities for some of the tasks discussed so far:</p>
<div class="column-page-right">
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
&nbsp;
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>All previous predictors and predictands known:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp;\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&amp;\qquad{}=
\frac{
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\sum_{\color[RGB]{170,51,119}y}
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}y}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\end{aligned}
\]</span></p>
<p><br>
</p>
<ul>
<li>Previous predictors known, previous predictands unknown:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp;\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&amp;\quad{}=
\frac{
\sum_{\color[RGB]{204,187,68}y_{N}, \dotsc, y_{1}}
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\color[RGB]{0,0,0}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
\color[RGB]{204,187,68}
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{204,187,68}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\sum_{{\color[RGB]{170,51,119}y}, \color[RGB]{204,187,68}y_{N}, \dotsc, y_{1}}
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}y}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\color[RGB]{0,0,0}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
\color[RGB]{204,187,68}
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{204,187,68}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\end{aligned}
\]</span></p>
</div>
</div>
</div>
<p><strong>All these formulae, even for hybrid tasks, involve sums and ratios of only one distribution:</strong></p>
<p><span class="math display">\[\boldsymbol{
\mathrm{P}(
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\]</span></p>
<p>Stop for a moment and think about the consequences:</p>
<ul>
<li><p><span class="blue"><i class="fa-solid fa-arrows-spin" aria-label="arrows-spin"></i>&nbsp;&nbsp;<em>An agent that can perform one of the tasks above can, in principle, also perform all other tasks.</em></span></p>
<p>This is why a perfect agent, working with probability, in principle does not have to worry about “supervised”, “unsupervised”, “missing data”, “imputation”, and similar situations. This also shows that all these task typologies are much closer to one another than it might look like from the perspective of current machine-learning methods.</p></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<p>The acronym <span class="green"><em>OPM</em></span> <img src="opm_fist2.png" style="height:2em"> can stand for <span class="green"><em>Optimal Predictor Machine</em></span> or <span class="green"><em>Omni-Predictor Machine</em></span></p>
</div></div><ul>
<li><p><span class="blue"><i class="fa-solid fa-microchip" aria-label="microchip"></i>&nbsp;&nbsp;<em>The probability distribution above encodes the agent’s background knowledge and assumptions; different agents differ only in the values of that distribution.</em></span></p>
<p>If two agents yield different probability values in the same task, with the same variates and same training data, the difference must come from the joint probability distribution above. And, since the data given to the two agents are exactly the same, the difference must lie in the agents’ background <span class="m">information <span class="math inline">\(\mathsfit{I}\)</span>.</span></p></li>
<li><p><span class="blue"><i class="fa-solid fa-comment-slash" aria-label="comment-slash"></i>&nbsp;&nbsp;<em>Data cannot “speak for themselves”</em></span></p>
<p>Given some data, we can choose two different joint distributions for these data, and therefore get different results in our inferences and tasks. This means that the data alone cannot determine the result: specific background information and assumptions, whether acknowledged or not, always affect the result.</p></li>
</ul>
<p>The qualification “in principle” in the first consequence is important. Some of the sums that enter the formulae above are computationally extremely expensive and, with current technologies and maths techniques, cannot be performed within a reasonable time. But <em>new technologies and new maths discoveries could make these calculations possible</em>. This is why a data engineer cannot simply brush them aside and forget them.</p>
<p>As regards the third consequence, we shall see that there are different states of knowledge which can converge to the same results, as the number of training data increases.</p>
<div id="cau-unique2" class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise&nbsp;24.2
</div>
</div>
<div class="callout-body-container callout-body">
<p>In a previous example of “hybrid” task we had the probability distribution</p>
<p><span class="math display">\[
\mathrm{P}(
Y_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\nonscript\:\vert\nonscript\:\mathopen{}
X_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
Y_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{2}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]</span></p>
<p>Rewrite it in terms of the underlying joint distribution.</p>
</div>
</div>
</section>
<section id="plan-for-the-next-few-chapters" class="level2 page-columns page-full" data-number="24.5">
<h2 data-number="24.5" class="anchored" data-anchor-id="plan-for-the-next-few-chapters"><span class="header-section-number">24.5</span> Plan for the next few chapters</h2>
<p>Our goal in building an “Optimal Predictor Machine” is now clear: we must find a way to</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="optimal_predictor_machine.png" class="img-fluid" style="width:100.0%"></p>
</div></div><ul>
<li><p><em>assign</em> the joint probability distribution above, in such a way that it reflects some reasonable background information</p></li>
<li><p><em>encode</em> the distribution in a computationally useful way</p></li>
</ul>
<p>The “encode” goal sounds quite challenging, because the number <span style="display:inline-block;"><span class="math inline">\(N\)</span></span> of units can in principle be infinite; we have an infinite probability distribution.</p>
<p>In the next <span class="green">Inference&nbsp;III</span> part we shall see that partially solving the “assign” goal actually makes the “encode” goal feasible.</p>
<p><br>
One question arises if we now look at present-day machine-learning algorithms. Many popular machine-learning algorithms don’t give us probabilities about values. They return <em>one</em> definite value. How do we reconcile this with the probabilistic point of view above? We shall answer this question in full in the last chapters; but a short, intuitive answer can already be given now.</p>
<p>If there are several possible correct answers to a given guess, but a machine-learning algorithm gives us only one answer, then the algorithm must have internally <em>chosen</em> one of them. In other words, the machine-learning algorithm is internally doing decision-making. We know from chapters&nbsp;<a href="framework.html" class="quarto-xref"><span>2</span></a> and&nbsp;<a href="basic_decisions.html" class="quarto-xref"><span>3</span></a> that this process should obey Decision Theory and therefore <em>must</em> involve:</p>
<ul>
<li><p><span class="green"><i class="fa-solid fa-scale-unbalanced-flip" aria-label="scale-unbalanced-flip"></i>&nbsp;&nbsp;the probabilities of the possible correct answers</span></p></li>
<li><p><span class="blue"><i class="fa-solid fa-sack-dollar" aria-label="sack-dollar"></i>&nbsp;&nbsp;the utilities of the possible answer choices</span></p></li>
</ul>
<p>Non-probabilistic machine-learning algorithms must therefore be approximations of an Optimal Predictor Machine that, after computing probabilities, selects one particular answer by using utilities.</p>


</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./samples.html" class="pagination-link" aria-label="[Infinite populations and samples]{.yellow}">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title"><span class="yellow">Infinite populations and samples</span></span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./exchangeable_probabilities.html" class="pagination-link" aria-label="[Exchangeable beliefs]{.green}">
        <span class="nav-page-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title"><span class="green">Exchangeable beliefs</span></span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>