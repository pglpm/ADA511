{{< include macros.qmd >}}

*If you can't join 'em,\
beat 'em.*\
[([J. Schwinger](https://www.nobelprize.org/prizes/physics/1965/schwinger/biographical/))]{style="text-align:right;font-size:75%"} 


# Dear student<br> and aspiring data engineer {.unnumbered}

The goal of this course is not to help you learn how to tune the parameters of the latest kind of deep network, or how to efficiently handle large amounts of data, or how to do cross-validation in the fastest way, or what is the latest improvement in random-forest algorithms.

The goal of this course is to help you learn the principles to build the machine-learning algorithms and AI devices *of the future*. And, as a side effect, you'll also learn how to concretely improve present-day algorithms, and also how to determine if any of them has already reached its theoretical maximum.

How can such a goal be achieved?

There is a small set of rules and one method that are *mathematically guaranteed* to output the optimal solution of any inference, prediction, classification, regression, and decision problem. You can think of this as the "unbeatable universal machine". Or, from an AI point of view, you can think of these rules and method as the "laws of robotics" that should govern any ideal AI designed to draw inferences and make decisions.

:::{.column-margin}
[$$
\begin{aligned}
&\blue\P(\lnot\se{Y}\|\se{X}) = 1 - \P(\se{Y}\|\se{X})
\\[0.5ex]
&\blue\P(\se{Z}\land\se{Y}\|\se{X}) = 
\P(\se{Z} \|\se{Y}\land\se{X})\cdot \P(\se{Y}\| \se{X})
\\[0.5ex]
&\blue\P(\se{Z}\lor\se{Y}\|\se{X}) = 
\P(\se{Z} \|\se{X}) + \P(\se{Y} \|\se{X}) - \P(\se{Z}\land\se{Y}\|\se{X})
\\[1ex]
&\green\texttt{\small choose }\ \argmax_{\se{D}}\ \mathrm{U}(\se{D} \| \se{Y}\land \se{X})\cdot \P(\se{Y} \| \se{D} \land\se{X})
\end{aligned}
$$]{style="font-size:60%;"}
:::

These rules and method are quite easy to grasp and understand, but are computationally extremely expensive; the more so, the more data points and data dimensions we need to deal with. Current machine-learning algorithms, from deep networks to large language models (chatGPT), are *approximations* to this ideal universal method; each one uses a different kind of approximation. The upside of these approximations is that they allow for much faster computations; their downside is that they generally give *sub-optimal* results.^[Is a suboptimality of, say, just 0.1% important? In a life-or-death situation for 1 000 000 people, 0.1% means 1000 more deaths.]

Approximations evolve toward the maximally optimal ideal method. The approximations used at any given time in history exploit the computational technologies then available. Deep networks, for instance, would have been a  useless approximation 50 years ago, before the introduction of Graphical Processing Units.

Every new technological advance (think of possibly forthcoming quantum computers) opens up possibilities for new approximations that get us closer to the ideal optimum. To *see* and *realize* these possibilities, or to judge whether they have already been realized, a data scientist needs at the very least:

[- {{< fa sort-numeric-up >}}\ \ to be familiar with the maximally optimal method]{.blue}

[- {{< fa box-open >}}\ \ to think outside the box]{.green}

Without the [first requirement]{.blue}, how do you know what is *the target* to approximate towards, and how far you are from it? You risk:\
[{{< fa exclamation-triangle >}}]{.red} making an approximation that leads to worse results than before;\
[{{< fa exclamation-triangle >}}]{.red} evaluating the approximation in the wrong way, so you don't even realize it's worse than before;\
[{{< fa exclamation-triangle >}}]{.red} trying to improve an approximation that has already attained the theoretical maximum. Think about an engine that has already the maximal efficiency dictated by thermodynamics; but an engineer, ignorant of thermodynamics, wastes effort in trying to improve it further.

Without the [second requirement]{.green}, you risk missing to take full advantage of the new technological possibilities. Consider the evolution of transportation: if you keep thinking in terms of how to improve a horse's hoofs, you'll never conceive a combustion engine; if you keep thinking in terms of how to improve combustion fuel, you'll never conceive an electric motor. Existing approximations may of course be good starting points; but you need to clearly understand how they approximate the ideal optimum -- so we're back to the first requirement.

If you want to make advances in machine learning and AI, you must know how the ideal universal algorithm looks like, and you must not limit yourself to thinking of "training sets", "cross-validation", "supervised learning", "overfitting", "models", and similar notions. In this course you'll see for yourself that such notions are anchored to the present-day box of approximations.

And we want to think outside that box.

But don't worry: this course does not only want to prepare you for the future. With the knowledge and insights acquired, you will be able to *propose and implement concrete improvements* to present-day methods as well, or calculate whether they can't be improved further.

## Your role in the course <br>Bugs & features

This course is still in an experimental, "alpha" version. So you will not only learn something from it (hopefully), but also test it together with us, and help improving it for future students. Thank you for this in advance!

For this reason it's good to clarify some goals and guidelines of this course: <!-- Some aspects that you might consider *bugs* are actually *features*: -->

[{{< fa square-root-alt >}}\ \ Light maths requirements]{.green}
: We believe that the fundamental rules and methods can be understood and also used (at least in not too complex applications) without complex mathematics. Indeed the basic laws of inference and decision-making involve only the four basic operations [$+ - \times /$]{.green}. So this course only requires maths at a beginning first-year undergraduate level.
\
\

[{{< fa coffee >}}\ \ Informal style]{.green}
: The course notes are written in an informal style; for example they are not developed along "definitions", "lemmata", "theorems". This does not mean that they are inexact. We will warn you about parts that are oversimplified or that only cover special contexts.\
    <!-- [*Scientific standards are terrible -- one should never joke. To be taken seriously, put people to sleep! In a paper, there should be no funny drawings, it would be a waste of paper. However, full pages of repetitive definitions, of Prussian formalism, are not considered a waste.*\ \ \ ([J.-Y. Girard](https://hvl.instructure.com/courses/25074/modules/items/679116))]{.small .midgrey} -->
\

[{{< fa language >}}\ \ Names don't constitute knowledge]{.green}
:   :::{.column-margin}
    {{< video https://www.youtube.com/watch?v=lFIYKmos3-s >}}
    <!-- {{< video https://vimeo.com/852936507?share=copy >}} -->
    :::
    In these course notes you'll often stumble upon [**terms in blue bold**]{.blue} and [*definitions in blue Italics*]{.blue}. This typographic emphasis does [***not***]{.red} mean that those terms and definitions should be [***memorized***]{.red}: rather, it means that there are important [***ideas***]{.green} around there which you must try to [***understand***]{.green} and [***use***]{.green}. In fact we don't care which terminology you adopt. Instead of the term [**statistical population**]{.blue}, feel free to use the term [**pink apple**]{.blue} if you like, as long you explain the terms you use by means of a discussion and examples.^[Some standard technical terms are no better. The common term *random variable*, for instance, often denotes something that is actually *not "random"* and *not variable*. Go figure. Using the term *green banana* would be less misleading!] What's important is that you know, can recognize, and can correctly use the ideas behind technical terms.
\
    [Memorizing terms, definitions, and where to use them, is how large language models (like chatGPT) operate. If your study is just memorization of terms, you'll have difficulties finding jobs in the future, because there will be algorithms that can do that better and at a cheaper cost than you.]{.small .midgrey}
\

[{{< fa book >}}\ \ Diverse textbooks]{.green}
: This course does not have only one textbook: it refers to and merges together parts from several books and articles. You will notice that most of these works adopt quite different terminologies, employ different symbolic notations, and give different definitions for similar ideas.\
[*These differences and contrasts are a feature, not a bug!*]{.yellow}\
You might think that this makes studying more difficult; but it actually helps you to really understand an idea and acquire real knowledge, because it forces you to go *beyond* words, symbols, and specific points of view and examples. This point connects with the previous point, "names don't constitute knowledge". The present course notes will help you build comprehension bridges across those books.
\
\

[{{< fa robot >}}\ \ Artificial intelligence]{.green}
: In order to grasp and use the fundamental laws of inference and decision-making, we shall use notions that are also at the foundations of Artificial Intelligence (and less common in present-day machine learning). So you'll also get a light introduction to AI for free. Indeed, a textbook that we'll draw frequently from is Russell & Norvig's *Artificial Intelligence: A Modern Approach* (we'll avoid part V on machine learning, which is really poorly explained and written).

    :::{.column-margin}
    ![](AI_a_modern_approach.jpg){width=60%}
    :::


[{{< fa wrench >}}\ \ Concrete examples]{.green}
: Some students find it easier to grasp an idea by starting from an abstract description and then examining concrete examples; some find it easier the other way around. We try to make both happy by alternating between the two approaches. Ideas and notions are always accompanied by examples that we try to keep simple yet realistic, drawing from scenarios ranging from glass forensics to hotel booking.
\
\

[{{< fa code >}}\ \ Code]{.green}
: We shall perform inferences on concrete datasets, also comparing different methodologies. Most of these can be performed with any specific programming language, so you can use your favourite one -- remember that we want to try to think outside the box of present-day technologies, and that includes present-day programming languages. Most examples in class and in exercises will be given in [`R`](https://www.r-project.org/) and [`Python`](https://www.python.org/), but are easily translated into other languages.
\
\

[{{< fa rocket >}}\ \ Extra material]{.green}
: The course has strong connections with many other disciplines, such as [formal logic]{.yellow}, [proof theory]{.yellow}, [psychology]{.yellow}, [philosophy]{.yellow}, [physics]{.yellow}, and [environmental sciences]{.yellow}. We have tried to provide a lot of extra reading material in "For the extra curious" side boxes, for those who want to deepen their understanding of topics covered or just connected to the present course. Maybe you'll stumble into a new passion or even into your life call?

    ::::{.column-margin}
    ::: {.callout-tip}
    ## {{< fa rocket >}} For the extra curious
    :::
    ::::



## Course structure

The course structure reflects the way in which the ideal universal decision-making machine works. It can be roughly divided into three or four parts, illustrated as follows (this is just a caricature, don't take this diagram too literally):

```{mermaid}
flowchart TB
  P{{probability}} --o Z[/max expected utility\]
  subgraph probability [ ]
  S([sentences]) --> P
  end
  subgraph data [ ]
  A[quantity] --o S
%%  D[value] --o S
  E[population] --o S
  F[...] -.-o S
  end
  G[(problem)] --x A & E %% & D
  G -.-x F
  U{{utility}} --o Z
  subgraph utility [ ]
  C[decisions] --o S
  S --> U
  T([gains]) --> U
  Q([costs]) --> U
  end
  G --x C & T & Q
  subgraph exp [ ]
  Z --> W(optimal solution)
  end
  %%
  style G fill:#e67
  style A fill:#cb4,stroke-width:0pt
%%  style D fill:#cb4,stroke-width:0pt
  style E fill:#cb4,stroke-width:0pt
  style F fill:#cb4,stroke-width:0pt
  style S fill:#283,color:#fff
  style P fill:#283,stroke-width:3pt,color:#fff
  style C fill:#6ce,stroke-width:0pt
  style T fill:#6ce,stroke-width:0pt
  style Q fill:#6ce,stroke-width:0pt
  style U fill:#6ce,stroke-width:3pt
  style Z fill:#47a,color:#fff,stroke-width:0pt,color:#fff
  style W fill:#47a,color:#fff,stroke-width:0pt,color:#fff
  style probability fill:#fff,stroke:#283,stroke-width:1px
  style data fill:#fff,stroke:#cb4,stroke-width:1px
  style utility fill:#fff,stroke:#6ce,stroke-width:1px
  style exp fill:#fff,stroke:#47a,stroke-width:1px
```

- [**Inference**]{.green} parts develop the "inference engine" of the machine. Here you will learn ideas at the foundation of AI; and you will also meet probability, but from a point of view that may be quite novel to you -- and much more fun.

- [**Data**]{.yellow} parts develop the language in which a [**problem**]{.red} can be fed into the inference engine. Here you will also learn about important pitfalls in handling data.

These two parts will alternate so that their development proceeds almost in parallel.

- The [**utility**]{.lightblue} part develops the "decision engine" of the machine. Here you will meet several ideas that will probably be quite new to you -- but also very simple and intuitive.

- The final [**solution**]{.blue} part simply shows how the inference and utility engines combine together to yield the optimal solution to the problem. This part is simple, short, intuitive; it will be a breeze.

\

As soon as the [inference]{.green} and [data]{.yellow} parts are complete, you will be able to apply the machine to real inference problems, and also learn how the solution is approximated in some popular machine-learning algorithms.

These applications will immediately extend to decision problems as the short [utility]{.lightblue} and [solution]{.blue} part are covered. Again you will also see how this solution is approximated in other machine-learning algorithms, classification and regression ones.
