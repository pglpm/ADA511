% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod,
  oneside]{scrreprt}
\usepackage{xcolor}
\usepackage[left=1in,marginparwidth=2.0666666666667in,textwidth=4.1333333333333in,marginparsep=0.3in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{2}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{multirow}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\usepackage{mathtools}
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{sidenotes}{}{\usepackage{sidenotes}}
\@ifpackageloaded{marginnote}{}{\usepackage{marginnote}}
\makeatother
\makeatletter
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={ADA511 0.3  Data Science and AI prototyping},
  pdfauthor={P.G.L. Porta Mana ORCID ; S. Mæland ORCID},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{ADA511 {0.3} Data Science and AI prototyping}
\author{P.G.L. Porta Mana
\href{https://orcid.org/0000-0002-6070-0784}{\includegraphics[width=1em,height=\textheight,keepaspectratio]{orcid_32x32.png}}
\href{https://portamana.org/}{\faIcon{home}} \and S. Mæland
\href{https://orcid.org/0000-0002-4652-4753}{\includegraphics[width=1em,height=\textheight,keepaspectratio]{orcid_32x32.png}}}
\date{2025-08-21}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{\texorpdfstring{Dear student and aspiring data- \&
AI-engineer}{Dear student  and aspiring data- \& AI-engineer}}\label{dear-student-and-aspiring-data--ai-engineer}
\addcontentsline{toc}{chapter}{Dear student and aspiring data- \&
AI-engineer}

\markboth{Dear student and aspiring data- \& AI-engineer}{Dear student
and aspiring data- \& AI-engineer}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}

\DeclarePairedDelimiter{\set}{\{}{\}}
\providecommand{\argmax}{\operatorname{argmax}}

\emph{If you can't join 'em,\\
beat 'em.}\\
{(\href{https://www.nobelprize.org/prizes/physics/1965/schwinger/biographical/}{J.
Schwinger})}

The goal of this course is not to help you learn how to tune the
parameters of the latest kind of deep network, or how to choose a good
prompt for a Large Language Model, or how to do cross-validation in the
fastest way, or what is the latest improvement in random-forest
algorithms.

The goal of this course is to help you learn the principles to build the
machine-learning algorithms and AI devices \emph{of the future}. And, as
a side effect, you'll also learn how to concretely improve present-day
algorithms, and also how to determine if any of them has already reached
its maximal theoretical performance.

How can such a goal be achieved?

There is a small set of rules and one method that are
\emph{mathematically guaranteed} to output the optimal solution of any
inference, prediction, classification, and decision-making problem. You
can think of this set as defining an ``unbeatable, optimal universal
machine''. Or, from an AI point of view, you can think of these rules
and method as the ``laws of robotics'' that should govern any ideal AI
designed to draw inferences, give answers, and make decisions.

\marginnote{\begin{footnotesize}

{\[
\begin{aligned}
&\color[RGB]{68,119,170}\mathrm{P}(\lnot\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X}) = 1 - \mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X})
\\[0.5ex]
&\color[RGB]{68,119,170}\mathrm{P}(\mathsfit{Z}\land\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X}) = 
\mathrm{P}(\mathsfit{Z} \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Y}\land\mathsfit{X})\cdot \mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X})
\\[0.5ex]
&\color[RGB]{68,119,170}\mathrm{P}(\mathsfit{Z}\lor\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X}) = 
\mathrm{P}(\mathsfit{Z} \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X}) + \mathrm{P}(\mathsfit{Y} \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X}) - \mathrm{P}(\mathsfit{Z}\land\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X})
\\[0.5ex]
&\color[RGB]{68,119,170}\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X} \land \mathsfit{Z}) = 1 
\\[1ex]
&\color[RGB]{34,136,51}\texttt{\small choose }\ \operatorname{argmax}_{\mathsfit{D}}\ \sum_{\mathsfit{Y}}\mathrm{U}(\mathsfit{Y} \land \mathsfit{D}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X})\cdot \mathrm{P}(\mathsfit{Y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{D} \land\mathsfit{X})
\end{aligned}
\]}

\end{footnotesize}}

These rules and method are quite easy to grasp and understand. You'll
learn them very quickly, and they'll be the solid ground on which your
data \& AI engineering knowledge and skills are built.

These rules and method are computationally extremely expensive; the more
so, the more data points and data dimensions we need to deal with.
Current machine-learning algorithms, from deep networks to large
language models, are \emph{approximations} to this ideal universal
method; each one uses a different kind of approximation. The upside of
these approximations is that they allow for much faster computations;
their downside is that they generally give \emph{sub-optimal} or
\emph{non-intelligent} results.\footnote{Is a suboptimality of, say,
  just 0.1\% important? In a life-or-death situation for 1\,000\,000
  people, 0.1\% means 1000 more deaths.}

But approximations can be improved with new technologies. The
approximations used at any given time in history exploit the
computational technologies then available. Deep networks, for instance,
would have been a useless approximation 50 years ago, before the
introduction of Graphical Processing Units.

Every new technological advance (think of possibly forthcoming quantum
computers) opens up possibilities for new approximations that get us
closer and closer to the ideal optimum. However, in order to \emph{see}
and \emph{realize} these possibilities, or to judge whether they have
already been realized, a data scientist needs at the very least:

{\faIcon{mountain}~~to know the foundation of the maximally optimal
method}

{\faIcon{box-open}~~to think outside the box}

Without the {first requirement}, how do you know what is \emph{the
target} to approximate towards, and how far you are from it? You risk:\\
{\faIcon{exclamation-triangle}} making an approximation that leads to
worse results than before;\\
{\faIcon{exclamation-triangle}} evaluating the approximation in the
wrong way, so you don't even realize it's worse than before;\\
{\faIcon{exclamation-triangle}} trying to improve an approximation that
has already attained the theoretical optimum. Think about an engine that
has already the maximal efficiency dictated by thermodynamics; and an
engineer, ignorant of thermodynamics, who wastes effort in trying to
improve it further.

Without the {second requirement}, you risk missing to take full
advantage of the new technological possibilities. Consider the evolution
of transportation: if you keep thinking in terms of how to improve a
horse-carriage wooden wheels, you'll never conceive a combustion engine.
If you keep thinking in terms of how to improve combustion fuel, you'll
never conceive an electric motor. Existing approximations may of course
be good starting points; but you need to clearly understand how they
approximate the ideal optimum -- so we're back to the first requirement.

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{ibm_quantum.jpg}
What new ways of doing data science will quantum computers lead to?

\end{footnotesize}}

If you want to make advances in machine learning and AI, you must know
how the ideal universal algorithm looks like, and you must not limit
yourself to thinking of ``training sets'', ``cross-validation'',
``supervised learning'', ``overfitting'', ``models'', and similar
notions. In this course you'll see for yourself that such notions are
anchored to the box of present-day approximations.

And we want to think outside that box.

This course will not only prepare you for the future. With the knowledge
and insights acquired, you will be able to devise and \emph{implement
concrete improvements} to present-day methods as well, or calculate
whether they can't be improved further.

\section*{\texorpdfstring{Your role in the course Bugs \&
features}{Your role in the course  Bugs \& features}}\label{your-role-in-the-course-bugs-features}
\addcontentsline{toc}{section}{Your role in the course Bugs \& features}

\markright{Your role in the course Bugs \& features}

This course is still in an experimental, ``alpha'' version. So you will
not only learn something from it (hopefully), but also test it together
with us, and help improving it for future students. Thank you for this
in advance!

For this reason it's good to clarify some goals and guidelines of this
course:

\begin{description}
\item[{\faIcon{square-root-alt}~~Undergraduate maths requirements}]
We believe that the fundamental rules and methods can be understood and
also used (at least in not too complex applications) without complex
mathematics. Indeed the basic laws of inference and decision-making
involve only the four basic operations {\(+ - \times /\)}. So this
course only requires maths at a beginning first-year undergraduate
level.\\
\strut \\
\item[{\faIcon{coffee}~~Informal style}]
The course notes are written in an informal style; for example they are
not developed along ``definitions'', ``lemmata'', ``theorems''. This
does not mean that they are inexact. We will warn you about parts that
are oversimplified or that only cover special contexts.\\
\strut \\
\item[{\faIcon{language}~~Names don't constitute knowledge}]
\marginnote{\begin{footnotesize}

\url{https://vimeo.com/852936507?share=copy}

\end{footnotesize}}

In these course notes you'll often stumble upon {\textbf{terms in blue
bold}} and {\emph{definitions in blue Italics}}. This typographic
emphasis does {\textbf{\emph{not}}} mean that those terms and
definitions should be {\textbf{\emph{memorized}}}: rather, it means that
there are important {\textbf{\emph{ideas}}} around there which you must
try to {\textbf{\emph{understand}}} and {\textbf{\emph{use}}}. In fact
we don't care which terminology you adopt. Instead of the term
{\textbf{statistical population}}, feel free to use the term
{\textbf{pink apple}} if you like, as long you explain the terms you use
by means of a discussion and examples.\footnote{Some standard technical
  terms are no better. The common term \emph{random variable}, for
  instance, often denotes something that is actually \emph{not
  ``random''} and \emph{not variable}. Go figure. Using the term
  \emph{green banana} would be less misleading!} What's important is
that you know, can recognize, and can correctly use the ideas behind
technical terms.

Memorizing terms, definitions, and where to use them, is how large
language models (like chatGPT) operate. If your study is just
memorization of terms, you'll have difficulties finding jobs in the
future, because there will be algorithms that can do that better and at
a cheaper cost than you.\\
\item[{\faIcon{book}~~Diverse textbooks}]
This course does not have only one textbook: it refers to and merges
together parts from several books and articles. As you read these works,
you will notice that they adopt quite different terminologies, employ
different symbolic notations, give different definitions for similar
ideas, and sometimes even contradict each other.\\
{\textbf{\emph{These differences and contradictions are a feature, not a
bug!}}}\\
You might think that this makes studying more difficult; but it actually
helps you to really understand an idea and acquire real knowledge,
because it forces you to go \emph{beyond} words, symbols, and specific
points of view and examples. This point connects with the previous
point, ``names don't constitute knowledge''. The present course notes
will help you build comprehension bridges across those books.\\
\strut \\
\item[{\faIcon{robot}~~Artificial intelligence}]
In order to grasp and use the fundamental laws of inference and
decision-making, we shall use notions that are also at the foundations
of Artificial Intelligence (and less common in present-day machine
learning). So you'll also get a light introduction to AI for free.
Indeed, a textbook that we'll draw frequently from is Russell \&
Norvig's
\href{https://aima.cs.berkeley.edu/global-index.html}{\emph{Artificial
Intelligence: A Modern Approach}} (we'll avoid its part~V on machine
learning, however, because it's poorly explained and written).

\marginnote{\begin{footnotesize}

\includegraphics[width=0.6\linewidth,height=\textheight,keepaspectratio]{AI_a_modern_approach.jpg}

\end{footnotesize}}
\item[{\faIcon{wrench}~~Concrete examples}]
Some students find it easier to grasp an idea by starting from an
abstract description and then examining concrete examples; some find it
easier the other way around. We try to make both happy by alternating
between the two approaches. Ideas and notions are always accompanied by
examples that we try to keep simple yet realistic, drawing from
scenarios ranging from glass forensics to hotel booking.\\
\strut \\
\item[{\faIcon{code}~~Code}]
We shall perform inferences on concrete datasets, also comparing
different methodologies. Most of these can be performed with any
specific programming language, so you can use your favourite one --
remember that we want to try to think outside the box of present-day
technologies, and that includes present-day programming languages. Most
examples in class and in exercises will be given in
\href{https://www.r-project.org/}{\texttt{R}} and sometimes in
\href{https://www.python.org/}{\texttt{Python}}, but are easily
translated into other languages.\\
\strut \\
\item[{\faIcon{rocket}~~Extra material}]
The course has strong connections with many other disciplines, such as
\textbf{formal logic}, \textbf{proof theory}, \textbf{psychology},
\textbf{philosophy}, \textbf{physics}. We have tried to provide a lot of
extra reading material in ``For the extra curious'' side boxes, for
those who want to deepen their understanding of topics covered or just
connected to the present course. Maybe you'll stumble into a new passion
or even into your life call?

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\end{tcolorbox}

\end{footnotesize}}
\end{description}

\section*{Course structure}\label{course-structure}
\addcontentsline{toc}{section}{Course structure}

\markright{Course structure}

The course structure reflects the way in which the ideal universal
decision-making machine works. It can be roughly divided into three or
four parts, illustrated as follows (this is just a caricature, don't
take this diagram too literally):

\pandocbounded{\includegraphics[keepaspectratio]{course_structure.png}}

\begin{itemize}
\item
  {\textbf{Data} parts (top-left, yellow box)} develop the language in
  which a {\textbf{problem}} can be fed into the decision-making
  machine. Here you will also learn about important pitfalls in handling
  data.
\item
  {\textbf{Inference} parts (left-centre, green box)} develop the
  ``inference engine'' of the machine. Here you will learn ideas at the
  foundation of AI; and you will also meet probability, but from a point
  of view that may be quite novel to you -- and much more fun.
\end{itemize}

These two parts will alternate so that their development proceeds almost
in parallel.

\begin{itemize}
\item
  The {\textbf{utility} part (top-right, light-blue box)} develops the
  ``decision engine'' of the machine. Here you will meet several ideas
  that will probably be quite new to you -- but also very simple and
  intuitive.
\item
  The {\textbf{solution} part (bottom, dark-blue box)} simply shows how
  the inference and utility engines combine together to yield the
  optimal solution to the problem. This part is simple, short,
  intuitive; it will be a breeze.
\end{itemize}

\hfill\break

We shall start with a quick preview of the {\textbf{solution}} part in
chapters 1--4, because it is very simple to understand, and it shows why
the \emph{inference} and the \emph{utility} parts are necessary.

Then we shall continue with the {\textbf{inference}} part in chapters
5--10 and 14--18, alternating it with the {\textbf{data}} part in
chapters 12--13 and 20--23, and with interludes about
{\textbf{present-day machine-learning algorithms}} and their
approximations in chapters 4, 11, 19, and 24--26.

As soon as the {inference} and {data} parts are complete, you will be
able to apply the machine to real, albeit not too complex, inference
problems. This {\textbf{application}} will be made in chapters 32--35.

We finally round up with the {\textbf{utility}} part in chapters 36--37,
extending our concrete {application} to it in chapter 38. Final
connections with {present-day machine learning} are made in chapters
39--40.

You should be able to see this timeline in the index tab on the side.

\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

\emph{Science is built up with facts, as a house is with stones. But a
collection of facts is no more a science than a heap of stones is a
house.}
~~~~{(\href{https://hvl.instructure.com/courses/32045/modules}{H.
Poincaré})}

\hfill\break

\section*{Mechanics and engineers}\label{mechanics-and-engineers}
\addcontentsline{toc}{section}{Mechanics and engineers}

\markright{Mechanics and engineers}

What is the difference between a \emph{car mechanic} and an
\emph{automotive engineer}?

Both have knowledge about cars, but their knowledge domains are
different and focus on different goals.

A car mechanic can keep your car in top-notch condition; can do
different kinds of easy and difficult repairs if problems arise with it;
knows whether a particular brand of valve can be used as a replacement
for another brand; can recommend the optimal kind of tyres to use in a
given season for different brands of cars. But a car mechanic would face
difficulties in calculating the theoretical maximal efficiency of an
engine; or predicting the temperature increase caused by a new kind of
fuel; or exploiting the phase transition of a new kind of foam to design
a safer airbag system; or calculating the optimal surface curvature for
a spoiler. A car mechanic typically possesses a large amount of
case-specific knowledge, and doesn't need to know in depth the
principles of electromechanics and thermochemistry, or the laws of
balance of momentum, energy, entropy.

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{car_mechanic.jpg}

\end{footnotesize}}

Vice versa, an automotive engineer can assess how to use the
electromechanical properties of a new material in order to design a more
efficient and environmentally friendly engine; can calculate how a new
material-surface handling would affect air drag and speed; and
ultimately can research how to exploit new physical phenomena to build
completely new means of transportation. Yet, an automotive engineer
could be completely incapable of changing a pipe in your car, or tell
you whether it can use a particular brand of lubricant oil. An
automotive engineer typically possesses knowledge about the principles
of electromagnetism, mechanics, or thermochemistry; is acquainted with
relevant physical laws; and doesn't need to have in-depth case-specific
kinds of knowledge.

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{auto_engineer2.jpg}
~
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{nasa_rover2.jpg}
~
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{auto_engineer3b.jpg}

\end{footnotesize}}

Note that the differences just sketched \emph{do not imply a judgement
of value}. Both professions, kinds of knowledge, and goals are
necessary, interesting, and couldn't exist without each other. Choice
between them is a subjective matter of personal passions and
aspirations.

In fact there isn't a clear divide between these two kinds of knowledge,
but rather a continuum between two vague extremities. A car mechanic can
have knowledge and insight about new technologies, and an automotive
engineer can know how to fix a carburettor. The two sketches above are
meant to expose and emphasize the existence of such a continuum of
knowledge and of goals.

\section*{Data mechanics and data
engineers}\label{data-mechanics-and-data-engineers}
\addcontentsline{toc}{section}{Data mechanics and data engineers}

\markright{Data mechanics and data engineers}

A continuum with two similar extremities can also be drawn in
{\textbf{data science}}.

Some data scientists have in-depth knowledge on, for instance, how to
optimally store and read large amounts data; what kind of
machine-learning algorithm to use in a given task; how to fine-tune an
algorithm's parameters, and the currently best software for this
purpose. Their particular knowledge is fundamental for the working of
today's technological infrastructure.

At the same time, these data scientists typically face difficulties, for
instance, in:

\begin{itemize}
\item
  calculating the theoretical maximal accuracy or performance achievable
  -- by \emph{any} possible algorithm -- in a given inference problem
\item
  explaining how the fundamental rules of inference and decision-making
  are implemented in a particular machine-learning algorithm
\item
  identifying which sub-optimal approximations to the fundamental rules
  are made by popular machine-learning algorithms
\item
  exploiting new technologies to build new algorithms that do
  calculations closer to the exact theoretical ones, thereby achieving a
  performance closer to the theoretical optimum
\end{itemize}

And it is also possible that they are not aware of, and maybe would be
surprised by, some basic facts of data science. For instance:

\begin{itemize}
\item
  there is an optimal, universal inference \& decision algorithm, of
  which all machine-learning algorithms (from support vector machines
  and deep networks to random forests and large language models), are an
  approximation
\item
  there are only five or six fundamental laws upon which any inference,
  prediction, classification, regression, decision task is (or ought to
  be) based upon
\item
  splittings of data into ``training set'', ``validation set'', and
  similar sets, are not part of the exact application of the laws of
  inference and decision-making; such splittings arise as coarse
  approximations of the exact method.
\item
  cross-validation and related techniques are not part of the exact
  method either; they also arise as approximations
\item
  overfitting, underfitting and related notions are not problems that
  appear in the exact method (which takes care of them automatically);
  they also arise from approximations
\item
  it is possible to calculate, within probable bounds, the maximal
  accuracy (or other performance metric) achievable by \emph{any}
  classification or regression algorithm for a given application
\item
  some evaluation metrics, such as precision or the area under the curve
  of the receiver operating characteristic (AUC), have intrinsic flaws
  and may attribute higher values to worse-performing algorithms
\end{itemize}

\ldots because this is a kind of general and principled knowledge that
these data scientists don't need in their jobs. Their knowledge is more
case-specific.

Drawing a parallel with the car example, a data scientist with this kind
of case-specific knowledge is like a ``data mechanic''.

A ``data engineer'', on the other hand, is the kind of data scientist
who has no difficulties with the knowledge and skills implicit in the
bullet points above; but at the same time might not know what software
to use for tuning parameters of a particular class of deep networks, or
the best format to store particular kinds of data.

Just like in the case of the automotive industry, the difference just
sketched does \emph{not} imply any judgement of value. Both kinds of
knowledge and goals are important and can't exist without each other.

\section*{Goals of this course}\label{goals-of-this-course}
\addcontentsline{toc}{section}{Goals of this course}

\markright{Goals of this course}

There is a plethora of academic courses, in all kinds of format, that
target knowledge and goals for the ``data mechanic''. Those courses are
usually inadequate to cover the knowledge and goals for the ``data
engineer''. Some courses, misleadingly, even present approximations and
recipes that are only valid for particular situations as if they were
universal rules or methods instead.

Courses that target the ``data engineer'' seem to be more rare. One
possible reason is that this kind of knowledge is actually hidden in
courses on probability, statistics, and risk analysis, presented with a
language which makes only opaque and confusing connections with fields
in data science and their goals; or, worse, with a language which
emphasizes connections that are actually superficial and misleading.

We believe that it is important to teach and keep alive the less
``mechanic'' and more ``engineer'' side of data science:

\begin{itemize}
\tightlist
\item
  Continuous advances in computational technology -- think of quantum
  computers -- will offer completely novel and superior ways to
  approximate the exact method of inference and decision. Only the data
  scientist who knows the exact method and theory, and understands how
  present-day algorithms approximate it, will be able to exploit new
  technologies.
\item
  Even without looking at the future, several present-day
  machine-learning algorithms could already be greatly optimized by any
  data engineer who is acquainted with the basic principles underlying
  data science.
\item
  The foundations of data science are the bridge to the sibling
  discipline of Artificial Intelligence.
\end{itemize}

The present course aspires to give an introduction to the ``data
engineer'' side, rather than ``data mechanic'' one, of data science, but
using a point of view more familiar to data scientists than to, say,
statisticians.

More details about its aims, structure, and features are already given
in the \href{index.html}{\emph{Dear student}} introduction.

\part{{\textbf{An invitation}}}

\chapter{\texorpdfstring{{Accept or
discard?}}{Accept or discard?}}\label{sec-intro}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

Let's start with a question that could arise in an engineering problem:

\begin{quote}
A particular kind of electronic component is produced on an assembly
line. At the end of the line there is an \emph{automated inspection
device} that works as follows on each new component:

\begin{itemize}
\item
  The inspection device first performs some tests on the component. The
  tests give an uncertain forecast of whether that component will fail
  \textbf{within its first year of use}, or \textbf{after}.
\item
  Then the device decides whether the component is \textbf{accepted} and
  packaged for sale, or \textbf{discarded} and thrown away.
\end{itemize}

Consider also the following context. When a new electronic component is
sold, the manufacturer has a net gain of 1\$. That's the net gain if the
component works \emph{for at least a year}. But if the component instead
\emph{fails within a year} of use, the manufacturer incurs a \emph{net
loss} of 11\$ (12\$ loss, minus the 1\$ gained at first), owing to
warranty refunds and damage costs to be paid to the buyer. When a new
electronic component is \emph{discarded}, the manufacturer has 0\$ net
gain.

Now we have a new electronic component, just come out of the assembly
line. The tests of the automated inspection device indicate that there
is a \textbf{10\% probability} that the component will \textbf{fail
within its first year} of use.
\end{quote}

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{accept_discard.png}

\end{footnotesize}}

{\textbf{Should the inspection device accept the new component? or
discard it?}}\\

Try to give and motivate an answer:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Very first exercise!}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  Should the inspection device accept or discard the new component?
\end{itemize}

It doesn't matter if you don't get the correct answer; not even if you
don't manage to get an answer at all. The purpose here is for you to do
some introspection about your own reasoning.

Then examine and discuss the following points:

\begin{itemize}
\item
  Which numerical elements in the problem seem to affect the answer?
\item
  Can these numerical elements be clearly separated? How would you
  separate them?
\item
  How would the answer change, if these numerical elements were changed?
  Feel free to change them, also in extreme ways, and see how the answer
  would change.
\item
  Could we solve the problem if we didn't have the probabilities? Why?
\item
  Could we solve the problem if we didn't know the various gains and
  losses? Why?
\item
  Can this problem be somehow abstracted, and then transformed into
  another one with completely different details? For instance, consider
  translating along these lines:

  \begin{itemize}
  \tightlist
  \item
    inspection device → computer pilot of self-driving car
  \item
    tests → camera image
  \item
    fail within a year → pedestrian in front of car
  \item
    accept/discard → keep on going/~break
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\chapter{\texorpdfstring{{Framework}}{Framework}}\label{sec-framework}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\section{What does the intro problem tell
us?}\label{what-does-the-intro-problem-tell-us}

Let's approach the ``accept or discard?'' problem of the previous
chapter~\ref{sec-intro} in an intuitive way.

\marginnote{\begin{footnotesize}

We're jumping the gun here, because we haven't learned the method to
solve this problem yet!

\end{footnotesize}}

First, what happens if we \texttt{accept} the component?

We must try to make sense of the 10\% probability that the component
fails within a year. For the moment let's use an imagination trick:
imagine that the present situation is repeated {100 times}. In {10} of
these repetitions the accepted electronic component is sold and fails
within a year after selling. In the remaining {90} repetitions, the
component is sold and works fine for at least a year. Later on we'll
approach this in a more rigorous way, where the idea of ``imaginary
repetitions'' is not needed.

In each of the {10} imaginary repetitions where the component fails
early, the manufacturer loses {\(\color[RGB]{238,102,119}11\$\).} That's
a total loss of
{\({\color[RGB]{204,187,68}10} \cdot {\color[RGB]{238,102,119}11\$} = {\color[RGB]{238,102,119}110\$}\).}
In each of the {90} imaginary repetitions in which the component doesn't
fail early, the manufacturer gains {\(\color[RGB]{34,136,51}1\$\).}
That's a total gain of
{\({\color[RGB]{204,187,68}90} \cdot {\color[RGB]{34,136,51}1\$} = {\color[RGB]{34,136,51}90\$}\).}
So over all {100} imaginary repetitions the manufacturer gains

\[
{\color[RGB]{204,187,68}10}\cdot ({\color[RGB]{238,102,119}-11\$}) + {\color[RGB]{204,187,68}90}\cdot {\color[RGB]{34,136,51}1\$} = {\color[RGB]{238,102,119}-20\$}
\]

that is, the manufacturer has not gained, but {\emph{lost} \(20\$\)}!
That's an average of {\(0.2\$\)} \emph{lost} per repetition.

\hfill\break

Now let's examine the second choice: what happens if we \texttt{discard}
the component instead?

In this case it's clear that the manufacturer doesn't gain or lose
anything. That is, the ``gain'' is {\(0\$\)} (this is for sure, so we
don't need to imagine any ``repetitions'').

The conclusion is this: If in a situation like the present one we
{accept} the component, then we'll {lose \(0.2\$\)} on average. Whereas
if we {discard} it, then we'll {lose \(0\$\)} on average.

Obviously the best, or ``least worst'', decision to make is to
\textbf{discard} the component.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Now that we have an idea of the general reasoning, check what happens
  with different values of the probability of failure and different
  values of the cost of failure. Is it still best to discard? For
  instance, try with

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    failure probability \texttt{10\%} and failure cost \texttt{5\$};
  \item
    failure probability \texttt{5\%} and failure cost \texttt{11\$};
  \item
    failure probability \texttt{10\%}, failure cost \texttt{11\$},
    non-failure gain \texttt{2\$}.
  \end{enumerate}

  Feel free to get wild and do plots.
\item
  Identify the probability of failure for which there is no loss or
  gain, on average, if we accept the component (so it doesn't matter
  whether we discard or accept). You can solve this as you prefer:
  analytically with an equation, visually with a plot, by
  trial\,\&\,error on several cases, or whatnot.
\item
  Consider the special case with failure probability \texttt{0\%} and
  failure cost \texttt{10\$}. That probability means that no new
  component will ever fail. It's clear what's the optimal decision in
  this limit case, without any calculations or imaginary repetitions.
  Yet, \textbf{confirm mathematically} that we arrive at this obvious
  conclusions if we perform a mathematical analysis like before.
\item
  Consider this completely different problem:

  \begin{quote}
  A patient is examined by a brand-new medical diagnostics AI system.

  First, the AI performs some clinical tests on the patient. The tests
  give an uncertain forecast on whether the patient has a particular
  disease or not.

  Then the AI decides whether the patient should be dismissed without
  treatment, or treated with a particular medicine.

  If the patient is dismissed, then their life expectancy doesn't
  increase or decrease if the disease is not present, but it decreases
  by 10~years if the disease is actually present. If the patient is
  treated, then their life expectancy decreases by 1~year if the disease
  is not present (owing to treatment side-effects), but also if the
  disease is present (because it cures the disease, so the life
  expectancy doesn't decrease by 10 years; but it still decreases by 1
  year owing to the side effects).

  For this patient, the clinical tests indicate that there is a 10\%
  probability that they have the disease.
  \end{quote}

  Should the diagnostic AI dismiss or treat the patient? Find
  differences and similarities, even numerical, with the assembly-line
  problem.
\end{enumerate}

\end{tcolorbox}

\hfill\break

From the solution of the problem and from the exploring exercises, we
gather some instructive points:

\begin{itemize}
\item
  Is it enough if we simply know that the component is less likely to
  fail than not? In other words, is it enough to know that the
  probability of failure is \emph{less than 50\% without knowing its
  precise value}?

  Obviously not. We found that if the failure probability is 10\% then
  it's best to discard. But we also found that if it's 5\% then it's
  best to accept. In either case the probability of failure was less
  than 50\%, but the decision was different.

  On top of that, we also found that the probability value determines
  the average amount of loss when the non-optimal decision is made.
  Therefore:

  {\textbf{\faIcon{hand-point-right} Knowledge of \emph{precise}
  probabilities is absolutely necessary for making the best
  decision.}}\\
  \strut \\
\item
  Is it enough if we simply know that failure leads to a loss, and
  non-failure leads to a gain, without knowing the precise amounts of
  loss and gain?

  Obviously not. In the exercise we found that if the cost of failure is
  11\$, then it's best to discard. But we also found that if it's 5\$,
  then it's best to accept (given the same probability of failure). And
  we also found that it's best to accept when the cost of failure is
  11\$ but the gain from non-failure is 2\$. Therefore:

  {\textbf{\faIcon{hand-point-right} Knowledge of the precise gains and
  losses is absolutely necessary for making the best decision.}}\\
  \strut \\
\item
  Is this kind of decision situation only relevant to assembly lines and
  sales?

  By all means not. We examined a clinical problem that's exactly
  analogous: there's uncertainty and probability, there are gains and
  losses (of lifetime rather than money), and the best decision depends
  on both probabilities and costs.
\end{itemize}

\section{Our focus: decision-making, inference, and data
science}\label{our-focus-decision-making-inference-and-data-science}

Every data-driven engineering problem is unique, with unique
difficulties, questions, issues. But there are some general aspects that
are common to all engineering problems.

In the scenarios that we explored above, we found an extremely important
problem-pattern:\\
\faIcon{cube} There is a decision or choice to make (and ``not
deciding'' is not an option, or it's just another kind of choice).\\
\faIcon{cube} Making a particular decision will lead to some
consequences. Some consequences are desirable, others are undesirable.\\
\faIcon{cube} The decision is difficult to make, because its
consequences are not known with certainty, even considering the
information and data available in the problem: we may lack information
and data about past or present details, about future events and
responses, and so on.

This is what we call a problem of {\textbf{decision-making under
uncertainty}} or \textbf{under risk}\footnote{We'll avoid the word
  ``risk'' because it has several different technical meanings in the
  literature, some even contradictory.}; or simply a ``decision
problem'' for short.

This problem-pattern appears literally everywhere. Stop for a second,
and think about all different situations in which you had to make a
decision today. Do they show this pattern?

But our exploration of different scenarios also suggests something
important: this problem-pattern seems to have a sort of systematic
method of solution!

In this course we're going to focus on decision problems and their
systematic solution method. We'll learn a framework and some general
notions that allow us to frame and analyse this kind of problems. And
we'll learn a universal set of principles to solve it. This set of
principles goes under the name of {\textbf{Decision Theory}}.

But what do decision-making under uncertainty and Decision Theory have
to do with \emph{data} and \emph{data science}? The three are
profoundly, tightly connected on many different planes:

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Decision
theory in expert systems and artificial intelligence}}

\end{tcolorbox}

\end{footnotesize}}

\begin{itemize}
\item
  \emph{Data science} is based on the laws of \emph{Decision Theory}.
  These laws are similar to what the laws of physics are to a rocket
  engineer. Failure to account for these fundamental laws leads to
  sub-optimal solutions -- or to disasters.
\item
  \emph{Machine-learning} algorithms, in particular, are realizations or
  approximations of the rules of \emph{Decision Theory}. This is clear,
  for instance, considering that a machine-learning classifier is
  actually \emph{choosing} among possible output classes.
\item
  The rules of \emph{Decision Theory} are also the foundations upon
  which \emph{artificial-intelligence agents} -- which must perform
  optimal inferences and decisions -- are built.
\item
  We saw that \emph{probability} values are essential to a decision
  problem. How do we find them? Obviously \emph{data} play an important
  part in their calculation. In our introductory example, the failure
  probability must have come from observations or experiments on
  previous similar electronic components.
\item
  We saw that the values of \emph{gains and losses} are essential.
  \emph{Data} play an important part in their calculation as well.
\end{itemize}

These five planes will constitute the major parts and motivations of the
present course.

\hfill\break

There are other important aspects in engineering problems, besides the
one of making decisions under uncertainty. For instance the
\emph{discovery} or the \emph{invention} of new technologies and
solutions. Aspects such as these can barely be planned or decided. Their
drive and direction, however, rest on a strive for improvement and
optimization. But the fundamental laws of Decision Theory tell us what's
optimal and what's not, so they play some part in these creative aspects
as well.

Artificial intelligence is proving to be a valuable aid in these
creative aspects. This kind of use of AI is outside the scope of the
present notes. But some aspects of this creativity-assisting use
\emph{do} fall within the domain of the present notes. A
pattern-searching algorithm, for example, can be optimized by means of
the method we are going to study.

\section{Our goal: optimality, not ``success''}\label{sec-optimality}

What should we demand from a systematic method for solving decision
problems?

By definition, in a decision problem under \emph{uncertainty} there is
generally no method to determine the decision that \emph{surely} leads
to the desired consequence. If such a method existed, the problem would
not have any uncertainty! Therefore, if there is a method to deal with
decision problems, its goal cannot be the determination of the
\emph{successful} decision. Then what should be the goal of such a
method?

Imagine two persons, Henry and Tina, who must choose between a
``heads-bet'' or a ``tails-bet'' before a coin is tossed. The bets are
these:

\begin{itemize}
\item
  {``heads-bet''}: If the coin lands {heads}, the person {wins a
  \emph{small} amount} of money. But if it lands {tails}, they {lose a
  \emph{large} amount} of money.
\item
  {``tails-bet''}: If the coin lands {tails}, the person {\emph{wins} a
  small amount} of money. If it lands {heads}, they {lose the same
  \emph{small} amount} of money.
\end{itemize}

\pandocbounded{\includegraphics[keepaspectratio]{choose_bet.png}}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Which bet would you choose? why?

\end{tcolorbox}

Now this happens: {Henry chooses the heads-bet}. {Tina chooses the
tails-bet}. The coin comes down {heads}. So Henry wins the small amount
of money, while Tina loses the same small amount.

What would we say about their decisions?

{Henry's decision} was lucky, and yet \emph{irrational}: he risked
losing much more money than he could win. {Tina's decision} was unlucky,
and yet \emph{rational}: she wasn't risking to lose more than she could
win. Said otherwise, the {heads-bet} had higher risk of loss than the
{tails-bet}, and not even an higher chance of gain. We expect that any
person making Henry's decision in similar, future bets will eventually
lose more money than any person making Tina's decision.

The method we're looking for is therefore one that, in the hypothetical
situation above, would lead to the same decision as {Tina's} -- even if
Tina's decision was unlucky. That's the decision that we call rational
or \emph{optimal} in such an uncertain situation.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

If you're thinking \emph{``wouldn't it be best to have a method that
works under uncertainty but that leads to Henry's decision, every time
that decision is lucky?''} -- then let's repeat: \textbf{such a method
cannot logically exist}. If we know which decision is ``lucky'', then it
means that we have no uncertainty. If we are uncertain, then it means
that we don't know which decision is ``lucky'', and so it's impossible
to choose it for sure.

\end{tcolorbox}

\hfill\break

Our discussion and the distinction between ``successful'' and
``optimal'' decisions also shows that \emph{we cannot evaluate the
efficacy of a method for decisions under uncertainty, by checking
whether or how often that method leads to the desired, ``successful''
consequence}. This point is also easily illustrated with a variation on
Henry and Tina's example:

Suppose the general context and the bets are exactly the same. But now
imagine \textsc{Henry} and \textsc{Tina} to be the names of two
automated decision methods, say two machine-learning algorithms. Also,
let's say that you first toss the coin in secret and see its outcome,
then you offer the possible bets to \textsc{Henry} and \textsc{Tina},
who are completely ignorant about the outcome (note that \emph{no}
cheating is involved).

You toss the coin and see that it lands {heads}. Then the choice of bets
is offered to \textsc{Henry} and \textsc{Tina}. \textsc{Henry} chooses
the {heads-bet} and \textsc{Tina} the {tails-bet}.

Now consider this: \emph{you know} the ``truth'', you know what the
successful decision would be. It turns out that {\textsc{Henry}} made
the choice corresponding to the truth. {\textsc{Tina}} didn't. Would you
then evaluate the {\textsc{Henry}} algorithm to be better than the
{\textsc{Tina}} algorithm?

For exactly the same reasons already discussed, the {\textsc{Tina}}
algorithm is the better one; it made the optimal decision. Yet it didn't
choose the ``truth''. You realize that \emph{comparing algorithms is not
as simple as checking which one yields the truth more often}.

\hfill\break

We have then arrived at two conclusions:

\begin{itemize}
\item
  \faIcon{hand-point-right} ``Success'' or ``correspondence to truth''
  is generally \textbf{not} a good criterion to judge a decision under
  uncertainty or to evaluate an algorithm that makes such decisions.
\item
  \faIcon{hand-point-right} Even if there is no method to determine
  which decision is successful, there is nevertheless a method to
  determine which decision is {\textbf{rational}} or {\textbf{optimal}},
  given the particular gains, losses, and uncertainties involved in the
  decision problem.
\end{itemize}

We had a glimpse of this method in our introductory scenarios with
electronic components and their variations.

Let us emphasize, however, that we are not giving up on ``success''; nor
are we trading ``success'' for ``optimality''. We'll find out that
{\emph{Decision Theory automatically leads to the \textbf{successful}
decision}} in problems where uncertainty is not present or is
irrelevant. It's a win-win. Keep this point firmly in mind:

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

{Aiming to find the solution that is \emph{successful} can make us
\emph{fail} to find the solution that is optimal, when the successful
one cannot be determined.}

{Aiming to find the solution that is \emph{optimal} makes us
automatically also find the solution that is \emph{successful}, when
this can be determined.}

\end{tcolorbox}

\end{figure*}%

We shall later witness this fact with our own eyes. We will also take it
up in the discussion of some misleading techniques to evaluate
machine-learning algorithms.

\section{Decision Theory}\label{sec-decision-theory}

So far we have mentioned that Decision Theory has the following
features:

\begin{itemize}
\item
  \faIcon{check} It tells us what's optimal and, when possible, what's
  successful.
\item
  \faIcon{check} It takes into consideration decisions, consequences,
  costs and gains.
\item
  \faIcon{check} It is able to deal with uncertainties.
\end{itemize}

What other kinds of features should we demand from it, in order to be
applied to as many kinds of decision problems as possible, and to be
relevant for data science? Here are two:

\begin{itemize}
\item
  If we find an optimal decision in regards to some problem, it may
  still happen that this decision leads to new, subsequent decision
  problems. For example, in the assembly-line scenario the decision
  \texttt{discard} could be carried out by burning, recycling, and so
  on. And each of these actions could have uncertain results and costs
  or gains. We thus face a decision within a decision. In general, a
  decision problem may involve several decision sub-problems, in turn
  involving decision sub-sub-problems, and so on.
\item
  In data science, a common engineering goal is to design and build an
  automated or AI-based device capable of making an optimal decision, at
  least in specific kinds of uncertain situations. Think for instance of
  an aeronautic engineer designing an autopilot system; or a software
  company designing an image classifier.
\end{itemize}

Well, Decision Theory turns out to meet these two demands too, thanks to
the following features:

\begin{itemize}
\item
  \faIcon{check} It is susceptible to recursive, sequential, and modular
  application.
\item
  \faIcon{check} It can be used not only for human decision-makers, but
  also for AI or automated devices.
\end{itemize}

\hfill\break

Decision Theory has a long history, going back to Leibniz in the 1600s
and partly even to Aristotle in the −300s. It appeared in its present
form around 1920--1960. What's remarkable about it is that it is not
only \textbf{a} framework: it is \textbf{the} framework we must use. A
logico-mathematical theorem shows that {\emph{any framework that does
not break basic optimality and rationality criteria has to be equivalent
to Decision Theory}}. In other words, an ``alternative'' framework might
use different terminology and apparently different mathematical
operations, but it would boil down to the same notions and mathematical
operations of Decision Theory. So if you wanted to invent and use
another framework, then either (a) your framework would lead to some
irrational or illogical consequences; or (b) your framework would lead
to results identical to Decision Theory. Many frameworks that you are
probably familiar with, such as optimization theory or Boolean logic,
are just specific applications or particular cases of Decision Theory.

Thus we list one more important characteristic of Decision Theory:

\begin{itemize}
\tightlist
\item
  \faIcon{check} It is {\textbf{normative}}.
\end{itemize}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Judgment
  under uncertainty}}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Heuristics
  and Biases}}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Thinking,
  Fast and Slow}}
\end{itemize}

\end{tcolorbox}

\end{footnotesize}}

\emph{Normative} contrasts with \emph{descriptive}. The purpose of
Decision Theory is not to describe, for example, how human
decision-makers typically make decisions. Human decision-makers
typically make irrational, sub-optimal, or biased decisions. That's
exactly what we want to avoid! We want a theory, a \emph{norm}, that
human decision-makers should aspire to. That's what Decision Theory is.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\emph{Who says that Decision Theory should be normative?} -- this is a
respectable scientific question. If you found yourself wondering and
doubting about this, then congratulations: that's how a scientist should
think!

Later on we'll examine material and arguments about this point. If you
like, feel free to already skim through the following works, as a start
in your investigations:

\begin{itemize}
\item
  Ch.~15, especially §15.1 and §``Bibliographical and Historical Notes''
  of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}
\item
  \href{https://plato.stanford.edu/archives/fall2019/entries/rationality-normative-utility}{\emph{Normative
  Theories of Rational Choice: Expected Utility}}
\item
  \href{https://plato.stanford.edu/archives/win2020/entries/decision-theory}{\emph{Decision
  Theory}}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Decision
  Analysis}}
\end{itemize}

\end{tcolorbox}

\chapter{\texorpdfstring{{Basic decision
problems}}{Basic decision problems}}\label{sec-basic-decisions}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

Decision Theory analyses any decision-making problem in terms of nested
or sequential \emph{basic} or \emph{minimal} decision problems. The
assembly-line scenario of the introduction~\ref{sec-intro} is an
example.

\section{Graphical representation and
elements}\label{graphical-representation-and-elements}

A basic decision problem can be represented by a diagram like this:

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{basic_decision_tree.png}

It has one {\textbf{decision node}}, usually represented by a square
\faIcon{square}, from which the available decisions depart as lines.
Each decision leads to an {\textbf{inference node}},\footnote{also
  called \emph{chance node} or \emph{uncertainty node}} usually
represented by a circle \faIcon{circle}, from which the possible
outcomes depart as lines. Each outcome leads to a particular gain or
loss, depending on the decision. The uncertainty of each outcome is
quantified by a probability.

A basic decision problem is analysed in terms of the following elements:

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

{\faIcon{seedling} Remember: What matters is to be able to identify
these elements in a concrete problem, understanding their role. Their
technical names don't matter.}

\end{tcolorbox}

\end{footnotesize}}

\begin{itemize}
\tightlist
\item
  {\faIcon{cube} \textbf{Agent}}, and {\textbf{background}} or
  {\textbf{prior information}}. The agent is the person or device that
  has to make the decision. An agent possesses (or has been programmed
  with) specific background information that is used and taken for
  granted in the decision-making process. This background information
  determines the probabilities, gains, and losses of the outcomes,
  together with other available data and information. Different agents
  typically have different background information.
\end{itemize}

\marginnote{\begin{footnotesize}

\emph{Agent} means ``conductor'', ``mover'', and similar (from Latin
\emph{ago}~=~\emph{to move} or \emph{drive} and similar meanings).

We'll use the neutral pronouns \emph{it}/\emph{its} when referring to an
agent, since an agent could be a person or a machine.

\end{footnotesize}}

\begin{itemize}
\item
  {\faIcon{cube} \textbf{Data}} and other {\textbf{additional
  information}}, sometimes called {\textbf{evidence}}. They differ from
  the background information in that they can change with every decision
  instance made by the same agent, while the background information
  stays the same. In the assembly-line scenario, for example, the test
  results could be different for every new electric component.
\item
  {\faIcon{cube} \textbf{Decisions}} available to the agent. They are
  assumed to be mutually exclusive and exhaustive; this can always be
  achieved by recombining them if necessary, as we'll discuss later.
\end{itemize}

\marginnote{\begin{footnotesize}

\emph{Decisions} are called \emph{courses of action} in some literature.

\end{footnotesize}}

\begin{itemize}
\tightlist
\item
  {\faIcon{cube} \textbf{Outcomes}} of the possible decisions. Every
  decision can have a different set of outcomes, or some outcomes can
  appear for several or all decisions (in this case they are reported
  multiple times in the decision diagram). Note that even if an outcome
  can happen for two or more different decisions, its probabilities can
  still be different depending on the decision.
\end{itemize}

\marginnote{\begin{footnotesize}

Many other terms instead of \emph{outcome} are used in the literature,
for instance \emph{state} or \emph{event}.

\end{footnotesize}}

\begin{itemize}
\item
  {\faIcon{cube} \textbf{Probabilities}} for each of the outcomes and
  for each decision. Their values typically depend also on the
  background information and the additional data.
\item
  {\faIcon{cube} \textbf{Utilities}}: the gains or losses associated
  with each possible outcome and each decision. We shall mainly use the
  term {\textbf{utility}}, instead of ``gain'', ``loss'', and similar,
  for several reasons:

  \begin{itemize}
  \tightlist
  \item
    gain and losses may involve not money, but time, or energy, or
    health, or emotional value, or other kinds of commodities and things
    that are important to us; or even a combination of them. The term
    ``utility'' is useful as a neutral term that doesn't mean ``money'',
    but depends on the context
  \item
    we can just use one term instead of two: for example, when the
    utility is positive it's a ``gain''; when it's negative it's a
    ``loss''
  \end{itemize}

  The particular numerical values of the utilities are always
  context-dependent: they may depend on the background information, the
  decisions, the outcomes, and the additional data.

  {We shall sometimes use the generic currency sign~~{\textbf{¤}}~~to
  denote utilities, to make clear that gains and losses do not
  necessarily involve money, and not to reference any country in
  particular.}
\end{itemize}

\hfill\break

The relation between the elements above can be depicted as follows --
but note that this is just an intuitive illustration:
\includegraphics[width=0.75\linewidth,height=\textheight,keepaspectratio]{basic_decision_tree_agent.png}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Don't over-interpret the decision diagram}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  The diagram above \emph{doesn't have any temporal meaning}, that is,
  it doesn't mean that the decisions happen before the outcomes, or vice
  versa.

  In some situations the outcome can be realized after the decision is
  made; for instance, someone bets on heads or tails, and then a coin is
  tossed.

  In other situations, the outcome can be realized before the decision
  is made; for instance, sometimes a coin is tossed and covered, then
  one is asked to bet on what the outcome was. Another example is some
  research decision made by a archaeologist, the unknown being some
  detail about a dinosaur from millions of years ago.

  In yet other situations the outcome may have a complex nature, and it
  may be realized partly before the decision is made, and partly after;
  for instance, someone can bet on the outcome of two coin tosses; one
  coin is tossed before the decision is made, and the other after.
\item
  The diagram above is not something that an agent \emph{must} use in
  making decisions. It is not part of the theory. It's just a very
  convenient way to visualize and operate with the mathematics
  underlying the theory.
\item
  It not always the case that the \emph{outcomes} are unknown and the
  \emph{data} are known. As we'll discuss later, in some situations we
  reason in hypothetical or counterfactual ways, using hypothetical data
  and considering outcomes which have already occurred. In such
  situations we can still use diagrams like the one above, because the
  help us doing the calculation, although the actual outcome is already
  known.
\end{itemize}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  §1.1.4 in
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}
\item
  \emph{Skim through} Ch.~15 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}. No need to read thoroughly: just quickly glimpse
  whether there are ideas and notions that look familiar (a little like
  when you're in a large crowd and look quickly around to see if there
  are any familiar faces)
\end{itemize}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  Identify the elements above in the assembly-line decision problem of
  the introduction~\ref{sec-intro}.
\item
  Sketch the decision diagram for the assembly-line decision problem.
\end{itemize}

\end{tcolorbox}

Some of the decision-problem elements listed above may need to be in
turn analysed by a decision sub-problem. For instance, the utilities
could depend on uncertain factors: thus we have a decision sub-problem
to determine the optimal values to be used for the utilities of the main
problem. This is an example of the modular character of decision theory.

We shall soon see how to mathematically represent these elements.

The elements above must be identified unambiguously in every decision
problem. The analysis into these elements greatly helps in making the
problem and its solution well-defined.

An advantage of decision theory is that its application \emph{forces} us
to make sense of an engineering problem. A useful procedure is to
formulate the general problem in terms of the elements above,
identifying them clearly. If the definition of any of the terms involves
uncertainty of further decisions, then we analyse it in turn as a
decision sub-problem, and so on.

\begin{quote}
Suppose someone (probably a politician) says: ``We must solve the energy
crisis by reducing energy consumption or producing more energy''. From a
decision-making point of view, this person has effectively said
\emph{nothing whatsoever}. By definition the ``energy crisis'' is the
problem that energy production doesn't meet demand. So this person has
only said ``we would like the problem to be solved'', without specifying
any solution. A decision-theory approach to this problem requires us to
specify which concrete courses of action should be taken for reducing
consumption or increasing productions, and what their probable outcomes,
costs, and gains would be.
\end{quote}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

See MacKay's options-vs-costs rational analysis in
\href{https://www.withouthotair.com}{Sustainable Energy -- without the
hot air}

\end{tcolorbox}

\end{footnotesize}}

\section{Setting up a basic decision
problem}\label{sec-decision-matrices}

A basic decision problem can be set up along the following steps (which
we illustrate afterwards with a couple of examples):

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={Setup of a basic decision problem}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{List all available decisions}
\item
  \textbf{For each decision, list its possible outcomes}
\item
  \textbf{Pool together all outcomes of all decisions, counting the
  common ones only once}
\item
  \textbf{Prepare two tables: in each, display the decisions as rows,
  and the pooled outcomes as columns} (or you can do the opposite:
  decisions as columns and outcomes as rows)
\item
  \textbf{In one table, report the probabilities for all
  decision-outcome pairs. If an outcome is not available for that
  decision, give it a \(0\%\) probability}
\item
  \textbf{In the other table, report the utilities for all
  decision-outcome pairs. If an outcome is not available for that
  decision, give it a \(0\) utility}
\end{enumerate}

\end{tcolorbox}

\subsubsection{Example: the assembly-line
problem}\label{example-the-assembly-line-problem}

Let's apply the steps above in the assembly-line example of
ch.~~\ref{sec-intro}:

{\textbf{1. List all available decisions}}

Easy: they are ``{accept} the electronic component'' and ``{discard}
it''.

\hfill\break

{\textbf{2. For each decision, list its possible outcomes}}

In general you will notice that some outcomes may be common to all
decisions, while other outcomes can happen for some decisions only, or
even for just one decision.

In the present example, the {accept} decision has two possible outcomes:
``the component works with {no faults} for at least a year'' and ``the
component {fails} within a year''.

The {discard} cannot have those outcomes, because the component is
discarded. It has indeed only one outcome: ``component {discarded}''.

\hfill\break

{\textbf{3. Pool together all outcomes of all decisions, counting the
common ones only once}}

In total we have \emph{three} pooled outcomes:

\begin{itemize}
\tightlist
\item
  {\textbf{no faults}} (from the {accept} decision)
\item
  {\textbf{fails}} (from the {accept} decision)
\item
  {\textbf{discarded}} (from the {discard} decision)
\end{itemize}

\hfill\break

{\textbf{4. Prepare two tables: in each, display the decisions as rows,
and the pooled outcomes as columns} (or you can do the opposite:
decisions as columns and outcomes as rows)}

In the present example each table looks like this:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2138}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2621}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2621}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2621}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{no faults for a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{fails within a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{discarded}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{\textbf{accept}} & & & \\
{\textbf{discard}} & & & \\
\end{longtable}

\hfill\break

{\textbf{5. In one table, report the probabilities for all
decision-outcome pairs. If an outcome is not available for that
decision, give it a \(0\%\) probability}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2138}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2621}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2621}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2621}}@{}}
\caption{{\emph{Probability table}}}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{no faults for a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{fails within a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{discarded}
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{no faults for a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{fails within a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{discarded}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{\textbf{accept}} & \(90\%\) & \(10\%\) & {\(0\%\)} \\
{\textbf{discard}} & {\(0\%\)} & {\(0\%\)} & \(100\%\) \\
\end{longtable}

Note how the outcomes that do not exist for a particular decision have
been given a {\(0\%\)} probability (in {grey}). This is just a way of
saying ``this outcome can't happen, if this decision is made''.

\hfill\break

{\textbf{6. In the other table, report the utilities for all
decision-outcome pairs. If an outcome is not available for that
decision, give it a \(0\) utility}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2138}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2621}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2621}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2621}}@{}}
\caption{{\emph{Utility table}}}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{no faults for a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{fails within a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{discarded}
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{no faults for a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{fails within a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{discarded}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{\textbf{accept}} & \(+1\$\) & \(-11\$\) & {\(0\$\)} \\
{\textbf{discard}} & {\(0\$\)} & {\(0\$\)} & \(0\$\) \\
\end{longtable}

Note how the outcomes that do not exist for a particular decision have
been given a {\(0\$\)} utility (in {grey}). We shall see later that it
actually doesn't matter which utilities we give to these impossible
outcomes.

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Apply the steps above to the following basic decision problems (you only
need to set them up with their probability \& utility tables, but feel
free to solve them as well, if you like):

\begin{itemize}
\item
  The ``heads-bet'' vs ``tails-bet'' example of §~\ref{sec-optimality}.
  Assume that the ``small amount'' of money is {\(10\$\),} the ``large
  amount'' is {\(1000\$\),} and the two outcomes' probabilities are
  {\(50\%\)} each.
\item
  Peter must reach a particular destination, and is undecided between
  two alternatives: \emph{go by car}, or \emph{ride a bus}, or \emph{go
  on foot}. If he goes by car, he could \emph{arrive without problems},
  with a probability of {\(80\%\)} and a utility of {\(10\,¤\),} or he
  could \emph{get stuck in a traffic jam} and arrive late, with a
  probability of {\(20\%\)} and a utility of {\(-10\,¤\).} If he rides a
  bus, he could \emph{arrive without problems}, with a probability of
  {\(95\%\)} and a utility of {\(15\,¤\),} or arrive in time but
  \emph{travelling in a fully-packed bus}, with a probability of
  {\(5\%\)} and a utility of {\(-10\,¤\).} If he goes on foot, he could
  \emph{arrive without problems}, with a probability of {\(20\%\)} and a
  utility of {\(20\,¤\),} or he could \emph{get soaked from rain}, with
  a probability of {\(80\%\)} and a utility of {\(-5\,¤\).}

  (We are using the symbol~~{``\(¤\)''}~~because Peter's utilities are a
  combination of money savings, time of arrival, and comfort.)
\end{itemize}

\end{tcolorbox}

\hfill\break

\section{How to make a basic decision?}\label{sec-make-decision}

Up to now we have seen what are the elements of a basic decision
problem, and how to arrange them in a diagram and with tables. \emph{But
how do we determine what's the optimal decision?}

Decision Theory says that the optimal decision is determined by the
``{\textbf{principle of maximal expected utility}}''.

We shall study this principle more in detail toward the end of the
course, although you already know its basic idea, because you
intuitively used this very principle in solving all decision problems we
met so far, starting from the assembly-line one.

However, let's quickly describe already now the basic procedure for this
principle:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={Principle of maximal expected utility}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  For each decision, multiply the probability and the utility of each of
  its outcomes, and then sum up these products. This way you obtain the
  \emph{expected utility} of the decision.
\item
  Choose the decision that has the largest expected utility; if several
  decisions are maximal, choose any of them unsystematically.
\end{enumerate}

\end{tcolorbox}

This procedure can also be described in terms of the probability and
utility tables introduced in the previous section:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  {Multiply element-by-element the probability table and the utility
  table, obtaining a new table with the same number of rows and columns}
\item
  {Sum up the elements of each row of the new table (this sum is the
  expected utility); remember that every row corresponds to a decision}
\item
  {Choose the decision corresponding to the largest of the sums above;
  if there are several maximal ones, choose among them unsystematically}
\end{enumerate}

\subsubsection{Example: the assembly-line
problem}\label{example-the-assembly-line-problem-1}

Multiplying the \emph{Probability table} and the \emph{Utility table}
above, element-by-element, we obtain the following table, where we also
indicate the sum of each row:

\begin{figure*}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1694}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2077}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2077}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2077}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2077}}@{}}
\caption{{\emph{Probability × Utility table}}}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{no faults for a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{fails within a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{discarded}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\emph{sum}
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{no faults for a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{fails within a year}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{discarded}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\emph{sum}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{\textbf{accept}} & \(+0.9\$\) & \(-1.1\$\) & {\(0\$\)} &
\(\boldsymbol{-0.2\$}\) \\
{\textbf{discard}} & {\(0\$\)} & {\(0\$\)} & \(0\$\) &
\(\boldsymbol{0\$}\) \\
\end{longtable}

\end{figure*}%

and, as we already knew, {discard}ing the electronic component is the
decision with the maximal expected utility.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Feel free to sketch some code (in your preferred programming language)
that chooses the optimal decision according to the principle above. The
code should take two inputs: the table or matrix of probabilities, and
the table or matrix of utilities; and should give one output: the
row-number of the optimal decision.

\end{tcolorbox}

\section{Plan for the next chapters}\label{plan-for-the-next-chapters}

The {\textbf{expected-utility maximization}} above is intuitive and
simple, and is the last stage in a basic decision problem.

But there are two stages which occur before, and which are the most
difficult:

\begin{description}
\tightlist
\item[{\faIcon{cube} \textbf{Inference}}]
is the stage where the probabilities of the possible outcomes are
calculated. Its rules are given by the {\textbf{Probability Calculus}}.
Inference is independent from decision: in some situations we may simply
wish to assess whether some hypotheses, conjectures, or outcomes are
more or less plausible than others, without making any decision. This
kind of assessment can be very important in problems of communication
and storage, and it is specially considered by {\textbf{Information
Theory}}.
\end{description}

The calculation of probabilities can be the part that demands most
thinking, time, and computational resources in a decision problem. It is
also the part that typically makes most use of data -- and where data
can be most easily misused.

Roughly half of this course will be devoted in understanding the laws of
inference, their applications, uses, and misuses.\\

\begin{description}
\tightlist
\item[{\faIcon{cube} \textbf{Utility assesment}}]
is the stage where the gains or losses of the possible outcomes are
calculated. Often this stage requires further inferences and further
decision-making sub-problems. The theory underlying utility assessment
is still much underdeveloped, compared to probability theory.\\
\end{description}

\hfill\break

We shall now explore each of these two stages. We take up inference
first because it is the most demanding and probably the one that can be
optimized the most by new technologies.

\chapter{\texorpdfstring{{Connection with machine learning and
AI}}{Connection with machine learning and AI}}\label{connection-with-machine-learning-and-ai}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\section{Inferences with machine-learning
algorithms}\label{inferences-with-machine-learning-algorithms}

Some works in machine learning focus on ``guessing the correct answer'',
and this focus is reflected in the way their machine-learning algorithms
-- especially classifiers -- are trained and used.

In §~\ref{sec-optimality} we emphasized that ``guessing successfully''
can be a misleading goal, however, because it can lead us away from
guessing \emph{optimally}. We shall now see two simple but concrete
examples of this.

\subsection{A ``max-success'' classifier vs an optimal
classifier}\label{a-max-success-classifier-vs-an-optimal-classifier}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

You find the code for this chapter and exercises also in
\href{code/mlc_vs_opm.ipynb}{this JupyterLab notebook for R} and
(courtesy of Viktor Karl Gravdal!) \href{code/mlc_vs_opm_py.ipynb}{this
JupyterLab notebook for python}.

\end{tcolorbox}

We shall compare the results obtained in some numerical simulations by
using

\begin{itemize}
\tightlist
\item
  a {Machine-Learning Classifier} trained to do most successful guesses
\item
  a prototype ``{Optimal Predictor Machine}'' trained to make the
  optimal decision
\end{itemize}

For the moment we treat both as ``black boxes'', that is, we don't study
yet how they're calculating their outputs (although you may already have
a good guess at how the Optimal Predictor Machine works).

Their operation is implemented in \href{code/mlc_vs_opm.R}{this R
script} that we now load:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}code/mlc\_vs\_opm.R\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This script simply defines the function \texttt{hitsvsgain()}:

\begin{verbatim}
hitsvsgain(
    ntrials,
    chooseAtrueA,
    chooseAtrueB,
    chooseBtrueB,
    chooseBtrueA,
    probsA
)
\end{verbatim}

having six arguments:

\begin{itemize}
\tightlist
\item
  \texttt{ntrials}: how many simulations of guesses to make
\item
  \texttt{chooseAtrueA}: utility gained by guessing \texttt{A} when the
  successful guess is indeed \texttt{A}
\item
  \texttt{chooseAtrueB}: utility gained by guessing \texttt{A} when the
  successful guess is \texttt{B} instead
\item
  \texttt{chooseBtrueB}: utility gained by guessing \texttt{B} when the
  successful guess is indeed \texttt{B}
\item
  \texttt{chooseBtrueA}: utility gained by guessing \texttt{B} when the
  successful guess is \texttt{A} instead
\item
  \texttt{probsA}: a tuple of probabilities (between \texttt{0} and
  \texttt{1}) to be used in the simulations (recycling it if necessary),
  for the successful guess being \texttt{A}; the corresponding
  probabilities for \texttt{B} are therefore \texttt{1-probsA}. If this
  argument is omitted it defaults to \texttt{0.5} (not very interesting)
\end{itemize}

\subsection{Example 1: electronic
component}\label{example-1-electronic-component}

Let's apply our two classifiers to the \emph{Accept or discard?} problem
of §~\ref{sec-intro}. We call \texttt{A} the alternative in which the
element won't fail before one year, and should therefore be accepted
\emph{if this alternative were known at the time of the decision}. We
call \texttt{B} the alternative in which the element will fail within a
year, and should therefore be discarded \emph{if this alternative were
known at the time of the decision}. Remember that the crucial point here
is that the classifiers \emph{don't} have this information at the moment
of making the decision.

We simulate this decision for 100\,000 components (``trials''), assuming
that the probabilities of failure can be \texttt{0.05}, \texttt{0.20},
\texttt{0.80}, \texttt{0.95}. The values of the arguments should be
clear:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hitsvsgain}\NormalTok{(}
    \AttributeTok{ntrials =} \DecValTok{100000}\NormalTok{,}
    \AttributeTok{chooseAtrueA =} \SpecialCharTok{+}\DecValTok{1}\NormalTok{,}
    \AttributeTok{chooseAtrueB =} \SpecialCharTok{{-}}\DecValTok{11}\NormalTok{,}
    \AttributeTok{chooseBtrueB =} \DecValTok{0}\NormalTok{,}
    \AttributeTok{chooseBtrueA =} \DecValTok{0}\NormalTok{,}
    \AttributeTok{probsA =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.05}\NormalTok{, }\FloatTok{0.20}\NormalTok{, }\FloatTok{0.80}\NormalTok{, }\FloatTok{0.95}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Trials: 100000
Machine-Learning Classifier: successes 87549 ( 87.5 %) | total gain -24681
Optimal Predictor Machine:   successes 72671 ( 72.7 %) | total gain 10571
\end{verbatim}

Note how the {machine-learning classifier} is the one that \emph{makes
most successful guesses} (around 88\%), \textbf{and yet it leads to a
net loss!} If the utility were in \emph{kroner}, this classifier would
cause the company producing the components a {net loss of more than
20\,000\,kr}.

The {optimal predictor machine}, on the other hand, \emph{makes fewer
successful guesses} overall (around 72\%), \textbf{and yet it leads to a
net gain!} It would earn the company a {net gain of around 10\,000\,kr}.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

How is this possible? Try to understand what's happening; feel free to
research this by modifying the \texttt{hitsvsgain()} function, so that
it prints additional outputs.

\end{tcolorbox}

\subsection{Example 2: find Aladdin! (image
recognition)}\label{example-2-find-aladdin-image-recognition}

A typical use of machine-learning classifiers is for image recognition:
for instance, the classifier guesses whether a particular subject is
present in the image or not.

Intuitively one may think that ``guessing successfully'' should be the
best goal here. But exceptions to this may be more common than one
thinks. Consider the following scenario:

\begin{quote}
Bianca has a computer folder with 10\,000 photos. Some of these include
her beloved cat Aladdin, who sadly passed away recently. She would like
to select all photos that include Aladdin and save them in a separate
``Aladdin'' folder. Doing this by hand would take too long, if at all
possible; so Bianca wants to employ a machine-learning classifier.

For Bianca it's important that no photo with Aladdin goes missing, so
she would be very sad if any photo with him weren't correctly
recognized; on the other hand she doesn't mind if some photos without
him end up in the ``Aladdin'' folder -- she can delete them herself
afterwards.
\end{quote}

Let's apply and compare our two classifiers to this image-recognition
problem, using again the \texttt{hitsvsgain()} function. We call
\texttt{A} the case where Aladdin is present in a photo, and \texttt{B}
where he isn't. To reflect Bianca's preferences, let's use these
``emotional utilities'':

\begin{itemize}
\tightlist
\item
  \texttt{chooseAisA\ =\ +2}: Aladdin is correctly recognized
\item
  \texttt{chooseBisA\ =\ -2}: Aladdin is not recognized and photo goes
  missing
\item
  \texttt{chooseBisB\ =\ +1}: absence of Aladding is correctly
  recognized
\item
  \texttt{chooseAisB\ =\ -1}: photo without Aladding end up in
  ``Aladding'' folder
\end{itemize}

and let's say that the photos may have probabilities \texttt{0.3},
\texttt{0.4}, \texttt{0.6}, \texttt{0.7} of including Aladding:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hitsvsgain}\NormalTok{(}\AttributeTok{ntrials =} \DecValTok{10000}\NormalTok{, }\AttributeTok{chooseAtrueA =} \SpecialCharTok{+}\DecValTok{2}\NormalTok{, }\AttributeTok{chooseAtrueB =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\AttributeTok{chooseBtrueB =} \DecValTok{1}\NormalTok{, }\AttributeTok{chooseBtrueA =} \SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\AttributeTok{probsA =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\FloatTok{0.7}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Trials: 10000
Machine-Learning Classifier: successes 6517 ( 65.2 %) | total gain 4525
Optimal Predictor Machine:   successes 6000 ( 60 %) | total gain 5537
\end{verbatim}

Again we see that the {machine-learning classifier} makes more
successful guesses than the {optimal predictor machine}, but the latter
yields a higher ``emotional utility''.

You may sensibly object that this result could depend on the peculiar
utilities or probabilities chosen for this example. The next exercise
helps answering your objection.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Is there any case in which the optimal predictor machine yields a
  strictly lower utility than the machine-learning classifier?

  \begin{itemize}
  \tightlist
  \item
    Try using different utilities, for instance using \texttt{±5}
    instead of \texttt{±2}, or whatever other values you please.
  \item
    Try using different probabilities as well.
  \end{itemize}
\item
  As in the previous exercise, try to understand what's happening.
  Consider this question: \emph{how many photos including Aladdin did
  each classifier miss?}

  Modify the \texttt{hitsvsgain()} function to output this result.
\item
  Do the comparison using the following utilities:
  \texttt{chooseAtrueA\ =\ +1}, \texttt{chooseAtrueB\ =\ -1},
  \texttt{chooseBtrueB\ =\ 1}, \texttt{chooseBtrueA\ =\ -1}. What's the
  result? what does this tell you about the relationship between the
  machine-learning classifier and the optimal predictor machine?
\end{itemize}

\end{tcolorbox}

\hfill\break

\section{What is ``Artificial
Intelligence''?}\label{what-is-artificial-intelligence}

\subsection{``AI'' as opposed to what?}\label{ai-as-opposed-to-what}

The field of Artificial Intelligence is vast, and its boundaries are not
clear-cut. Different books give slightly different definitions of AI. In
everyday parlance the term ``AI'' is moreover used in ways that are
\emph{not} technically correct -- a bit like it happens with physics
terms such as ``energy'' or ``force''. In this course we want to use
\emph{AI} in a technically more correct way.

The discussion of the possible definitions of AI could take several
chapters. Let's try a shorter approach, by examining why the two words
``artificial'' and ``intelligence'' are used specifically.\\

\textbf{\emph{Artificial}} as opposed to what? As opposed to
\emph{natural} for example. So it denotes something human-made, as
opposed to something directly found in nature; say in an orangutan or in
a dolphin.\\

\textbf{\emph{Intelligence}} as opposed to what? As opposed to
\emph{stupidity}. The definition of ``intelligence'' itself, even
natural intelligence, is still quite open. Generally we mean something
that is \emph{logical} or \emph{rational}. Thus an agent that breaks
some logical procedure, or that does not follow a procedure that it
claims to follow, is not ``intelligent''.\\

Of course neither term is fully dichotomous: we can distinguish
different degrees of artificiality and of intelligence.

\subsection{``Intelligence'' is not
``human-likeness''}\label{intelligence-is-not-human-likeness}

We can distinguish two distinct endeavours in the field of Artificial
Intelligence, considered in its most general extension:

\begin{itemize}
\tightlist
\item
  achieving \emph{human-like} behaviour;
\item
  achieving \emph{intelligent reasoning}, or we could say \emph{logical}
  or \emph{rational reasoning}.
\end{itemize}

It's important to recognize immediately that these two endeavours may
\emph{not be mutually compatible}. We often associate human behaviour
with error-making and irrationality. We may say that a person is very
irrational, yet we don't say that because of this the person is inhuman.

Given the incompatible character of the two endeavours above, we must be
very clear and conscious about which goal we're trying to achieve;
otherwise we won't achieve any goal at all. And in technical discussions
we must be careful to adopt the correct terminology. In particular we
should avoid the term ``intelligent'' when we instead mean
``human-like'', and vice versa.

An example of such confusion is with present-day \emph{large language
models} (LLMs), and in particular those with a Generative Pre-training
Transformer (GPT) architecture. In many media they are referred to as
``AI systems''; yet what they achieve is not \emph{intelligence}, but
rather \emph{human-like} language processing -- including
non-intelligent processing.

If you have access to a large language model, you have surely witnessed
examples of stupid output\footnote{often euphemistically called
  ``hallucination'' because this term may increase sales, whereas
  ``stupid'' would risk decreasing sales.}. You can try a variation of
the following experiment:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Ask the LLM to write down a short list of some set, for instance of
  all Norwegian counties.
\item
  Ask the LLM to select from the list only those item that have one or
  more letter ``r'' in their name. See the result.
\item
  Ask the LLM to give you a step-by-step procedure to achieve the
  selection required in the previous step.
\end{enumerate}

Typically a LLM fails at task 2., even if it can give a completely sound
procedure in task 3. Clearly it isn't internally following the logical
procedure.\\

This is the reason why in this course we do \emph{not} categorize LLMs
as ``artificial intelligence'', but rather as human-mimicking machines.
But we shall consider possible ways in which a true intelligence
framework could be built into these machines.

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  Chapters 1--2 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}.
\end{itemize}

\end{tcolorbox}

\part{{\textbf{Inference I}}}

\chapter{\texorpdfstring{{What is an
inference?}}{What is an inference?}}\label{sec-what-inference}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

In the assembly-line decision problem of §~\ref{sec-intro}, the
probability of early failure was very important in determining the
optimal decision. If the probability had been {\(5\%\)} instead of
{\(10\%\),} the optimal decision would have been different. Also, if the
probability had been {\(100\%\)} or {\(0\%\),} it would have meant that
we knew \emph{for sure} what was the successful decision.

In that decision problem, the probabilities of the outcomes were already
given. But in real decision problems the probabilities of the outcomes
almost always need to be calculated, and their calculation can be the
most time- and resource-demanding stage in solving a decision problem.

We'll loosely refer to problems of calculating probabilities as
``\emph{inference} problems'', and to their calculation as ``drawing an
inference''. Drawing inferences is very often a goal or need in itself,
without any underlying decision process.

Our purpose now is to learn how to draw inferences -- that is, how to
calculate probabilities. We'll proceed by facing the following
questions, in order:

\begin{itemize}
\item
  What do we mean by ``inference'' and ``probability'', more precisely?
  What important aspects about inferences and probabilities should we
  keep in mind?
\item
  What kind of mathematical notation do we use for inferences and
  probabilities?
\item
  What are the rules for drawing inferences, that is, for calculating
  probabilities?
\end{itemize}

\section{The wide scope and characteristics of
inferences}\label{sec-inference-scenarios}

Let's see a couple more informal examples of inference problems. For
some of them an underlying decision-making problem is also alluded to:

\begin{enumerate}
\def\labelenumi{\Alph{enumi}.}
\item
  Looking at the weather, we try to assess if it'll rain today, to
  decide whether to take an umbrella.
\item
  Considering a patient's symptoms, test results, and medical history, a
  clinician tries to assess which disease affects the patient, in order
  to decide on the optimal treatment.
\item
  Looking at the present game position
  \includegraphics[width=0.1\linewidth,height=\textheight,keepaspectratio]{XsOs.png}
  the X-player, which moves next, wonders whether placing the next
  {\textbf{X}} on the mid-right position leads to a win.
\item
  The computer of a self-driving car needs to assess, from the current
  set of camera frames, whether a particular patch of colours in the
  frames is a person, in order to slow down the car and stop if that's
  the case.
\item
  Given that {\(G=6.67 \cdot 10^{-11}\,\mathrm{m^3\,s^{-2}\,kg^{-1}}\),}
  {\(M = 5.97 \cdot 10^{24}\,\mathrm{kg}\)} (mass of the Earth), and
  {\(r = 6.37 \cdot 10^{6}\,\mathrm{m}\)} (radius of the Earth),
  \href{https://www.feynmanlectures.caltech.edu/TIPS_03.html}{a rocket
  engineer needs to know} how much is {\(\sqrt{2\,G\,M/r\,}\).}
\item
  We'd like to know whether the rolled die is going to show
  \faIcon{dice-six}.
\item
  An
  \href{https://aerospaceamerica.aiaa.org/features/a-i-in-the-cockpit}{aircraft's
  autopilot system} needs to assess how much the aircraft's
  \href{https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/airplane/roll.html}{roll}
  will change, if the right wing's
  \href{https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/airplane/incline.html}{angle
  of attack} is increased by {\(0.1\,\mathrm{rad}\).}
\item
  By looking at the dimensions, shape, texture of a newly dug-out fossil
  bone, an archaeologist wonders whether it belonged to a Tyrannosaurus
  rex.
\item
  A voltage test on a newly produced electronic component yields a value
  of {\(100\,\mathrm{mV}\).} The electronic component turns out to be
  defective. An engineer wants to assess whether the voltage-test value
  could have been {\(100\,\mathrm{mV}\)} even if the component had
  \emph{not} been defective.
\item
  Same as above, but the engineer wants to assess whether the
  voltage-test value could have been {\(80\,\mathrm{mV}\)} if the
  component had not been defective.
\end{enumerate}

\hfill\break

\begin{enumerate}
\def\labelenumi{\Alph{enumi}.}
\setcounter{enumi}{10}
\tightlist
\item
  From measurements of the Sun's energy output, measurements of
  concentrations of various substances in the Earth's atmosphere over
  the past 500\,000 years, and measurements of the emission rates of
  various substances in the years 1900--2022, climatologists and
  geophysicists try to assess the rate of mean-temperature increase in
  the years 2023--2100.
\end{enumerate}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Ch.\,10 in
\href{https://hvl.instructure.com/courses/32045/modules}{\emph{A
Survival Guide to the Misinformation Age}}.

\end{tcolorbox}

\end{footnotesize}}

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\item
  For each example above, pinpoint what has to be inferred, and also the
  \emph{agent} interested in the inference.
\item
  Point out which of the examples above \emph{explicitly} give data or
  information that should be used for the inference.
\item
  For the examples that do not give explicit data or information,
  speculate what information could be implicitly assumed. For those that
  do give explicit data, speculate which other additional information
  could be implicitly assumed.
\item
  Can any of the inferences above be done with full certainty (that is,
  to know which decision is successful), based the data given explicitly
  and implicitly?
\item
  Find the examples that explicitly involve a decision. In which of them
  does the decision affect the results of the inference? In which it
  does not?
\item
  Are any of the inferences ``\emph{one-time only}''? That is, has their
  object or the data on which they are based never happened before and
  will never happen again?
\item
  Are any of the inferences above based on data and information that
  come chronologically \emph{after} the object of the inference?
\item
  Are any of the inferences above about something that is actually
  already known to the agent that's making the inference?
\item
  Are any of the inferences about something that actually did not
  happen?
\item
  Do any of the inferences use ``data'' or ``information'' that are
  actually known (within the scenario itself) to be fictive, that is,
  \emph{not} real?
\end{enumerate}

\end{tcolorbox}

From the examples and from your answers to the exercise we observe some
very important characteristics of inferences:

\begin{itemize}
\item
  Some inferences can be made exactly, that is, {\emph{without
  uncertainty}}: it is possible to say for sure whether the object of
  the inference is true or false. Other inferences, instead, involve an
  uncertainty.
\item
  {\emph{All inferences are based on some data and information}}, which
  may be explicitly expressed or only implicitly understood.
\item
  An inference can be about something \emph{past}, but based on
  \emph{present or future} data and information. In other words,
  inferences can show {\emph{all sorts of temporal relations}}.
\item
  An inference can be {\emph{essentially unrepeatable}}, because it's
  about something unrepeatable or based on unrepeatable data and
  information.
\item
  The data and information on which an inference is based can actually
  be unknown; that is, they can be only momentarily contemplated as
  real. Such an inference is said to be based on {\textbf{hypothetical
  reasoning}}.
\item
  The object of an inference can actually be something already known to
  be false or not real: the inference tries to assess it in the case
  that some data or information had been different. Such an inference is
  said to be based on {\textbf{counterfactual reasoning}}.
\end{itemize}

\section{Where are inferences drawn from?}\label{sec-inference-origin}

This question is far from trivial. In fact it has connections with the
earth-shaking development and theorems in the foundations of mathematics
that originated in the 1900s.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Mathematics:
The Loss of Certainty}}.

\end{tcolorbox}

\end{footnotesize}}

The proper answer to this question will take up the next sections. But a
central point can be emphasized now:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\textbf{Inferences can only be drawn from other inferences.}

\end{tcolorbox}

In order to draw an inference -- calculate a probability -- we usually
go up a chain: we must first draw other inferences, and for drawing
those we must draw yet other inferences, and so on.

At some point we must stop at \emph{inferences that we take for granted
without further proof}. These typically concern direct experiences and
observations. For instance, you see a tree in front of you, so you can
take ``there's a tree here'' as a true fact. Yet, notice that the
situation is not so clear-cut: how do you know that you aren't
hallucinating, and there's actually no tree there? That is taken for
granted. If you analyse the possibility of hallucination, you realize
that you are taking other things for granted, and so on.

Probably most philosophical research in the history of humanity has been
about grappling with this runaway process -- which is also a continuous
source of sci-fi films. In logic and mathematical logic, this
corresponds to the fact that in order to prove some \emph{theorem}, we
must always start from some \emph{axioms}. There are ``inferences'',
called \emph{tautologies}, that can be drawn without requiring others,
but they are all trivial: for example ``this component failed early, or
it didn't''. These tautologies are of little use in a real problem,
although they have a deep theoretical importance. Useful inferences, on
the other hand, must always start from some axioms.

\marginnote{\begin{footnotesize}

\begin{figure}[H]

{\centering \includegraphics[width=0.75\linewidth,height=\textheight,keepaspectratio]{the_matrix.jpg}

}

\caption{Sci-fi films like
\href{https://www.themoviedb.org/movie/603-the-matrix}{\emph{The
Matrix}} ultimately draw on the fact that we must take some inferences
for granted without further proof.}

\end{figure}%

\end{footnotesize}}

In concrete applications, we start from many inferences upon which
everyone, luckily, agrees. But sometimes we must also use starting
inferences that are more dubious or not agreed upon by everyone. In this
case the final inference has a somewhat contingent character. We accept
it (as well as the solution of any underlying decision problem) as the
best available one for the moment. This is partly the origin of the term
``{\textbf{model}}''.

\section{Basic elements of an
inference}\label{sec-basic-elements-inference}

Let us introduce some mathematical notation and more precise terminology
for inferences.

\begin{itemize}
\item
  Every inference has an ``object'': what is to be assessed or guessed.
  We call {\textbf{proposal}} the object of the inference.
\item
  Every inference also has data, information, hypotheses, or
  hypothetical scenarios on which it is based. We call
  {\textbf{conditional}} what the inference is based upon.
\item
  We separate \emph{proposal} and \emph{conditional} with a vertical
  bar~~{{``\,\(\pmb{\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}}}\)\,''},}
  which can be pronounced ``{\textbf{given}}'' or ``{\textbf{conditional
  on}}''.
\item
  Finally, we put parentheses around this and a {``\(\mathrm{P}\)''} in
  front, short for ``probability'':
\end{itemize}

\marginnote{\begin{footnotesize}

{\emph{Proposal} is Johnson's (1924) terminology; Keynes (1921) uses
``conclusion''; modern textbooks do not seem to use any specialized
term. \emph{Conditional} is modern terminology; other terms used:
``evidence'', ``premise'', ``supposal''. The \emph{vertical bar},
originally a
\href{https://dictionary.cambridge.org/dictionary/english/solidus}{solidus},
was introduced by Keynes (1921).}

\end{footnotesize}}

\[
\mathrm{P}( \underbracket[1px]{\color[RGB]{34,136,51}\boldsymbol{\cdots}}_{\textit{proposal}}
\nonscript\:\vert\nonscript\:\mathopen{}
\underbracket[1px]{\color[RGB]{68,119,170}\boldsymbol{\cdots}}_{\textit{conditional}}
) = {\color[RGB]{238,102,119}\boldsymbol{\cdots}\%}
\]

this means ``{the probability that
{\emph{\hyperref[proposal]{proposal}}}, supposing
{\emph{\hyperref[conditional]{conditional}}}, is
{\emph{.\,.\,.\,\%}}}''. Or also: ``{supposing
{\emph{\hyperref[conditional]{conditional}}}, we can infer
{\emph{\hyperref[proposal]{proposal}}} with {\emph{.\,.\,.\,\%}}
probability}''.

We have remarked that in order to calculate the probability for an
inference, we must use the probabilities of other inferences, which in
turn are calculated by using the probabilities of other inferences, and
so on, until we arrive at probabilities that are taken for granted. A
basic inference process could therefore be schematized like this:

\begin{center}
\includegraphics[width=0.9\linewidth,height=\textheight,keepaspectratio]{probtree.png}
\end{center}

\hfill\break

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

The next important task ahead of us is to introduce a flexible and
enough general mathematical representation for the objects of an
inference. Thereafter we shall study the rules for drawing correct
inferences.

\chapter{\texorpdfstring{{Sentences}}{Sentences}}\label{sec-sentences}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

We have seen that an inference involves, at the very least, two things:
the object of the inference (\emph{proposal}), and the data,
information, or hypotheses on which the inference is based
(\emph{conditional}).

We also observed that wildly different ``things'' can be the object of
an inference or the information on which the inference is based:
measurement results, decision outcomes, hypotheses, not-real events,
assumptions, data and information of all kinds (for example, images). In
fact, such variety in some cases can make it difficult to pinpoint what
an inference is about or what it is based upon.

Is there a general, flexible, yet precise way of representing all these
kinds of ``things''?

\section{The central components of knowledge
representation}\label{sec-central-comps}

When speaking of ``data'', what comes to mind to many people is numbers
or collections of numbers. Maybe numbers, then, could be used to
represent all the variety of ``things'' exemplified above? Well, this
option turns out to be too restrictive.

I give you this number: {``\(8\)''}, saying that it is ``data''. But
what is it about? You, as an agent, can hardly call this number a piece
of information, because you have no clue what to do with it.

Instead, if I tell you:
``\href{https://solarsystem.nasa.gov/planets/overview}{The number of
official planets in the solar system is 8}'', then we can say that I've
given you data. You can do different things with this piece of
information. For instance, if you had decided to send one probe to each
official planet, now you know you have to build eight probes. Or maybe
you can win at a pub quiz with it.

``Data'' is therefore not just numbers. A number is not ``data'' unless
there's an additional verbal and non-numeric context accompanying it --
even if only implicitly. Sure, we could represent this meta-data
information as numbers too; but this move would only shift the problem
one level up: we would need an auxiliary verbal context explaining what
the meta-data numbers are about.

Data can, moreover, be completely non-numeric. A clinician saying ``The
patient has fully recovered from the disease'' is giving us a piece of
information that we could further use, for instance, to make prognoses
about other, similar patients. The clinician's statement surely is
``data'', but is essentially non-numeric data. Sure, in some situations
we could represent this data with numbers, say ``1'' for ``recovered''
and ``0'' for ``not recovered''. But the opposite or some other
convention could also be used: ``0'' for ``recovered'' and ``1'' for
``not recovered'', or the numbers ``0.3'' and ``174''. These numbers
have intrinsically nothing to do with the clinician's ``recovery'' data.

\hfill\break

The examples above, however, actually reveal the answer to our needs! In
the examples we expressed the data by means of \emph{sentences}. Clearly
any measurement result, decision outcome, hypothesis, not-real event,
assumption, data, and any piece of information can be expressed by a
sentence.

We shall therefore use {\textbf{sentences}}, also called
{\textbf{propositions}} or \textbf{statements},\footnote{These three
  terms are not always equivalent in formal logic, but here we'll use
  them as synonyms.} to represent and communicate all the kinds of
``things'' that can be the proposal or the conditional of an inference.
In some cases we can of course summarize a sentence by a number, as a
shorthand, when the full meaning of the sentence is understood.\\
\strut \\

\emph{Sentences are the central components of knowledge representation
in AI agents}. For example they appear at the heart of automated control
programs and fault-management systems in NASA spacecrafts.

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{SMART.png}
(From the \emph{SMART} paper)

\end{footnotesize}}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  §7.1 in
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}.
\item
  Take a \emph{quick look} at these:

  \begin{itemize}
  \tightlist
  \item
    \href{https://hvl.instructure.com/courses/32045/modules}{\emph{SMART:
    A propositional logic-based trade analysis and risk assessment tool
    for a complex mission}}
  \item
    around p.\,22 in
    \href{https://www.nasa.gov/sites/default/files/637606main_day_1-michel_ingham.pdf}{\emph{No
    More Band-Aids: Integrating FM into the Onboard Execution
    Architecture}}
  \item
    part\,IV in
    \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Model-based
    programming of intelligent embedded systems and robotic space
    explorers}}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\section{Identifying and working with
sentences}\label{identifying-and-working-with-sentences}

But what is a sentence, more exactly? The everyday meaning of this word
will work for us, even though there are more precise definitions -- and
still a lot of research in logic an artificial intelligence on how to
define and use sentences. We shall adopt this useful definition:

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://plato.stanford.edu/archives/win2020/entries/propositions}{Propositions}

\end{tcolorbox}

\end{footnotesize}}

{\emph{A \textbf{sentence} is a verbal message for which an agent can
determine, at least in principle, whether it is \texttt{true} or
\texttt{false}.}}

Let's make this definition clearer with some remarks:

\begin{itemize}
\item
  {\textbf{\faIcon{hand-point-right} A sentence doesn't have to contain
  only words}}. It can contain pictures, sounds, and other non-verbal
  items. For example, the following:

  ``{This:
  \includegraphics[width=\linewidth,height=3em,keepaspectratio]{saitama_transform.png}
  is an animated picture of Saitama.}''

  is a sentence, even if it contains animated graphics, because we can
  say that it is \texttt{true}. Likewise, the following:

  ``{\href{iliketrafficlights.mp3}{This link} leads to a song by Pink
  Floyd.}''

  is also a sentence, even if it contains links and audio, because we
  can say that it is \texttt{false} (that's a song by Monty Python).
\item
  {\textbf{\faIcon{hand-point-right} A meaningful phrase may not be a
  sentence}}. For instance, a phrase like ``{Apples are much tastier
  than pears}'' may not be a sentence, because it's a matter of personal
  taste whether it's \texttt{true} or \texttt{false}. Moreover, an
  agent's opinion about apples and pears might change from time to time.

  The phrase ``{Jenny right now finds apples tastier than pears}'', on
  the other hand, could be a sentence; its truth being found by asking
  Jenny at that very moment.

  In an engineering context, the phrase ``{This valve will operate for
  at least two months}'' is a sentence, even if its truth is unknown at
  the moment: one has to wait two months, and then its truth will be
  unambiguously known.
\end{itemize}

\begin{itemize}
\item
  {\textbf{\faIcon{hand-point-right} An expression involving technical
  terms may not be a sentence (and not meaningful either)}}. For
  instance, in a data-science context the phrase ``{This neural-network
  algorithm has better performance than that random-forest one}'' is
  \emph{not} a sentence unless we have objectively specified what
  ``better'' means (higher accuracy? higher true-positive rate?
  faster?), for example by adopting a particular comparison metric.

  Some expressions involving technical terms may appear to be sentences
  at first; but a deeper analysis then reveals that they are not. A
  famous example is the sentence ``{The two events (at different spatial
  locations) are simultaneous}''. Einstein showed that there's no
  physical way to determine whether such an expression is true or false.
  Its truth turns out to be a matter of convention. The Theory of
  Relativity was born from this observation.
\end{itemize}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://einsteinpapers.press.princeton.edu/vol2-trans/154}{\emph{On
the electrodynamics of moving bodies}}.

\end{tcolorbox}

\end{footnotesize}}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={Important}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\faIcon{exclamation-circle} Be particularly careful when reading
scientific and engineering papers with a lot of technical terms and
phrases. Technical jargon often makes it especially difficult to see
whether something true or at least meaningful is being said, or not!

\end{tcolorbox}

\begin{itemize}
\tightlist
\item
  {\textbf{\faIcon{hand-point-right} A sentence can be expressed in
  different ways}} by different phrases and in different languages. For
  instance, ``{The temperature is 248.15\,K}'', ``{Temperaturen ligger
  på minus 25 grader}'', and ``{25\,°C is the value of the
  temperature}'' all represent the \emph{same} sentence.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

There are many advantages in working with sentences (rather than just
numbers), and in keeping in mind that every inference is about
sentences:

First, this point of view leads to \textbf{clarity} in engineering
problems, and makes them more \textbf{goal-oriented}. A data engineer
must acquire information and convey information. ``Acquiring
information'' does not simply consist in making measurements or counting
something: the engineer must understand \emph{what} is being measured
and \emph{why}. If data is gathered from third parties, the engineer
must ask what exactly the data mean and how they were acquired. In
designing a solution, it is important to understand what information or
outcomes the end user exactly wants. These ``what'', ``why'', ``how''
are expressed by sentences. A data engineer will often ask ``\emph{wait,
what do you mean by that?}''. This question is not just an unofficial
parenthesis in the official data-transfer workflow between the engineer
and someone else. It is an integral part of that workflow: it means that
some information has not been completely transferred yet.

Second, this point of view is extremely important in AI and
machine-learning design. A (human) engineer may proceed informally when
drawing inferences, without worrying about ``sentences'' unless a need
for disambiguation arises. A data engineer who's \emph{designing} or
\emph{programming} an algorithm that will do inferences automatically,
must instead be unambiguous and cover beforehand all possible cases that
the algorithm will face.

\hfill\break

We therefore agree that {\emph{the proposal and the conditional of an
inference have to be sentences}}. This means that the proposal of the
inference must be something that can be true or false.

Many inferences, especially when they concern numerical measurements,
involve more than one sentence. For example, an inference about the
result of rolling a die actually consists of the probabilities for six
separate proposals:

\[
\begin{aligned}
&\textsf{\small`The result of the roll is 1'}
\\
&\textsf{\small`The result of the roll is 2'}
\\
&\dotso
\\
&\textsf{\small`The result of the roll is 6'}
\end{aligned}
\]

Later on we shall see how to work with more complex inferences of this
kind. In real applications it can be useful, on some occasions, to pause
and reduce an inference to its basic set of \texttt{true}/\texttt{false}
sentences. This analysis may reveal contradictions in our inference
problem. A simple way to do this is to reduce the complex inference into
a set of yes/no questions.

This kind of analysis is also important in information-theoretic
situations: the {\textbf{information content}} provided by an inference,
when measured in \emph{Shannons}, is related to the minimal amount of
yes/no questions that the inference answers.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Rewrite each inference scenario of §~\ref{sec-inference-scenarios} in a
formal way, as one or more inferences

\[
\textit{[proposal]}\ \pmb{\nonscript\:\Big\vert\nonscript\:\mathopen{}}\ \textit{[conditional]}
\]

where proposal and conditional are well-defined sentences.

In ambiguous cases, use your judgement and motivate your choices.

\end{tcolorbox}

\section{Notation and abbreviations}\label{sec-sentence-notation}

Writing full sentences would take up \emph{a lot} of space. Even an
expression such as ``{The speed is 10\,m/s}'' is not a sentence,
strictly speaking, because it leaves unspecified the speed of what, when
it was measured and in which frame of reference, what we mean by
``speed'', how the unit ``m/s'' is defined, and so on.

Typically we leave the full content of a sentence to be understood from
the context, and we denote the sentence by a simple expression. Example:

\[
\textsf{\small The speed is 10\,m/s}
\]

or even more compactly introducing physical symbols:

\[
v \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}10\,\mathrm{m/s}
\]

where {\(v\)} is a physical variable denoting the speed. Sometimes we
may simply write

\[
10\,\mathrm{m/s}
\]

In some problems it's useful to introduce symbols to denote sentences.
As mentioned before, in these notes we'll use sans-serif italic letters:
{\(\mathsfit{A},\mathsfit{B},\mathsfit{a},\mathsfit{b},\dotsc\),}
possibly with sub- or super-scripts. For instance, the sentence ``{The
speed is 10\,m/s}'' could be denoted by the symbol
{\(\mathsfit{S}_{10}\).} We express such a definition like this:

\[
\mathsfit{S}_{10} \coloneqq\textsf{\small`The speed is 10\,m/s'}
\]

which means that the symbol {\(\mathsfit{S}_{10}\)} is defined to be the
sentence {\(\textsf{\small`The speed is 10\,m/s'}\)}.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} We must be wary of how much we shorten
sentences}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Consider these three sentences:

\[
\begin{aligned}
&\textsf{\small`The speed is measured to be 10\,m/s'}
\\
&\textsf{\small`The speed is set to 10\,m/s'}
\\
&\textsf{\small`The speed is reported, by a third party, to be 10\,m/s'}
\end{aligned}
\]

The quantity ``10\,m/s'' is the same in all three sentences, but their
meanings are very different. They represent different kinds of data. The
difference greatly affect any inference about or from these data. For
instance, in the third case an engineer may not take the
indirectly-reported speed ``10\,m/s'' at face value, unlike in the first
case. In a scenario where all three sentences can occur, it would be
ambiguous to simply write {``\(v = 10\,\mathrm{m/s}\)''}: would the
equal-sign mean ``measured'', ``set'', or ``indirectly reported''?

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

How would you denote the three sentences above, to make their
differences clear?

\end{tcolorbox}

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={Get familiar with abbreviations of sentences}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

To summarize, a sentence like

\[
\textsf{\small`The temperature $T$ has value $x$'}
\]

could be abbreviated in these different ways:

\begin{itemize}
\item
  A symbol for the sentence (note the sans-serif font):

  \[
  \mathsfit{S}
  \]
\item
  Some key word appearing in the sentence:

  \[
  \textsf{\small temperature}
  \]
\item
  An equality:

  \[
  T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
  \]
\item
  The quantity appearing in the sentence:

  \[
  T
  \]
\item
  The value appearing in the sentence:

  \[
  x
  \]
\end{itemize}

Get familiar with these kinds of abbreviations because they are all very
common. Some texts may even jump from one abbreviation to another in the
same page or paragraph!

\end{tcolorbox}

\hfill\break

\section{Connecting sentences}\label{sec-connecting-sentences}

\subsection{Atomic sentences}\label{atomic-sentences}

In analysing the measurement results, decision outcomes, hypotheses,
assumptions, data and information that enter into an inference problem,
it is convenient to find a collection of \textbf{basic sentences} or,
using a more technical term, {\textbf{atomic sentences}}, out of which
all other sentences of interest can be constructed. These atomic
sentences often represent elementary pieces of information in the
problem.

Consider for instance the following composite sentence, which could
appear in our assembly-line scenario:

\begin{quote}
``The electronic component is still whole after the shock test and the
subsequent heating test. The voltage reported in the final power test is
either 90\,mV or 110\,mV.''
\end{quote}

In this statement we can identify at least four atomic sentences, which
we denote by these symbols:

\[\begin{aligned}
\mathsfit{s} &\coloneqq\textsf{\small`The component is whole after the shock test'}
\\
\mathsfit{h} &\coloneqq\textsf{\small`The component is whole after the heating test'}
\\
\mathsfit{v}_{90} &\coloneqq\textsf{\small`The power-test voltage reading is 90\,mV'}
\\
\mathsfit{v}_{110} &\coloneqq\textsf{\small`The power-test voltage reading is 110\,mV'}
\end{aligned}
\]

The inference may actually require additional atomic sentences. For
example it might become necessary to consider atomic sentences with
other values for the reported voltage, such as

\[\begin{aligned}
\mathsfit{v}_{110} &\coloneqq\textsf{\small`The power-test voltage reading is 100\,mV'}
\\
\mathsfit{v}_{80} &\coloneqq\textsf{\small`The power-test voltage reading is 80\,mV'}
\end{aligned}\]

and so on.

\subsection{Connectives}\label{connectives}

How do we construct composite sentences, like the one above, out of
atomic sentences?

We consider three ways: one operation to change a sentence into another
related to it, and two operations to combine two or more sentences
together. These operations are called {\textbf{connectives}}. You may
have already encountered them in Boolean algebra. Our natural language
offers many more operations to combine sentences, but these three
connectives turn out to be all we need in virtually all engineering and
data-science problems:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{description}
\tightlist
\item[{Not {(symbol}~~\(\lnot\)\,{)}}]
example:
\end{description}

\[\begin{aligned}
\mathsfit{s} &\coloneqq\textsf{\small`The component is whole after the shock test'}
\\[1ex]
\lnot \mathsfit{s} &= \textsf{\small`The component is broken after the shock test'}
\end{aligned}\]

\begin{description}
\tightlist
\item[{And
{(symbols}~~\(\land\)~~{also}~~\(\mathbin{\mkern-0.5mu,\mkern-0.5mu}\)~{)}}]
example:
\end{description}

\[
\begin{aligned}
\mathsfit{s} &\coloneqq\textsf{\small`The component is whole after the shock test'}
\\
\mathsfit{h} &\coloneqq\textsf{\small`The component is whole after the heating test'}
\\[1ex]
\mathsfit{s} \land \mathsfit{h} &= \textsf{\small`The component is whole after the shock and heating tests'}
\\
\mathsfit{s} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{h} &= \textsf{\small`The component is whole after the shock and heating tests'}
\end{aligned}
\]

\begin{description}
\tightlist
\item[{Or {(symbol}~~\(\lor\)\,{)}}]
example:
\end{description}

\[\begin{aligned}
\mathsfit{v}_{90} &\coloneqq\textsf{\small`The power-test voltage reading is 90\,mV'}
\\
\mathsfit{v}_{110} &\coloneqq\textsf{\small`The power-test voltage reading is 110\,mV'}
\\[1ex]
\mathsfit{v}_{90} \lor \mathsfit{v}_{110} &= \textsf{\small`The power-test voltage reading is 90\,mV, or 110\,mV, or both'}
\end{aligned}\]

\end{tcolorbox}

These connectives can be applied multiple times, to form increasingly
more complex composite sentences.

The \texttt{and} connective appears very frequently in probability
formulae. Using its standard symbol {``\(\land\)''} would consume a lot
of horizontal space. For this reason a comma
{``\(\mathbin{\mkern-0.5mu,\mkern-0.5mu}\)''} is often used as an
alternative symbol. So the expressions
{\(\mathsfit{s} \land \mathsfit{h}\)} and
{\(\mathsfit{s} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{h}\)}
\textbf{are completely equivalent}.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Important subtleties of the connectives:}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  There is \emph{no strict correspondence} between the words ``not'',
  ``and'', ``or'' in natural language and the three connectives. The
  \texttt{and} connective may for instance correspond to the words
  ``but'' or ``whereas'', or just to a comma ``\,,\,''.
\item
  \texttt{Not} means not some kind of complementary quality, but the
  denial. For
  instance,~~{\(\lnot\textsf{\small`The chair is black'}\)~~generally}
  does not mean~~{\(\textsf{\small`The chair is white'}\)\,,~~}
  (although in some situations these two sentences could amount to the
  same thing).

  It's always best to \emph{declare explicitly what the \texttt{not} of
  a sentence concretely means}. In our example we take

  \[
    \lnot\textsf{\small`The component is whole'} \coloneqq\textsf{\small`The component is broken'}
    \]

  But in other examples the negation of ``being whole'' could comprise
  several different conditions. A good guideline is to always state the
  \texttt{not} of a sentence in \emph{positive} terms.
\item
  \texttt{Or} does not exclude that the sentences it connects can be
  both true. So in our
  example~~{\(\mathsfit{v}_{90} \lor \mathsfit{v}_{110}\)~~does} not
  exclude, a priori, that the reported voltage could be both 90\,mV and
  110\,mV. (There is a connective for that: ``exclusive-or'', but it can
  be constructed out of the three we already have.)
\end{itemize}

\end{tcolorbox}

From the last remark we see that the sentence

\[
\textsf{\small`The power-test voltage reading is 90\,mV or 110\,mV'}
\]

does \emph{not} correspond to
~~{\(\mathsfit{v}_{90} \lor \mathsfit{v}_{110}\)\,.~~It} is implicitly
understood that a voltage reading cannot yield two different values at
the same time. Convince yourself that the correct way to write that
sentence is this:

\[
(\mathsfit{v}_{90} \lor \mathsfit{v}_{110})
\land
\lnot(\mathsfit{v}_{90} \land \mathsfit{v}_{110})
\]

Finally, the full composite sentence of the present example can be
written in symbols as follows:

\begin{quote}
``{The electronic component is still whole after the shock test} and
{the subsequent heating test}. {The voltage reported in the final power
test is} either {90\,mV} or {110\,mV}.''
\end{quote}

\[
\textcolor[RGB]{102,204,238}{\mathsfit{s}} \land \textcolor[RGB]{34,136,51}{\mathsfit{h}} \land
(\textcolor[RGB]{238,102,119}{\mathsfit{v}_{90}} \lor \textcolor[RGB]{170,51,119}{\mathsfit{v}_{110}})
\land
\lnot
(\textcolor[RGB]{238,102,119}{\mathsfit{v}_{90}} \land \textcolor[RGB]{170,51,119}{\mathsfit{v}_{110}})
\]

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Take a quick look at §7.4.1 in
\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
Intelligence}} and note the similarities with what we've just learned.
In these notes we follow a faster approach leading directly to
probability logic.

\end{tcolorbox}

\section{\texorpdfstring{``If\ldots{}
then\ldots{}''}{``If\ldots{} then\ldots''}}\label{if-then}

Sentences expressing data and information in natural language also
appear connected with \emph{if\ldots{} then\ldots{}}. For instance:
``{If the voltage reading is 200\,mV, then the component is
defective}''. This kind of expression actually indicates that the
following inference

\[
\textsf{\small`The component is defective'} \pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} \textsf{\small`The voltage reading is 200\,mV'}
\]

is \texttt{true}.

This kind of information is very important because it is often the
starting point of our inferences. We shall discuss this point in more
detail in the next sections.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Careful}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

There is a connective in logic, called
``\href{https://plato.stanford.edu/entries/logic-propositional/\#MateCond}{material
conditional}'', which is also often translated as ``if\ldots{}
then\ldots{}''. But it is not the same as the inference relation
discussed above. ``If\ldots{} then\ldots{}'' in natural language usually
denotes an inference rather than a material conditional.

Research is still ongoing on these topics. If you are curious and in for
a headache, look over
\href{https://plato.stanford.edu/entries/logic-conditionals}{\emph{The
logic of conditionals}}.

\end{tcolorbox}

\hfill\break

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

We are now equipped with all the notions and symbolic notation to deal
with our next task: learning the rules for drawing correct inferences.

{@@ TODO: add connections to impossibility of large language models to
learn maths (Gödel \& Co.).}

\chapter{\texorpdfstring{{Truth
inference}}{Truth inference}}\label{sec-truth-inference}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\ys}{\se{s}}
\providecommand*{\yh}{\se{h}}
\providecommand*{\yf}{\se{f}}
\providecommand{\tru}{\mathrm{T}}
\providecommand*{\yZ}{\se{Z}}

Some inferences can be drawn with absolute certainty, that is, we can
ascertain for sure the truth or falsity of their proposal. We call this
particular ``sure'' kind of inferences \emph{truth inferences}.
Mathematical inferences are a typical example of this kind. You probably
have some acquaintance with rules for drawing truth inferences, so we
start from these.

\section{A trivial inference}\label{sec-trivial-inference}

Consider again the assembly-line scenario of §~\ref{sec-intro}, and
suppose that an inspector has the following information about an
electric component:

\begin{quote}
This electric component had an early failure (within a year of use). If
an electric component fails early, then at production it didn't pass
either the shock test or the heating test. This component passed the
shock test.
\end{quote}

The inspector wants to assess whether the component did not pass the
heating test.

From the data and information given, the conclusion is that the
component \emph{for sure} did not pass the heating test. This conclusion
is certain and somewhat trivial. But how did we obtain it? Which rules
did we follow to arrive at it from the given data?

{\emph{Formal logic}}, with its \emph{deduction systems}, is the huge
field that formalizes and makes rigorous the rules that a rational
person or an artificial intelligence should use in drawing \emph{sure}
inferences like the one above. We'll now get a glimpse of it, as a
trampoline for jumping towards more general and \emph{uncertain}
inferences.

\section{Analysis and representation of the
problem}\label{analysis-and-representation-of-the-problem}

First let's analyse our simple problem and represent it with compact
symbols.

\subsection{Atomic sentences}\label{atomic-sentences-1}

We can introduce the following atomic sentences and symbols:

\[
\begin{aligned}
\mathsfit{h}&\coloneqq\textsf{\small`The component passed the heating test'}
\\
\mathsfit{s}&\coloneqq\textsf{\small`The component passed the shock test'}
\\
\mathsfit{f}&\coloneqq\textsf{\small`The component had an early failure'}
\\
\mathsfit{I}&\coloneqq\textsf{\small (all other implicit background information)}
\end{aligned}
\]

\subsection{Proposal}\label{proposal}

The proposal is {\(\lnot\mathsfit{h}\),} but in the present case we
could also have chosen {\(\mathsfit{h}\).}

\subsection{Conditional}\label{conditional}

The bases for the inference are two known facts in the present case:
{\(\mathsfit{s}\)} and {\(\mathsfit{f}\).} There may also be other
obvious facts implicitly assumed in the inference, which we denote by
{\(\mathsfit{I}\).}

\subsection{Starting inferences}\label{starting-inferences}

Let us emphasize again that any inference is drawn from other
inferences, which are either taken for granted, or drawn in turn from
others. In the present case we are told that if an electric component
fails early, then at production it didn't pass either the shock test or
the heating test. We write this as

\[
\lnot\mathsfit{s}\lor \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I}
\]

and we shall take this to be \texttt{true} (that is, to have probability
{\(100\%\)).}

But our scenario actually has at least one more, hidden, inference. We
said that the component failed early, and that it did pass the shock
test. This means, in particular, that it must be possible for the
component to pass the shock test, even if it fails early. This means
that

\[
\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I}
\]

can\emph{not} be \texttt{false}.

\subsection{Target inference}\label{target-inference}

The inference that the inspector wants to draw can be compactly written:

\[
\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{s}\land \mathsfit{f}\land \mathsfit{I}
\]

\section{Truth-inference rules}\label{sec-truth-inference-rules}

\subsection{Deduction systems; a specific
choice}\label{deduction-systems-a-specific-choice}

Formal logic gives us a set of rules for correctly drawing sure
inferences, \emph{when sure inferences are possible}. These rules can be
formulated in different ways, leading to a wide variety of
\href{https://plato.stanford.edu/archives/spr2023/entries/natural-deduction}{deduction
systems} (each one with a wide variety of possible notations). These
systems are all equivalent, of course. The picture on the margin, for
instance, shows how a proof of how our inference would look like, using
the so-called sequent calculus, which consists of a dozen or so
inference rules.

\marginnote{\begin{footnotesize}

\begin{figure}[H]

{\centering \includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{failure_sequent_red.png}

}

\caption{The {bottom formula} is the target inference. Each line denotes
the application of an inference rule, from one or more inferences above
the line, to one below the line. The two formulae with no line above are
our {starting inference}, and a tautology.}

\end{figure}%

\end{footnotesize}}

\hfill\break

We choose to compactly encode all truth-inference rules in the following
way.

First, represent \texttt{true} by the number {\(\mathbf{1}\),} and
\texttt{false} by {\(\mathbf{0}\).}

Second, symbolically write that a proposal {\(\mathsfit{Y}\)} is
\texttt{true}, given a conditional {\(\mathsfit{X}\),} as follows:

\[
\mathrm{T}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}) = 1
\]

or {``\(=0\)''} if it's \texttt{false}.

The rules of truth-inference are then encoded by the following
equations, which must always hold for any atomic or composite sentences
{\(\mathsfit{X},\mathsfit{Y},\mathsfit{Z}\):}

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{description}
\tightlist
\item[Rule for ``not'':]
\begin{equation}\phantomsection\label{eq-t-not}{\mathrm{T}(\lnot \mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) 
+ \mathrm{T}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
= 1}\end{equation}
\item[Rule for ``and'':]
\begin{equation}\phantomsection\label{eq-t-and}{
\mathrm{T}(\mathsfit{X}\land \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) 
= \mathrm{T}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}\land \mathsfit{Z}) \cdot
\mathrm{T}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) 
= \mathrm{T}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land \mathsfit{Z}) \cdot
\mathrm{T}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
}\end{equation}
\item[Rule for ``or'':]
\begin{equation}\phantomsection\label{eq-t-or}{\mathrm{T}(\mathsfit{X}\lor \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) 
= \mathrm{T}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) +
\mathrm{T}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) 
- \mathrm{T}(\mathsfit{X}\land \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
}\end{equation}
\item[Rule for truth:]
\begin{equation}\phantomsection\label{eq-t-unity}{\mathrm{T}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land \mathsfit{Z}) 
= 1
}\end{equation}
\end{description}

\textbf{How to use the rules}: Each equality can be rewritten in
different ways according to the usual rules of algebra. Then the
resulting left side can be replaced by the right side, and vice versa.
The numerical values of starting inferences can be replaced in the
corresponding expressions.

\end{tcolorbox}

\end{figure*}%

Let's see two examples:

\begin{itemize}
\item
  from one rule for ``and'' we can obtain the equality

  \[
  {\color[RGB]{102,204,238}\mathrm{T}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}\land \mathsfit{Z})}
  =\color[RGB]{204,187,68}\frac{\mathrm{T}(\mathsfit{X}\land \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})}{\mathrm{T}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})}
  \]

  provided that
  {\(\mathrm{T}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) \ne 0\).}
  Then wherever we see the {left side}, we can replace it with the
  fraction on the {right side}, and vice versa.
\item
  from the rule for ``or'' we can obtain the equality

  \[
  {\color[RGB]{102,204,238}
  \mathrm{T}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) - \mathrm{T}(\mathsfit{X}\land \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})}
  =\color[RGB]{204,187,68}
  \mathrm{T}(\mathsfit{X}\lor \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) - \mathrm{T}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
  \]

  Again wherever we see the {left side}, we can replace it with the sum
  on the {right side}, and vice versa.
\end{itemize}

\subsection{Target inference in our
scenario}\label{target-inference-in-our-scenario}

Let's see how these rules allow us to arrive at our target inference,

\[
\color[RGB]{238,102,119}\mathrm{T}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{s}\land \mathsfit{f}\land \mathsfit{I})
\]

starting from the given ones

\[
\color[RGB]{34,136,51}\mathrm{T}(\lnot\mathsfit{s}\lor \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I}) = 1
\ ,
\qquad
\mathrm{T}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I}) \ne 0
\]

One possibility is to work backwards from the target inference:

\begin{figure*}

\[
\begin{aligned}
&\color[RGB]{238,102,119}\mathrm{T}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{s}\land \mathsfit{f}\land \mathsfit{I})&&
\\[1ex]
&\qquad=\frac{\mathrm{T}(\lnot\mathsfit{h}\land \mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})}
{\color[RGB]{34,136,51}\underbracket[1pt]{\mathrm{T}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})}_{\ne 0}}
&&\text{\small ∧-rule and starting inference}
\\[1ex]
&\qquad=\frac{\mathrm{T}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \lnot\mathsfit{h}\land \mathsfit{f}\land \mathsfit{I})\cdot
\mathrm{T}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})
}
{\mathrm{T}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})}
&&\text{\small ∧-rule}
\\
&\qquad=\frac{\bigl[1-\mathrm{T}(\lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \lnot\mathsfit{h}\land \mathsfit{f}\land \mathsfit{I})\bigr]\cdot
\mathrm{T}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})
}
{\mathrm{T}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})}
&&\text{\small ¬-rule}
\\
&\qquad=\frac{\mathrm{T}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})-
\mathrm{T}(\lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \lnot\mathsfit{h}\land \mathsfit{f}\land \mathsfit{I})\cdot
\mathrm{T}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})
}
{\mathrm{T}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})}
&&\text{\small algebra}
\\
&\qquad=\frac{\mathrm{T}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})-
\mathrm{T}(\lnot\mathsfit{s}\land \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})
}
{\mathrm{T}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})}
&&\text{\small  ∧-rule}
\\
&\qquad=\frac{{\color[RGB]{34,136,51}\mathrm{T}(\lnot\mathsfit{s}\lor \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})}-
\mathrm{T}(\lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})
}
{\mathrm{T}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})}
&&\text{\small  ∨-rule}
\\
&\qquad=\frac{{\color[RGB]{34,136,51}1} -
\mathrm{T}(\lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})
}
{\mathrm{T}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})}
&&\text{\small starting inference}
\\
&\qquad=\frac{\mathrm{T}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})}
{\mathrm{T}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})}
&&\text{\small ¬-rule}
\\[1ex]
&\qquad=\color[RGB]{238,102,119}1
&&\text{\small algebra}
\end{aligned}
\]

\end{figure*}%

Therefore
{\(\color[RGB]{238,102,119}\mathrm{T}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{s}\land \mathsfit{f}\land \mathsfit{I}) = 1\).}
We find that, indeed, the electronic component must for sure have failed
the heating test!

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Retrace the proof above step by step. At each step, how was its
particular rule (indicated on the right) used?

\end{tcolorbox}

\hfill\break

The way in which the rules can be applied to arrive at the target
inference is not unique. In fact, in some concrete applications it can
require a lot of work to find how to connect target inference with
starting ones via the rules. The result, however, will always be the
same:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\textbf{The rules of truth-inference are self-consistent}: even if
applied in different sequences of steps, they always lead to the same
final result.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Prove the target inference
{\(\color[RGB]{238,102,119}\mathrm{T}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{s}\land \mathsfit{f}\land \mathsfit{I}) = 1\)}
using the rules of truth-inference, but beginning from the starting
inference
{\(\color[RGB]{34,136,51}\mathrm{T}(\lnot\mathsfit{s}\land \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I})=1\).}

\end{tcolorbox}

\subsection{\texorpdfstring{{[}\emph{Optional}{]} Equivalence with
truth-tables}{{[}Optional{]} Equivalence with truth-tables}}\label{optional-equivalence-with-truth-tables}

If you have studied Boolean algebra, you may be familiar with
truth-tables; for instance the one for ``and'' displayed on the side.
The truth-inference rules (\ref{eq-t-not})--(\ref{eq-t-unity}) contain
the truth-tables that you already know as special cases.

\marginnote{\begin{footnotesize}

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
\(\mathsfit{X}\) & \(\mathsfit{Y}\) &
\(\mathsfit{X}\land \mathsfit{Y}\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 1 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 0 \\
\end{longtable}

\end{footnotesize}}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Use the truth-inference rules for ``or'' and ``and'' to build the
truth-table for ``or''. Check if it matches the one you already knew.

\end{tcolorbox}

The truth-inference rules (\ref{eq-t-not})--(\ref{eq-t-unity}) are more
complicated than truth-tables, but have two important advantages. First,
they allow us to work with conditionals, and to move sentences between
proposals and conditionals. Second, they provide a smoother transition
to the rules for probability-inference.

\section{Logical AI agents and their
limitations}\label{logical-ai-agents-and-their-limitations}

The truth-inference discussed in this section are also the rules that a
\emph{logical AI agent} should follow. For example, the automated
control and fault-management programs in NASA spacecrafts, mentioned in
§~\ref{sec-central-comps}, are programmed according to these rules.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Look over Ch.~7 in
\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
Intelligence}}.

\end{tcolorbox}

Many -- if not most -- inference problems that human and AI agents must
face are, however, of the \emph{uncertain} kind: it is not possible to
surely infer the truth of some outcome, and the truth of some initial
data or initial inferences may not be known either. We shall now see how
to generalize the truth-inference rules to uncertain situations.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Our cursory visit of formal logic only showed a microscopic part of this
vast field. The study of truth-inference rules continues still today,
with many exciting developments and applications. Feel free to take a
look at

\begin{itemize}
\tightlist
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Logic
  in Computer Science}}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Mathematical
  Logic for Computer Science}}
\item
  \href{https://plato.stanford.edu/archives/spr2023/entries/natural-deduction}{\emph{Natural
  Deduction Systems in Logic}}
\end{itemize}

\end{tcolorbox}

\end{footnotesize}}

\chapter{\texorpdfstring{{Probability
inference}}{Probability inference}}\label{sec-probability}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\ys}{\se{s}}
\providecommand*{\yh}{\se{h}}
\providecommand*{\yf}{\se{f}}
\providecommand*{\yv}{\se{v}}
\providecommand*{\yJ}{\se{J}}
\providecommand*{\yZ}{\se{Z}}
\providecommand*{\yH}{\se{H}}

In most engineering and data-science problems we don't know the truth or
falsity of outcomes and hypotheses that interest us. But this doesn't
mean that nothing can be said or done in such situations. Now we shall
finally see how to draw \emph{uncertain} inferences, that is, how to
calculate the \emph{probability} of something that interests us, given
particular data, information, and assumptions.

So far we have used the term ``probability'' somewhat informally and
intuitively. It is time to make it more precise and to emphasize some of
its most important aspects. Then we'll dive into the rules of
probability-inference.

\section{When truth isn't known: probability}\label{sec-probability-def}

When we cross a busy city street we look left and right to check whether
any cars are approaching. We typically don't look \emph{up} to check
whether something is falling from the sky. Yet, couldn't it be
\texttt{false} that cars are approaching at that moment? and couldn't it
be \texttt{true} that
\href{https://www.aerotime.aero/articles/32818-cessna-door-falls-off-lands-in-parking-lot}{some
object is falling from the sky}? Of course both events are possible.
Then why do we look left and right, but not up?

The main reason is that we \emph{believe strongly} that cars might be
approaching, and \emph{believe very weakly} that some object might be
falling from the sky. In other words, we consider the first occurrence
to be \emph{very probable}, and the second extremely \emph{improbable}.

We shall take the notion of {\textbf{probability}} as intuitively
understood (just as we did with the notion of truth). Terms equivalent
to ``probability'' are {\emph{degree of belief}}, {\emph{plausibility}},
{\emph{credibility}}\footnote{\emph{credibility} literally means
  ``believability'' (from Latin \emph{credo}~=~\emph{to believe}).},
{\emph{certainty}}.\\
\strut \\

Probabilities are quantified between {\(0\)} and {\(1\),} or
equivalently between {\(0\%\)} and {\(100\%\).} Assigning to a sentence
a probability \texttt{1} is the same as saying that it is \texttt{true};
and a probability \texttt{0}, that it is \texttt{false}. A probability
of {\(0.5\)} represents a belief completely symmetric with respect to
truth and falsity.

Alternatively, if an agent assigns to a sentence a probability
\texttt{1}, it means that the agent is completely certain that the
sentence is \texttt{true}. If the agent assigns a probability
\texttt{0}, it means that the agent is completely certain that the
sentence is \texttt{false}. If the agent assigns a probability
\texttt{0.5}, it means that the agent is equally uncertain about the
truth as about the falsity of the sentence.

Let's emphasize and agree on some important facts about probabilities:

\begin{itemize}
\item
  {\textbf{\faIcon{hand-point-right} Probabilities are assigned to
  \emph{sentences}}}. We already discussed this point in
  §~\ref{sec-sentence-notation}, but let's reiterate it. Consider an
  engineer working on a problem of electric-power distribution in a
  specific geographical region. At a given moment the engineer may
  believe with {\(75\%\)} probability that the measured average power
  output in the next hour will be 100\,MW. The {\(75\%\)} probability is
  assigned not to the quantity ``100\,MW'', but to the \emph{sentence}

  \[
  \textsf{\small`The measured average power output in the next hour will be 100\,MW'}
  \]

  This difference is extremely important. Consider the alternative
  sentence

  \[
  \textsf{\small`The average power output in the next hour will be \emph{set} to 100\,MW'}
  \]

  the numerical quantity is the same, but the meaning is very different.
  The probability can therefore be very different. If the engineer is
  the person who decides how to set that output, and has decided to set
  it to 100\,MW, then the probability is obviously {\(100\%\)} (or very
  close to), because the engineer already knows what the output will be.
  The probability depends not only on a number, but on what it's being
  done with that number: measuring, setting, third-party reporting, and
  so on. Often we write simply
  {``\(O \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}10\,\mathrm{W}\)''},
  provided that the full sentence behind this shorthand is understood.
\item
  {\textbf{\faIcon{hand-point-right} Probabilities are agent- and
  knowledge-dependent}}. A coin is tossed, comes down heads, and is
  quickly hidden from view. Alice sees that it landed heads-up. Bob
  instead doesn't manage to see the outcome and has no clue. Alice
  considers the sentence {\(\textsf{\small`Coin came down heads'}\)} to
  be \texttt{true}, that is, to have {\(100\%\)} probability. Bob
  considers the same sentence to have {\(50\%\)} probability.

  Note how Alice and Bob assign two different probabilities to the same
  sentence; yet both assignments are completely rational. If Bob
  assigned {\(100\%\)} to {\(\textsf{\small`heads'}\),} we would suspect
  that he had seen the outcome after all. If he assigned {\(0\%\)} to
  {\(\textsf{\small`heads'}\),} we would consider it unreasonable (he
  didn't see the outcome, so why exclude {\(\textsf{\small`heads'}\)?).}
  At the same time we would be baffled if Alice assigned only {\(50\%\)}
  to {\(\textsf{\small`heads'}\),} because she actually saw that the
  outcome was heads; maybe we would wonder whether she feels unsure
  about what she saw.

  An omniscient agent would know the truth or falsity of every sentence,
  and assign only probabilities \texttt{0} or \texttt{1}. Some authors
  speak of ``\emph{actual} (but unknown) probabilities''. But if there
  were ``actual'' probabilities, they would be all \texttt{0} or
  \texttt{1}, and it would be pointless to speak about probabilities at
  all -- every inference would be a truth-inference.
\item
  {\textbf{\faIcon{hand-point-right} Probabilities are not
  frequencies}}. Consider the fraction of defective mechanical
  components to total components produced per year in some factory. This
  quantity can be physically measured and, once measured, would be
  agreed upon by every agent. It is a \emph{frequency}, not a degree of
  belief or probability.

  It is important to understand the difference between
  \emph{probability} and \emph{frequency}: mixing them up may lead to
  sub-optimal decisions. Later we shall say more about the difference
  and the precise relations between probability and frequency.

  Frequencies can be unknown to some agents. Probabilities cannot be
  ``unknown'': they can only be difficult to calculate. Be careful when
  you read authors speaking of an ``unknown probability'': they actually
  mean either ``unknown frequency'', or a probability that has to be
  calculated (it's ``unknown'' in the same sense that the value of
  {\(1-0.7 \cdot 0.2/(1-0.3)\)} is ``unknown'' to you right now).
\item
  {\textbf{\faIcon{hand-point-right} Probabilities are not physical
  properties}}. Whether a tossed coin lands heads up or tails up is
  fully determined by the initial conditions (position, orientation,
  momentum, rotational momentum) of the toss and the boundary conditions
  (air velocity and pressure) during the flight. The same is true for
  all macroscopic engineering phenomena (even quantum phenomena have
  never been proved to be non-deterministic, and there are
  \href{https://doi.org/10.48550/arXiv.quant-ph/9504010}{deterministic
  and experimentally consistent} mathematical representations of quantum
  theory). So we cannot measure a probability using some physical
  apparatus; and the mechanisms underlying any engineering problem boil
  down to physical laws, not to probabilities.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Dynamical
Bias in the Coin Toss}}.

\end{tcolorbox}

\hfill\break

These points listed above are not just a matter of principle. They have
important practical consequences. A data scientist who is not attentive
to the source of the data (measured? set? reported, and so maybe less
trustworthy?), or who does not carefully assess the context of a
probability, or who mixes a probability with a frequency, or who does
not take advantage (when possible) of the physics involved in the a
problem -- such data scientist will design systems with sub-optimal
performance\footnote{This fact can be mathematically proven.} -- or even
cause deaths.

\section{\texorpdfstring{\faIcon{exclamation-triangle} The many uses of
the word
``probability''}{ The many uses of the word ``probability''}}\label{the-many-uses-of-the-word-probability}

In these notes we shall consistently use the term ``probability'' in the
sense explained above. But beware that this term is used in many
different and incompatible senses, depending on whom you're speaking
with or which literature you're reading.

Some people use this term in the sense of ``frequency'': the number of
times something happened in a series of repetitions. But a frequency is
an objective, measurable quantity; it doesn't depend on the knowledge of
an agent. To us is not useful, because it doesn't quantify the belief or
certainty of an agent. Suppose a coin is tossed 100 times, and it comes
up heads 80 times. The frequency of heads is 80/100. Now suppose that an
agent \emph{that does not know anything about the 100 tosses} is asked
to predict whether the next toss will be heads or tails. What should the
agent's degree of belief or of certainty be? Obviously it should be
50\%/50\%. If we were to program the agent so that it has a degree of
belief of 80\% for heads \emph{in situations where nothing is know about
previous tosses} (because that's the situation our agent was in), then
such an agent would on average lose big time in dealing with new coins.

But frequency is \emph{data}, and if a frequency is known, then
obviously an agent should take it into account in quantifying its
credibility. If an agent \emph{knows} that the coin came up heads 80
times in 100, then it is reasonable that the agent's degree of belief
for the next toss should be around 80\% for heads. And we shall see that
this is indeed what happens.

So the distinction between ``frequency'' and ``probability'' is crucial.
Frequencies do not enable us to quantify an agent's beliefs in
situations where data are missing.\\
\strut \\

Some people use ``probability'' in the sense of the number of
\emph{a-priori} successes over the number of possibilities. For
instance, if you roll a die, and the die comes up \faIcon{dice-three},
then this result was 1 among six possible results. This is fine, but
this definition does not allow us to capture the difference between an
agent who has seen the outcome of the roll was \faIcon{dice-three}, and
an agent who has \emph{not} seen the outcome of the roll. We expect the
two agents to behave differently. If we programmed the agent to have a
degree of belief of 1/6 \emph{even after seeing the outcome of a die
roll}, we would have programmed an agent incapable of using new data
(seeing the outcome). Would you be happy if a clinician made some
medical tests, and then ignored the results of the tests, behaving as if
they were still unknown?\\
\strut \\

All these different uses are just a matter of semantics, and in the end
it doesn't matter which word we use, as long as we understand its
meaning and as long as we're adopting the meaning that is \emph{useful}
for our present task.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Beware of \emph{likelihood} as a synonym
for \emph{probability}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

In everyday language,
``\href{https://dictionary.cambridge.org/dictionary/english/likelihood}{likelihood}''
is synonym with ``probability''. In technical writings about probability
or statistics, however, ``likelihood'' means something different and is
\emph{not} a synonym of ``probability'', as we explain below
(§~\ref{sec-likelihood}).

\end{tcolorbox}

\section{An unsure inference. Probability
notation}\label{sec-uncertain-inference}

Consider now the following variation of the trivial inference problem of
§~\ref{sec-trivial-inference}.

\begin{quote}
This electric component had an early failure. If an electric component
fails early, then at production either it didn't pass the heating test
or it didn't pass the shock test. The probability that it passed neither
test (that is, \emph{both} tests failed) is 10\%. There's no reason to
believe that the component passed the heating test, more than to believe
that it passed the shock test.
\end{quote}

Again the inspector wants to assess whether the component \emph{did not
pass} the heating test.

From the data and information given, what would you say is the
probability that the component didn't pass the heating test?

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Try to argue why a conclusion cannot be drawn with certainty in this
  case. One way to argue this is by presenting two different scenarios
  that fit the given data but have opposite conclusions.
\item
  Try to reason intuitively and assess the probability that the
  component didn't pass the heating test. Should it be larger or smaller
  than 50\%? Why?
\end{itemize}

\end{tcolorbox}

For this inference problem we cannot find a \texttt{true} or
\texttt{false} final value. The truth-inference rules
(\ref{eq-t-not})--(\ref{eq-t-unity}) therefore cannot help us here. In
fact even the
{``\(\mathrm{T}(\dotso \nonscript\:\vert\nonscript\:\mathopen{} \dotso)\)''}
notation is unsuitable, because it only admits the values {\(1\)}
(\texttt{true}) and {\(0\)} (\texttt{false}).

Let us first generalize this notation in a straightforward way:

First, let's represent the probability or degree of belief of a sentence
by a number in the range {\([0,1]\),} that is, between {\(\mathbf{1}\)}
(certainty or \texttt{true}) and {\(\mathbf{0}\)} (impossibility or
\texttt{false}). The value {\(0.5\)} represents a belief in the truth of
the sentence which is as strong as the belief in its falsity.

Second, let's symbolically write in the following way that the
probability of a proposal {\(\mathsfit{Y}\),} given a conditional
{\(\mathsfit{X}\),} is some number {\(p\):}

\[
\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}) = p
\]

Note that this notation includes the notation for truth-values as a
special case:

\[
\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}) = 0\text{ or }1
\quad\Longleftrightarrow\quad
\mathrm{T}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}) = 0\text{ or }1
\]

\section{Inference rules}\label{sec-fundamental}

Extending our truth-inference notation to probability-inference notation
has been straightforward. But which rules should we use for drawing
inferences when probabilities are involved?

The amazing result is that \emph{the rules for truth-inference, formulae
(\ref{eq-t-not})--(\ref{eq-t-unity}), extend also to
probability-inference}. The only difference is that they now hold for
all values in the range {\([0,1]\),} rather than only for {\(0\)} and
{\(1\).}

This important result was taken more or less for granted at least since
Laplace in the 1700s, but was formally proven for the first time in 1946
by R.~T.~Cox. The proof has been refined since then. What kind of proof
is it? It shows that if we don't follow the rules we are doomed to
arrive at illogical conclusions; we'll show some examples later.

\hfill\break
Finally, here are \emph{the fundamental rules of all inference}. They
are encoded by the following equations, which must always hold for any
atomic or composite sentences
{\(\mathsfit{X},\mathsfit{Y},\mathsfit{Z}\):}

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={{\textbf{\faIcon{landmark} THE FUNDAMENTAL LAWS OF INFERENCE
\faIcon{landmark}}}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{description}
\tightlist
\item[\(\boldsymbol{\lnot}\) ``Not'' rule]
\[\mathrm{P}(\lnot \mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) 
+ \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
= 1\]\\
\item[\(\boldsymbol{\land}\) ``And'' rule]
\[
\mathrm{P}(\mathsfit{X}\land \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) 
= \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}\land \mathsfit{Z}) \cdot
\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) 
= \mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land \mathsfit{Z}) \cdot
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) 
\]\\
\item[\(\boldsymbol{\lor}\) ``Or'' rule]
\[\mathrm{P}(\mathsfit{X}\lor \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) 
= \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) +
\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) 
- \mathrm{P}(\mathsfit{X}\land \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
\]\\
\item[Truth rule]
\[\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land \mathsfit{Z}) 
= 1
\]
\end{description}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\textbf{How to use the rules}:}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Each equality can be rewritten in different ways according to the usual
rules of algebra. Then the resulting left side can be replaced by the
right side, and vice versa. The numerical values of starting inferences
can be replaced in the corresponding expressions.

\end{tcolorbox}

\end{figure*}%

It is amazing that \textbf{ALL} inference is nothing else but a repeated
application of these four rules -- maybe billions of times or more. All
machine-learning algorithms are just applications or approximations of
these rules. Methods that you may have heard about in statistics are
just specific applications of these rules. Truth inferences are also
special applications of these rules. Most of this course is just a study
of how to apply these rules to particular kinds of problems.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Skim through
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Probability,
  Frequency and Reasonable Expectation}}. Try to get the ideas behind
  the reasoning, even if you can't follow the mathematical details.
\item
  Ch.~2 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Bayesian
  Logical Data Analysis for the Physical Sciences}}
\item
  Ch.~1 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Probability}}
\item
  §§1.0--1.2 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Data
  Analysis}}
\item
  Skim through Chs~1--2 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Probability
  Theory}}
\end{itemize}

\end{tcolorbox}

\hfill\break
The fundamental inference rules are used in the same way as their
truth-inference counterpart of {[}§@truth-inference-rules{]}: Each
equality can be rewritten in different ways according to the usual rules
of algebra. The left and right side of the equality thus obtained can
replace each other in a proof.

\section{Solution of the uncertain-inference
example}\label{solution-of-the-uncertain-inference-example}

Armed with the fundamental rules of inference, let's solve our earlier
inference problem. As usual, we first analyse it and represent it in
terms of atomic sentences; we find what are its proposal and
conditional; and we find which initial inferences are given in the
problem.

\subsection{Atomic sentences}\label{atomic-sentences-2}

\[
\begin{aligned}
\mathsfit{h}&\coloneqq\textsf{\small`The component passed the heating test'}
\\
\mathsfit{s}&\coloneqq\textsf{\small`The component passed the shock test'}
\\
\mathsfit{f}&\coloneqq\textsf{\small`The component had an early failure'}
\\
\mathsfit{J}&\coloneqq\textsf{\small (all other implicit background information)}
\end{aligned}
\]

The background information in this example is different from the
previous, truth-inference one, so we use the different symbol
{\(\mathsfit{J}\)} for it.

\subsection{Proposal, conditional, and target
inference}\label{proposal-conditional-and-target-inference}

The proposal is {\(\lnot\mathsfit{h}\),} just like in the
truth-inference example.

The conditional is different now. We know that the component failed
early, but we don't know whether it passed the shock test. Hence the
conditional is {\(\mathsfit{f}\land \mathsfit{J}\).}

The target inference is therefore

\[
\color[RGB]{238,102,119}\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
\]

\subsection{Starting inferences}\label{starting-inferences-1}

We are told that if an electric component fails early, then at
production it didn't pass the heating test or the shock test (or
neither). This is given as a sure fact. Let's write it as

\begin{equation}\phantomsection\label{eq-start-inf-a}{
\color[RGB]{34,136,51}\mathrm{P}(\lnot\mathsfit{h}\lor \lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J}) = 1
}\end{equation}

We are also told that there is a {\(10\%\)} probability that both tests
fail:

\begin{equation}\phantomsection\label{eq-start-inf-b}{
\color[RGB]{34,136,51}\mathrm{P}(\lnot\mathsfit{h}\land \lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J}) = 0.1
}\end{equation}

Finally the problem says that there's no reason to believe that the
component didn't pass the heating test, more than it didn't pass the
shock test. This can be written as follows:

\begin{equation}\phantomsection\label{eq-start-inf-c}{
\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J}) = \mathrm{P}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
}\end{equation}

Note the interesting situation above: we are not given the numerical
values of these two probabilities; we are only told that they are equal.
This is an example of application of the \emph{principle of
indifference}, which we'll discuss more in detail later.

\subsection{Final inference}\label{final-inference}

Also in this case there is no unique way of applying the rules to reach
our target inference, but \emph{all paths will lead to the same result}.
Let's try to proceed backwards:

\begin{figure*}

\[
\begin{aligned}
&\color[RGB]{238,102,119}\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})&&
\text{\small ∨-rule}
\\[1ex]
&\qquad= {\color[RGB]{34,136,51}\mathrm{P}(\lnot\mathsfit{s}\lor \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})}
+ {\color[RGB]{34,136,51}\mathrm{P}(\lnot\mathsfit{s}\land \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})}
- \mathrm{P}(\lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
&&
\text{\small starting inferences (8.1–2)}
\\[1ex]
&\qquad= {\color[RGB]{34,136,51}1}
+ {\color[RGB]{34,136,51}0.1}
- \mathrm{P}(\lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
&&
\text{\small ¬-rule}
\\[1ex]
&\qquad= 0.1 + \color[RGB]{34,136,51}\mathrm{P}(\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
&&
\text{\small starting inference (8.3)}
\\[1ex]
&\qquad= 0.1 + \mathrm{P}(\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
&&
\text{\small ¬-rule}
\\[1ex]
&\qquad= 0.1 + 1 -\color[RGB]{238,102,119}\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})
&&
\end{aligned}
\]

\end{figure*}%

The target probability appears on the left and right side with opposite
signs. We can solve for it:

\[
\begin{aligned}
2\,{\color[RGB]{238,102,119}\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})} &= 0.1 + 1
\\[1ex]
{\color[RGB]{238,102,119}\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})} &= 0.55
\end{aligned}
\]

So the probability that the component didn't pass the heating test is
{\(55\%\).}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Try to find an intuitive explanation of why the probability is 55\%,
  slightly larger than 50\%. If your intuition says this probability is
  wrong, then:

  \begin{itemize}
  \tightlist
  \item
    Check the proof of the inference for mistakes, or try to find a
    proof with a different path.
  \item
    Examine your intuition critically and educate it.
  \end{itemize}
\item
  Check how the target probability
  {\(\mathrm{P}(\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})\)}
  changes if we change the value of the probability
  {\(\mathrm{P}(\lnot\mathsfit{s}\land \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})\)}
  from {\(0.1\).}

  \begin{itemize}
  \tightlist
  \item
    What result do we obtain if
    \(\mathrm{P}(\lnot\mathsfit{s}\land \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})=0\)?
    Can it be intuitively explained?
  \item
    What if
    \(\mathrm{P}(\lnot\mathsfit{s}\land \lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{J})=1\)?
    Does the result make sense?
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\section{How the inference rules are
used}\label{how-the-inference-rules-are-used}

In the solution above you noticed that the equations of the fundamental
rules are not only used to obtain some of the probabilities appearing in
them from the remaining probabilities.

The rules represent, first of all, {\emph{constraints of logical
consistency}}\footnote{The technical term is {\textbf{coherence}}.}
among probabilities. For instance, if we have
probabilities~~{\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X}\land \mathsfit{Z})=0.1\),~~}{\(\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z})=0.7\),~~and}
{\(\mathrm{P}(\mathsfit{X}\land \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z})=0.2\),~~then}
there's an inconsistency somewhere, because these values violate the
and-rule:~~{\(0.2 \ne 0.1 \cdot 0.7\).~~In} this case we must find the
inconsistency and solve it. However, since probabilities are quantified
by real numbers, it's possible and acceptable to have slight
discrepancies within numerical round-off errors.

The rules also imply more general constraints. For example we must
\emph{always} have

\[
\begin{gathered}
\mathrm{P}(\mathsfit{X}\land \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}) \le \min\set[\big]{\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}),\  \mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z})}
\\
\mathrm{P}(\mathsfit{X}\lor \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}) \ge \max \set[\big]{\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}),\  \mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z})}
\end{gathered}
\]

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Try to prove the two constraints above.

\end{tcolorbox}

\section{Consequences of not following the
rules}\label{consequences-of-not-following-the-rules}

The fundamental rules of inference guarantee that the agent's uncertain
reasoning is self-consistent, and that it follows logic when there's no
uncertainty. Breaking the rules means that the resulting inference has
some logical or irrational inconsistencies.

There are many examples of inconsistencies that appear when the rules
are broken. Imagine for instance an agent that gives an 80\% probability
that it rains\footnote{to be precise, let's say ``it rains above 1\,mm''}
in the next hour; and it also gives a 90\% probability that it rains
\emph{and} that the average wind is above 3⋅m/s in the next hour. This
is clearly unreasonable, because the raining scenario alone would be
true with wind above 3\,m/s \emph{and also} below 3⋅m/s -- therefore it
should be \emph{more} probable than the scenario where the wind is above
3\,m/s. And indeed the two given probabilities break the
\texttt{and}-rule, showing that they are unreasonable or illogical.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Prove that the two probabilities in the example above break the
\texttt{and}-rule. {(Hint: you must use the fact that probabilities are
numbers between 0 and 1, and that multiplying a number by something
between 0 and 1 can only yield a smaller number.)}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  §12.2.3 in
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}
\item
  As you continue your studies, go through chapters 4--8 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Rational
  Choice in an Uncertain World}}, just to get the main messages and an
  overview of curious psychological phenomena.
\end{itemize}

\end{tcolorbox}

\section{Remarks on terminology and
notation}\label{remarks-on-terminology-and-notation}

\subsection{Likelihood}\label{sec-likelihood}

In everyday language, ``likely'' is often a synonym of ``probable'', and
``likelihood'' of ``probability''. But in technical writings about
probability, inference, and decision-making, ``likelihood'' has a very
different meaning. Beware of this important difference in definitions:

\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X})\)
is:

\begin{itemize}
\item
  the {\textbf{probability of \(\mathsfit{Y}\) given \(\mathsfit{X}\)}}
  (or \textbf{conditional on \(\mathsfit{X}\)}),
\item
  the {\textbf{likelihood of \(\mathsfit{X}\) in view of
  \(\mathsfit{Y}\)}}.
\end{itemize}

We can also say:

\begin{itemize}
\item
  the {\textbf{probability of \(\mathsfit{Y}\)}} given
  {\(\mathsfit{X}\),} is
  {\(\mathrm{P}({\color[RGB]{68,119,170}\mathsfit{Y}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X})\).}
\item
  the {\textbf{likelihood of \(\mathsfit{Y}\)}} in view of
  {\(\mathsfit{X}\),} is
  {\(\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{}{\color[RGB]{68,119,170}\mathsfit{Y}})\).}
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

A priori there is no relation between the probability and the likelihood
of a sentence {\(\mathsfit{Y}\):} this sentence could have very high
probability and very low likelihood, and vice versa.

\end{tcolorbox}

In these notes we'll avoid the possibly confusing term ``likelihood''.
All we need to express can be phrased in terms of probability.

\subsection{Omitting background
information}\label{omitting-background-information}

In the analyses of the inference examples of
§~\ref{sec-trivial-inference} and §~\ref{sec-uncertain-inference} we
defined sentences ({\(\mathsfit{I}\)} and {\(\mathsfit{J}\))} expressing
all background information, and always included these sentences in the
conditionals of the inferences -- because those inferences obviously
depended on that specific background information.

In many concrete inference problems the background information usually
stays in the conditional from beginning to end, while the other
sentences jump around between conditional and proposal as we apply the
rules of inference. For this reason the background information is often
omitted from the notation, being implicitly understood. For instance, if
the background information is denoted {\(\mathsfit{I}\),} one writes

\begin{itemize}
\item
  {``\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X})\)''}~~instead
  of~~{\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{X}\land \mathsfit{I})\)}
\item
  {``\(\mathrm{P}(\mathsfit{Y})\)''}~~instead
  of~~{\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})\)}
\end{itemize}

This is what's happening in books where you see {``\(P(x)\)''} without
conditional.

Such practice may be convenient, but be wary of it, especially in
particular situations:

\begin{itemize}
\item
  In some inference problems we suddenly realize that we must
  distinguish between cases that depend on hypotheses, say
  {\(\mathsfit{H}_1\)} and {\(\mathsfit{H}_2\),} that were buried in the
  background information {\(\mathsfit{I}\).} If the background
  information {\(\mathsfit{I}\)} is explicitly reported in the notation,
  this is no problem: we can rewrite it as

  \[ \mathsfit{I}= (\mathsfit{H}_1 \lor \mathsfit{H}_2) \land \mathsfit{I}'\]

  and then proceed as usual. If the background information was not
  explicitly written, this may lead to confusion and mistakes: there may
  suddenly appear two instances of {\(\mathrm{P}(\mathsfit{X})\)} with
  \emph{different} values, just because one of them is invisibly
  conditional on {\(\mathsfit{I}\),} the other on {\(\mathsfit{I}'\).}
\item
  In some inference problems we are considering \emph{several different}
  instances of background information -- for example because more than
  one agent is involved. It's then extremely important to write the
  background information explicitly, lest we mix up the degrees of
  belief of different agents.
\end{itemize}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

A once-famous
\href{https://hvl.instructure.com/courses/32045/modules}{paper published
in the quantum-theory literature} arrived at completely wrong results
simply by omitting background information, mixing up probabilities
having different conditionals.

\end{tcolorbox}

\end{footnotesize}}

This kind of confusion from poor notation happens more often than one
thinks, and even appears in the scientific literature.

\subsection{``Random variables''}\label{random-variables}

Some texts speak of the probability of a ``random variable'', or more
precisely of the probability ``that a random variable takes on a
particular value''. As you notice, we have just expressed that idea by
means of a \emph{sentence}. The viewpoint and terminology of random
variables is therefore a special case of that based on sentences, which
we use here.

The dialect of ``random variables'' does not offer any advantages in
concepts, notation, terminology, or calculations, and it has several
shortcomings:

\marginnote{\begin{footnotesize}

\begin{figure}[H]

{\centering \includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{maxwell1.jpg}

}

\caption{\href{https://clerkmaxwellfoundation.org/html/about_maxwell.html}{James~Clerk~Maxwell}
is one of the main founders of statistical mechanics and kinetic theory
(and electromagnetism). Yet he never used the word ``random'' in his
technical writings. Maxwell is known for being very clear and meticulous
with explanations and terminology.}

\end{figure}%

\end{footnotesize}}

\begin{itemize}
\item
  As discussed in §~\ref{sec-probability-def}, in concrete applications
  it is important to know how a quantity ``takes on'' a value: for
  example it could be directly measured, indirectly reported, or
  purposely set to that specific value. Thinking and working in terms of
  sentences, rather than of random variables, allows us to account for
  these important differences.
\item
  We want a general AI agent to be able to deal with uncertainty and
  probability also in situations that do not involve mathematical sets.
\item
  Very often the object (proposal) of a probability is not a
  ``variable'': it is actually a \emph{constant} value that is simply
  unknown (simple example: we are uncertain about the mass of a
  particular block of concrete, so we speak of the probability of some
  mass value; this doesn't mean that the mass of the block of concrete
  is changing).
\item
  What does ``random'' (or ``chance'') mean? Good luck finding an
  understandable and non-circular definition in texts that use that
  word. Strangely enough, texts that use that word never define it. In
  these notes, if the word ``random'' is ever used, it stands for
  ``unpredictable'' or ``unsystematic''.
\end{itemize}

It's a question for sociology of science why some people keep on using
less flexible points of view or terminologies. Probably they just
memorize them as students and then a fossilization process sets in.

\hfill\break
Finally, some texts speak of the probability of an ``event''. For all
purposes, an ``event'' is just what's expressed in a sentence.

\chapter{\texorpdfstring{{Shortcut
rules}}{Shortcut rules}}\label{sec-derived-rules}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\ys}{\se{s}}
\providecommand*{\yh}{\se{h}}
\providecommand*{\yf}{\se{f}}
\providecommand*{\yv}{\se{v}}
\providecommand*{\yJ}{\se{J}}
\providecommand*{\yZ}{\se{Z}}
\providecommand*{\yH}{\se{H}}

The fundamental rules introduced in chapter~~\ref{sec-probability} are
all we need, and all an AI needs, in order to draw inferences from other
inferences and from initial data.

From them, however, it is possible to derive some ``shortcut'' rules
than can make the inferences shorter and faster. The situation is
similar to what happens with some rules in algebra: for instance, we
know that whenever we find the expression

\[
(a+b) \cdot (a-b)
\]

then we can automatically substitute it with

\[
a^2 - b^2
\]

no matter the values of {\(a\)} and {\(b\).} The rule
{{``\((a+b) \cdot (a-b) = a^2-b^2\)''}} is not a new algebraic rule:
it's simply the result of the application of the rules for addition
{\(+\)} and multiplication {\(\cdot\),} and indeed we could just apply
them directly:

\[
\begin{aligned}
(a+b) \cdot (a-b)
&=a\cdot a + b\cdot a - a\cdot b - b\cdot b
\\
&=a^2 + b\cdot a - b\cdot a - b^2
\\
&=a^2 - b^2
\end{aligned}
\]

But if we remember that they always lead to the result {\(a^2-b^2\),}
then we can directly use the ``shortcut'' rule
{\((a+b) \cdot (a-b) = a^2-b^2\)} and save ourselves some time.

~Likewise with the four rules of inference. Some particular sequences of
application of the rules occur very often. We can then simply memorize
the starting and final steps of these sequences, and use them directly,
skipping all the steps in between. These shortcut rules are not only
useful for saving time, however. We shall see that they reveal
interesting and intuitive inference patterns, which are implicit in the
four inference rules.

It is possible and legitimate to implement these shortcut rules in an AI
agent, besides the four fundamental ones. Such an agent will arrive at
the same results and decisions of an identical AI agent that doesn't use
the shortcut rules -- but a little faster.

Here are the shortcut rules we'll frequently use in the rest of the
course:

\section{Falsity and truth cannot be altered by additional
knowledge}\label{sec-truth-stable}

Suppose that sentence {\(\mathsfit{X}\)} is judged to be completely
impossible, conditional on sentence {\(\mathsfit{Z}\):}

\[
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) = 0
\]

It can then be proved, from the fundamental rules, that
{\(\mathsfit{X}\)} is also completely impossible if we add information
to {\(\mathsfit{Z}\).} That is, for any sentence {\(\mathsfit{Y}\)}
we'll also have

\[
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}\land \mathsfit{Z}) = 0
\]

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Try to prove this. {(Hint: try using the \texttt{and}-rule one or more
times.)}

\end{tcolorbox}

\faIcon{exclamation-circle} What if we use {\(\lnot\mathsfit{X}\)} for
{\(\mathsfit{Y}\),} that is, what if we acquire knowledge that
{\(\mathsfit{X}\)} is actually true? Then it can be proved that all
probability calculations break down. The problem is that
{\(\lnot\mathsfit{X}\)} and {\(\mathsfit{Z}\)} turn out to be mutually
contradictory, so all inferences are starting from contradictory
premises. You probably know that in formal logic if we start from
contradictory premises then we can obtain any conclusion whatsoever. The
same happens with probability logic.

Note that this problem does not arise, however, if {\(\mathsfit{X}\)} is
only extremely improbable conditional on {\(\mathsfit{Z}\),} say with a
probability of {\(10^{-100}\),} rather than flat-out impossible. In
practical applications we often approximate extremely small
probabilities by {\(0\),} or extremely large ones by {\(1\).} If the
probability calculations break down, we must then step back and correct
the approximation.

\hfill\break
By using the \texttt{not}-rule it is possible to prove that full
certainty about a sentence behaves in a similar manner. If sentence
{\(\mathsfit{X}\)} is judged to be completely certain conditional on
sentence {\(\mathsfit{Z}\):}

\[
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) = 1
\]

then, from the fundamental rules, {\(\mathsfit{X}\)} is also completely
certain if we add information to {\(\mathsfit{Z}\).} That is, for any
sentence {\(\mathsfit{Y}\)} we'll also have

\[
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}\land \mathsfit{Z}) = 1
\]

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={Shortcut rules: permanence of truth and falsity}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\[
\begin{aligned}
&\text{if}\quad \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) = 0\text{ or }1
\\
&\text{then}\quad \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}\land \mathsfit{Z}) = \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
\quad\text{for any $\mathsfit{Y}$ not contradicting $\mathsfit{Z}$}
\end{aligned}
\]

\end{tcolorbox}

\hfill\break

\section{Boolean algebra}\label{sec-boolean}

It is possible to show that all rules you may know from Boolean algebra
\emph{are a consequence of the fundamental rules} of
§~\ref{sec-fundamental}. So we can always make the following convenient
replacements anywhere in a probability expression:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={Shortcut rules: Boolean algebra}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\[
\begin{gathered}
\lnot\lnot \mathsfit{X}= \mathsfit{X}
\\[1ex]
\mathsfit{X}\land \mathsfit{X}= \mathsfit{X}
\\[1ex]
\mathsfit{X}\lor \mathsfit{X}= \mathsfit{X}
\\[1ex]
\mathsfit{X}\land \mathsfit{Y}= \mathsfit{Y}\land \mathsfit{X}
\\[1ex]
\mathsfit{X}\lor \mathsfit{Y}= \mathsfit{Y}\lor \mathsfit{X}
\\[1ex]
\mathsfit{X}\land (\mathsfit{Y}\lor \mathsfit{Z}) = (\mathsfit{X}\land \mathsfit{Y}) \lor (\mathsfit{X}\land \mathsfit{Z})
\\[1ex]
\mathsfit{X}\lor (\mathsfit{Y}\land \mathsfit{Z}) = (\mathsfit{X}\lor \mathsfit{Y}) \land (\mathsfit{X}\lor \mathsfit{Z})
\\[1ex]
\lnot (\mathsfit{X}\land \mathsfit{Y}) = \lnot \mathsfit{X}\lor \lnot \mathsfit{Y}
\\[1ex]
\lnot (\mathsfit{X}\lor \mathsfit{Y}) = \lnot \mathsfit{X}\land \lnot \mathsfit{Y}
\end{gathered}
\]

\end{tcolorbox}

For example, if we have the probability

\[\mathrm{P}[\mathsfit{X}\lor (\mathsfit{Y}\land \mathsfit{Y}) \nonscript\:\vert\nonscript\:\mathopen{} (\lnot\lnot\mathsfit{Z}) \land \mathsfit{I}]\]

we can directly replace it with

\[\mathrm{P}[\mathsfit{X}\lor \mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}\land \mathsfit{I}]\]

\hfill\break
The derivation of the Boolean-algebra rules from the four inference
rules is somewhat involved. As as example, a partial proof of the rule
{\(\mathsfit{X}\land \mathsfit{X}= \mathsfit{X}\),} called
``\texttt{and}-idempotence'' goes as follows:

\[
\begin{aligned}
&\mathrm{P}(\mathsfit{X}\land \mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})&&
\\[1ex]
&\qquad= \mathrm{P}(\mathsfit{X}| \mathsfit{X}\land \mathsfit{Z}) \cdot \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})&&
&&\text{\small ∧-rule}
\\[1ex]
&\qquad= 1 \cdot \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})&&
&&\text{\small truth-rule}
\\[1ex]
&\qquad= \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
\end{aligned}
\]

and with a similar procedure it can be shown that
{\(\mathsfit{X}\land \mathsfit{X}\)} can be replaced with
{\(\mathsfit{X}\)} no matter where it appears. The above proof shows
that the \texttt{and}-idempotence rule is tightly connected with the
\texttt{truth}-rule of inference.

\section{Law of total probability or ``extension of the
conversation''}\label{sec-extension-conversation}

Suppose we have a set of {\(n\)} sentences
{\(\set{\mathsfit{H}_1, \mathsfit{H}_2, \dotsc, \mathsfit{H}_n}\)}
having these two properties:

\begin{itemize}
\tightlist
\item
  They are {\textbf{mutually exclusive}}, meaning that the ``and'' of
  any two of them is false, given some background knowledge
  \(\mathsfit{Z}\):
\end{itemize}

\begin{figure*}

\[
    \mathrm{P}(\mathsfit{H}_1\land\mathsfit{H}_2\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}) = 0\ , \quad
    \mathrm{P}(\mathsfit{H}_1\land\mathsfit{H}_3\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}) = 0\ , \quad
\dotsc \ , \quad
    \mathrm{P}(\mathsfit{H}_{n-1}\land\mathsfit{H}_n\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}) = 0
    \]

\end{figure*}%

\begin{itemize}
\item
  They are {\textbf{exhaustive}}, meaning that the ``or'' of all of them
  is true, given the background knowledge {\(\mathsfit{Z}\):}

  \[
    \mathrm{P}(\mathsfit{H}_1\lor \mathsfit{H}_2 \lor \dotsb \lor \mathsfit{H}_n \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{Z}) = 1
    \]
\end{itemize}

In other words, according to our background knowledge, one of those
sentences \emph{must} be true, but \emph{only one}.

Then the probability of a sentence {\(\mathsfit{X}\),} conditional on
{\(\mathsfit{Z}\),} is equal to a combination of probabilities
conditional on {\(\mathsfit{H}_1,\mathsfit{H}_2,\dotsc\):}

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={{Shortcut rule: extension of the conversation}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\[
\begin{aligned}
&\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) 
\\[2ex]
&\quad{}=
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}_1 \land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{H}_1 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) +
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}_2 \land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{H}_2 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) + 
\dotsb + \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}_n \land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{H}_n \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
\end{aligned}
\]

\end{tcolorbox}

\end{figure*}%

This rule is useful when it is difficult to assess the probability of a
sentence conditional on the background information, but it is easier to
assess the probability of that sentence conditional on several auxiliary
``scenarios'' or hypotheses\footnote{this is why we used the symbol
  {\(\mathsfit{H}\)} for these sentences}. The name {\textbf{extension
of the conversation}} for this shortcut rule comes from the fact that we
are able to call these additional scenarios or hypotheses into play.
This situation occurs very often in concrete applications.

\section{Bayes's theorem}\label{sec-bayes-theorem}

The probably most famous -- or infamous -- rule derived from the laws of
inference is {\textbf{Bayes's theorem}}. It allows us to relate the
probability of a proposal {\(\mathsfit{Y}\)} and a conditional
{\(\mathsfit{X}\)} to the probability where their proposal-conditional
roles are exchanged:

\marginnote{\begin{footnotesize}

\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{bayes_big-bang.jpg}}

}

\caption{Bayes's theorem guest-starring in
\href{https://www.imdb.com/title/tt0898266/}{\emph{The Big Bang
Theory}}}

\end{figure}%

\end{footnotesize}}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={{Shortcut rule: Bayes's theorem}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\[
\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land \mathsfit{Z}) =
\frac{\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}\land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})}{\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})}
\]

\end{tcolorbox}

Obviously this rule can only be used if
{\(\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) > 0\),}
that is, if the sentence {\(\mathsfit{X}\)} is not false conditional on
{\(\mathsfit{Z}\).}

Bayes's theorem is extremely useful when we want to assess the
probability of a hypothesis (the proposal) given some data (the
conditional), and it is easy to assess the probability of the data
conditional on the hypothesis. Note, however, that the sentences
{\(\mathsfit{Y}\)} and {\(\mathsfit{X}\)} in the theorem can be about
anything whatsoever: {\(\mathsfit{Y}\)} doesn't always need to be a
``hypothesis'', and {\(\mathsfit{X}\)} doesn't always need to be
``data''.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Prove Bayes's theorem from the fundamental rules of inference.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

§8.8 of
\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Rational
Choice in an Uncertain World}}

\end{tcolorbox}

\section{Bayes's theorem \& extension of the
conversation}\label{sec-bayes-extension}

Bayes's theorem is often used with several sentences
{\(\set{\mathsfit{Y}_1, \mathsfit{Y}_2, \dotsc, \mathsfit{Y}_n}\)} that
are mutually exclusive and exhaustive. Typically these represent
competing hypotheses. In this case the probability of the sentence
{\(\mathsfit{X}\)} in the denominator can be expressed using the rule of
extension of the conversation:

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={{Shortcut rule: Bayes's theorem with extension of the conversation}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\[
\mathrm{P}(\mathsfit{Y}_1 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land \mathsfit{Z}) =
\frac{\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}_1 \land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{Y}_1 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})}{
\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}_1 \land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{Y}_1 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z}) + 
\dotsb + \mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Y}_n \land \mathsfit{Z})\cdot \mathrm{P}(\mathsfit{Y}_n \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
}
\]

and similarly for {\(\mathsfit{Y}_2\)} and so on.

\end{tcolorbox}

\end{figure*}%

We will use this form of Bayes's theorem very frequently.

\section{The many facets of Bayes's
theorem}\label{the-many-facets-of-bayess-theorem}

Bayes's theorem is a very general result of the fundamental rules of
inference, valid for any sentences
{\(\mathsfit{X},\mathsfit{Y},\mathsfit{Z}\).} This generality leads to
many uses and interpretations.

The theorem is often proclaimed to be the rule for ``updating an agent's
beliefs''. The meaning of this proclamation is the following. Let's say
that at some point {\(\mathsfit{Z}\)} represents all the agent's
knowledge. The agent's degree of belief about some sentence
{\(\mathsfit{Y}\)} is then (at least in theory) the value of
{\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})\).}
At some later point, the agent gets to know -- maybe thanks to an
observation or measurement -- that the sentence {\(\mathsfit{X}\)} is
true. The agent's whole knowledge at that point is represented no longer
by {\(\mathsfit{Z}\),} but by {\(\mathsfit{X}\land \mathsfit{Z}\).} The
agent's degree of belief about {\(\mathsfit{Y}\)} is then given by the
value of
{\(\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land\mathsfit{Z})\).}
Bayes's theorem allows us to find the agent's degree of belief about
{\(\mathsfit{Y}\)} conditional on the new state of knowledge, from the
one conditional on the old state of knowledge.

This chronological element, however, comes only from this particular way
of using Bayes's theorem. The theorem can more generally be used to
connect any two states of knowledge {\(\mathsfit{Z}\)} and
{\(\mathsfit{X}\land\mathsfit{Z}\),} no matter their temporal order,
even if they happen simultaneously, and even if they belong to two
different agents.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Using Bayes's theorem and the fundamental laws of inference, prove that
if
{\(\mathrm{P}(\mathsfit{X}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})=1\),}
that is, if you already know that {\(\mathsfit{X}\)} is true in your
current state of knowledge {\(\mathsfit{Z}\),} then

\[
\mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{X}\land \mathsfit{Z}) = \mathrm{P}(\mathsfit{Y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{Z})
\]

that is, your degree of belief about {\(\mathsfit{Y}\)} doesn't change
(note that this is different from the rule of truth-permanence of
§~\ref{sec-truth-stable}).

Is this result reasonable?

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  §§4.1--4.3 in
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Medical
  Decision Making}} give one more point of view on Bayes's theorem.
\item
  Ch.~3 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Probability}}
\item
  A graphical explanation of how Bayes's theorem works mathematically
  (using a specific interpretation of the theorem):

  \url{https://vimeo.com/852937378?share=copy}
\end{itemize}

\end{tcolorbox}

\section{Importance of seemingly trivial rules}\label{sec-idempotent}

Some of the fundamental or shortcut rules may seem obvious or
unimportant, but are of extreme importance in data science. For
instance, the \texttt{and}-idempotence rule~~~
{\(\mathsfit{X}\land\mathsfit{X}= \mathsfit{X}\)~~~effectively} asserts
that {\emph{whenever we draw inferences, redundant information or data
is \textbf{automatically} counted only once}}.

This amazing feature saves us from a lot of headaches. Imagine that an
AI decision agent at the assembly line has been given the following
background information: if an electronic component passes the heating
test ({\(\mathsfit{h}\)),} then its probability of early failure
({\(\mathsfit{f}\))} is only 10\%:

\[\mathrm{P}(\mathsfit{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{h}\land \mathsfit{Z}) = 0.1\]

Now let's say that a new voltage test has also been devised, and if a
component passes this test ({\(\mathsfit{v}\))} then its probability of
early failure is also 10\%:

\[\mathrm{P}(\mathsfit{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{v}\land \mathsfit{Z}) = 0.1\]

However, it is discovered that the voltage test works in exactly the
same way as the heating test -- they're basically the same test!
{\(\mathsfit{v}=\mathsfit{h}\).} This means that if an element passes
the heating test then it will automatically pass the voltage test, and
vice versa (they're the same test!):\footnote{We are assuming that a
  test, if repeated, will always give the same result.}

\[\mathrm{P}(\mathsfit{v}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{h}\land \mathsfit{Z}) = 1\]

or
equivalently~~~{\(\mathsfit{v}\land \mathsfit{h}= \mathsfit{h}\land \mathsfit{h}= \mathsfit{h}\).}

Now suppose that inadvertently we give our AI agent the redundant
information that an electronic component has passed the heating test and
the voltage test. What will the agent say about the probability of early
failure, given this duplicate information? will it count the test twice?
Let's calculate:

\[
\begin{aligned}
&\mathrm{P}(\mathsfit{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{v}\land \mathsfit{h}\land \mathsfit{Z})&&
\\[1ex]
&\qquad= \frac{\mathrm{P}(\mathsfit{f}\land \mathsfit{v}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{h}\land \mathsfit{Z})}{
\mathrm{P}(\mathsfit{v}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{h}\land \mathsfit{Z})
}
&&\text{\small ∧-rule}
\\[1ex]
&\qquad= \frac{\mathrm{P}(\mathsfit{f}\land \mathsfit{v}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{h}\land \mathsfit{Z})}{1}
=\mathrm{P}(\mathsfit{f}\land \mathsfit{v}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{h}\land \mathsfit{Z})
&&\text{\small initial probability}
\\[1ex]
&\qquad= \mathrm{P}(\mathsfit{v}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{h}\land \mathsfit{Z}) \cdot
\mathrm{P}(\mathsfit{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{h}\land \mathsfit{Z})
&&\text{\small ∧-rule}
\\[1ex]
&\qquad= 1 \cdot
\mathrm{P}(\mathsfit{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{h}\land \mathsfit{Z})
&&\text{\small truth cannot be altered}
\\[1ex]
&\qquad= 0.1
&&\text{\small initial probability}
\end{aligned}
\]

The AI agent, thanks to the \texttt{truth}-rule or equivalently the
\texttt{and}-idempotence rule, correctly detected the redundancy of the
sentence {\(\mathsfit{v}\)} (``the element passed the voltage test'')
and automatically discarded it.

{\faIcon{exclamation-circle} This feature is of paramount importance in
machine learning and data-driven engineering: the ``features'' that we
give as an input to a machine-learning classifier could contain
redundancies that we don't recognize, owing to the complexity of the
data space. But if the classifier makes inferences according to the four
fundamental rules, it will automatically discard any redundant
features.}

\chapter{\texorpdfstring{{Monty Hall and related inference
problems}}{Monty Hall and related inference problems}}\label{sec-monty}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\car}[1]{\sei{car#1}}
\providecommand*{\you}[1]{\sei{you#1}}
\providecommand*{\door}[1]{\sei{door#1}}
\providecommand*{\host}[1]{\sei{host#1}}
\providecommand*{\yH}{\se{K}}

\section{Motivation: calculation vs
intuition}\label{sec-monty-motivation}

The ``Monty Hall problem'', inspired by the TV show \emph{Let's make a
deal!} hosted by Monty Hall, was proposed in the
\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Parade}
magazine in 1990} (the numbers of the doors are changed here):

\begin{quote}
Suppose you are on a game show and given a choice of three doors. Behind
one is a car; behind the others are goats. You pick door No.\,1, and the
host, who knows what is behind them {[}and wouldn't open the door with
the car{]}, opens No.\,2, which has a goat. He then asks if you want to
pick No.\,3. Should you switch?
\end{quote}

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{letsmakeadeal70sdoors.jpg}

\end{footnotesize}}

The web is full of insightful intuitive solutions and of informal
probability discussions about this inference problem. Our purpose here
is different: we want to solve it \emph{mechanically}, by applying the
fundamental rules of inference (§~\ref{sec-fundamental}) and the
shortcut rules (§~\ref{sec-derived-rules}) derived from them. No
intuitive arguments. Our purpose is different because of two main
reasons:

\begin{itemize}
\item
  We want to be able to implement or encode the procedure
  algorithmically in an AI agent.
\item
  We generally cannot ground inferences on intuition. Intuition is shaky
  ground, and hopeless in data-science problems involving millions of
  data with thousands of numbers in abstract spaces of thousands of
  dimensions. To solve such complex problems we need to use a more
  mechanical procedure, a procedure \emph{mathematically guaranteed} to
  be self-consistent. That's the probability calculus. Intuition is only
  useful for arriving at a method which we can eventually prove, by
  mathematical and logical means, to be correct; or for approximately
  explaining a method that we already know, again by mathematical and
  logical means, to be correct.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Misleading intuition in high dimensions}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

As an example of our intuition can be completely astray in problems
involving many data dimensions, consider the following fact.

Take a one-dimensional Gaussian distribution of probability. You
probably know that the probability that a data point is within three
standard deviations from the peak is approximately {\(99.73\%\).} If we
take a two-dimensional (symmetric) Gaussian distribution, the
probability that a data point (two real numbers) is within three
standard deviations from the peak is {\(98.89\%\),} slightly less than
the one-dimensional case. For a three-dimensional Gaussian, the
analogous probability is {\(97.07\%\),} slightly smaller yet.

Now try to answer this question: for a \emph{100-dimensional} Gaussian,
what is the probability that a data point is within three standard
deviations from the peak? The answer is
{\(\boldsymbol{(1.83 \cdot 10^{-32})\%}\).} This probability is so small
that you would never observe a data point within three standard
deviations from the peak, even if you checked one data point every
second for the same duration as the present age of the universe -- which
is ``only'' around {\(4\cdot 10^{17}\)} seconds.

\end{tcolorbox}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

For further examples of how our intuition leads us astray in high
dimensions see

\begin{itemize}
\item
  \href{https://people.eecs.berkeley.edu/~jrs/highd/}{Counterintuitive
  Properties of High Dimensional Space}
\item
  Exercise~2.20 (and its solution) in
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Information
  Theory, Inference, and Learning Algorithms}}
\end{itemize}

\end{tcolorbox}

\end{footnotesize}}

It is instructive, however, if you also check what your intuition told
you about the problem:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Examine what your intuition tells you the answer should be, without
spending too much time thinking, just as if you were on the game show.
Examine which kind of heuristics your intuition uses. If you already
know the solution to this puzzle, try to remember what your intuition
told you the first time you faced it. Keep your observations in mind for
later on.

\end{tcolorbox}

\section{Which agent? whose knowledge?}\label{sec-monty-agent}

A sentence can be assigned different probabilities by different agents
having different background information, although in some cases
different background information can still lead to numerically equal
probabilities.

In the present case, who's the agent solving the inference problem? And
what background information does it have?

From the problem statement it sounds like you (on the show) are the
agent. But we can imagine that you have programmed an AI agent having
your same background information, and ready to make the decision for
you.

We must agree on which background information {\(\mathsfit{H}\)} to give
to this agent. Let's define {\(\mathsfit{H}\)} as the knowledge you have
right \emph{before} picking door\,1. We make this choice so that we can
add your door pick as additional information.

\section{Define the atomic sentences relevant to the
problem}\label{sec-monty-sentences}

The following sentences seem sufficient:

\[
\begin{aligned}
\mathsfit{H}&\coloneqq\text{\small[the background knowledge discussed in the previous section]}
\\[1ex]
\mathsfit{\small car1} &\coloneqq\textsf{\small`The car is behind door 1'}
\\
\mathsfit{\small you1} &\coloneqq\textsf{\small`You initially pick door 1'}
\\
\mathsfit{\small host2} &\coloneqq\textsf{\small`The host opens door 2'}
\\
&\text{\small and similarly for the other door numbers}
\end{aligned}
\]

We could have used other symbols for the sentences, for instance
{``\(C_1\)''} instead of {``\(\mathsfit{\small car1}\)''}. The specific
symbol choice doesn't matter. We could also have stated the sentences
slightly differently, for instance ``{You choose door\,1 at the
beginning of the game}''. What's important is that we understand and
agree on the meaning of the atomic sentences above.

\section{Specify the desired inference}\label{sec-monty-goal}

We want the probabilities of the sentences {\(\mathsfit{\small car1}\),}
{\(\mathsfit{\small car2}\),} {\(\mathsfit{\small car3}\),} given the
knowledge that you picked door\,1 ({\(\mathsfit{\small you1}\)),} that
the host opened door\,2 ({\(\mathsfit{\small host2}\)),} and the
remaining background knowledge ({\(\mathsfit{H}\)).} So in symbols we
want the values of the following probabilities:

\[
\begin{aligned}
&\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\
&\mathrm{P}(\mathsfit{\small car2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\
&\mathrm{P}(\mathsfit{\small car3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\end{aligned}
\]

You may object: ``but we already know that there's no car behind
door\,2, the one opened by the host; so that probability is 0\%''.
That's correct, but how did you arrive at that probability value?
Remember our goal: to solve this inference \emph{mechanically}. Your
intuitive probability must therefore either appear as an initial
probability, or be derived via the inference rules. No intuitive
shortcuts.

\section{Specify all initial probabilities}\label{sec-monty-prior}

As discussed in §~\ref{sec-inference-origin}, any inference -- logical
or uncertain -- can only be derived from other inferences, or taken for
granted as a starting point (``initial probability'', or ``axiom'' in
logic). The only inferences that don't need any initial probabilities
are tautologies. We must explicitly write down the initial probabilities
implicit in the present inference problem:

\begin{itemize}
\item
  The car is for sure behind one of the three doors, and cannot be
  behind more than one door:

  \[
  \begin{gathered}
  \mathrm{P}(\mathsfit{\small car1} \lor \mathsfit{\small car2} \lor \mathsfit{\small car3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) = 1
  \\[1ex]
  \mathrm{P}(\mathsfit{\small car1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small car2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) =
  \mathrm{P}(\mathsfit{\small car1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small car3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) =
  \mathrm{P}(\mathsfit{\small car2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small car3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) = 0
  \end{gathered}
  \]

  Remember from the shortcut rule for the permanence of truth and
  falsity (§~\ref{sec-truth-stable}) that the {\(1\)} and {\(0\)}
  probabilities above do not change if we \texttt{and} additional
  information to {\(\mathsfit{H}\).}
\item
  The host cannot open the door you picked or the door with the car.
  This translates in several initial probabilities. Here are some:

  \[\begin{gathered}
  \mathrm{P}(\mathsfit{\small host2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) = 0
  \\[1ex]
  \mathrm{P}(\mathsfit{\small host1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) =
  \mathrm{P}(\mathsfit{\small host3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) = 0
    \end{gathered}
    \]
\item
  The host must open one door, and cannot open more than one door:

  \[
  \begin{gathered}
  \mathrm{P}(\mathsfit{\small host1} \lor \mathsfit{\small host2} \lor \mathsfit{\small host3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) = 1
  \\[1ex]
  \mathrm{P}(\mathsfit{\small host1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small host2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) =
  \mathrm{P}(\mathsfit{\small host1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small host3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) =
  \mathrm{P}(\mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small host3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) = 0
  \end{gathered}
  \]
\end{itemize}

\hfill\break
The probabilities above are all quite clear from the description of the
puzzle. But implicit in that description are some more probabilities
that will be needed in our inference. The values of these probabilities
can be more open to debate, because the problem, as stated, provides
ambiguous information. You shall later explore possible alternative
values for these probabilities.

\begin{itemize}
\item
  It is equally probable that the car is behind any of the three doors,
  and your initial pick doesn't change this uncertainty:

  \[\begin{aligned}
  \mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) &= \mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) = 1/3
  \\
  \mathrm{P}(\mathsfit{\small car2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) &= \mathrm{P}(\mathsfit{\small car2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) = 1/3
  \\
  \mathrm{P}(\mathsfit{\small car3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) &= \mathrm{P}(\mathsfit{\small car3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) = 1/3
    \end{aligned}
    \]

  Remember that a probability is not a physical property. We aren't
  saying that the car should appear behind each door with a given
  frequency, or something similar. The values 1/3 are simply saying that
  in the present situation you have no reason to \emph{believe} the car
  to be behind one specific door more than behind another.
\item
  If the host can choose between two doors (because the car is behind
  the door you picked initially), we are equally uncertain about the
  choice:

  \[
  \mathrm{P}(\mathsfit{\small host2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) =
  \mathrm{P}(\mathsfit{\small host3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) = 1/2
    \]
\end{itemize}

This probability could be analysed into further hypotheses. Maybe the
host, out of laziness, could more probably open the door that's closer.
But from the problem it isn't fully clear which one is closer. The host
could also more probably open the door that's further from the one you
choose. The host could have a predetermined scheme on which door to
open. The hypotheses are endless. We can imagine some hypotheses that
make {\(\mathsfit{\small host2}\)} more probable, and some that make
{\(\mathsfit{\small host3}\)} more probable, conditional on
{\(\mathsfit{\small you1} \land \mathsfit{\small car1} \land \mathsfit{H}\).}
The probability of 50\% seems like a good compromise. You shall later
examine the effects of changing this probability.

\subsection{Some peculiar probabilities}\label{sec-monty-youprob}

We defined the background knowledge {\(\mathsfit{H}\)} as the one you
have right \emph{before} choosing door\,1. In this way the sentence
{\(\mathsfit{\small you1}\),} expressing your door pick, can be added as
additional information: {\(\mathsfit{\small you1}\land \mathsfit{H}\).}

It is legitimate to ask: what is the probability that you pick door\,1,
given only the background information {\(\mathsfit{H}\):}

\[\mathrm{P}(\mathsfit{\small you1}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H})\ ?\]

To answer this question we would need to specify {\(\mathsfit{H}\)} more
in detail. It is possible, for instance, that you planned to pick
door\,1 already the day before. In this case we would have
{\(\mathrm{P}(\mathsfit{\small you1}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) = 1\)}
or very nearly so. Or you could pick door\,1 right on the spot, with no
clear conscious thought process behind your choice. In this case we
would have
{\(\mathrm{P}(\mathsfit{\small you1}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}) = 1/3\)}
or a similar value.

Luckily in the present problem these probabilities are not needed. If
they are used, their numerical values turn out not to matter: they will
``cancel out'' of the computation.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Silly literature}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Some texts on probability say that if you have decided something and
therefore know for certain it in advance, then the probability of that
something is undefined ``because it is not random''. Obviously this is
nonsense. If you already know something, then the probability of that
something is well-defined and its value is 100\% -- or something short
of this value, if you want to make allowance for the occurrence of
unplanned events.

\end{tcolorbox}

\section{Solution}\label{sec-monty-solution}

Let's try first to calculate
{\(\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})\),}
that is, the probability that the car is behind the door you picked.

Seeing that we have several initial probabilities of the
{``\(\mathrm{P}(\mathsfit{\small host} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small car} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})\)''}
form, we can use Bayes's theorem together with the ``extension of the
conversation'' (§~\ref{sec-bayes-extension}) to swap the positions of
{``\(\mathsfit{\small car}\)''} and {``\(\mathsfit{\small host}\)''}
sentences between proposal and conditional. In the present case the
exhaustive and mutually exclusive sentences are
{\(\mathsfit{\small car1}\),} {\(\mathsfit{\small car2}\),}
{\(\mathsfit{\small car3}\):}

\[
\begin{aligned}
&\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\[1ex]
&\qquad=\frac{
{\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})} \cdot
{\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})}
}{
\enspace\left[\,\begin{gathered}
{\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})} \cdot
{\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})} +{}\\
{\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})} \cdot
{\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small car2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})} +{}\\
\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) \cdot
{\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small car3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})}
\end{gathered}\,\right]\enspace
}
\\[1ex]
&\qquad=\dotso
\end{aligned}
\]

All probabilities in {green} are initial probabilities discussed in the
previous steps. Let's substitute their values:

\[
\begin{aligned}
&\qquad=\frac{
{\color[RGB]{34,136,51}1/2} \cdot
{\color[RGB]{34,136,51}1/3}
}{
\enspace\left[\,\begin{gathered}
{\color[RGB]{34,136,51}1/2} \cdot
{\color[RGB]{34,136,51}1/3} +{}\\
{\color[RGB]{34,136,51}0} \cdot
{\color[RGB]{34,136,51}1/3} +{}\\
\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) \cdot
{\color[RGB]{34,136,51}1/3}
\end{gathered}\,\right]\enspace
}
\\[1ex]
&\qquad=\frac{ 1/6
}{
1/6 +
\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) \cdot
1/3
}
\\[1ex]
&\qquad=\dotso
\end{aligned}
\]

All that's left is to find
{\(\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})\).}
It's intuitively clear that this probability is 100\%, because the host
is forced to choose door\,2 if you picked door\,1 and the car is behind
door\,3. But our purpose is to make a fully mechanical derivation,
starting from the initial probabilities only. We can find this
probability by applying the \texttt{or}-rule and the \texttt{and}-rule
to the probabilities that the host opens at least one door and cannot
open more than one:

\[
\begin{aligned}
&\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\[1ex]
&\qquad=
\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small host2} \lor \mathsfit{\small host1} \lor \mathsfit{\small host3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\
&\qquad\quad{}-
\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small host1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\
&\qquad\quad{}-
\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small host3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\
&\qquad\quad{}+
\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small host1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small host2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\
&\qquad\quad{}+
\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small host1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small host3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\
&\qquad\quad{}+
\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small host3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\
&\qquad\quad{}-
\color[RGB]{34,136,51}\mathrm{P}(\mathsfit{\small host1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small host3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\[1ex]
&\qquad= 1 - 0 - 0 + 0 + 0 + 0 - 0 = 1
\end{aligned}
\]

as expected.

Finally, using this probability in our previous calculation we find

\[
\begin{aligned}
&\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\[1ex]
&\qquad=\frac{ 1/6
}{
1/6 +
\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) \cdot
1/3
}
\\[1ex]
&\qquad=\frac{ 1/6
}{
1/6 +
1 \cdot
1/3
}
= \frac{1/6}{3/6} = \boldsymbol{\frac{1}{3}}
\end{aligned}
\]

that is, there's a 1/3 probability that the car is behind the door we
picked!

\hfill\break
What about door\,3, that is, the probability
{\(\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})\)?}
Also in this case we can use Bayes's theorem with the extension of the
conversation. The calculation is immediate, because we have already
calculated all the relevant pieces:

\[
\begin{aligned}
&\mathrm{P}(\mathsfit{\small car3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\\[1ex]
&\qquad=\frac{
\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) \cdot
\mathrm{P}(\mathsfit{\small car3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
}{
\enspace\left[\,\begin{gathered}
\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) \cdot
\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) +{}\\
\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) \cdot
\mathrm{P}(\mathsfit{\small car2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) +{}\\
\mathrm{P}(\mathsfit{\small host2}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car3} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) \cdot
\mathrm{P}(\mathsfit{\small car3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
\end{gathered}\,\right]\enspace
}
\\
&\qquad=\frac{
 1 \cdot
 1/3
}{
\enspace\left[\,\begin{gathered}
 1/2 \cdot
 1/3 +{}\\
 0 \cdot
1/3 +{}\\
1
\cdot
 1/3
\end{gathered}\,\right]\enspace
}
\\[1ex]
&\qquad=\frac{1/3}{1/2} = \boldsymbol{\frac{2}{3}}
\end{aligned}
\]

that is, there's a 2/3 probability that the car is behind door\,3. If
we'd like to win the car, then we should switch doors.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Perform a similar calculation to find
{\(\mathrm{P}(\mathsfit{\small car2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})\)}

\end{tcolorbox}

\hfill\break
Note that we found these probabilities, and solved the Monty Hall
problem, just by applying the fundamental rules of inference
(§~\ref{sec-fundamental}), specifically the \texttt{and}-rule and
\texttt{or}-rule, and the Boolean-algebra shortcut rules
(§~\ref{sec-derived-rules}), starting from given probabilities. Here is
a depiction of how the fundamental and the shortcut rules connect the
initial probabilities, at the top, to the final ones, at the bottom:

\begin{figure*}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{prob_tree_monty3.png}

\end{figure*}%

\hfill\break

\section{Remarks on the use of Bayes's theorem}\label{sec-monty-remarks}

You notice that at several points our calculations could have taken a
different path. For instance, in order to find
{\(\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})\)}
we applied Bayes's theorem to swap the sentences
{\(\mathsfit{\small car1}\)} and {\(\mathsfit{\small host2}\)} in their
proposal and conditional positions. Couldn't we have swapped
{\(\mathsfit{\small car1}\)} and
{\(\mathsfit{\small host2}\land \mathsfit{\small you1}\)} instead? That
is, couldn't we have made a calculation starting with

\[
\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})
=\frac{
\mathrm{P}(\mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) \cdot
\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H})
}{\dotso} \enspace ?
\]

after all, this is also a legitimate application of Bayes's theorem.

The answer is: yes, we could have, \textbf{and the final result would
have been the same.} The self-consistency of the probability calculus
guarantees that there are no ``wrong steps'', as long as every step is
an application of one of the four fundamental rules (or of their
shortcuts). The worst that can happen is that we take a longer route --
but to exactly the same result. In fact it's possible that there's a
shorter calculation route to arrive at the probabilities that we found
in the previous section. But it doesn't matter, because it would lead to
the same result that we found.

\hfill\break

\section{Sensitivity analysis}\label{sec-monty-sensitivity}

In §~\ref{sec-monty-prior} we briefly discussed possible interpretations
or variations of the Monty Hall problem, for which the probability that
the host chooses among the available doors\,2 and~3 (if the car is
behind the door you picked) is different from 50\%.

When we want to know how an initial probability value can affect the
final probabilities, we can leave its value as a variable, and check how
the final probabilities change as we change this variable. This
procedure is often called {\textbf{sensitivity analysis}}. Try to do a
sensitivity analysis for the Monty Hall problem:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Instead of assuming

\[\mathrm{P}(\mathsfit{\small host2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) =
\mathrm{P}(\mathsfit{\small host3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) = 1/2\]

assign a generic variable value {\(p\)}

\[\mathrm{P}(\mathsfit{\small host2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) = p
\qquad
\mathrm{P}(\mathsfit{\small host3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small car1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) = 1-p\]

where {\(p\)} could be any value between {\(0\)} and {\(1\).}

\begin{itemize}
\item
  Calculate
  {\(\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})\)}
  as was done in the previous sections, but keeping {\(p\)} as a generic
  variable. This way you'll find a probability
  {\(\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})\)}
  that depends numerically on {\(p\);} it could be considered as a
  function of {\(p\).}
\item
  Plot how the value of
  {\(\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H})\)}
  depends on {\(p\),} as the latter ranges from {\(0\)} to {\(1\).}
\item
  For which range of values of {\(p\)} is it convenient to switch door,
  that is,
  {\(\mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small host2} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}) < 1/2\)\,?}
\item
  Imagine and describe alternative scenarios or background information
  that would lead to values of {\(p\)} different from {\(0.5\).}
\end{itemize}

\end{tcolorbox}

\section{Variations and further exercises}\label{sec-monty-variations}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise: other variations}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  In §~\ref{sec-monty-agent} we decided that the agent in this inference
  was you, with the knowledge {\(\mathsfit{H}\)} right before you picked
  door\,1. Try to change the agent: do you arrive at different
  probabilities?

  \begin{itemize}
  \item
    Consider a person in the audience, right before you picked door\,1,
    as the agent, and re-solve the problem, adjusting all initial
    probabilities as needed.
  \item
    Consider the \emph{host} as the agent, right before you picked
    door\,1, and re-solve the problem, adjusting all initial
    probabilities as needed. Note that the host knows for certain where
    the car is, so you need to provide this additional, secret
    information. Consider the cases where the car is behind door\,1 and
    behind door\,3.
  \end{itemize}
\end{itemize}

\hfill\break

\begin{itemize}
\item
  Suppose a friend of yours, backstage, gave you partial information
  about the location of the car (you cheater!), which makes you believe
  that the car should be closer to door\,1. Assign the probabilities

  \[\begin{aligned}
  \mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}') &= \mathrm{P}(\mathsfit{\small car1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}') = 1/3 + q
  \\
  \mathrm{P}(\mathsfit{\small car2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}') &= \mathrm{P}(\mathsfit{\small car2} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}') = 1/3
  \\
  \mathrm{P}(\mathsfit{\small car3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{H}') &= \mathrm{P}(\mathsfit{\small car3} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\small you1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{H}') = 1/3 - q
    \end{aligned}
    \]

  with {\(0 \le q \le 1/3\)} (this background information is different
  from the previous one, so we denote it {\(\mathsfit{H}'\)).} Re-solve
  the problem keeping the variable {\(q\),} and find if there's any
  value for {\(q\)} for which it's best to keep door\,1.
\end{itemize}

\end{tcolorbox}

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise: making decisions}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

In this chapter we only solved the \emph{inference} problem for the
Monty Hall scenario. We calculated the probabilities of various
outcomes. But no decision has been made yet.

\begin{itemize}
\item
  Assign utilities to winning the car or winning the goat from the point
  of view of an agent who values the car more. The available decisions
  are, of course, ``keep door\,1'' vs ``switch to door\,3''. Then solve
  the decision-making problem according to the procedure of
  §~\ref{sec-make-decision}. What's the optimal decision?
\item
  Now assign utilities from the point of view of an agent who values the
  \emph{goat} more than the car. Then solve the decision-making problem
  according to the usual procedure. What's the optimal decision?
\end{itemize}

\end{tcolorbox}

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise: the Sleeping Beauty problem}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Take a look at the inference problem presented in this video:

\url{https://vimeo.com/893102563?share=copy}

and try to solve it, not using intuition, but using the mechanical
procedure and steps as in the Monty Hall solution above.

Note that the video asks ``What do you believe is the probability that
the coin came up heads?''. Since probability and degree of belief are
the same thing, that is like asking ``What do you believe is your belief
that the coin came up heads?'' which is a redundant or quirky question.
Instead, simply answer the question ``What is your degree of belief
(that is, probability) that the coin came up heads?''.

\end{tcolorbox}

\chapter{\texorpdfstring{{Second connection with machine
learning}}{Second connection with machine learning}}\label{sec-2-connection-ML}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\ys}{\se{s}}
\providecommand*{\yh}{\se{h}}
\providecommand*{\yf}{\se{f}}
\providecommand*{\yv}{\se{v}}
\providecommand*{\yJ}{\se{J}}
\providecommand*{\yZ}{\se{Z}}
\providecommand*{\yH}{\se{H}}

In these first chapters we have been developing notions and methods
about agents that draw inferences and make decisions, sentences
expressing facts and information, and probabilities expressing
uncertainty and certainty. Let's draw some first qualitative connections
between these notions and notions typically used in machine learning.

A machine-learning algorithm is usually presented in textbooks as
something that first ``learns'' from some training data, and thereafter
performs some kind of task -- typically it yields a response or outcome,
for example a label, of some kind. More precisely, the training data are
instances or examples of the task that the algorithm is expected to
perform. These instances have a special status because their details are
fully known, whereas new instances, where the algorithm will be applied,
have some uncertain aspects. A new instance typically has an ideal or
optimal outcome, for example ``choosing the correct label'', but this
outcome is unknown beforehand. The response given by the algorithm in
new instances depends on the algorithm's internal architecture and
parameters (for brevity we shall just use ``architecture'' to mean
both).

Let's try to rephrase this description from the point of view of the
previous chapters. A machine-learning algorithm is given {known pieces
of information (the training data)}, and then forms some kind of
connection with {a new piece of information of similar kind (the outcome
in a new application) that was not known beforehand}. The connection
depends on the {algorithm's architecture}.

\section{``Learning'' and ``output'' from the point of view of inference
\& decision}\label{sec-1stconn-inference}

The remarks above reveal similarities with what an agent does when
drawing an inference: it uses known pieces of information, expressed by
sentences
{\({\color[RGB]{34,136,51}\mathsfit{D}_1}, {\color[RGB]{34,136,51}\mathsfit{D}_2}, {\color[RGB]{34,136,51}\dots}, {\color[RGB]{34,136,51}\mathsfit{D}_N}\),}
together with some background or built-in information
{\(\color[RGB]{204,187,68}\mathsfit{I}\),} in order to calculate the
probability of a new piece of information of a similar kind, expressed
by a sentence {\(\color[RGB]{238,102,119}\mathsfit{D}_{N+1}\):}

\[
\mathrm{P}(\color[RGB]{238,102,119}\mathsfit{D}_{N+1}\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} 
\color[RGB]{34,136,51}\mathsfit{D}_{N} \land \dotsb \land \mathsfit{D}_2 \land \mathsfit{D}_1 \color[RGB]{0,0,0}\land {\color[RGB]{204,187,68}\mathsfit{I}})
\]

We can thus consider a first \emph{tentative} correspondence:

\[
\mathrm{P}(\underbracket[0ex]{\color[RGB]{238,102,119}\mathsfit{D}_{N+1}}_{\mathclap{\color[RGB]{238,102,119}\text{outcome?}}} \nonscript\:\vert\nonscript\:\mathopen{} 
\color[RGB]{34,136,51}\underbracket[0ex]{\mathsfit{D}_N \land \dotsb \land \mathsfit{D}_2 \land \mathsfit{D}_1}_{\mathclap{\color[RGB]{34,136,51}\text{training data?}}} 
\color[RGB]{0,0,0}\land \underbracket[0ex]{\color[RGB]{204,187,68}\mathsfit{I}}_{\mathrlap{\color[RGB]{204,187,68}\uparrow\ \text{architecture?}}})
\]

This correspondence seems convincing for {architecture} and {training
data}: in both cases we're speaking about the use of pre-existing or
built-in information, combined with additional information.

But the correspondence is less convincing with regard to the {outcome}.
The ``agents'' that we have envisioned find the probabilities for
several possible ``outcomes'' or ``outputs''; they don't yield only one
output. This indicates that there must also be some \textbf{decision}
involved among the possible outcomes.

We'll return to this tentative connection later.

\section{Why different outputs?}\label{sec-1stconn-outputs}

In the previous chapters we have seen, over and over, what was claimed
at the beginning of these lecture notes: that an inference \& decision
problem has only one optimal solution. Once we specify the utilities and
the initial probabilities of the problem, the fundamental rules of
inference and the principle of maximal expected utility lead to one
unique answer (unless, of course, there are several optimal ones with
equal expected utilities).

Different machine-learning algorithms, trained with the same training
data, often give different answers or outputs to the same problem. Where
do these differences come from? From the point of view of decision
theory there are three possibilities, which don't exclude one another:

\begin{itemize}
\item
  {\textbf{The initial probabilities given to the algorithms are
  different}}. Since the training data are the same, this means that the
  \textbf{background information built into} one machine-learning
  algorithm is different from those built into another.

  It is therefore important to {\emph{understand what are the built-in
  background information and initial probabilities}} of different
  machine-learning algorithms. The built-in assumptions of an algorithm
  must match those of the real problem as closely as possible, in order
  to avoid sub-optimal or even disastrously wrong answers and outputs.
\item
  {\textbf{The utilities built into one machine-learning algorithm are
  different}} from those built into another.

  It is therefore also important to {\emph{understand what are the
  built-in utilities}} of different machine-learning algorithms. The
  built-in utilities must also match those of the real problem as
  closely as possible.
\item
  {\textbf{The calculations made by the algorithms are approximate}},
  and different algorithms use different approximations. This means that
  the algorithms don't arrive at the unique answer determined by
  decision theory, but to some other answers which may be approximately
  close to the optimal one -- or not!

  It is therefore important to {\emph{understand what are the
  calculation approximations}} made by different machine-learning
  algorithms. Some approximations may be too crude for some real
  problems, and may again lead to sub-optimal or even disastrously wrong
  answers and outputs.
\end{itemize}

\section{Data pre-processing and the data-processing
inequality}\label{sec-1stconn-preprocess}

``Data pre-processing'' is a collective name given to very different
operations on data before they are used in some algorithm to solve a
decision or inference problem. Some of these operations are often said
to be essential for the solution of these problems. This statement in
not completely true, and needs qualification.

We can divide pre-processing procedures in roughly three categories:

\begin{description}
\tightlist
\item[Inconsistency checks]
Procedures in this category make sure that the data are what they were
intended to be. For instance, if data should consist of the power
outputs of several engines, but one datapoint is the physical
\emph{weight} of an engine, then that ``datapoint'' is actually no data
at all for the present problem. It's something included by mistake and
should be removed. Such procedures are necessary and useful, but they
are just consistency checks and do not change the information contained
in the \emph{proper} data.
\end{description}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

In later chapters we shall say more about some often erroneous
procedures, like ``tail trimming'', that actually remove \emph{proper}
data and lead to sub-optimal or completely erroneous solutions.

\end{tcolorbox}

\begin{description}
\tightlist
\item[Formatting]
These procedures make sure that data are in the correct format to be
inputted into the algorithm. They may also include rescaling of
numerical values for avoiding numerical overflow or underflow errors
during computation. Such procedures are often necessary and useful, but
they just change the way data are encoded. They do not actually change
the information contained in the data.
\item[``Mutilation'' or information-alteration]
Procedures of this kind \emph{alter the content of data}. For instance,
such a procedure may replace, in a dataset of temperatures, a datapoint
having value 20\,°C with one having value 25\,°C; this is not just a
simple rescaling. Procedures of this kind include ``de-noising'',
``de-biasing'', ``de-trending'', ``filtering'', ``dimensionality
reduction'' and similar ones (often having noble-sounding names). We
must state, clearly and strongly, that {\emph{within Decision Theory and
Probability Theory, such information-altering pre-processing is
\textbf{not} necessary , and is in fact \textbf{detrimental}}}. This is
why we call it ``mutilation'' here.
\end{description}

\emph{It is important that you understand that such data pre-processing
is \textbf{not} something that one, in principle, has to do in data
science. Quite the opposite, in principle we should \textbf{not} do it,
because it is a destructive procedure. Such pre-processing is done in
order to correct deficiencies of the algorithms currently in use, as
discussed below.}

If we build an ``optimal predictor machine'' that fully operates
according to the four rules of inference (§~\ref{sec-fundamental}) and
of maximization of expected utility, then the data fed into this machine
\emph{should not be pre-processed with any information-altering
procedures}. The reason is that the four fundamental rules automatically
take care, in an optimal way, of factors such as noise, bias, systematic
errors, redundancy. We briefly discussed this fact in
§~\ref{sec-idempotent} and saw a simple example of how redundancy is
accounted for by the four inference rules.

If we have information about noise or other factors affecting the data,
then we should include this information in the background information
provided to the ``optimal predictor machine'', rather than altering the
data given to it. The reason, in intuitive terms, is that the machine
does the adjustments while fully exploring the data themselves; so it
can ``see'' more deeply how to make optimal adjustments given the
``inner structure'' of the data. In the pre-processing phase -- as the
prefix ``\emph{pre-}'' indicates -- we don't have the full picture about
the data, so any adjustment risks to eliminate actually useful
information.

More formally, this is the content of the {\textbf{data-processing
inequality}} from information theory:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={Data-processing inequality}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

``No clever manipulation of the data can improve the inferences that can
be made from the data''\\
{(\emph{Elements of Information Theory} §2.8)}

{or, from a complementary point of view:}

``Data processing can only destroy information''\\
{(\emph{Information Theory, Inference, and Learning Algorithms}
exercise~8.9)}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  Skim through §2.8 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Elements
  of Information Theory}}
\item
  Take a look Exercise 8.9 and its solution in
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Information
  Theory, Inference, and Learning Algorithms}}
\end{itemize}

\end{tcolorbox}

\hfill\break
There are two main, partially connected reasons why one performs
``mutilating'' pre-processing of data:

\begin{itemize}
\item
  The algorithm used is \emph{non-optimal}: it's only using
  approximations of the four fundamental rules, and therefore cannot
  remove noise, bias, redundancies, or similar factors in an optimal
  way, or at all. In this case, pre-processing is an approximate way of
  correcting the deficiency of the non-optimal algorithm.
\item
  Full optimal processing is \emph{computationally too expensive}. In
  this case we try to simplify the optimal calculation by doing, in
  advance and in a cruder, faster way, some of the ``cleaning'' that the
  full calculation would otherwise spend time doing in an optimal way.
\end{itemize}

\part{{\textbf{Data I}}}

\chapter{\texorpdfstring{{Quantities and data
types}}{Quantities and data types}}\label{sec-quantities-types-basic}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\section*{\texorpdfstring{{Motivation for the ``Data~I''
part}}{Motivation for the ``Data~I'' part}}\label{motivation-for-the-data-i-part}
\addcontentsline{toc}{section}{{Motivation for the ``Data~I'' part}}

\markright{{Motivation for the ``Data~I'' part}}

In the ``{Inference~I}'' part we surveyed the four fundamental rules of
inference, which determine how an agent's degrees of belief should
propagate and be self-consistent. We explored some applications and
consequences of the four fundamental rules. The rules can be used with
any sentences whatsoever, so their application can be further developed
and specialized in a wide spectrum of directions, with applications
ranging from robotics to psychology. Each of these possible developments
would require by itself a full university course!

We shall now restrict our attention to applications typical of ``data
science'' and machine learning, like classification, forecast,
prognosis, hypothesis testing, in situations that involve
\emph{quantifiable} and \emph{measurable} phenomena. For this purpose we
focus on sentences of particular kinds, which can express such
quantification and measurement. In a sense, we develop a specialized
``language'' for this kind of situations.

Still, since we're nonetheless dealing with sentences
(Ch.\,~\ref{sec-sentences}), the probability calculus and its inference
rules apply without changes of any kind.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hfill\break

\section{Quantities}\label{quantities}

\subsection{Quantities, values, domains}\label{sec-quant-value-dom}

Most decisions and inferences in engineering and data science involve
things or properties of things that we can \emph{measure}. We represent
them by mathematical objects of different kinds. These objects have
particular mathematical properties and can undergo particular
operations.

The different mathematical properties of these things reflect the kind
of activities that we can do with them. For instance, colours are
represented by particular tuples of numbers. These tuples can be
multiplied by some numeric weights and added, to obtain another tuple.
This mathematical operation, called ``convex combination'', represents
the fact that colours can be obtained by mixing other colours in
different proportions.

\marginnote{\begin{footnotesize}

25\%\,{\textbf{\#FF0000}}~+ 75\%\,{\textbf{\#0000FF}}~=
{\textbf{\#4000C0}}

\end{footnotesize}}

It's difficult to find a general term to denote any instance of such
``things'' and their mathematical representation. Yet it's convenient if
we find one, so we can discuss the general theory without getting bogged
down in individual cases. To this purpose we'll borrow the term
{\textbf{quantity}} from physics and engineering.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

The definition of ``quantity'' we are using here is similar to the one
having the \emph{maximum specific level} as defined in
\href{https://www.iso.org/sites/JCGM/VIM/JCGM_200e_FILES/MAIN_JCGM_200e/01_e.html\#L_1_1}{§1.1
of the \emph{International vocabulary of metrology}} by the
\href{https://www.bipm.org/en/committees/jc/jcgm/publications}{Joint
Committee for Guides in Metrology}.

Using the word ``quantity'' this way is just a convention between us.
Other texts and scientists may use other words -- for example
``variable'', ``event'', ``state''. When you read a text or listen to a
scientist, try to grasp the general idea \emph{behind} their words.

As a general term, we prefer the word ``quantity'' to a word like
``variable'', because the latter may give the idea of something changing
in time, and that may very well \emph{not} be the case (think of the
mass of a block of concrete). Same goes with a word like ``state'', for
the opposite reason.

\end{tcolorbox}

\hfill\break

We distinguish between a quantity and its {\textbf{value}}. For
instance, a quantity could be:\\
``{The temperature at the point having GPS coordinates~~60.3775029,
5.3869233, 643,~~at time 1895-10-04T10:03:14Z}'';\\
and its value could be:\\
{\(24\,\mathrm{°C}\)}. To understand the difference between a quantity
and its value, you may think of the quantity as a question, and of the
value as the answer to that question:

(\emph{quantity}:) ``{What was the temperature at the point having GPS
coordinates~~60.3775029, 5.3869233, 643,~~at time
1895-10-04T10:03:14Z}?''\\
(\emph{value}:) ``It was {\(24\,\mathrm{°C}\)}.''

The distinction between a quantity and its value is important and
necessary in inference and decision problems, because an agent may
\emph{not} know the value of a particular quantity, while still knowing
what the quantity is. In this case the agent can consider every possible
value that the quantity could have, and assign a probability to each.
The set of possible values is called the {\textbf{domain}} of the
quantity. Think of it as the collection of all meaningful answers that
could be given to the question. In our temperature example, the domain
is the set of all possible temperatures from {\(0\,\mathrm{K}\)} and
above.

Keep in mind that our definition of quantity is quite general. Here's
another example:

\begin{itemize}
\item
  \emph{Quantity}: the image taken by a particular camera at a
  particular time, represented by a specific collection of numbers (say
  128\,×\,128\,×\,3 integers between {\(0\)} and {\(255\)).}
\item
  One example \emph{value} is this:
  \includegraphics[width=2em,height=\textheight,keepaspectratio]{cat_image.png}
  (corresponding to a grid of 128\,×\,128\,×\,3 \emph{specific}
  numbers). Another example value:
  \includegraphics[width=2em,height=\textheight,keepaspectratio]{saitama_image.png}.
\item
  \emph{Domain}: the collection of
  {\(256^{3\times128\times128} \approx 10^{118 370}\)} possible images
  (corresponding to the collection of possible grids of numeric values).
\end{itemize}

\hfill\break
Other examples of quantities and their domains:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The distance between two objects in the Solar System at a specific
  \href{https://www.aanda.org/articles/aa/full/2002/34/aa2452/aa2452.html}{Barycentric
  Coordinate Time}. The domain could be, say, all values from
  {\(0\,\mathrm{m}\)} to {\(6\cdot10^{12}\,\mathrm{m}\)}
  (\href{https://solarsystem.nasa.gov/planets/dwarf-planets/pluto}{Pluto}'s
  average orbital distance).
\item
  The number of total views of a specific online video (at a specific
  time), with a domain, say, from 0 to 20 billions.
\item
  The force on an object at a specific time and place. The domain could
  be, say, 3D vectors with components in
  {\([-100\,\mathrm{N},\,+100\,\mathrm{N}]\).}
\item
  The degree of satisfaction in a customer survey, with five possible
  values \texttt{Not\ at\ all\ satisfied}, \texttt{Slightly\ satisfied},
  \texttt{Moderately\ satisfied}, \texttt{Very\ satisfied},
  \texttt{Extremely\ satisfied}.
\item
  The graph representing a particular social network. Individuals are
  represented by nodes, and different kinds of relationships by directed
  or undirected links between nodes, possibly with numbers indicating
  their strength. The domain consists of all possible graphs with, say,
  0 to 10\,000 nodes and all possible combinations of links and weights
  between the nodes.
\item
  The relationship between the input voltage and output current of an
  electric component. The domain could be all possible continuous
  \emph{curves} from {\([0\,\mathrm{V}, 10\,\mathrm{V}]\)} to
  {\([0\,\mathrm{A}, 1\,\mathrm{A}]\).} Note that the domain in this
  case is not made of \emph{numbers}.
\item
  A 1-minute audio track recorded by a device with a sampling frequency
  of 48\,kHz (that is, 48\,000 audio samples per second). The domain
  could be all possible sequences of 2\,880\,000 numbers in {\([0,1]\).}
\item
  The subject of an image, with domain of three possible values
  \texttt{cat}, \texttt{dog}, \texttt{something\ else}.
\item
  The
  \href{https://www.grc.nasa.gov/www/k-12/rocket/rotations.html}{roll,
  pitch, yaw} of a rocket at a specific time and place, with domain
  {\((-180°,+180°]\times(-90°,+90°]\times(-180°,+180°]\).}
\end{enumerate}

\hfill\break

The vague term ``data'' typically means the values of a collection of
quantities.

\textbf{In these notes we agree that {\emph{a \textbf{quantity} has one,
and only one, actual value}}.}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Quantity vs variate or variable}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

We can consider something that changes with time, or with space, or from
individual to individual, or from unit to unit. Then this ``something''
is not a quantity, according to our present terminology, but a
\emph{collection} of quantities: one for each time, or space, or
individual. Later we shall call this collection a \textbf{variate},
especially when it refers to individuals or unit; or a
\textbf{variable}, especially when it refers to time.

For instance, your height at this exact moment is a \emph{quantity}, but
your height throughout your life is a \emph{variable}, and the height
(at this moment) across all Norwegian people is a \emph{variate}.

These are just terminological conventions adopted in the present notes.
As mentioned before, different scientists often adopt different terms.
What matters is not the terms, but that you have a clear understanding
of the difference between the two \textbf{notions} that we here call
``quantity'' and ``variate''.

\end{tcolorbox}

\subsection{Notation}\label{notation}

We shall denote quantities by italic letters, such as {\(X\),} or
{\(U\),} or {\(A\).} The sentences that appear in decision-making and
inferences are therefore often of the kind:\\
{``the quantity \(X\) was observed to have value \(x\)''},\\
where {``\(x\)''} stands for a specific value. This kind of sentences
are often abbreviated in the form
{``\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x\)''}.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\faIcon{exclamation-circle} Keep in mind our discussion from
§~\ref{sec-sentence-notation}: we must make clear what
{``\(\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\)''}
means. It could mean ``observed'', ``set'', ``reported'', and so on.

\faIcon{exclamation-circle} Note the subtle difference between {\(X\)},
in italics, and {\(\mathsfit{X}\)}, in sans-serif. The first denotes a
\emph{quantity}, the second denotes a \emph{sentence}. Usually we don't
have to worry too much about these symbol differences, because the
meaning of the symbol is clear from the context. But just in case, you
know the convention.

\end{tcolorbox}

\section{Basic types of quantities}\label{sec-basic-types}

As the examples above show, quantities and data come in all sorts, and
with various degrees of complexity. There is no clear-cut divide between
different sorts of quantities. The same quantity can moreover be viewed
and represented in many different ways, depending on the specific
context, problem, purpose, and background information.

It is possible, however, to roughly differentiate between a handful of
basic {\textbf{types}} of quantities, from which more complex types are
built. Here is one kind of differentiation that is useful for inference
problems about quantities:

\subsection{Nominal}\label{nominal}

A {\textbf{nominal}} or {\textbf{categorical}} quantity has a domain
with a discrete and usually finite number of values. The values
{\emph{are not related by any mathematical property}}, and {\emph{do not
have any specific order}}.

This means that when we speak of a nominal quantity, it does not make
sense to say, for instance, that one value is ``twice'' or ``1.5 times''
another; or that one value is ``larger'' or ``later'' than another. Nor
does it make sense to ``add'' two quantities. In particular,
{\emph{there is no notion of cumulative probability, quantile, median,
average, or standard deviation for a nominal quantity}}; these are
notions that we'll discuss in Ch.\,~\ref{sec-statistics}.

Examples: the possible breeds of a dog, or the characters of a film.

It is of course possible to represent the values of a nominal quantity
with numbers; say \texttt{1} for \texttt{Dachshund}, \texttt{2} for
\texttt{Labrador}, \texttt{3} for \texttt{Dalmatian}, and so on. But
that doesn't mean that\\
\texttt{Dalmatian}{\({}-{}\)}\texttt{Labrador}{\({}={}\)}\texttt{Labrador}{\({}-{}\)}\texttt{Dachshund}\\
just because {\(3-2=2-1\),} or similar nonsense.

\subsection{Ordinal}\label{ordinal}

An {\textbf{ordinal}} quantity has a domain with a discrete and usually
finite number of values. The values {\emph{are not related by any
mathematical property}}, but they {\emph{do have a specific order}}.

This means that that when we speak of a nominal quantity, it does
\emph{not} make sense to say that one value is ``twice'' or ``1.5
times'' another, and we can\emph{not} add or subtract two values. But it
does make sense to say, for any two values, which one has higher rank,
for example ``stronger'', or ``later'', or ``larger'', and similar.
Owing to the ordering property, {\emph{it does make sense to speak of
cumulative probability, quantile, and median of an ordinal quantity}};
but {\emph{there is no notion of average or standard deviation for an
ordinal quantity}}.

Example: a
\href{https://doi.org/10.1016/j.jpainsymman.2004.08.007}{pain-intensity
scale}. A patient can say whether some pain is more severe than another,
but it isn't clear what a pain ``twice as severe'' as another would mean
(although there's a lot of research on more precise quantification of
pain). Another example: the ``strength of friendship'' in a social
network. We can say that we have a ``stronger friendship'' with a person
than with another; but it doesn't make sense to say that we are ``four
times stronger friends'' with a person than with another.

It is possible to represent the values of an ordinal quantity with
numbers which reflect the \emph{order} of the values. But it's important
to keep in mind that differences or averages of such numbers do
\emph{not} make sense. For this reason the use of numbers to represent
an ordinal quantity can be misleading. A less misleading possibility is
to represent ordered values by alphabet letters.

\subsection{Binary}\label{binary}

A {\textbf{binary}} or {\textbf{dichotomous}} quantity has only two
possible values. It can be seen as a special case of a nominal or
ordinal quantity, but the fact of having only two values lends it some
special properties in inference problems. This is why we list it
separately.

Obviously it doesn't make much sense to speak of the difference or
average of the two values; and their ranking is trivial even if it makes
sense.

There's an abundance of examples of binary quantities: yes/no answers,
presence/absence of something, and so on.

\subsection{Interval}\label{interval}

An {\textbf{interval}} quantity has a domain that can be discrete or
continuous, finite or infinite. The values {\emph{do admit some
mathematical operations}}, at least \emph{convex combination} and
\emph{subtraction}. They also admit an ordering.

This means that for such a quantity we can say, at the very least,
whether the interval or ``distance'' between one pair of values is the
same, or larger, or smaller than the interval between another pair. For
this reason we can also say whether one value is larger than another. We
can also take weighted sums of values, called \emph{convex combinations}
(keep in mind that simple \emph{addition} of values may be meaningless
for some quantities).

Owing to these mathematical properties, {\emph{it does make sense to
speak of the cumulative probability, quantile, median, and also average
and standard deviation for an interval quantity}}.

The number of electronic components produced in a year by an assembly
line is an example of a discrete interval quantity. The power output of
a nuclear plant at a given time is an example of a continuous interval
quantity.

It is also possible to speak of \emph{ratio} quantities, which are a
special case of interval quantities, but we won't have use of this
distinction in the present notes.

\subsection{How to decide the basic type of a
quantity?}\label{how-to-decide-the-basic-type-of-a-quantity}

To attribute a basic type to a quantity we must ultimately {\emph{check
how that quantity is defined, obtained, and used}}. In some cases the
values of the quantity may give some clue. For example, if we see values
{``\(2.74\)''}, {``\(8.23\)''}, {``\(3.01\)''}, then the quantity is
probably of the interval type. But if we see values {``\(1\)''},
{``\(2\)''}, {``\(3\)''}, then it's unclear whether the quantity is
interval, ordinal, nominal, or maybe of yet some other type.

The type of a quantity also depends on its use in the specific problem.
A quantity of a more complex type can be treated as a simpler type if
needed. For instance, the response time of some device is in principle
an interval quantity: it could be measured, say, in seconds, as
precisely as we want. But in a specific situation we could simply label
its values as \texttt{slow}, \texttt{medium}, \texttt{fast}, thus
turning it into an ordinal quantity.

{@@ TODO: add examples for image spaces}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  For each example at the beginning of the present section, assess
  whether that quantity can be considered as being of a basic type, and
  which type.
\item
  For each basic type discussed above, find two more concrete examples
  of that type of quantity.
\end{itemize}

\end{tcolorbox}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/32045/modules}{\emph{On the
theory of scales of measurement}}

\end{tcolorbox}

\end{footnotesize}}

\section{Other attributes of basic
types}\label{other-attributes-of-basic-types}

It is useful to consider other basic aspects of quantities that are
somewhat transversal to ``type''. These aspects are also important when
drawing inferences.

\subsection{Discrete vs continuous}\label{discrete-vs-continuous}

Nominal and ordinal quantities have discrete domains. The domain of an
interval quantity can be discrete or continuous. Ultimately all domains
are discrete, since we cannot observe, measure, report, or store values
with infinite precision. In a modern computer, for example, a real
number can ``only'' take on
{\(2^{64} \approx 20 000 000 000 000 000 000\)} possible values. But in
practice, in many situations the available precision is so high that we
can consider the quantity as continuous for all practical purposes. This
can be convenient also because we can then use the mathematics of
continuous sets -- derivation, integration, and so on -- to our
advantage.

\subsection{Bounded vs unbounded}\label{bounded-vs-unbounded}

Ordinal and interval quantities may have domains with no minimum value,
or no maximum value, or neither. Typical terms for these situations are
\emph{lower-} or \emph{upper-bounded}, or \emph{left-} or
\emph{right-bounded}, and analogously with \emph{unbounded}; or similar
terms.

Whether to treat a quantity domain as bounded or unbounded depends on
the quantity, the specific problem, and the computational resources. For
example, the number of times a link on a webpage has been clicked can in
principle be (upper-)unbounded. Another example is the distance between
two objects: we can consider it unbounded, but in concrete problems
might be bounded, say, by the size of a laboratory, or by
\href{https://solarsystem.nasa.gov/planets/earth}{Earth}'s
circumference, or the
\href{https://solarsystem.nasa.gov/solar-system/our-solar-system}{Solar
System}'s extension, and so on.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  If you had to set a maximum number of times a web link can be clicked,
  what number would you choose? Try to find a reasonable number,
  considering factors such as how fast a person can repeatedly click on
  a link, how long a website (or the Earth?) can last, and how many
  people can live during such an extent of time.
\item
  What about the age of a person? What upper bound would you set, if you
  had to treat it as a bounded quantity?
\end{itemize}

\end{tcolorbox}

\subsection{Finite vs infinite}\label{finite-vs-infinite}

The domain of a discrete quantity can consist of a finite or an infinite
number (at least in theory) of possible values. The domain of a
continuous quantity always has an infinite number of values. Note that a
domain can be infinite and yet bounded: consider the numbers in the
range {\([0,1]\).}

Whether to treat a domain as finite or infinite depends on the quantity,
the specific problem, and the computational resources. For example, the
intensity of a base colour in a pixel of a particular image might really
take on 256 discrete steps between {\(0\)} and {\(1\):}
{\(0, 0.0039215686, 0.0078431373, \dotsc, 1\)}. But in some situations
we can treat this domain as practically infinite, with any possible
value between {\(0\)} and {\(1\).}

\subsection{Rounded}\label{sec-rounded}

A continuous interval quantity may be rounded, because of the way it's
measured. In this case the quantity could be considered discrete rather
than continuous.

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{iris_dataset.png}
The \emph{Iris} dataset from its original paper

\end{footnotesize}}

For instance, the famous
\href{https://doi.org/10.1111/j.1469-1809.1936.tb02137.x}{\emph{Iris}
dataset} consists of several lengths -- continuous interval quantities
-- of parts of flowers. All values are rounded to the millimetre, even
if in reality the lengths could of course have intermediate values. The
age of a person is another frequent example of an in-principle
continuous quantity which is often rounded, say to the year or to the
month.

Rounding can impact the way we do inferences about such a quantity. In
some situations, rounding can lead to quantities with different
unrounded values to take on identical rounded ones.

\subsection{Censored}\label{censored}

The measurement procedure of a quantity may have an artificial lower or
upper bound. A clinical thermometer, for instance, could have a maximum
reading of {\(45\,\mathrm{°C}\).} If we measure with it the temperature
of a {\(50\,\mathrm{°C}\)-hot} body, we'll read
{``\(45\,\mathrm{°C}\)''}, not the real temperature.

A quantity with this characteristic is called {\textbf{censored}}, more
specifically \emph{left-censored} or \emph{right-censored} when there's
only one artificial bound. The bound is called the \emph{censoring
value}.

A censoring value denotes an actual value that could also be greater or
less. This is important when we draw inferences about this kind of
quantities.

\hfill\break

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Explore datasets in a database such as the
\href{https://archive.ics.uci.edu/datasets}{UC Irvine Machine Learning
Repository}:

\begin{itemize}
\item
  Read the description of the quantities listed in the dataset
  (sometimes in a \texttt{readme} file included with the dataset
  download)
\item
  Analyse the values of some of the quantities in the dataset: check if
  they can be considered continuous, discrete, or rounded; bounded or
  unbounded; uncensored or censored; and so on.
\end{itemize}

\end{tcolorbox}

\section{``True'' vs ``measured'' values}\label{sec-true-quantities}

A difference is often drawn, especially in physics and engineering,
between the ``true'' value of a quantity and the value ``observed'' or
``measured'' with a particular measuring instrument. What's the
difference? and how is the ``true'' value defined? There actually are
deep philosophical questions and choices underlying this distinction,
and it would take a whole university course to do them justice.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://archive.org/details/logicofmodernphy0000pwbr}{\emph{The
Logic of Modern Physics}}

\end{tcolorbox}

\end{footnotesize}}

Intuitively we define the ``true'' value as the value that would be
measured with an instrument that is perfectly calibrated and as precise
as theoretically possible. If we make a distinction between such value
and the currently measured value then we're implying that the current
measurement is made with a less precise instrument, and that the
``true'' and ``measured'' values could be different.

In some circumstances this distinction is unimportant and an agent can
use the ``measured'' value without worries, and consider it as the
``true'' one. Typically this is the case when the possible discrepancy
between measured and true value is enough small to have no consequences.
In other circumstances the discrepancy is important: slightly different
values might lead to quite different consequences. In such circumstances
it is then necessary for the agent to try to \emph{infer} -- using the
probability calculus -- the true value, using the measured one as
``data'' or ``evidence''. Said otherwise, the agent doesn't use the
measured value directly, but only as an intermediate step to guess the
true value. The latter, in turn, can be used for further inferences.

From the point of view of inference and decision-making, the distinction
between ``true'' and ``measured'' value doesn't lead to anything
methodologically new. It just means that an agent has to do a chain of
inferences instead of just one, using the four rules of inference as
usual. This situation often requires the definition of two distinct
quantities, the ``true'' and the ``observed'', which can have slightly
different domains. For instance, we could have a voltage
{\(V_\text{obs}\)} measured with rounding to {\(1\,\mathrm{V}\)} and
therefore with discrete domain
{\(\set{10\,\mathrm{V}, 11\,\mathrm{V}, 12\,\mathrm{V}, \dotsc}\);} but
we need the ``true'' voltage {\(V_\text{true}\)} with a precision of at
least {\(0.01\,\mathrm{V}\),} so this latter quantity could have a
continuous domain.

In solving data-science and engineering problems it's important to make
clear whether a particular quantity value can be considered ``true'' and
used as-is, or only ``observed'' with insufficient precision and used as
data to infer the true value.

\section{Importance of metadata for inference and
decision}\label{sec-metadata}

The characteristics of quantities and domains that we have discussed so
far are examples of {\textbf{metadata}}. As the name implies,
\emph{meta}data is information that typically \emph{cannot} be found in
the data.

As a simple example, consider this collection of numerical data
values:\\
{8~~~2~~~6~~~19~~~1~~~5~~~4~~~19~~~1~~~8~~~12~~~3~~~1~~~2~~~17}\\
and suppose that some machine-learning algorithm has to generate a new
number ``similar'' to the ones above, or guess what a new one could be.
Consider the following possible guesses; would they be acceptable?:

\begin{itemize}
\tightlist
\item
  {\textbf{13}}.~~Note that this number does not appear among the values
  above. Could it be that it is impossible for some particular reason?
  For example, this value is omitted from the seat numbers of some
  airlines or street addresses, because of
  \href{https://mathworld.wolfram.com/Triskaidekaphobia.html}{triskaidekaphobia}.
\end{itemize}

\begin{marginfigure}

\begin{minipage}{\linewidth}
\pandocbounded{\includegraphics[keepaspectratio]{dice.jpg}}\end{minipage}%

\end{marginfigure}%

\begin{itemize}
\item
  {\textbf{21}}.~~This guess would be impossible if the reported values
  are rolls of a 20-sided die, typical of fantasy roleplay games. But if
  the values are, say, the ages of some people, then {\textbf{21}} could
  be an admissible guess.
\item
  {\textbf{3.5}}.~~The reported values are all integers. But they could
  be \hyperref[sec-rounded]{rounded} values of say, temperature readings
  or ages. We don't know whether a more precise, non-rounded guess such
  as {\textbf{3.5}} could be acceptable.
\item
  {\textbf{-2}}.~~If the reported values are people's ages or objects'
  weights, then a negative value would be impossible. But if the values
  were temperatures in degrees Celsius, then the guess {\textbf{-2}}
  could be acceptable.
\end{itemize}

The collection of values does \emph{not} allow us to determine which of
the possible scenarios above applies.

\hfill\break
A simple piece of metadata can actually correspond to an infinite amount
of datapoints. Even if we have a collection of one million positive
numbers, they still don't tell us whether negative values are impossible
or not. When we are given the information that the domain of the
relevant quantity is positive, this effectively corresponds to knowing
that all future data -- possibly an infinity -- will not be negative.

An AI agent or machine-learning algorithm will therefore make better
guesses and better decisions if it is given full metadata, besides
``training'' data. For this reason metadata are extremely important for
inference and decision-making, and an optimal agent should make use of
metadata.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Examine the
\href{https://archive.ics.uci.edu/dataset/2/adult}{adult-income dataset}
at the UC Irvine Machine Learning Repository. This set contains more
than 30\,000 datapoints.

Take a look at the quantity \texttt{native\_country} (what type of
variate is this?).

\begin{itemize}
\item
  Do you see the values \texttt{Norway} or \texttt{Finland} or
  \texttt{Sweden} listed among these values?
\item
  Does this mean that in the adult USA population there are no people
  coming from these three countries?
\item
  Should an AI agent or machine-learning algorithm exclude these three
  values from its future guesses?
\item
  What would you do to give the algorithm this metadata information? (In
  a later chapter we shall see how to do this in a rigorous way.)
\end{itemize}

\end{tcolorbox}

\chapter{\texorpdfstring{{Joint quantities and complex data
types}}{Joint quantities and complex data types}}\label{sec-quantities-types-multi}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

Quantities of more complex types can often be viewed and represented as
sets (that is, collections) of quantities of basic and possibly
different types.

\section{Joint quantities}\label{sec-data-multiv}

A simple collection of quantities of basic types, for instance ``age,
sex, nationality'', usually does not have any new mathematical
properties appearing just because we're considering those quantities
together. We shall call such a collection a {\textbf{joint quantity}}.
Note that a ``joint quantity'' it is still a quantity, but not a
quantity of a basic type.

The values of a joint quantity are just tuples of values of its basic
component quantities. Its domain is the
\href{https://mathworld.wolfram.com/CartesianProduct.html}{Cartesian
product} of the domains of the basic quantities.

Consider for instance the age, sex\footnote{We define \emph{sex} by the
  presence of at least one
  \href{https://www.genome.gov/about-genomics/fact-sheets/Y-Chromosome-facts}{Y
  chromosome} or not. It is different from \emph{gender}, which involves
  how a person identifies.}, and
\href{https://www.gov.uk/government/publications/nationalities/list-of-nationalities}{nationality}
of a particular individual. They can be represented as an
interval-continuous quantity {\(A\),} a binary one {\(S\),} and a
nominal one {\(N\).} We can join them together to form the joint
quantity~~``(age,~sex,~nationality)''~~which can be denoted
by~~{\((A,S,N)\).~~One} value of this joint quantity is, for example,
{\((25\,\mathrm{y}, {\small\verb;F;}, {\small\verb;Norwegian;})\).} The
domain could be

\[
[0,+\infty)\times
\set{{\small\verb;F;}, {\small\verb;M;}} \times
\set{{\small\verb;Afghan;}, {\small\verb;Albanian;}, \dotsc, {\small\verb;Zimbabwean;}}
\]

\subsection{Discreteness, boundedness,
continuity}\label{discreteness-boundedness-continuity}

A joint quantity may not be simply characterized as ``discrete'', or
``bounded'', or ``infinite'', and so on. Usually we must specify these
characteristics for each of its basic component quantities instead.
Sometimes a joint quantity is called, for instance, ``continuous'' if
all its basic components are continuous; but other conventions are also
used.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Consider again the examples of §~\ref{sec-quant-value-dom}. Do you find
any examples of joint quantities?

\end{tcolorbox}

\section{Complex quantities}\label{sec-data-complex}

We shall call ``complex quantity'' a quantity that is not of a basic
type, nor a collection of quantities of basic type, that is, a joint
quantity.

Familiar examples of complex quantities are vectorial quantities from
physics and engineering, such as location, velocity, force, torque.
Other examples are images, sounds, videos.

Note that a complex quantity may be \emph{represented} as a collection
of quantities of basic type. This collection, however, is ``more than
the sum of its parts'', in the sense that it has new mathematical
properties that do not apply or do not make sense for the single
components.

Consider for example a 4\,×\,4 monochrome image, represented as a grid
of 16 binary quantities {\(0\)} or {\(1\).} Three possible values could
be these:

\includegraphics[width=6em,height=\textheight,keepaspectratio]{threegrid1.png}~~\includegraphics[width=6em,height=\textheight,keepaspectratio]{threegrid2.png}~~\includegraphics[width=6em,height=\textheight,keepaspectratio]{threegrid3.png}

We can numerically represent these images as the matrices

\(\begin{psmallmatrix}1&0&0&0\\0&0&0&0\\0&0&0&0\\0&0&0&0\end{psmallmatrix}\),
{\(\begin{psmallmatrix}0&1&0&0\\0&0&0&0\\0&0&0&0\\0&0&0&0\end{psmallmatrix}\),}
{\(\begin{psmallmatrix}0&0&0&0\\0&0&0&0\\0&0&0&0\\0&0&0&1\end{psmallmatrix}\).}

With this representation, this quantity is made to correspond to 16
binary digits, or in other words 16 \hyperref[binary]{binary
quantities}.

From the point of view of the individual binary quantities, these three
values are ``equally different'' from one another: where one of them has
grid value {\(1\),} the others have {\(0\).} But properly considered as
images, we can say that the first and the second are somewhat more
``similar'' or ``closer'' to each other than the first and the third.
This similarity can be represented and quantified by a
\href{https://mathworld.wolfram.com/Metric.html}{\emph{metric}} over the
domain of all such images. This metric involves all basic binary
quantities at once; it is a new mathematical property that does not
belong to any of the 16 binary quantities individually.

More generally, complex quantities have additional, peculiar properties,
represented by mathematical structures, which distinguish them from
joint quantities; although there is not a clear separation between the
two.

These properties and structures are very important for inference
problems, and usually make them computationally very hard.
Machine-learning methods are important because they allow us to do
approximate inference on these kinds of complex data. The peculiar
structures of these data, however, are often also the cause of striking
failures of some machine-learning methods, for example the reason why
\href{https://towardsdatascience.com/breaking-neural-networks-with-adversarial-attacks-f4290a9a45aa}{they
may classify incorrectly}, or why they may classify correctly but for
the wrong reason.

\part{{\textbf{Inference II}}}

\chapter{\texorpdfstring{{Probability
distributions}}{Probability distributions}}\label{sec-prob-distribs}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\section*{\texorpdfstring{{Motivation for the ``Inference~II''
part}}{Motivation for the ``Inference~II'' part}}\label{motivation-for-the-inference-ii-part}
\addcontentsline{toc}{section}{{Motivation for the ``Inference~II''
part}}

\markright{{Motivation for the ``Inference~II'' part}}

In the ``{Data~I}'' part we developed a language, that is, particular
kinds of sentences, to approach inferences and probability calculations
typical of data-science and engineering problems.

In the present part we focus on probability calculations that often
occur with this kind of sentences and data. We also focus on how to
visually represent such probabilities in useful ways.

Always keep in mind that at bottom we're just using the
\hyperref[sec-fundamental]{four fundamental rules of inference} over and
over again -- nothing more than that!

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hfill\break

\section{Distribution of probability among
values}\label{sec-distribute-prob}

When an agent is uncertain about the value of a quantity, its
uncertainty is expressed and quantified by assigning a degree of belief,
conditional on the agent's knowledge, to all the possible cases -- all
the possible values that could be the true one.

For a temperature measurement, for instance, the cases could be ``{The
temperature is measured to have value 271\,K}'', ``{The temperature is
measured to have value 272\,K}'', and so on up to 275\,K. These cases
are expressed by mutually exclusive and exhaustive sentences. Denoting
the temperature with {\(T\),} these sentences can be abbreviated as

\[
{\color[RGB]{34,136,51}T = 271\,\mathrm{K}} \ , \quad
{\color[RGB]{34,136,51}T = 272\,\mathrm{K} \ ,} \quad
{\color[RGB]{34,136,51}T = 273\,\mathrm{K} \ ,} \quad
{\color[RGB]{34,136,51}T = 274\,\mathrm{K} \ ,} \quad
{\color[RGB]{34,136,51}T = 275\,\mathrm{K}} \ .
\]

The agent's belief about the quantity is then expressed by the
{probabilities} about these five sentences, conditional on the agent's
state of knowledge, which we may denote by the letter
{\({\color[RGB]{204,187,68}\mathsfit{I}}\).} These probabilities could
be, for instance,

\[\begin{aligned}
\mathrm{P}({\color[RGB]{34,136,51}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}271\,\mathrm{K}} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{204,187,68}\mathsfit{I}}) &= {\color[RGB]{170,51,119}0.04} \\[1ex]
\mathrm{P}({\color[RGB]{34,136,51}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}272\,\mathrm{K}} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{204,187,68}\mathsfit{I}}) &= {\color[RGB]{170,51,119}0.10} \\[1ex]
\mathrm{P}({\color[RGB]{34,136,51}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}273\,\mathrm{K}} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{204,187,68}\mathsfit{I}}) &= {\color[RGB]{170,51,119}0.18} \\[1ex]
\mathrm{P}({\color[RGB]{34,136,51}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}274\,\mathrm{K}} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{204,187,68}\mathsfit{I}}) &= {\color[RGB]{170,51,119}0.28} \\[1ex]
\mathrm{P}({\color[RGB]{34,136,51}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}275\,\mathrm{K}} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{204,187,68}\mathsfit{I}}) &= {\color[RGB]{170,51,119}0.40}
\end{aligned}
\]

Note that they sum up to one:

\[
\begin{aligned}
&\quad\mathrm{P}({\color[RGB]{34,136,51}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}271\,\mathrm{K}} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{204,187,68}\mathsfit{I}}) +
\dotsb +
\mathrm{P}({\color[RGB]{34,136,51}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}275\,\mathrm{K}} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{204,187,68}\mathsfit{I}}) 
\\[1ex]
&= 
{\color[RGB]{170,51,119}0.04}+{\color[RGB]{170,51,119}0.10}+{\color[RGB]{170,51,119}0.18}+{\color[RGB]{170,51,119}0.28}+{\color[RGB]{170,51,119}0.40} 
\\[1ex]
&=
{\color[RGB]{170,51,119}1}
\end{aligned}\]

This collection of probabilities is called a {\textbf{probability
distribution}}, because we are distributing the probability among the
possible alternatives.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} What's ``distributed''?}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

The \emph{probability} is distributed among the possible values, as
illustrated in the side picture. The quantity cannot be ``distributed'':
it has one, definite value, which is however unknown to the agent.

\end{tcolorbox}

\marginnote{\begin{footnotesize}

\pandocbounded{\includegraphics[keepaspectratio]{illustration_prob_distr2.png}}

\end{footnotesize}}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Consider three sentences
{\(\mathsfit{X}_1, \mathsfit{X}_2, \mathsfit{X}_3\)} that are mutually
exclusive and exhaustive on conditional {\(\mathsfit{I}\),} that is:

\[
\begin{gathered}
\mathrm{P}(\mathsfit{X}_1 \land \mathsfit{X}_2 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) =
\mathrm{P}(\mathsfit{X}_1 \land \mathsfit{X}_3 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) =
\mathrm{P}(\mathsfit{X}_2 \land \mathsfit{X}_3 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) = 0
\\
\mathrm{P}(\mathsfit{X}_1 \lor \mathsfit{X}_2 \lor \mathsfit{X}_3 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) = 1
\end{gathered}
\]

Prove, using the fundamental rules of inferences and any derived rules
from §~\ref{sec-probability}, that we must then have

\[
\mathrm{P}(\mathsfit{X}_1 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) + \mathrm{P}(\mathsfit{X}_2 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) + \mathrm{P}(\mathsfit{X}_3 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) = 1
\]

\end{tcolorbox}

\hfill\break
Let's see how probability distributions can be represented and
visualized for the basic types of quantities discussed in
§~\ref{sec-quantities-types-basic}.

We start with probability distributions over discrete domains.

\section{Discrete probability distributions}\label{sec-discr-prob-distr}

\subsection{Tables and functions}\label{tables-and-functions}

A probability distribution over a discrete domain can obviously be
displayed as a table of values and their probabilities. For instance

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2202}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1560}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1560}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1560}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1560}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1560}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
{\emph{value}}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{271\,K}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{272\,K}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{273\,K}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{274\,K}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
{275\,K}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{\emph{probability}} & {0.04} & {0.10} & {0.18} & {0.28} & {0.40} \\
\end{longtable}

In the case of ordinal or interval quantities it is sometimes possible
to express the probability as a \emph{function} of the value. For
instance, the probability distribution above could be summarized by this
function of the value {\({\color[RGB]{34,136,51}t}\):}

\[
\mathrm{P}({\color[RGB]{34,136,51}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}t} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{204,187,68}\mathsfit{I}}) = 
{\color[RGB]{170,51,119}\frac{({\color[RGB]{34,136,51}t}/\textrm{\small K} - 269)^2}{90}}
\quad\text{\small (rounded to two decimals)}
\]

\hfill\break

A graphical representation is often helpful to detect features,
peculiarities, and even inconsistencies in one or more probability
distributions.

\subsection{Histograms and area-based
representations}\label{histograms-and-area-based-representations}

A probability distribution for a nominal, ordinal, or discrete-interval
quantity can be neatly represented by a {\textbf{histogram}}.

\marginnote{\begin{footnotesize}

\begin{figure}[H]

{\centering \includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{example_histogram.png}

}

\caption{Histogram for the probability distribution over possible
component failures}

\end{figure}%

\end{footnotesize}}

The possible values are placed on a line. For an ordinal or interval
quantity, the sequence of values on the line should correspond to their
natural order. For a nominal quantity the order is irrelevant.

A rectangle is then drawn above each value. The rectangles might be
contiguous or not. The bases of the rectangles are all equal, and the
{\emph{areas}} of the rectangles are proportional to the probabilities.
Since the bases are equal, this implies that the heights of the
rectangles are also proportional to the probabilities.

Such kind of drawing can of course be horizontal, vertical, upside-down,
and so on, depending on convenience.

Since the probabilities must sum to one, the total area of the
rectangles represents an area equal to~1. So in principle there is no
need of writing probability values on some vertical axis, or grid, or
similar visual device, because the probability value can be visually
read as the ratio of a rectangle area to the total area. An axis or grid
can nevertheless be helpful. Alternatively the probabilities can be
reported above or below each rectangle.

Nominal quantities do not have any specific order, so their values do
not need to be ordered on a line. Other area-based representations, such
as pie charts, can also be used for these quantities.

\subsection{Line-based
representations}\label{line-based-representations}

Histograms give faithful representations of discrete probability
distributions. Their graphical bulkiness, however, can be a disadvantage
in some situations, for instance when we want to have a clearer idea of
how the probability varies across values for ordinal or interval
quantities; or when we want to compare several different probability
distributions over the same values.

In these cases we can use standard line plots, or variations thereof.
Compare the following example.

A technician wonders which component of a laptop failed first (only one
can fail at a time), with seven possible alternatives:
{\(\set{{\small\verb;hard-drive;}, {\small\verb;motherboard;}, {\small\verb;CPU;}, {\small\verb;keyboard;}, {\small\verb;screen;}, {\small\verb;graphics-card;}, {\small\verb;PCI;}}\).}
This is a \hyperref[nominal]{nominal quantity}.

Before examining the laptop, the technician's belief about which
component failed first is distributed among the seven alternatives as
shown by the {blue histogram with solid borders}. After a first
inspection of the laptop, the technician's belief has a new
distribution, shown by the {red histogram with dashed borders}:

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{example_histogram_double.png}

It requires some concentration to tell the two probability distributions
apart, for example to understand where their peaks are. Let us represent
them by two line plots instead: {solid blue with circles} for the
pre-inspection belief distribution, and {dashed red with squares} for
the post-inspection one:

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{example_curve_double.png}

this line plot displays more cleanly the differences between the two
distributions. We see that at first the technician most strongly
believed the {\({\small\verb;keyboard;}\)} to be the faulty candidate,
the second strongest belief being for the {\({\small\verb;PCI;}\).}
After the preliminary inspection, the technician most strongly believes
the {\({\small\verb;PCI;}\)} to be the faulty candidate, followed by the
{\({\small\verb;graphics card;}\).}

\section{Probability densities}\label{sec-prob-densities}

Distributions of probability over continuous domains present several
counter-intuitive aspects, which essentially arise because we are
dealing with uncountable infinities -- while often using linguistic
expressions that make only sense for countable infinities. Here we
follow a practical and realistic approach for working with such
distributions.

Consider a quantity {\(X\)} with a continuous domain. When we say that
this quantity has some value~~{\(x\)}~~we really mean that it has a
value somewhere in the range~~
{\(x -\epsilon/2\)~~to~~\(x+\epsilon/2\)},~~ where the width
{\(\epsilon\)} is usually extremely small, because we never have
infinite precision. For example, for
\href{https://rdrr.io/r/base/double.html}{double-precision} values
stored in a computer, the width\footnote{more precisely the relative
  width} must be at least {\(\epsilon \approx 2\cdot 10^{-16}\)\,.} You
can check indeed that your computer might not distinguish between two
numbers that differ in their 16th decimal digit:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\# R code}
\DocumentationTok{\#\# difference in 15th decimal digit}
\SpecialCharTok{\textgreater{}} \FloatTok{1.234567890123456} \SpecialCharTok{==} \FloatTok{1.234567890123455}
\NormalTok{[}\DecValTok{1}\NormalTok{] }\ConstantTok{FALSE}

\DocumentationTok{\#\# difference in 16th decimal digit}
\SpecialCharTok{\textgreater{}} \FloatTok{1.2345678901234567} \SpecialCharTok{==} \FloatTok{1.2345678901234566}
\NormalTok{[}\DecValTok{1}\NormalTok{] }\ConstantTok{TRUE}
\end{Highlighting}
\end{Shaded}

The value \texttt{1.3} really represents a range between
{\texttt{1.29999999999999982236431605997495353221893310546875}} and
{\texttt{1.300000000000000266453525910037569701671600341796875}}, this
range coming from the internal binary representation of \texttt{1.3}.
Often the width {\(\epsilon\)} is much larger than the computer's
precision, and comes from the precision with which the value is
\emph{experimentally} measured.

When we consider a distribution of probability for a continuous
quantity, the probabilities are therefore distributed among such small
ranges, not among single values.

Since these ranges are very small, they are also very numerous. But the
total probability assigned to all of them must still sum up to {\(1\).}
This means that each small range receives an extremely small amount of
probability. A standard Gaussian distribution for a real-valued
quantity, for instance, assigns a probability of approximately
{\(8\cdot 10^{-17}\),} or {\(0.000 000 000 000 000 08\)}, to a range of
width {\(2\cdot 10^{-16}\)} around the value {\(0\).} All other ranges
are assigned even smaller probabilities.

In would be impractical to work with such small probabilities. We use
{\textbf{probability densities}} instead. As implied by the term
``\href{https://www.nist.gov/pml/special-publication-811/nist-guide-si-chapter-8}{density}'',
a probability density is the amount of probability {\(P\)} assigned to a
standard range of width {\(\epsilon\),} \emph{divided} by that width.
For example, if the probability assigned to a range of
width~~{\(\epsilon=2\cdot10^{-16}\)~~around} the value {\(0\)}
is~~{\(P=7.97885\cdot10^{-17}\),~~then} the \emph{probability density}
around {\(0\)} is

\[
\frac{P}{\epsilon} =
\frac{7.97885\cdot10^{-17}}{2\cdot10^{-16}} = 0.398942
\]

which is a more convenient number to work with.

Probability densities are convenient because they usually do not depend
on the range width {\(\epsilon\),} if it's small enough. Owing to
physics reasons, we don't expect a situation where {\(X\)} is between
{\(0.9999999999999999\)} and {\(1.0000000000000001\)} to be very
different from one where {\(X\)} is between {\(1.0000000000000001\)} and
{\(1.0000000000000003\)}. The probabilities assigned to these two small
ranges of width {\(\epsilon=2\cdot 10^{-16}\)} will therefore be
approximately equal, let's say {\(P\)} each. Now if we use a small range
of width {\(\epsilon\)} around {\(X=1\),} the probability is {\(P\),}
and the probability \emph{density} is {\(P/\epsilon\).} If we consider a
range of double width {\(2\,\epsilon\)} around {\(X=1\),} then the
probability is {\(P+P\)} instead, but the probability density is still

\[\frac{P+P}{2\,\epsilon} =
\frac{1.59577\cdot10^{-16}}{4\cdot10^{-16}}
= 0.398942 \ .
\]

As you see, even if we consider a range with double the width as before,
the probability density is still the same.

\hfill\break

In these notes we'll denote probability densities with a
{\emph{lowercase} \(\mathrm{p}\)}, with the following notation:

\[
\underbracket[0pt]{\mathrm{p}}_{\mathrlap{\color[RGB]{119,119,119}\!\uparrow\ \textit{lowercase}}}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) \coloneqq
\frac{
\overbracket[0pt]{\mathrm{P}}^{\mathrlap{\color[RGB]{119,119,119}\!\downarrow\ \textit{uppercase}}}(\textsf{\small`\(X\) has value between \(x-\epsilon/2\) and \(x+\epsilon/2\)'} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{\epsilon}
\]

This definition works even if we don't specify the exact value of
{\(\epsilon\),} as long as it's small enough.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Probability densities are not
probabilities}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

If {\(X\)} is a continuous quantity, the expression
{``\(\mathrm{p}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}2.5 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})=0.3\)''}
does \emph{not} mean ``There is a {\(0.3\)} probability that
{\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}2.5\)}{''}.
The probability that
{\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}2.5\)}
\emph{exactly} is, if anything, zero.

That expression instead means ``There is a~~{\(0.3\cdot \epsilon\)~~}
probability that {\(X\)} is between {\(2.5-\epsilon/2\)} and
{\(2.5+\epsilon/2\),} for any {\(\epsilon\)} small enough{''}.

In fact, \textbf{probability densities can be larger than 1}, because
they are obtained by dividing by a number, the width, that is in
principle arbitrary. This fact shows that they cannot be probabilities.

It is important not to mix up probabilities and probability
\emph{densities}. We shall see later that densities have very different
properties, for example with respect to maxima and averages.

\end{tcolorbox}

A helpful practice (though followed by few texts) is to always write a
probability density as

\[\mathrm{p}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\,\mathrm{d}X\]

where {``\(\mathrm{d}X\)''} stands for the width of a small range around
{\(x\).} This notation is also helpful with integrals. Unfortunately it
becomes a little cumbersome when we are dealing with more than one
quantity.

\subsection{Physical dimensions and
units}\label{physical-dimensions-and-units}

In the
\href{https://www.nist.gov/pml/owm/metric-si/si-units}{International
System of Units (SI)}, ``Degree of belief'' is considered to be a
dimensionless quantity, or more precisely a quantity of dimension ``1''.
This is why we don't write units such as ``metres'' ({\(\mathrm{m}\)),}
``kilograms'' ({\(\mathrm{kg}\))} or similar together with a probability
value.\footnote{See also the material at the
  \href{https://www.bipm.org/en/measurement-units}{International Bureau
  of Weights and Measures (BIPM)}}

A probability \emph{density}, however, is defined as the ratio of a
probability amount and an interval {\(\epsilon\)} of some quantity. This
latter quantity might well have physical dimensions, say ``metres''
{\(\mathrm{m}\).} Then the ratio, which is the probability density, has
dimensions {\(1/\mathrm{m}\).} So {\emph{probability densities in
general have physical dimensions}}.

As another example, suppose that an agent with background knowledge
{\(\mathsfit{I}\)} assigns a degree of belief {\(0.00012\)} to an
interval of temperature of width {\(0.0001\,\mathrm{°C}\),} around the
temperature {\(T = 20\,\mathrm{°C}\).} Then the probability
\emph{density} at {\(20\,\mathrm{°C}\)} is equal to

\[
\mathrm{p}(T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}20\mathrm{°C} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) =
\frac{0.00012}{0.0001\,\mathrm{°C}} = 1.2\,\mathrm{°C^{-1}}
\]

It is an error to report probability densities without their correct
physical units. In fact, keeping track of these units is often useful
for consistency checks and finding errors in calculations, just like in
other engineering or physics calculations.

On the other hand, if we write probability densities as previously
suggested, in this case as
{``\(\mathrm{p}(T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}20\mathrm{°C} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\,\mathrm{d}T\)''},
then the density written this way does not need any units: the units
{``\(\mathrm{°C^{-1}}\)''} disappear because multiplied by
{\(\mathrm{d}T\),} which has the inverse units {``\(\mathrm{°C}\)''}.

\section{Representation of probability
densities}\label{sec-represent-dens}

\subsection{Line-based
representations}\label{line-based-representations-1}

The histogram and the line representations become indistinguishable for
a probability density.

If we represent the probability {\(P\)} assigned to a small range of
width {\(\epsilon\)} as the area of a rectangle, and the width of the
rectangle is equal to {\(\epsilon\),} then the height {\(P/\epsilon\)}
of the rectangle is numerically equal to the probability density. The
difference from histograms for discrete quantities lies in the values
reported on the vertical axis: for discrete quantities the values are
\emph{probabilities} (the \emph{areas} of the rectangles), but for
continuous quantities they are probability \emph{densities} (the
\emph{heights} of the rectangles). This is also evident from the fact
that the values reported on the vertical axis can be larger than 1, as
in the example plots shown in the margin.

The rectangles, however, are so thin (usually thinner than a pixel on a
screen) that they appear just as vertical lines, and together they look
just like a curve delimiting a coloured area. If we don't colour the
area underneath the curve, then we just have a line-based, or rather
curve-based, representation of the probability density.

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{example_histo_density_0.08.png}
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{example_histo_density_0.01.png}
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{example_curve_density.png}
As the width {\(\epsilon\)} of the small ranges is decreased, a
histogram based on these widths become indistinguishable from a line
plot

\end{footnotesize}}

Keep in mind that the curve representing the probability density is
\emph{not quite a function}. In fact it's best to call it a ``density''
or a ``density function''. There are important reasons for keeping this
distinction, which have also consequences for probability calculations,
but we shall not delve into them for the moment.

\subsection{Scatter plots}\label{sec-scatter-plot}

Line plots of a probability density are very informative, but they can
also be slightly deceiving. Try the following experiment.

Consider a continuous quantity {\(X\)} with the following probability
density:

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{example_curve_density.png}

We want to represent the amount of probability in any small range, say
between
{\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}0\)}
and
{\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}0.1\),}
by drawing in that range a number of short thin lines, the number being
proportional to the probability. So a range containing 10 lines has
twice the probability of a range containing 5 lines. The probability
density around a value is therefore roughly represented by the density
of the lines around that value.

Suppose that we have 50 lines available to distribute this way. Where
should we place them?

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Which of these plots shows the correct placement of the 50 lines? {(NB:
the position of the correct answer is determined by a
pseudorandom-number generator.)}

\begin{figure}[H]

\begin{minipage}{0.50\linewidth}

\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{example_scatter_densityd_p50.png}}

}

\subcaption{(A)}

\end{figure}%

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{example_scatter_densitya_p50.png}}

}

\subcaption{(B)}

\end{figure}%

\end{minipage}%
\newline
\begin{minipage}{0.50\linewidth}

\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{example_scatter_densityb_p50.png}}

}

\subcaption{(C)}

\end{figure}%

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{example_scatter_densityf_p50.png}}

}

\subcaption{(D)}

\end{figure}%

\end{minipage}%

\end{figure}%

\end{tcolorbox}

\end{figure*}%

In a {\textbf{scatter plot}}, the probability density is (approximately)
represented by density of lines, or points, or similar objects, as in
the examples above (only one of the examples above, though, correctly
matches the density represented by the curve).

As the experiment and exercise above may have demonstrated, line plots
sometimes give us slightly misleading ideas of how the probability is
distributed across the domain. For example, peaks at some values make us
overestimate the probability density around those values. Scatter plots
often give a less misleading representation of the probability density.

Scatter plots are also useful for representing probability densities in
more than one dimension -- sometimes even in infinite dimensions! They
can moreover be easier to produce computationally than line plots.

{@@ TODO Behaviour of representations under transformations of data.}

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  §§5.3.0--5.3.1 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Risk
  Assessment and Decision Analysis with Bayesian Networks}}
\end{itemize}

\end{tcolorbox}

\section{Combined probabilities}\label{sec-combined-probs}

A probability distribution is defined over a set of mutually exclusive
and exhaustive sentences. In some inference problems, however, we do not
need the probability of those sentences, but of some other sentence that
can be obtained from them by an \texttt{or} operation. The probability
of this sentence can then be obtained by a sum, according to the
\texttt{or}-rule of inference. We can call this a \emph{combined
probability}. Let's explain this procedure with an example.

Back to our initial assembly-line scenario from Ch.\,~\ref{sec-intro},
the inference problem was to predict whether a specific component would
fail within a year or not. Consider the time when the component will
fail (if it's sold), and represent it by the quantity {\(T\)} with the
following 24 different values, where {``\(\mathrm{mo}\)''} stands for
``months'':

\[\begin{aligned}
&\textsf{\small`The component will fail during it 1st month of use'}\\
&\textsf{\small`The component will fail during it 2nd month of use'}\\
&\dotsc \\
&\textsf{\small`The component will fail during it 23rd month of use'}\\
&\textsf{\small`The component will fail during it 24th month of use or after'}
\end{aligned}\]

which we can shorten
to~~{\(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}2 \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsc \mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}24\);}
note the slightly different meaning of the last value.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

What is the basic type of the quantity {\(T\)?} Which other
characteristics does it have? for instance discrete? unbounded? rounded?
uncensored?

\end{tcolorbox}

Suppose that the inspection device -- our agent -- has internally
calculated a probability distribution for {\(T\),} conditional on its
internal programming and the results of the tests on the component,
collectively denoted {\(\mathsfit{I}\).} The probabilities, compactly
written, are

\[
\mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1 \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}), \quad
\mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}2 \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}), \quad
\dotsc, \quad
\mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}24 \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})
\]

Their values are stored in the file
\href{datasets/failure_probability.csv}{\texttt{failure\_probability.csv}}
and plotted in the histogram on the side.

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{failure_probabilities.png}

\end{footnotesize}}

What's important for the agent's decision about rejecting or accepting
the component, is not the exact time when it will fail, but only whether
it will fail within the first year or not. That is, the agent needs the
probability of the sentence
{\(\textsf{\small`The component will fail within a year of use'}\).} But
this sentence is just the \texttt{or} of the first 12 sentences
expressing the values of {\(T\):}

\[
\begin{aligned}
&\textsf{\small`The component will fail within a year of use'}
\\[1ex]
&\qquad\qquad{}\equiv
\textsf{\small`The component will fail during it 1st month of use'}
\lor{}
\\&\qquad\qquad\qquad
\textsf{\small`The component will fail during it 2nd month of use'}
\lor \dotsb
\\&\qquad\qquad\qquad
\dotsb \lor
\textsf{\small`The component will fail during it 12th month of use'}
\\[1ex]&\qquad\qquad{}\equiv
(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1) \lor (T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}2) \lor \dotsb \lor (T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}12)
\end{aligned}
\]

The probability needed by the agent is therefore

\[
\mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1 \lor T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}2 \lor \dotsb \lor T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}12\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

which can be calculated using the \texttt{or}-rule, considering that the
sentences involved are mutually exclusive:

\[
\begin{aligned}
&\mathrm{P}(\textsf{\small`The component will fail within a year of use'} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) 
\\[1ex]&\qquad{}=
\mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1 \lor T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}2 \lor \dotsb \lor T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}12\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\\[1ex]&\qquad{}=
\mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1 \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}) + \mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}2 \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}) + \dotsb + \mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}12 \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})
\\[1ex]&\qquad{}= \sum_{t=1}^{12} \mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}t \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\end{aligned}
\]

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={Sum notation}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

We shall often use the {\(\sum\)-notation} for sums, as in the example
above. A notation like {``\(\displaystyle\sum_{i=5}^{20}\)''} means:
write multiple copies of what's written on its right side, and in each
copy replace the symbol {``\(i\)''} with values from {\(5\)} to
{\(20\),} in turn; then sum up these copies. The symbol {``\(i\)''} is
called the \emph{index} of the sum. Sometimes the initial and final
values, {\(5\)} and {\(20\)} in the example, are omitted if they are
understood from the context, and the sum is written simply
{``\(\displaystyle\sum_{i}\)''}.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Using your favourite programming language:

\begin{itemize}
\tightlist
\item
  Load the file
  \href{datasets/failure_probability.csv}{\texttt{failure\_probability.csv}}
  containing the probabilities.
\item
  Inspect this file, find the headers of its columns and so on.
\item
  Calculate the probability that the component will fail within a year
  of use.
\item
  Calculate the probability that the component will fail ``within two
  months of use, or after a year of use''.
\end{itemize}

\end{tcolorbox}

\chapter{\texorpdfstring{{Joint probability
distributions}}{Joint probability distributions}}\label{sec-prob-joint}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand{\urge}{\cat{urgent}}
\providecommand{\nonu}{\cat{non-urgent}}
\providecommand{\heli}{\cat{helicopter}}
\providecommand{\ambu}{\cat{ambulance}}
\providecommand{\othe}{\cat{other}}
\providecommand{\yJ}{\se{J}}
\providecommand{\yK}{\se{K}}

So far we have considered probability distributions for quantities of a
basic (binary, nominal, ordinal, interval) type. These distributions
have a sort of one-dimensional character and can be represented by
ordinary histograms, line plots, and scatter plots. We now consider
probability distributions for the kind of joint quantities that were
discussed in §~\ref{sec-data-multiv}.

\section{Joint probability
distributions}\label{joint-probability-distributions}

A joint quantity is just a collection or set of quantities of basic
types. Saying that a joint quantity has a particular value means that
each basic component quantity has a particular value in its specific
domain. This is expressed by an \texttt{and} of sentences.

Consider for instance the joint quantity {\(X\)} consisting of the age
{\(\color[RGB]{102,204,238}A\)} and sex {\(\color[RGB]{34,136,51}S\)} of
a specific person. The fact that {\(X\)} has a particular value is
expressed by a composite sentence such as

\[
\textsf{\small`The person's age is 25 years and the person's sex is female'}
\]

which we can compactly write with an \texttt{and}:

\[
{\color[RGB]{102,204,238}A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}25\,\mathrm{y}} \land {\color[RGB]{34,136,51}S\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\mathrm{f}}
\]

All the possible composite sentences of this kind are \emph{mutually
exclusive} and \emph{exhaustive}.

An agent's uncertainty about {\(X\)'s} true value is therefore
represented by a probability distribution over all \texttt{and}-ed
sentences of this kind, representing all possible joint values:

\[
\mathrm{P}\bigl({\color[RGB]{102,204,238}A \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}25\,\mathrm{y}} \land {\color[RGB]{34,136,51}S\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\mathrm{f}} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}\bigr) \ , \qquad
\mathrm{P}\bigl({\color[RGB]{102,204,238}A \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}31\,\mathrm{y}} \land {\color[RGB]{34,136,51}S\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\mathrm{m}} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}\bigr) \ , \qquad
\dotsc
\]

where {\(\mathsfit{I}\)} is the agent's state of knowledge, and the
probabilities sum up to~1. We call each of these probabilities a
{\textbf{joint probability}}, and their collection a {\textbf{joint
probability distribution}}. Usually these probabilities are written in a
much abbreviated form. A comma
{``\(\mathbin{\mkern-0.5mu,\mkern-0.5mu}\)''} is typically used instead
of {``\(\land\)''} (§~\ref{sec-connecting-sentences}). You can commonly
encounter the following notation:

\[
\mathrm{P}(A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}25 \mathbin{\mkern-0.5mu,\mkern-0.5mu}S\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\mathrm{f} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

or even just

\[
\mathrm{P}(25, \mathrm{f} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

\section{Representation of joint probability
distributions}\label{sec-repr-joint-prob}

There is a wide variety of ways of representing joint probability
distributions, and new ways are invented (and rediscovered) all the
time. In some cases, especially when the quantity has more than three
component quantities, it can become impossible to graphically represent
the probability distribution in a faithful way. Therefore one often
tries to represent only some aspects or features of interest of the full
distribution. Whenever you see a plot of a joint probability
distribution, you should carefully read what the plot shows and how it
was made. Here we only illustrate some examples and ideas for
representations.

\subsection{Tables}\label{tables}

When a joint quantity consists of \emph{two, discrete and finite}
component quantities, the joint probabilities can be reported as a
table, sometimes called a {\textbf{contingency table}}\footnote{this
  term is most often used for joint distributions of \emph{frequencies}
  rather than probability}.

Example: Consider the next patient that will arrive at a particular
hospital. There's the possibility of arrival by
{\({\small\verb;ambulance;}\),} {\({\small\verb;helicopter;}\),} or
{\({\small\verb;other;}\)} transportation means; and the possibility
that the patient will need {\({\small\verb;urgent;}\)} or
{\({\small\verb;non-urgent;}\)} care. We can represent these
possibilities by two quantities {\(T\)} (nominal) and {\(U\)} (binary).
Now suppose that an agent has the following joint probability
distribution, conditional on the hospital's data
{\(\mathsfit{I}_{\text{H}}\):}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3056}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}@{}}
\caption{Joint probability distribution for transportation and
urgency}\label{tbl-urgent-arrival}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u \mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}t\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}_{\text{H}})\)
& &
\multicolumn{3}{>{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.5000} + 4\tabcolsep}@{}}{%
\textbf{transportation at arrival} \(T\)} \\
& & ambulance & helicopter & other \\
\multirow{2}{=}{\textbf{urgency} \(U\)} & urgent & 0.11 & 0.04 & 0.03 \\
& non-urgent & 0.17 & 0.01 & 0.64 \\
\end{longtable}

From the table we see that the most probable possibility is that the
next patient will arrive by other transportation means than ambulance
and helicopter, and will not require urgent care:

\[\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}_{\text{H}}) =
0.64\]

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{mackay_jointprob_squares.png}
Probability distribution over the 27\,×\,27 possible bigrams {\(xy\)} in
an English language document. Probabilities are represented by the areas
of white squares. From MacKay's
\href{https://www.inference.org.uk/itila/book.html}{\emph{Information
Theory, Inference, and Learning Algorithms}}

\end{footnotesize}}

In this kind of tables it is also possible to replace the numerical
probability values with graphical representations; for example as shades
of a colour, or squares with different areas.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise -- never forget the agent!}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Who could be the agent whose degrees of belief are represented in the
table above? What could be the background information leading to such
beliefs?

\end{tcolorbox}

\subsection{Scatter plots and similar}\label{scatter-plots-and-similar}

We saw in §~\ref{sec-discr-prob-distr} that probability distributions
for nominal, ordinal, or discrete-interval quantities can be represented
by histograms or line plots. Histograms could be generalized to
quantities consisting of \emph{two} joint discrete quantities: a
probability could be represented by a
\href{https://mathworld.wolfram.com/Cuboid.html}{cuboid or rectangular
prism}, or cylinder, or similar. This representation, even if it can
look flamboyant, is often inconvenient because some of the
three-dimensional objects can be hidden from view, as in the example in
the margin illustration.

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{2d_hist.png}\\
\strut \\
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{colour_hist.png}
Examples of a
\href{https://reference.wolfram.com/language/ref/DensityHistogram.html}{density
histogram} and a
\href{https://reference.wolfram.com/language/ref/Histogram3D.html}{generalized
histogram} (from Mathematica)

\end{footnotesize}}

Alternatively, one can replace the numerical values of the probabilities
in the tabular representation of the previous section with some
graphical encoding. An example is a colour scheme with \texttt{white}
for probability {\(0\),} \texttt{black} for probability {\(1\),} and
grey levels for intermediate probabilities. This is sometimes called a
``density histogram''; see the example in the margin figure. This
representation can be useful for qualitative or semi-quantitative
assessments, for example for seeing which joint values have highest
probabilities.

\hfill\break
Another representation, similar to the scatter plot
(§~\ref{sec-scatter-plot}), is to encode the probability values with a
proportional number of points or other shapes, as illustrated here for
the probabilities of table~\ref{tbl-urgent-arrival}:

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{scatter_hospital_arrival.png}

}

\caption{\label{fig-scatter-contingency}{Scatter plot for the
urgency-transportation joint probability distribution}}

\end{figure}%

the points do not need to be scattered in regular fashion as long as
it's clear which quantity value they are associated with. The scatter
plot above has 100 points, and therefore we can see for instance that
{\(\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\textrm{\small urgent} \mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\textrm{\small helicopter}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}_{\text{H}}) =
0.03\),} since the corresponding region has 3 points out of 100.

\section{Joint probability densities}\label{sec-joint-prob-densities}

If a joint quantity consists in several continuous interval quantities,
then its joint probability distribution is usually represented by a
{\textbf{joint probability density}}, which generalizes the
one-dimensional discussion of §~\ref{sec-prob-densities} to several
dimensions.

For instance, if {\(X\)} and {\(Y\)} are two continuous interval
quantities, then the notation

\[
\mathrm{p}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) = 0.001
\]

means that the joint sentence ``{\(X\) has value between
\(x-\epsilon/2\) and \(x+\epsilon/2\), and \(Y\) between \(y-\delta/2\)
and \(y+\delta/2\)}'', or in symbols

\[
\bigl(x-\tfrac{\epsilon}{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small<}\nonscript\mkern 0mu}\mathopen{} X \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small<}\nonscript\mkern 0mu}\mathopen{} x+\tfrac{\epsilon}{2}\bigr)
\land
\bigl(y-\tfrac{\delta}{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small<}\nonscript\mkern 0mu}\mathopen{} Y \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small<}\nonscript\mkern 0mu}\mathopen{} y+\tfrac{\delta}{2}\bigr)
\]

in being given a degree of belief {\(0.001\cdot\epsilon\cdot\delta\),}
conditional on the background knowledge {\(\mathsfit{I}\).} Visually,
the rectangular region of values around {\((x,y)\)} with sides of
lengths {\(\epsilon\)} and {\(\delta\)} is assigned a probability
{\(0.001\cdot\epsilon\cdot\delta\).}

Remember that a density typically has physical units, as in the
one-dimensional case (§~\ref{sec-prob-densities}). For instance, if
{\(X\)} above is a temperature measured in kelvin ({\(\mathrm{K}\))} and
{\(Y\)} a resistance measured in ohm ({\(\Omega\)),} then we should
write

\(\mathrm{p}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) = \frac{0.001}{\mathrm{K}\,\Omega}\).

\section{Representation of joint probability
densities}\label{sec-repr-joint-dens}

For one-dimensional densities we discussed line-based representations
and scatter plots (§~\ref{sec-represent-dens}). The first of these
representations can be generalized to two-dimensional densities, leading
to a {\textbf{surface plot}}. Below you see the surface density plot for
the probability density given by the formula

\begin{figure*}

\[
\mathrm{p}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) =
\tfrac{3}{8\,\pi}\, \mathrm{e}^{-\frac{1}{2} (x-1)^2-(y-1)^2}+
\tfrac{3}{64\,\pi}\,\mathrm{e}^{-\frac{1}{32} (x-2)^2-\frac{1}{2} (y-4)^2}+ \tfrac{1}{40\,\pi}\,\mathrm{e}^{-\frac{1}{8} (x-5)^2-\frac{1}{5} (y-2)^2}
\]

\end{figure*}%

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{index_files/mediabag/surfaceXY.pdf}

This kind of representation can be neat, but it has three drawbacks: 1.
It sometimes hides from view some features of the density (in the plot
above, can you exclude that there's a small peak right behind the main
one?). 2. It cannot be extended to three-dimensional densities. 3.
Sometimes the analytical expression for the probability density (like
the formula above) is not available.

The scatter plot overcomes the three drawbacks above. It does not hides
features; it can also be used for three-dimensional densities; it can be
generated in cases where the analytical formula of a probability
distribution is not available or too complicated, but we can still
obtain ``representative'' points from it. The representation of a
scatter plot is, however, quantitatively more imprecise. Here is a
scatter plot, using 10\,000 points, for the probability density given
above:

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{scatter_2d.png}

}

\caption{\label{fig-scatterXY}Scatter-plot representation of the joint
probability density
\(\mathrm{p}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)
above}

\end{figure}%

The probability of a small region is proportional to the density of
points in that region. If we had a joint density for \emph{three}
continuous quantities, its scatter plot would consist of
three-dimensional clouds of points instead.

Clearly both kinds of representation have advantages and disadvantages.
The choice between them depends on the problem, on the probability
density, and on what we wish to visually emphasize. It is also possible
to use both, of course.

\section{Joint mixed discrete-continuous probability
distributions}\label{sec-joint-mix-distr}

Frequently occurring in engineering and data-science problems are joint
quantities composed by some discrete and some continuous quantities.
Their joint probability distribution is a density with respect to the
continuous component quantity.

Suppose for instance that {\(Z\)} is a binary quantity with domain
{\(\set{{\small\verb;low;}, {\small\verb;high;}}\),} and {\(X\)} a
real-valued continuous quantity with domain {\(\mathbf{R}\).} Together
they form the joint quantity
{\((Z,X) \in \set{{\small\verb;low;}, {\small\verb;high;}} \times \mathbf{R}\).}
Then the probability expression

\[
\mathrm{p}(Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}3 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) = 0.07
\]

means that the agent with background
information~~{\(\mathsfit{I}\)~~has} a degree of belief equal
to~~~{\(0.07\cdot \epsilon\)~~~in} the joint sentence ``{\(Z\) has value
\({\small\verb;low;}\) and \(X\) has value between \(3-\epsilon/2\) and
\(3+\epsilon/2\)}''.~~As usual, this is only valid for any small
{\(\epsilon\),} and if {\(X\)} has physical dimensions, say metres
{\(\mathrm{m}\),} then the probability density above has
value~~{\(0.07\,\mathrm{m^{-1}}\).}

\section{Representation of mixed probability
distributions}\label{sec-repr-mix-distr}

Mixed discrete-continuous probability distributions can be somewhat
tricky to represent graphically. Here we consider line-based
representations and scatter plots. We take as example the probability
that the next patient who arrives at a particular hospital has a given
age (positive continuous quantity) and arrives by
{\({\small\verb;ambulance;}\),} {\({\small\verb;helicopter;}\),} or
{\({\small\verb;other;}\)} transportation means
(table~\ref{tbl-urgent-arrival}).

\subsection{Multi-line plots}\label{multi-line-plots}

A line plot can be used to represent the probability density for the
continuous quantity and each specific value of the discrete quantity:

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{hospital_age_transp.png}

}

\caption{\label{fig-multiline}Line plot for the age-transportation joint
probability distribution (table~\ref{tbl-urgent-arrival})}

\end{figure}%

With the plot above it's important to keep in mind that the three curves
are three pieces of the \emph{same} probability density, not three
different densities. This is also clear from the fact that the three
areas under them (which partly overlap) cannot each be equal to~1, as
would instead be required for a probability density. The probability
density is separated into three curves owing to the presence of the
discrete quantity, which has three possible values.

The area under the {solid blue curve} is equal to {\(0.55\),} the area
under the {dashed red curve} is {\(0.25\),} and the area under the
{dotted green curve} is {\(0.20\)} . The total area under the three
curves (counting also the overlapping regions) is equal to {\(1\),} as
it should.

A possible disadvantage of this kind of plots is that some details, such
as peaks, of the densities for some values of the discrete quantity, may
be barely discernible.

\subsection{Scatter plots}\label{sec-scatter-joint}

As discussed before, in a scatter plot we represent the probability
density by a cloud of ``representative'' objects, such as points,
obtained from it. The density of these objects is approximately
proportional to the density of probability.

Here is an example of scatter plot for the probability density of
table~\ref{tbl-urgent-arrival}:

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{hospital_age_transp_scatter.png}

In the plot above, the probability density is reflected by the density
of vertical lines. Using points instead of vertical lines, the density
would have been difficult to discern, since the points would all lie on
three lines.

We can use points if we give some variation, usually called
\href{https://mathworld.wolfram.com/Jitter.html}{jitter}, to their
vertical coordinate; but we must keep in mind that such vertical
variation has no meaning. The idea is similar to the one of
fig.~~\ref{fig-scatter-contingency}. In our current example of
table~\ref{tbl-urgent-arrival} we obtain a plot like this:

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{hospital_age_transp_scatter2.png}

}

\caption{\label{fig-pointscatter}Point-scatter plot for the
age-transportation joint probability}

\end{figure}%

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Compare the line plot of fig.~~\ref{fig-multiline} and the point-scatter
plot of fig.~~\ref{fig-pointscatter}, which represent the same joint
probability density. Do some introspection, and analyse the contrasting
impressions that the two kinds of representations may give you. For
instance, does the line plot give you a wrong intuition about the
sharpness of the peaks in the density?

Compare with what you did in the exercise of §~\ref{sec-represent-dens}.

\end{tcolorbox}

\section{Representation of more general probability distributions and
densities}\label{sec-repr-general-distr}

Probability distributions for complex types of quantity can be quite
tricky to visualize and represent in an informative way. They typically
require a case-by-case approach.

Often the idea behind the scatter plot works also in these complex
cases: the probability distribution or density is represented by a
``representative'' sample of objects. The objects can even depict the
quantity itself.

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{voltage-current_converter.jpg}
A voltage-current converter

\end{footnotesize}}

For instance, imagine the complex quantity {\(L\)} defined as ``{the
linear relationship between input voltage and output current of a
specific electronic component}''. The possible values of this quantity
are \emph{straight lines}, that is, functions of the form
{``\(y=m\,x + q\)''}, where {\(x\)} is the input voltage and {\(y\)} the
output current. These possible values -- straight lines -- can differ in
their angular coefficient {\(m\)} or in their intercept {\(q\).} One
possible value could be the straight line

{\(y= (2\,\mathrm{A/V})\, x - 3\,\mathrm{A}\)}

another possible value could be the straight line

{\(y= (-1\,\mathrm{A/V})\, x + 5\,\mathrm{A}\)}

and so on. The quantity {\(L\)} so defined is a continuous quantity, but
it isn't a quantity of a basic type.

An agent may be uncertain about the actual value of {\(L\),} that is,
about what is the straight line that correctly expresses the
voltage-current relationship of this particular electronic component.
The agent therefore assignes a probability density over all possible
values: over all possible straight lines. How to visually represent such
a ``probability density over lines''?

One way is to use a \emph{scatter plot}. The probability distribution is
represented by a collection of \emph{straight lines}, whose density is
approximately proportional to the probability density. Here is an
example using 360 representative straight lines:

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{index_files/mediabag/scatter_lines.pdf}

}

\caption{\label{fig-scatterlines}Scatter plot for a probability density
over the voltage-current relationship}

\end{figure}%

From this plot we can read some important semi-quantitative information
about the agent's degrees of belief. For instance:

\begin{itemize}
\tightlist
\item
  It's most probable that the voltage-current relationship has a
  positive angular coefficient \(m\) with value around
  \(0.5\,\mathrm{A/V}\), and an intercept \(q\) around
  \(3\,\mathrm{A}\).
\item
  It is improbable, but not impossible, that the voltage-current
  relationship has a negative angular coefficient (that is, the output
  current decreases as the input voltage is increased).
\item
  It's practically impossible that the voltage-current relationship is
  almost vertical (say, changes in current larger than
  \(\sim 5\,\mathrm{A}\) with changes in voltage smaller than
  \(\sim 0.2\,\mathrm{V}\)).
\end{itemize}

\hfill\break

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Explore datasets in a database such as the
  \href{https://archive.ics.uci.edu/datasets}{UC Irvine Machine Learning
  Repository}, for example

  \begin{itemize}
  \tightlist
  \item
    The \href{https://archive.ics.uci.edu/dataset/2/adult}{adult-income
    dataset}
  \item
    The \href{https://doi.org/10.24432/C52P4X}{heart-disease dataset}
  \end{itemize}

  Assume that the data given are \emph{representative ``points''} of a
  probability distribution or density (of which we don't know the
  analytic formula). Plot the probability distributions and probability
  densities as scatter plots using some of these representative points.
\item
  Look around for analytic formulae of some probability distributions
  and densities of simple and joint quantities, and plot them using
  different representations.
\end{itemize}

\end{tcolorbox}

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  §5.3.2 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Risk
  Assessment and Decision Analysis with Bayesian Networks}}
\item
  §12.2.2 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}
\end{itemize}

\end{tcolorbox}

\chapter{\texorpdfstring{{Marginal probability
distributions}}{Marginal probability distributions}}\label{sec-prob-marginal}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand{\urge}{\cat{urgent}}
\providecommand{\nonu}{\cat{non-urgent}}
\providecommand{\heli}{\cat{helicopter}}
\providecommand{\ambu}{\cat{ambulance}}
\providecommand{\othe}{\cat{other}}
\providecommand{\yJ}{\se{J}}
\providecommand{\yK}{\se{K}}

\section{Marginal probability: neglecting some
quantities}\label{sec-marginal-probs}

In some situations an agent has a joint distribution of degrees of
belief for the possible values of a joint quantity, but it needs to
consider its belief in the value of \emph{one} component quantity alone,
\emph{irrespective of what the values for the other components
quantities might be}.

Consider for instance the joint probability for the next-patient arrival
scenario of table~~\ref{tbl-urgent-arrival} from
§~\ref{sec-repr-joint-prob}, with joint quantity {\((U,T)\).} We may be
interested in the probability that the next patient will need
{\({\small\verb;urgent;}\)} care, \emph{independently of how the patient
is transported to the hospital}. This probability can be found, as
usual, by analysing the problem in terms of \emph{sentences} and using
the basic rules of inference from §~\ref{sec-fundamental}.

The sentence of interest is ``{The next patient will require urgent
care}'', or in symbols

\[U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\]

This sentence is equivalent to ``{The next patient will require urgent
care, and will arrive by ambulance, helicopter, or other means}'', or in
symbols

\[
U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\land
(
T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\lor
T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\lor
T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}
)
\]

Using the derived rules of Boolean algebra of §~\ref{sec-boolean} we can
rewrite this sentence in yet another way:

\[
(U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\land T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}) \lor
(U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\land T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}) \lor
(U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\land T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;})
\]

This last sentence is an \texttt{or} of \emph{mutually exclusive}
sentences. Its probability is therefore given by the \texttt{or} rule,
with the \texttt{and} terms being zero (we shall now use the comma
{``\(\mathbin{\mkern-0.5mu,\mkern-0.5mu}\)''} for \texttt{and}):

\begin{figure*}

\[
\begin{aligned}
&\mathrm{P}(U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}})
\\[1ex]
&\quad{}=
\mathrm{P}\bigl[
(U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}) \lor
(U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}) \lor
(U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;})
\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}} \bigr]
\\[1ex]
&\quad{}=\begin{aligned}[t]
&\mathrm{P}(U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}}) +{}
\\
&\quad\mathrm{P}(U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}}) +{}
\\
&\quad\mathrm{P}(U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}})
\end{aligned}
\end{aligned}
\]

\end{figure*}%

We have found that the probability for a value of the urgency quantity
{\(U\),} independently of the value of the transportation quantity
{\(T\),} can be calculated by summing all joint probabilities with all
possible {\(T\)} values. Using the {\(\sum\)-notation} we can write this
compactly:

\[
\mathrm{P}(U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}}) =
\sum_{t}
\mathrm{P}(U \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}t \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}})
\]

where it's understood that the sum index {\(t\)} runs over the values
{\(\set{{\small\verb;ambulance;}, {\small\verb;helicopter;}, {\small\verb;other;}}\).}

This is called a {\textbf{marginal probability}}.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Using the values from table~\ref{tbl-urgent-arrival}, calculate:

\begin{itemize}
\tightlist
\item
  the marginal probability that the next patient will need urgent care
\item
  the marginal probability that the next patient will arrive by
  helicopter
\end{itemize}

\end{tcolorbox}

\hfill\break

Considering now a more generic case of a joint quantity with component
quantities {\(\color[RGB]{34,136,51}X\)} and
{\(\color[RGB]{238,102,119}Y\),} the probability for a specific value of
{\(\color[RGB]{34,136,51}X\),} conditional on some information
{\(\mathsfit{I}\)} and irrespective of what the value of
{\(\color[RGB]{238,102,119}Y\)} might be, is given by

\[
\mathrm{P}({\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) = \sum_{\color[RGB]{238,102,119}y} \mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

You may notice the similarity with the expression for a \emph{combined
probability} from §~\ref{sec-combined-probs}. Indeed a marginal
probability is just a special case of a combined probability: we are
combining all probabilities that exhaust the possibilities for the
sentence
{\(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y\).}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise: test your understanding}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Using again the values from table~\ref{tbl-urgent-arrival}, calculate
the probability that \emph{the next patient will need urgent care and
will be transported either by ambulance or by helicopter}.

\end{tcolorbox}

\section{Marginal density distributions}\label{sec-marginal-dens}

In the example of the previous section, suppose now that the quantities
{\(\color[RGB]{34,136,51}X\)} and {\(\color[RGB]{238,102,119}Y\)} are
continuous. Then the joint probability is expressed by a density:

\[\mathrm{p}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\]

with the usual meaning. The marginal probability density for
{\(\color[RGB]{34,136,51}X\)} is still given by a sum, but this sum
occurs over intervals of values of {\(\color[RGB]{238,102,119}Y\),}
intervals with very small widths. As a consequence the sum will have a
very large number of terms. To remind ourselves of this fact, which can
be very important in some situations, we use a different notation in
terms of integrals:

\[
\mathrm{p}({\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) = \int_{\color[RGB]{238,102,119}\varUpsilon} \mathrm{p}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\, \mathrm{d}{\color[RGB]{238,102,119}y}
\]

where {\(\color[RGB]{238,102,119}\varUpsilon\)} represents the domain of
the quantity {\(\color[RGB]{238,102,119}Y\).}

This is called a {\textbf{marginal probability density}}.

The appearance of integrals is sometimes extremely useful, because it
allows us to use the theory of integration to calculate marginal
probabilities quickly and precisely, instead of having to compute sums
of a large numbers of small terms -- a procedure that can be
computationally expensive and lead to numerical errors owing to
underflow or similar computation problems.

\hfill\break

\section{Marginal probabilities and scatter
plots}\label{sec-marginal-scatter}

In the previous chapters we have often discussed scatter plots
(§~\ref{sec-scatter-plot}, §~\ref{sec-scatter-joint}) for representing
probability distributions of various kinds: discrete, continuous, joint,
mixed, and so on.

One more advantage of representing a joint distribution with a scatter
plot is that it can be quickly modified to represent any marginal
distribution, again with a scatter plot. Whereas the use of a surface
plot would require analytical calculations or approximations thereof.

Consider for instance the joint probability density from
§~\ref{sec-repr-joint-dens}, represented by the formula

\begin{figure*}

\[
\mathrm{p}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) =
\tfrac{3}{8\,\pi}\, \mathrm{e}^{-\frac{1}{2} (x-1)^2-(y-1)^2}+
\tfrac{3}{64\,\pi}\,\mathrm{e}^{-\frac{1}{32} (x-2)^2-\frac{1}{2} (y-4)^2}+ \tfrac{1}{40\,\pi}\,\mathrm{e}^{-\frac{1}{8} (x-5)^2-\frac{1}{5} (y-2)^2}
\]

\end{figure*}%

and suppose we would like to visualize the marginal probability density
for {\(X\):}

\(\mathrm{p}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\).

In order to represent this marginal probability density with a line
plot, we would first need to calculate the integral of the formula above
over {\(Y\):}

\begin{figure*}

\[
\mathrm{p}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) =
\int_{-\infty}^{\infty}
\Bigl[
\tfrac{3}{8\,\pi}\, \mathrm{e}^{-\frac{1}{2} (x-1)^2-(y-1)^2}+
\tfrac{3}{64\,\pi}\,\mathrm{e}^{-\frac{1}{32} (x-2)^2-\frac{1}{2} (y-4)^2}+ \tfrac{1}{40\,\pi}\,\mathrm{e}^{-\frac{1}{8} (x-5)^2-\frac{1}{5} (y-2)^2}
\Bigr]
\, \mathrm{d}y
\]

\end{figure*}%

Now instead suppose that we have stored the points used to represent the
joint probability
density~~{\(\mathrm{p}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)~~as}
a scatter plot, as in fig.~~\ref{fig-scatterXY}. Each of these points is
a pair of coordinates {\((x, y)\),} representing an {\(X\)-value} and a
{\(Y\)-value.} It turns out that \emph{these same points can be used to
make a scatter-plot of the marginal density for \(X\)}, simply by
considering their {\(x\)-coordinates} only, that is, by discarding their
{\(y\)-coordinates.} Often we use a subsample (unsystematically chosen)
of them, so that the resulting one-dimensional scatter plot doesn't
become too congested and difficult to read.

As an example, here is a scatter plot for the marginal probability
density~~{\(\mathrm{p}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)~~above,}
obtained by selecting a subset of 400 points from the scatter plot
(fig.~~\ref{fig-scatterXY}) for the joint distribution. The points are
replaced by vertical lines for better visibility:

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{scatter_2d_marginalX.png}

}

\caption{\label{fig-scatterXY-marginalX}Scatter-plot representation of
the marginal probability density
\(\mathrm{p}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)}

\end{figure}%

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

The points for the scatter plot of fig.~~\ref{fig-scatterXY}
(§~\ref{sec-repr-joint-dens}) are saved in the file
\href{datasets/scatterXY_samples.csv}{\texttt{scatterXY\_samples.csv}}.
Use them to represent the marginal probability density
{\(\mathrm{p}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\),}
for the other quantity {\(Y\),} as a scatter plot.

\end{tcolorbox}

\section{Uses and pitfalls of marginal probability
distributions}\label{sec-use-pitfall-marginal}

An agent's distribution of degrees of belief for a multi-dimensional
joint quantity is not easily -- or at all -- visualizable. This
shortcoming is especially bad because, as discussed in
§~\ref{sec-monty-motivation}, our intuition often fails us horribly in
multi-dimensional problems.

Marginal probability distributions for one or two of the component
quantities are useful because they offer us a little glimpse of the
multi-dimensional ``monster'' distribution. In concrete engineering and
data-science problem, when we need to discuss a multi-dimensional
distribution it is good practice to visually report at least its
one-dimensional marginal distributions.

In the machine-learning literature, this low-dimensional glimpse is
often used to qualitatively assess whether two multi-dimensional
distributions are similar. Their one-dimensional marginals are visually
compared and, if they overlap, one hopes (but some works in the
literature even erroneously \emph{conclude}) that the multi-dimensional
distributions are somewhat similar as well.

Keep in mind that this may very well not be the case. Marginal
distributions can also be quite deceiving:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Here are three different joint probability densities for the joint
quantity {\((X,Y)\),} each density represented by a scatter plot with
200 points. the files containing the coordinates of the scatter-plot
points are also given:

\textbf{A}. File
\href{datasets/scatterXY_A.csv}{\texttt{scatterXY\_A.csv}}:\\
\includegraphics[width=0.9\linewidth,height=\textheight,keepaspectratio]{scatterXY_A.png}

\textbf{B}. File
\href{datasets/scatterXY_B.csv}{\texttt{scatterXY\_B.csv}}:\\
\includegraphics[width=0.9\linewidth,height=\textheight,keepaspectratio]{scatterXY_B.png}

\textbf{C}. File
\href{datasets/scatterXY_C.csv}{\texttt{scatterXY\_C.csv}}:\\
\includegraphics[width=0.9\linewidth,height=\textheight,keepaspectratio]{scatterXY_C.png}

\hfill\break

\begin{itemize}
\item
  Reproduce the three scatter plots above using the points from the
  three files, just to confirm that they are correct.
\item
  For each density, plot the marginal density for the quantity {\(X\)}
  as a scatter plot. Use the method described in
  §~\ref{sec-marginal-scatter}; do not subsample the points.\\
  What can you say about the three marginal densities you obtain?\\
\item
  Do the same, but for the marginal densities for {\(Y\).}\\
  What can you say about the three marginal densities you obtain?
\item
  If two joint probability distributions have the same marginals, can we
  conclude that they are identical, or at least similar?
\end{itemize}

\end{tcolorbox}

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  §§5.3.2--5.3.3 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Risk
  Assessment and Decision Analysis with Bayesian Networks}}
\item
  §12.3 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}
\item
  §§5.1--5.5 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Probability}}
\end{itemize}

\end{tcolorbox}

\chapter{\texorpdfstring{{Conditional probability and
learning}}{Conditional probability and learning}}\label{sec-learning}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand{\urge}{\cat{urgent}}
\providecommand{\nonu}{\cat{non-urgent}}
\providecommand{\heli}{\cat{helicopter}}
\providecommand{\ambu}{\cat{ambulance}}
\providecommand{\othe}{\cat{other}}
\providecommand{\yJ}{\se{J}}
\providecommand{\yK}{\se{K}}

\section{The meaning of the term ``conditional
probability''}\label{sec-conditional-probs}

When we introduced the notion of degree of belief -- a.k.a. probability
-- in chapter~~\ref{sec-probability}, we emphasized that \emph{every
probability is conditional on some state of knowledge or information}.
So the term ``conditional probability'' sounds like a
\href{https://dictionary.cambridge.org/dictionary/english/pleonasm}{pleonasm},
just like saying ``round circle''.

This term must be understood in a way analogous to ``marginal
probability'': it applies in situations where we have two or more
sentences of interest. We speak of a ``conditional probability'' when we
want to emphasize that additional sentences appear in the conditional
(right side of {``\(\nonscript\:\vert\nonscript\:\mathopen{}\)''}) of
that probability. For instance, in a scenario with these two
probabilities:

\[
\mathrm{P}(\mathsfit{A} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\color[RGB]{204,187,68}B} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\qquad
\mathrm{P}(\mathsfit{A} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

we call the first {\textbf{conditional probability}} of
{\(\mathsfit{A}\)} ({\textbf{given}}
{\(\mathsfit{\color[RGB]{204,187,68}B}\))} to emphasize or point out
that its conditional includes the additional sentence
{\(\mathsfit{\color[RGB]{204,187,68}B}\),} whereas the conditional of
the second probability doesn't include this sentence.

\section{\texorpdfstring{The relation between \emph{learning} and
conditional
probability}{The relation between learning and conditional probability}}\label{sec-conditional-prob_learning}

Why do we need to emphasize that a particular degree of belief is
conditional on an additional sentence? Because the additional sentence
usually represents \emph{new information that the agent has learned}.

Remember that the conditional of a probability usually contains all
factual information known to the agent\footnote{Exceptions are, for
  instance, when the agent does \emph{counterfactual} or
  \emph{hypothetical} reasoning, as we discussed in
  §~\ref{sec-inference-scenarios}.}. Therefore if an agent acquires new
data or a new piece of information expressed by a sentence
{\(\color[RGB]{204,187,68}\mathsfit{D}\),} it should draw inferences and
make decisions using probabilities that include
{\(\color[RGB]{204,187,68}\mathsfit{D}\)} in their conditional. In other
words, the agent before was drawing inferences and making decisions
using some probabilities

\[
\mathrm{P}(\dotso \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
\]

where {\(\mathsfit{K}\)} is the agent's knowledge until then. Now that
the agent has acquired information or data
{\(\color[RGB]{204,187,68}\mathsfit{D}\),} it will draw inferences and
make decisions using probabilities

\[
\mathrm{P}(\dotso \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\color[RGB]{204,187,68}D} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
\]

Vice versa, if we see that an agent is calculating new probabilities
conditional on an additional sentence
{\(\color[RGB]{204,187,68}\mathsfit{D}\),} then it means\footnote{But
  keep again in mind exceptions like counterfactual reasoning; see the
  previous side note.} that the agent has acquired that information or
data {\(\color[RGB]{204,187,68}\mathsfit{D}\).}

Therefore {\textbf{conditional probabilities represent an agent's
learning}} and {\textbf{should be used when an agent has learned
something}}.

This learning can be of many different kinds. Let's examine two
particular kinds by means of some examples.

\hfill\break

\section{\texorpdfstring{Learning about a quantity from a
\emph{different}
quantity}{Learning about a quantity from a different quantity}}\label{sec-conditional-joint-dis}

Consider once more the next-patient arrival scenario of
§~\ref{sec-repr-joint-prob}, with joint quantity {\((U,T)\)} and an
agent's joint probability distribution as in
table~~\ref{tbl-urgent-arrival}, reproduced here:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3056}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}@{}}
\caption{Joint probability distribution for transportation and
urgency}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u \mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}t\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}_{\text{H}})\)
& &
\multicolumn{3}{>{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.5000} + 4\tabcolsep}@{}}{%
\textbf{transportation at arrival} \(T\)} \\
& & ambulance & helicopter & other \\
\multirow{2}{=}{\textbf{urgency} \(U\)} & urgent & 0.11 & 0.04 & 0.03 \\
& non-urgent & 0.17 & 0.01 & 0.64 \\
\end{longtable}

Suppose that the agent must forecast whether the next patient will
require {\({\small\verb;urgent;}\)} or {\({\small\verb;non-urgent;}\)}
care, so it needs to calculate the probability distribution for {\(U\)}
(that is, the probabilities for
{\(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\)}
and
{\(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\)).}

In the first exercise of §~\ref{sec-marginal-probs} you found that the
marginal probability that the next patient will need urgent care is

\[\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}}) = 18\%\]

this is the agent's degree of belief if it has nothing more and nothing
less than the knowledge encoded in the sentence
{\(\mathsfit{I}_{\text{H}}\).}

But now let's imagine that the agent \emph{receives a new piece of
information}: it is told that the next patient is being transported by
helicopter. In other words, \textbf{the agent has learned that the
sentence~~\(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\)~~is
true}. The agent's complete knowledge is therefore now encoded in the
\texttt{and}ed sentence

\[T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\ \land\ \mathsfit{I}_{\text{H}}\]

and this composite sentence should appear in the conditional. The
agent's belief that the next patient requires urgent care, given the new
information, is therefore

\[\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{H}})\]

Calculation of this probability can be done by just one application of
the \texttt{and}-rule, leading to a formula connected with Bayes's
theorem (§~\ref{sec-bayes-theorem}):

\begin{figure*}

\[
\begin{aligned}
&\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}}) =
\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{H}}) \cdot
\mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}})
\\[3ex]
&\quad\implies\quad
\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{H}})
=
\frac{
\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}})
}{
\mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}})
}
\end{aligned}
\]

\end{figure*}%

Let's see how to calculate this. The agent already has the joint
probability for
{\(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\land T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\)}
that appears in the numerator of the fraction above. The probability in
the denominator is just a marginal probability for {\(T\),} and we know
how to calculate that too from §~\ref{sec-marginal-probs}. So we find

\[
\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{H}})
=\frac{
\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}})
}{
\sum_u\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u \mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}})
}
\]

where it's understood that the sum index {\(u\)} runs over the values
{\(\set{{\small\verb;urgent;}, {\small\verb;non-urgent;}}\).}

This is called a {\textbf{conditional probability}}; in this case, the
conditional probability
of~~{\(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\)~~}{\textbf{given}}~~{\(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\).}

The collection of probabilities for all possible values of the quantity
{\(U\),} given a \emph{specific} value of the quantity {\(T\),} say
{\({\small\verb;helicopter;}\):}

\[
\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{H}}) \ ,
\qquad
\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{H}})
\]

is called the {\textbf{conditional probability distribution}} for
{\(U\)~~}{\textbf{given}}~~{\(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\).}
It is indeed a probability distribution because the two probabilities
sum up to~1.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Note that the collection of probabilities for, say,
{\(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\),}
but for \emph{different} values of the conditional quantity {\(T\),}
that is:

\[
\begin{aligned}
&\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{H}}) \ ,
\\[1ex]
&\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{H}}) \ ,
\\[1ex]
&\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{H}})
\end{aligned}
\]

is \textbf{not} a probability distribution. Calculate the three
probabilities above and check that in fact they do \emph{not} sum up
to~1.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Using the values from table~\ref{tbl-urgent-arrival} and the formula
  for marginal probabilities, calculate:

  \begin{itemize}
  \item
    The conditional probability that the next patient needs urgent care,
    given that the patient is being transported by helicopter.
  \item
    The conditional probability that the next patient is being
    transported by helicopter, given that the patient needs urgent care.
  \end{itemize}
\item
  Now discuss and find an intuitive explanation for these comparisons:

  \begin{itemize}
  \item
    The two probabilities you obtained above. Are they equal? why or why
    not?
  \item
    The \emph{marginal} probability that the next patient will be
    transported by helicopter, with the \emph{conditional} probability
    that the patient will be transported by helicopter \emph{given} that
    it's urgent. Are they equal? if not, which is higher, and why?
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\hfill\break

\section{\texorpdfstring{Learning about a quantity from instances of
\emph{similar}
quantities}{Learning about a quantity from instances of similar quantities}}\label{sec-conditional-joint-sim}

In the previous section we examined how learning about one quantity can
change an agent's degree of belief about a \emph{different} quantity,
for example knowledge about ``transportation'' affects beliefs about
``urgency'', or vice versa. The agent's learning and ensuing belief
change are reflected in the value of the corresponding conditional
probability.

This kind of change can also occur with ``similar'' quantities, that is,
quantities that represent the same kind of phenomenon and have the same
domain. The maths and calculations are identical to the ones we explored
above, but the interpretation and application can be somewhat different.

As an example, imagine a scenario similar to the next-patient arrival
above, but now consider the \emph{next three patients} to arrive and
their urgency. Define the following three quantities:

\(U_1\)\,: urgency of the next patient\\
{\(U_2\)\,:} urgency of the second future patient from now\\
{\(U_3\)\,:} urgency of the third future patient from now\\

Each of these quantities has the same domain:
{\(\set{{\small\verb;urgent;},{\small\verb;non-urgent;}}\).}

The joint quantity {\((U_1, U_2, U_3)\)} has a domain with {\(2^3 = 8\)}
possible values:

\begin{itemize}
\tightlist
\item
  \(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\)
\item
  \(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\)
\item
  .\,.\,.
\item
  \(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\)
\item
  \(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\)
\end{itemize}

\hfill\break
Suppose that an agent, with background information {\(\mathsfit{I}\),}
has a particular joint belief distribution for the joint quantity
{\((U_1, U_2, U_3)\).} For example consider the joint distribution
implicitly given as follows:

\begin{itemize}
\tightlist
\item
  If \({\small\verb;urgent;}\) appears in the probability 0 times out of
  3:~~probability\,=\,\(53.6\%\)
\item
  If \({\small\verb;urgent;}\) appears 1 times out of
  3:~~probability\,=\,\(11.4\%\)
\item
  If \({\small\verb;urgent;}\) appears 2 times out of
  3:~~probability\,=\,\(3.6\%\)
\item
  If \({\small\verb;urgent;}\) appears 3 times out of
  3:~~probability\,=\,\(1.4\%\)
\end{itemize}

Here are some examples of how the probability values are determined by
the description above:

\begin{figure*}

\[
\begin{aligned}
&\mathrm{P}(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
= 0.036 \quad&&\text{\small(${\small\verb;urgent;}$ appears twice)}
\\[1ex]
&\mathrm{P}(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
= 0.114 &&\text{\small(${\small\verb;urgent;}$ appears once)}
\\[1ex]
&\mathrm{P}(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
= 0.036 &&\text{\small(${\small\verb;urgent;}$ appears twice)}
\\[1ex]
&\mathrm{P}(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
= 0.536 &&\text{\small(${\small\verb;urgent;}$ doesn't appear)}
\end{aligned}
\]

\end{figure*}%

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Check that the joint probability distribution as defined above indeed
  sums up to {\(1\).}
\item
  Calculate the marginal probability for
  {\(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\),}
  that
  is,~~{\(\mathrm{P}(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})\).}
\item
  Calculate the marginal probability that the second and third patients
  are non-urgent cases, that is
\end{itemize}

\[\mathrm{P}(U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}) \ .\]

\end{tcolorbox}

From this joint probability distribution the agent can calculate, among
other things, its degree of belief that the \emph{third} patient will
require urgent care, regardless of the urgency of the preceding two
patients. It's the marginal probability

\[
\begin{aligned}
\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})  &= 
\sum_{u_1}\sum_{u_2}
\mathrm{P}(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u_1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u_2 \mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\\[1ex]
&= 0.114 + 0.036 + 0.036 + 0.014
\\[1ex]
&= \boldsymbol{20.0\%}
\end{aligned}
\]

where each index {\(u_1\)} and {\(u_2\)} runs over the values
{\(\set{{\small\verb;urgent;}, {\small\verb;non-urgent;}}\).} This
double sum therefore involves four terms. The first term in the sum
corresponds to
{``\(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\)''}
and therefore has probability {\(0.014\)} . The second term corresponds
to
{``\(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\)''}
and therefore has probability {\(0.036\).} And so on.

Therefore the agent, with its current knowledge, has a {\(20\%\)} degree
of belief that the third patient will require urgent care.

\hfill\break

Now fast-forward in time, after \emph{two} patients have arrived and
have been taken good care of; or maybe they haven't arrived yet, but
their urgency conditions have been ascertained and communicated to the
agent. Suppose that \emph{both patients were or are non-urgent cases}.
The agent now knows this fact. The agent needs to forecast whether the
third patient will require urgent care.

The relevant degree of belief is obviously
not~~{\(\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})\),~~calculated}
above, because this belief represents an agent knowing only
{\(\mathsfit{I}\).} Now, instead, the agent has additional information
about the first two patients, encoded in this \texttt{and}ed sentence:

\[
U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}
\]

The relevant degree of belief is therefore the \emph{conditional}
probability

\[
\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]

Which we can calculate with the same procedure as in the previous
section:

\[
\begin{aligned}
&\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&\qquad{}=
\frac{
\mathrm{P}(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\mathrm{P}(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\\[1ex]
&\qquad{}=\frac{0.114}{0.65}
\\[2ex]
&\qquad{}\approx
\boldsymbol{17.5\%}
\end{aligned}
\]

This conditional probability {\(17.5\%\)} for
{\(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\)}
is \emph{lower} than {\(20.0\%\)} calculated previously, which was based
only on knowledge {\(\mathsfit{I}\).} \textbf{Learning about the two
first patients has thus affected the agent's degree of belief about the
third}.

\hfill\break
Let's also check how the agent's belief changes in the case where the
first two patients are both \emph{urgent} instead. The calculation is
completely analogous:

\[
\begin{aligned}
&\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&\qquad{}=
\frac{
\mathrm{P}(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\mathrm{P}(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\\[1ex]
&\qquad{}=\frac{0.030}{0.107}
\\[2ex]
&\qquad{}\approx
\boldsymbol{28.0\%}
\end{aligned}
\]

In this case the conditional probability {\(28.0\%\)} for
{\(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\)}
is \emph{higher} than the {\(20.0\%\),} which was based only on
knowledge {\(\mathsfit{I}\).}

One possible intuitive explanation of these probability changes,
\emph{in the present scenario}, is that observation of two non-urgent
cases makes the agent slightly more confident that ``this is a day with
few urgent cases''. Whereas observation of two urgent cases makes the
agent more confident that ``this is a day with many urgent cases''.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} The diversity of inference scenarios}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

In general we cannot say that the probability of a particular value
(such as {\({\small\verb;urgent;}\)} in the scenario above) will
decrease or increase as similar or dissimilar values are observed. Nor
can we say how much the increase or decrease will be.

In a different situation the probability of {\({\small\verb;urgent;}\)}
could actually \textbf{increase} as more and more
{\({\small\verb;non-urgent;}\)} cases are observed. Imagine, for
instance, a scenario where the agent initially knows that there are 10
urgent and 90 non-urgent cases ahead (maybe these 100 patients have
already been gathered in a room). Having observed 90 non-urgent cases,
the agent will give a much higher, in fact 100\%, probability that the
next case will be an urgent one. Can you see intuitively why this
conditional degree of belief must be 100\%?

The differences among scenarios are reflected in differences in joint
probabilities, from which the conditional probabilities are calculated.
One particular joint probability can correspond to a scenario where
observation of a value \emph{increases} the degree of belief in
subsequent instances of that value. Another particular joint probability
can instead correspond to a scenario where observation of a value
\emph{decreases} the degree of belief in subsequent instances of that
value.

\textbf{All} these situations are, in any case, correctly handled with
the four fundamental rules of inference and the formula for conditional
probability derived from them!

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  Using the same joint distribution above, calculate

  \[\mathrm{P}(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\]

  that is, the probability that the \emph{first} patient will require
  urgent care \emph{given that the agent knows the second and third
  patients will not require urgent care}.

  \begin{itemize}
  \item
    Why is the value you obtained different
    from~~{\(\mathrm{P}(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})\)\,?}
  \item
    Describe a scenario in which the conditional probability above makes
    sense, and patients~2 and~3 still arrive after patient~1. That is, a
    scenario where the agent learns that patients~2 and~3 are
    non-urgent, but still doesn't know the condition of patient~1.
  \end{itemize}
\end{enumerate}

\hfill\break

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\item
  Do an analysis completely analogous to the one above, but with
  different background information {\(\mathsfit{J}\)} corresponding to
  the following joint probability distribution for
  {\((U_1, U_2, U_3)\):}

  • If {\({\small\verb;urgent;}\)} appears 0 times out of
  3:~~probability\,=\,{\(0\%\)}\\
  • If {\({\small\verb;urgent;}\)} appears 1 times out of
  3:~~probability\,=\,{\(24.5\%\)}\\
  • If {\({\small\verb;urgent;}\)} appears 2 times out of
  3:~~probability\,=\,{\(7.8\%\)}\\
  • If {\({\small\verb;urgent;}\)} appears 3 times out of
  3:~~probability\,=\,{\(3.1\%\)}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Calculate

    \[\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{J})\]

    and

    \[\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{J})\]
    and compare them.
  \item
    Find a scenario for which this particular change in degree of belief
    makes sense.
  \end{enumerate}
\end{enumerate}

\end{tcolorbox}

\section{Learning in the general
case}\label{sec-conditional-joint-general}

Take the time to review the two sections above, focusing on the
application and meaning of the two scenarios and calculations, and
noting the similarities and differences:

\begin{itemize}
\item
  {\faIcon{equals} The calculations were completely analogous. In
  particular, the conditional probability was obtained as the quotient
  of a joint probability and a marginal one.}
\item
  {\faIcon{not-equal} In the first (urgency \& transportation) scenario,
  information about one aspect of the situation changed the agent's
  belief about another aspect. The two aspects were different
  (transportation and urgency). Whereas in the second (three-patient)
  scenario, information about analogous occurrences of an aspect of the
  situation changed the agent's belief about a further occurrence.}
\end{itemize}

\hfill\break
A third scenario is also possible, which combines the two above.
Consider the case with three patients, where each patient can require
{\({\small\verb;urgent;}\)} care or not, and can be transported by
{\({\small\verb;ambulance;}\),} {\({\small\verb;helicopter;}\),} or
{\({\small\verb;other;}\)} means. To describe this situation, introduce
three pairs of quantities, which together form the joint quantity

\[
(U_1, T_1, \ U_2, T_2, \ U_3, T_3)
\]

whose symbols should be obvious. This joint quantity has
{\((2\cdot 3)^3 = 216\)} possible values, corresponding to all urgency
\& transportation combinations for the three patients.

Given the joint probability distribution for this joint quantity, it is
possible to calculate all kinds of conditional probabilities, and
therefore consider all the possible ways the agent may learn new
information. For instance, suppose the agent learns this:

\begin{itemize}
\tightlist
\item
  the first two patients have not required urgent care
\item
  the first patient was transported by ambulance
\item
  the second patient was transported by other means
\item
  the third patient is arriving by ambulance
\end{itemize}

and with this learned knowledge, the agent needs to infer whether the
third patient will require urgent care. The required conditional
probability is

\begin{figure*}

\[
\begin{aligned}
&\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I})
\\[2ex]
&\qquad{}=
\frac{
\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\nonscript\:\vert\nonscript\:\mathopen{}
\mathsfit{I})
}{
\mathrm{P}(T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I})
}
\end{aligned}
\]

\end{figure*}%

and is calculated in a way completely analogous to the ones already
seen.

\hfill\break

All three kinds of inference scenarios that we have discussed occur in
data science and engineering. In machine learning, the second scenario
is connected to ``unsupervised learning''; the third, mixed scenario to
``supervised learning''. As you just saw, the probability calculus
``sees'' all of these scenarios as analogous: information about
something changes the agent's belief about something else. And the
handling of all three cases is perfectly covered by the four fundamental
rules of inference.

So let's write down the general formula for all these cases of learning.

Let's consider a more generic case of a joint quantity with component
quantities {\(\color[RGB]{34,136,51}X\)} and
{\(\color[RGB]{238,102,119}Y\).} Their joint probability distribution is
given. Each of these two quantities could be a complicated joint
quantity by itself.

The conditional probability for
{\(\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y\),}
given that the agent has learned that {\(\color[RGB]{34,136,51}X\)} has
some specific value {\(\color[RGB]{34,136,51}x^*\),} is then

\begin{equation}\phantomsection\label{eq-conditional-joint}{
\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y}\nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x^*}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) =
\frac{
\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x^*}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})
}{
\sum_{\color[RGB]{238,102,119}\upsilon}\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\upsilon}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x^*}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})
}
}\end{equation}

where the index {\(\color[RGB]{238,102,119}\upsilon\)} runs over all
possible values in the domain of {\(\color[RGB]{238,102,119}Y\).}

\hfill\break

\section{Conditional probabilities as initial
information}\label{sec-conditional-conditional}

Up to now we have calculated conditional probabilities, using the
derived formula (\ref{eq-conditional-joint}), starting from the joint
probability distribution, which we considered to be given. In some
situations, however, an agent may initially possess not a joint
probability distribution but \textbf{conditional probabilities} together
with \textbf{marginal probabilities}.

As an example let's consider a variation of our next-patient scenario
one more time. The agent has background information
{\(\mathsfit{I}_{\text{S}}\)} that provides the following set of
probabilities:

\begin{itemize}
\tightlist
\item
  Two conditional probability
  distributions~~\(\mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \nonscript\:\vert\nonscript\:\mathopen{} U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{S}})\)
  for transportation \(T\) given urgency \(U\), as reported in the
  following table:
\end{itemize}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3056}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}@{}}
\caption{Probability distributions for transportation given
urgency}\label{tbl-T-given-U}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}t \nonscript\:\vert\nonscript\:\mathopen{} U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{S}})\)
& &
\multicolumn{3}{>{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.5000} + 4\tabcolsep}@{}}{%
\textbf{transportation at
arrival}~~\(T\nonscript\:\vert\nonscript\:\mathopen{}{}\)} \\
& & ambulance & helicopter & other \\
\multirow{2}{=}{\emph{given}
\textbf{urgency}~~\({}\nonscript\:\vert\nonscript\:\mathopen{}U\)} &
urgent & 0.61 & 0.22 & 0.17 \\
& non-urgent & 0.21 & 0.01 & 0.78 \\
\end{longtable}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

{This table has \textbf{two} probability distributions: on the first
row, one conditional on
\(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\);
on the second row, one conditional on
\(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\).
Check that the probabilities on each row indeed sum up to~1.}

\end{tcolorbox}

\end{footnotesize}}

\hfill\break

\begin{itemize}
\tightlist
\item
  Marginal probability
  distribution~~\(\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{S}})\)
  for urgency \(U\):
\end{itemize}

\begin{equation}\phantomsection\label{eq-U-marg}{
\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{S}}) = 0.18 \ ,
\quad
\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{S}}) = 0.82
}\end{equation}

\hfill\break

With this background information, the agent can also compute all joint
probabilities simply using the \texttt{and}-rule. For instance, the
joint probability for
{\(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\)}
is

\[
\begin{aligned}
&P(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{S}})
\\[1ex]
&\quad{}= 
P(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{S}}) \cdot
P(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{S}})
\\[1ex]
&\quad{}= 0.22 \cdot 0.18 = \boldsymbol{3.96\%}
\end{aligned}
\]

And from the joint probabilities, the marginal ones for transportation
{\(T\)} can also be calculated. For instance

\[
\begin{aligned}
&P(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{S}})
\\[1ex]
&\quad{}= 
\sum_u P(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{S}})
\\[1ex]
&\quad{}= 
\sum_u P(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{S}}) \cdot
P(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{S}})
\\[1ex]
&\quad{}= 
0.22 \cdot 0.18 +
0.01 \cdot 0.82
\\[1ex]
&\quad{}= \boldsymbol{4.78\%}
\end{aligned}
\]

\hfill\break
Now suppose that the agent learns that the next patient is being
transported by {\({\small\verb;helicopter;}\),} and needs to forecast
whether {\({\small\verb;urgent;}\)} care will be needed. This inference
is the conditional
probability~~{\(\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{S}})\),}
which can also be rewritten in terms of the conditional probabilities
given initially:

\[
\begin{aligned}
&\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{H}})
\\[2ex]
&\quad{}=\frac{
\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}})
}{
\mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{H}})
}
\\[1ex]
&\quad{}=\frac{
P(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{S}}) \cdot
P(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{S}})
}{
\sum_u P(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\nonscript\:\vert\nonscript\:\mathopen{} U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{S}}) \cdot
P(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{S}})
}
\\[1ex]
&\quad{}=\frac{0.0396}{0.0478}
\\[2ex]
&\quad{}=\boldsymbol{82.8\%}
\end{aligned}
\]

This calculation was slightly more involved than the one in
§~\ref{sec-conditional-joint-dis}, because in the present case the joint
probabilities were not directly available. Our calculation involved the
steps~~{\(T\nonscript\:\vert\nonscript\:\mathopen{}U \enspace\longrightarrow\enspace T\land U \enspace\longrightarrow\enspace U\nonscript\:\vert\nonscript\:\mathopen{}T\)\,.}

\hfill\break
In this same scenario, note that if the agent were instead interested,
say, in forecasting the transportation means knowing that the next
patient requires urgent care, then the relevant degree of
belief~~{\(\mathrm{P}(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \nonscript\:\vert\nonscript\:\mathopen{} U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{S}})\)}
would be immediately available and no calculations would be needed.

\hfill\break

Let's find the general formula for this case, where the agent's
background information is represented by conditional probabilities
instead of joint probabilities.

Consider a joint quantity with component quantities
{\(\color[RGB]{34,136,51}X\)} and {\(\color[RGB]{238,102,119}Y\).} The
conditional
probabilities~~{\(\mathrm{P}({\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\)~~and~~}{\(\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)~~are}
encoded in the agent from the start.

The conditional probability for
{\(\color[RGB]{238,102,119}Y \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y\),}
given that the agent has learned that
{\(\color[RGB]{34,136,51}X \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x^*\),}
is then

\begin{equation}\phantomsection\label{eq-conditional-bayes}{
\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y}\nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x^*}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) =
\frac{
\mathrm{P}( {\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x^*}\nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) \cdot
\mathrm{P}( {\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})
}{
\sum_{\color[RGB]{238,102,119}\upsilon}
\mathrm{P}( {\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x^*}\nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\upsilon} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) \cdot
\mathrm{P}( {\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\upsilon} \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})
}
}\end{equation}

In the above formula we recognize {\textbf{Bayes's theorem}} from
§~\ref{sec-bayes-theorem}.

This formula is often exaggeratedly emphasized in the literature; some
texts even present it as an ``axiom'' to be used in situations such as
the present one. But we see that this formula is simply a by-product of
the four fundamental rules of inference in a specific situation. An AI
agent who knows the four fundamental inference rules, and doesn't know
what ``Bayes's theorem'' is, will nevertheless arrive at this very
formula.

\section{Conditional densities}\label{sec-conditional-dens}

The discussion so far about conditional probabilities extends to
conditional probability \emph{densities}, in the usual way explained in
§§\ref{sec-joint-prob-densities} and~\ref{sec-marginal-dens}.

If {\(\color[RGB]{34,136,51}X\)} and {\(\color[RGB]{238,102,119}Y\)} are
continuous quantities, the notation

\[
\mathrm{p}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) = {\color[RGB]{68,119,170}q}
\]

means that, given background information {\(\mathsfit{I}\)} and given
the sentence {``\(\color[RGB]{34,136,51}X\) has value between
\(\color[RGB]{34,136,51}x-\delta/2\) and
\(\color[RGB]{34,136,51}x+\delta/2\)''}, the sentence
{``\(\color[RGB]{238,102,119}Y\) has value between
\(\color[RGB]{238,102,119}y-\epsilon/2\) and
\(\color[RGB]{238,102,119}y+\epsilon/2\)''} has probability
{\({\color[RGB]{68,119,170}q}\cdot{\color[RGB]{238,102,119}\epsilon}\),}
as long as {\(\color[RGB]{34,136,51}\delta\)} and
{\(\color[RGB]{238,102,119}\epsilon\)} are small enough. Note that the
small interval {\(\color[RGB]{34,136,51}\delta\)} for
{\(\color[RGB]{34,136,51}X\)} is \emph{not} multiplied by the density
{\(\color[RGB]{68,119,170}q\).}

The relation between a conditional density and a joint density or a
different conditional density is given by

\[
\begin{aligned}
&\mathrm{p}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[1ex]
&\quad{}=
\frac{\displaystyle
\mathrm{p}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{\displaystyle
\int_{\color[RGB]{238,102,119}\varUpsilon}\mathrm{p}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\upsilon} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) \, \mathrm{d}{\color[RGB]{238,102,119}\upsilon}
}
\\[1ex]
&\quad{}=
\frac{\displaystyle
\mathrm{p}({\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) \cdot
\mathrm{p}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{\displaystyle
\int_{\color[RGB]{238,102,119}\varUpsilon} \mathrm{p}({\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\upsilon} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) \cdot
\mathrm{p}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\upsilon} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\, \mathrm{d}{\color[RGB]{238,102,119}\upsilon}
}
\end{aligned}
\]

where {\(\color[RGB]{238,102,119}\varUpsilon\)} is the domain of
{\(\color[RGB]{238,102,119}Y\).}

\section{Graphical representation of conditional probability
distributions and densities}\label{sec-repr-conditional}

Conditional probability distributions and densities can be plotted in
all the ways discussed in chapters~\ref{sec-prob-joint}
and~\ref{sec-prob-marginal}. If we have two quantities {\(A\)} and
{\(B\),} often we want to compare the different conditional probability
distributions for {\(A\),} conditional on different values of {\(B\):}

\begin{itemize}
\tightlist
\item
  \(\mathrm{P}(A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \nonscript\:\vert\nonscript\:\mathopen{} B\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;one-value;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\),
\item
  \(\mathrm{P}(A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \nonscript\:\vert\nonscript\:\mathopen{} B\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;another-value;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\),
\item
  \(\dotsc\)
\end{itemize}

and so on. This can be achieved by representing them by overlapping line
plots, or side-by-side scatter plots, or similar ways.

\hfill\break
In §~\ref{sec-marginal-scatter} we saw that if we have the scatter plot
for a joint probability \emph{density}, then from its points we can
often obtain a scatter plot for its marginal densities. Unfortunately no
similar advantage exists for the conditional densities that can be
obtained from a joint density. In theory, a conditional density for
{\(Y\),} given that a quantity {\(X\)} has value in some small interval
{\(\delta\)} around {\(x\),} could be obtained by only considering
scatter-plot points having {\(X\)} coordinate in a small interval
between {\(x-\delta/2\)} and {\(x+\delta/2\).} But the number of such
points is usually too small and the resulting scatter plot could be very
misleading.

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  §5.4 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Risk
  Assessment and Decision Analysis with Bayesian Networks}}
\item
  §§12.2.1, 12.3, and~12.5 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}
\item
  §§4.1--4.3 in
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Medical
  Decision Making}}
\item
  §§5.1--5.5 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Probability}}
  -- yes, once more!
\end{itemize}

\end{tcolorbox}

\chapter*{\texorpdfstring{{Learning and conditional probability: a
summary}}{Learning and conditional probability: a summary}}\label{learning-and-conditional-probability-a-summary}
\addcontentsline{toc}{chapter}{{Learning and conditional probability: a
summary}}

\markboth{{Learning and conditional probability: a summary}}{{Learning
and conditional probability: a summary}}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand{\urge}{\cat{urgent}}
\providecommand{\nonu}{\cat{non-urgent}}
\providecommand{\heli}{\cat{helicopter}}
\providecommand{\ambu}{\cat{ambulance}}
\providecommand{\othe}{\cat{other}}
\providecommand{\yJ}{\se{J}}
\providecommand{\yK}{\se{K}}

The previous chapter~\ref{sec-learning} discussed many concepts that are
important for what follows, and for artificial intelligence and machine
learning in general. So let's stop for a moment to emphasize and point
out some things to keep in mind.

\hfill\break

\begin{itemize}
\item
  \faIcon{hand-point-right} What does it means that an agent has
  ``\emph{learned}''? It means that the agent has acquired new
  information, knowledge, or data. But this acquisition is not just some
  passive memory storage. As a result of this acquisition, the agent
  \emph{modifies its degrees of belief} about any inferences it needs to
  draw, and consequently may make different decisions
  ({[}ch.@sec-basic-decisions{]}).

  This change is an important aspect of learning. Think of when a person
  receives useful information; but the person, in actions or word,
  doesn't seem to make use of it. We typically say ``that person hasn't
  learned anything''.
\end{itemize}

\hfill\break

\begin{itemize}
\item
  \faIcon{hand-point-right} The relation between the acquired knowledge
  and the change in beliefs is perfectly represented and quantified by
  \emph{conditional probabilities}. These probabilities take account of
  the acquired information in their conditionals (the right side of the
  bar {``\(\nonscript\:\vert\nonscript\:\mathopen{}\)''}). And the
  probability calculus automatically determines how to calculate the
  modified belief based on this new conditional.

  In other words, the probability calculus already has everything we
  need to deal with and calculate ``learning''. This is therefore
  \emph{the} optimal, self-consistent way to deal with learning. We may
  use approximate versions of it in some situations, for instance when
  the computations would be too expensive. But we must keep in mind that
  such approximations are also deviations from optimality and
  self-consistency.
\end{itemize}

\hfill\break

\begin{itemize}
\tightlist
\item
  \faIcon{hand-point-right} The formula for conditional probability --
  that is, for the belief change corresponding to learning -- involves
  and requires a \emph{joint distribution} over several possibilities
  ({[}ch.@sec-prob-joint{]}). Therefore such distribution \emph{must be
  somehow built into the agent} from the beginning, for the agent to be
  able to learn.
\end{itemize}

\hfill\break

\begin{itemize}
\item
  \faIcon{hand-point-right} The beliefs and behaviour arising from
  learning can be very different, depending on the context. For example,
  in some situations frequently observing a phenomenon may
  \emph{increase} an agent's belief in observing that phenomenon again;
  but in other situations such frequent observation may \emph{decrease}
  an agent's belief instead. Both kinds of behaviour can make sense in
  their specific circumstances.

  These differences in behaviour are also encoded in the \emph{joint
  distribution} built into the agent.
\end{itemize}

\hfill\break

\begin{itemize}
\item
  \faIcon{hand-point-right} The formula for belief change arising from
  learning is amazingly flexible and universal: it holds whether the
  agent is learning about different kinds of quantities or about past
  instances of similar quantities.

  From a machine-learning point of view, this must therefore be the
  formula underlying the use of ``features'' by a classifier, as well as
  its ``training''.

  This formula is moreover extremely simple in principle: it only
  involves addition and division! Computational difficulties arise from
  the huge amount of terms that may need to be added in specific
  data-science problems, not because of complicated mathematics. (A data
  engineer should keep this in mind, in case new hardware technologies
  may make it possible to deal with larger number of terms.)
\end{itemize}

\chapter{\texorpdfstring{{Information, relevance, independence,
association}}{Information, relevance, independence, association}}\label{sec-info-chapter}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand{\yA}{\se{A}}
\providecommand{\yB}{\se{B}}
\providecommand{\fail}{\cat{fail}}
\providecommand{\work}{\cat{work}}
\providecommand{\high}{\cat{high}}
\providecommand{\medium}{\cat{medium}}
\providecommand{\low}{\cat{low}}
\providecommand{\HH}{\mathrm{H}}

\providecommand{\urge}{\cat{urgent}}
\providecommand{\nonu}{\cat{non-urgent}}
\providecommand{\heli}{\cat{helicopter}}
\providecommand{\ambu}{\cat{ambulance}}
\providecommand{\othe}{\cat{other}}
\providecommand{\yJ}{\se{J}}
\providecommand{\yK}{\se{K}}

\section{Independence of sentences}\label{sec-indep-sentences}

In an ordinary situation represented by background information
{\(\mathsfit{I}\),} if you have to infer whether a coin will land heads,
then knowing that it is raining outside has no impact on your inference.
The information about rain is {\textbf{irrelevant}} for your inference.
In other words, your degree of belief about the coin remains the same if
you include the information about rain in the conditional.

In probability notation, representing ``{The coin lands heads}'' with
{\(\mathsfit{H}\),} and ``{It rains outside}'' with {\(\mathsfit{R}\),}
this irrelevance is expressed by this equality:

\[
\mathrm{P}(\mathsfit{H} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) = \mathrm{P}(\mathsfit{H} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{R} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]

\hfill\break

More generally two sentences {\(\mathsfit{A}\),} {\(\mathsfit{B}\)} are
said to be {\textbf{mutually irrelevant} or \textbf{informationally
independent given knowledge \(\mathsfit{I}\)}} if any one of these three
conditions holds:

\marginnote{\begin{footnotesize}

\href{https://dictionary.cambridge.org/dictionary/english/independent}{``independ\textbf{E}nt''
is written with an \textbf{E}}, not with an \textbf{A}.

\end{footnotesize}}

\begin{itemize}
\item
  \(\mathrm{P}(\mathsfit{A}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{B}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) = \mathrm{P}(\mathsfit{A}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)
\item
  \(\mathrm{P}(\mathsfit{B}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{A}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) = \mathrm{P}(\mathsfit{B}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)
\item
  \(\mathrm{P}(\mathsfit{A}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{B}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) = \mathrm{P}(\mathsfit{A}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) \cdot \mathrm{P}(\mathsfit{B}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)
\end{itemize}

These three conditions turn out to be \emph{equivalent} to one another.
In the first condition,
{\(\mathrm{P}(\mathsfit{A}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{B}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\)}
is undefined if
{\(\mathrm{P}(\mathsfit{B}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})=0\),}
but in this case independence still holds; analogously in the second
condition.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Irrelevance is not absolute and is not a
physical notion}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Irrelevance or independence is not an absolute notion, but
  \textbf{relative to some background knowledge}. Two sentences may be
  independent given some background information, and \textbf{not}
  independent given another.
\item
  Independence as defined above is an \textbf{informational} or
  \textbf{logical}, not physical, notion. It isn't stating anything
  about physical dependence between phenomena related to the sentences
  {\(\mathsfit{A}\)} and {\(\mathsfit{B}\).} It's simply stating that
  information about one does not affect an agent's beliefs about the
  other.
\end{itemize}

\end{tcolorbox}

\section{Independence of quantities}\label{sec-indep-quantities}

The notion of irrelevance of two sentences can be generalized to
quantities. Take two quantities {\(X\)} and {\(Y\).} They are said to be
{\textbf{mutually irrelevant} or \textbf{informationally independent
given knowledge \(\mathsfit{I}\)}} if any one of these three equivalent
conditions holds {\emph{for all possible values \(x\) of \(X\) and \(y\)
of \(Y\)}}:

\begin{itemize}
\item
  \(\mathrm{P}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) = \mathrm{P}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)~~~{all
  \(x,y\)}
\item
  \(\mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) = \mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)~~~{all
  \(x,y\)}
\item
  \(\mathrm{P}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) = \mathrm{P}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) \cdot \mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)~~~{all
  \(x,y\)}
\end{itemize}

\hfill\break
Note the difference between independence of \emph{two sentences} and
independence of \emph{two quantities}. The latter independence involves
not just two, but many sentences: as many as the combinations of values
of {\(X\)} and {\(Y\).}

In fact it may happen that for some particular values {\(x^*\)} of
{\(X\)} and {\(y^*\)} {\(Y\)} the probabilities become independent:

\[
\mathrm{P}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x^* \nonscript\:\vert\nonscript\:\mathopen{} Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y^* \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) = \mathrm{P}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x^* \nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})
\]

while at the same time this equality does \emph{not} occur for other
values. In this case the quantities {\(X\)} and {\(Y\)} are \emph{not}
independent given information {\(\mathsfit{I}\).} The general idea is
that two quantities are independent if knowledge about one of them
cannot change an agent's beliefs about the other, \emph{no matter what
their values might be}.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Irrelevance is not absolute and not
physical}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Also in this case, irrelevance or independence is not an absolute
  notion, but \textbf{relative to some background knowledge}. Two
  quantities may be independent given some background information, and
  \textbf{not} independent given another.
\item
  Also in this case, independence is an \textbf{informational} or
  \textbf{logical}, not physical, notion. It isn't stating anything
  about physical dependence between phenomena related to the quantities
  {\(X\)} and {\(Y\).} It's simply stating that information about one
  quantity does not affect an agent's beliefs about the other quantity.
\end{itemize}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Consider our familiar next-patient inference problem with quantities
urgency {\(U\)} and transportation {\(T\).} Assume a different
background information {\(\mathsfit{J}\)} that leads to the following
joint probability distribution:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3056}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mathrm{P}(U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u \mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}t\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{J})\)
& &
\multicolumn{3}{>{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.5000} + 4\tabcolsep}@{}}{%
\textbf{transportation at arrival} \(T\)} \\
& & ambulance & helicopter & other \\
\multirow{2}{=}{\textbf{urgency} \(U\)} & urgent & 0.15 & 0.08 & 0.02 \\
& non-urgent & 0.45 & 0.04 & 0.26 \\
\end{longtable}

\begin{itemize}
\item
  Calculate the marginal probability distribution
  {\(\mathrm{P}(U\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{J})\)}
  and the conditional probability distribution
  {\(\mathrm{P}(U \nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{J})\),}
  and compare them. Is the value
  {\(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\)}
  relevant for inferences about {\(U\)?}
\item
  Calculate the conditional probability distribution
  {\(\mathrm{P}(U \nonscript\:\vert\nonscript\:\mathopen{} T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{J})\),}
  and compare it with the marginal
  {\(\mathrm{P}(U\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{J})\).}
  Is the value
  {\(T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;helicopter;}\)}
  relevant for inferences about {\(U\)?}
\item
  Are the quantities {\(U\)} and {\(T\)} independent, given the
  background knowledge {\(\mathsfit{J}\)?}
\end{itemize}

\end{tcolorbox}

\section{Information and uncertainty}\label{sec-info-uncertainty}

The definition of irrelevance given above appears to be very ``black or
white'': either two sentences or quantities are independent, or they
aren't. But in reality there is no such dichotomy. We can envisage some
scenario {\(\mathsfit{I}\)} where for instance the probabilities
{\(\mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\)}
and
{\(\mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)}
are extremely close in value, although not exactly equal:

\[
\mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
= \mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) + \delta(x,y)
\]

with {\(\delta(x,y)\)} very small. This would mean that knowledge about
{\(X\)} modifies an agent's belief just a little. And depending on the
situation such modification could be unimportant. In this situation the
two quantities would be ``independent'' for all practical purposes.
Therefore there really are \emph{degrees of relevance}, rather than a
dichotomy ``relevant vs irrelevant''.

This suggests that we try to quantify such degrees. This quantification
would also give a measure of how ``important'' a quantity can be for
inferences about another quantity.

This is the domain of {\textbf{Information Theory}}, which would require
a course by itself to be properly explored. In this chapter we shall
just get an overview of the main ideas and notions of this theory.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Information
  Theory, Inference, and Learning Algorithms}}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Elements
  of Information Theory}}
\end{itemize}

\end{tcolorbox}

\end{footnotesize}}

\hfill\break
The notion of ``degree of relevance'' is important in data science and
machine learning, because it rigorously quantifies two related,
intuitive ideas often occurring in these fields:

\begin{itemize}
\item
  {``Correlation'' or ``association'': in its general meaning, it's the
  idea that if an agent's beliefs about some quantity change, then
  beliefs about another quantity may change as well.}
\item
  {``Feature importance'': it's the idea that knowledge about some
  aspects of a given problem may lead to improved inferences about other
  aspects.}
\end{itemize}

In the next section we explore, through examples, some tricky aspects
and peculiarities of these ideas. These examples also tell us which kind
of properties a quantitative measure for ``relevance'' or ``importance''
or ``informativeness'' should possess.

\section{Exploring ``importance'': some
scenarios}\label{sec-importance-scenarios}

The following examples are only meant to give an intuitive motivation of
the notions presented later.

\subsection{First two required properties: a lottery
scenario}\label{first-two-required-properties-a-lottery-scenario}

A lottery comprises 1\,000\,000 tickets numbered from \texttt{000000} to
\texttt{999999}. One of these tickets is the winner. Its number is
already known, but unknown to you. You are allowed to choose any ticket
you like (you can see the ticket numbers), before the winning number is
announced.

Before you choose, you have the possibility of getting for free some
clues about the winning number. The clues are these:

\begin{description}
\tightlist
\item[Clue {A}:~~{\faIcon{check}} {\faIcon{check}} {\faIcon{check}}
{\faIcon{check}} {\faIcon{question}} {\faIcon{question}}]
The first four digits of the winning number.
\item[Clue {B}:~~{\faIcon{check}} {\faIcon{check}} {\faIcon{check}}
{\faIcon{question}} {\faIcon{check}} {\faIcon{question}}]
The 1st, 2nd, 3rd, and 5th digits of the winning number.
\item[Clue {C}:~~{\faIcon{question}} {\faIcon{question}}
{\faIcon{question}} {\faIcon{check}} {\faIcon{check}} {\faIcon{check}}]
The last three digits of the winning number.
\end{description}

Now consider the following three ``clue scenarios''.

\subsubsection{Scenario 1: choose one
clue}\label{scenario-1-choose-one-clue}

You have the possibility of \emph{choosing one} of the three clues
above. Which would you choose, in order of importance?

Obviously {\textbf{A}} or {\textbf{B}} are the most important, and
equally important, because they increase your probability of winning
from 1/1\,000\,000 to 1/100. {\textbf{C}} is the least important because
it increases your probability of winning to 1/1000.

\subsubsection{Scenario 2: discard one
clue}\label{scenario-2-discard-one-clue}

All three clues are put in front of you (but you can't see their
digits). If you could keep all three, then you'd win for sure because
they would give you all digits of the winning number.

You are instead asked to \emph{discard one} of the three clues, keeping
the remaining too. Which would you discard, in order of least
importance?

If you discarded {\textbf{A}}, then {\textbf{B}} and {\textbf{C}}
together would give you all digits of the winning number; so you would
still win for sure. Analogously if you discarded {\textbf{B}}. If you
discarded {\textbf{C}}, then {\textbf{A}} and {\textbf{B}} together
would not give you the last digit; so you'd have a 1/10 probability of
winning.

Obviously {\textbf{C}} is the most important clue to keep, and
{\textbf{A}} and {\textbf{B}} are the least important.

\subsubsection{Scenario 3: discard one more
clue}\label{scenario-3-discard-one-more-clue}

In the previous Scenario~2, we saw that discarding {\textbf{A}} or
{\textbf{B}} would not alter your 100\% probability of winning. Either
clue could therefore be said to have ``importance\,=\,0''.

If you had to discard \emph{both} {\textbf{A}} and {\textbf{B}},
however, your situation would suddenly become worse, with only a 1/1000
probability of winning. Clues {\textbf{A}} and {\textbf{B}}
\emph{together} can therefore be said to have high
``importance\,\textgreater\,0''.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Let's draw some conclusions by comparing the scenarios above.

\hfill\break
In Scenario~1 we found that the ``importance ranking'' of the clues is\\
{\textbf{A}} = {\textbf{B}} \textgreater{} {\textbf{C}}\\
whereas in Scenario~2 we found the completely opposite ranking\\
{\textbf{C}} \textgreater{} {\textbf{A}} = {\textbf{B}}

We conclude:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={Importance is context-dependent}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

It doesn't make sense to ask which aspect or feature is ``most
important'' if we don't specify the context of its use. Important if
\emph{used alone}? Important if \emph{used with others}? and
\emph{which} others?

Depending on the context, an importance ranking could be completely
reversed. {\textbf{A quantitative measure of ``importance'' must
therefore take the context into account}}.

\end{tcolorbox}

\hfill\break
In Scenario~3 we found that two clues may be completely unimportant if
considered individually, but extremely important if considered jointly.

We conclude:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={Importance is non-additive}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

{\textbf{A quantitative measure of importance cannot be
\emph{additive}}}, that is, it cannot quantify the importance of two or
more features as the sum of their individual importance.

\end{tcolorbox}

\subsection{Third required property: A two-quantity
scenario}\label{third-required-property-a-two-quantity-scenario}

Suppose we have a discrete quantity {\(X\)} with domain
{\(\set{1,2,3,4,5,6}\)} and another discrete quantity {\(Y\)} with
domain {\(\set{1,2,3,4}\).} We want to infer the value of {\(Y\)} after
we are told the value of {\(X\).}

The conditional probabilities for {\(Y\)} given different values of
{\(X\)} are as follows (each column sums up to {\(1\))}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1146}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.0446}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1338}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1338}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1338}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1338}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1338}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1338}}@{}}
\caption{Example conditional distribution for two discrete
quantities}\label{tbl-distr-entropy}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mathrm{P}(Y\nonscript\:\vert\nonscript\:\mathopen{}X\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\)
& &
\multicolumn{6}{>{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.8025} + 10\tabcolsep}@{}}{%
\emph{~} \({}\nonscript\:\vert\nonscript\:\mathopen{}X\)} \\
& & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} &
\textbf{6} \\
\multirow{4}{=}{\emph{~}
\(Y\nonscript\:\vert\nonscript\:\mathopen{}{}\)} & \textbf{1} & 1.00 &
0.00 & 0.00 & 0.00 & 0.00 & 0.50 \\
& \textbf{2} & 0.00 & 1.00 & 0.00 & 0.00 & 0.50 & 0.00 \\
& \textbf{3} & 0.00 & 0.00 & 1.00 & 0.50 & 0.00 & 0.00 \\
& \textbf{4} & 0.00 & 0.00 & 0.00 & 0.50 & 0.50 & 0.50 \\
\end{longtable}

Let's see what kind of inferences could occur.

If we learn that
{\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1\),}
then we know \emph{for sure} that
{\(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1\).}
Similarly if we learn that
{\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}2\)}
or that
{\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}3\).}
These three values of {\(X\)} are therefore ``most informative'' for
inference about {\(Y\).} If we instead learn that
{\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}4\),}
then our uncertainty about {\(Y\)} is split between two of its values.
Similarly if we learn that
{\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}5\)}
or that
{\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}6\).}
These three values of {\(X\)} are therefore ``least informative'' for
inference about {\(Y\).}

But what if we want to quantify the importance of a \emph{quantity} or
feature like {\(X\),} and not just one specific value? What is the
``overall importance'' of {\(X\)?}

\hfill\break
Consider again three scenarios.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  In the first, we have 33\% probability each of learning one of the
  values {\(1\),} {\(2\),} {\(3\)} of {\(X\),} for a total of 99\%. And
  0.33\% probability of learning any one of the remaining values, for a
  total of 1\%. (Grand total 100\%.)

  In this scenario we expect to make an almost exact inference about
  {\(Y\)} after learning {\(X\).} The quantity {\(X\)} has therefore
  large ``overall importance''.
\item
  In the second scenario the reverse occurs. We have 0.33\% probability
  each of learning one of the values {\(1\),} {\(2\),} {\(3\)} of
  {\(X\),} for a total of 1\%. And 33\% probability of learning any one
  of the remaining values, for a total of 99\%.

  In this scenario we expect to be roughly equally uncertain between two
  values of {\(Y\)} after we learn {\(X\).} The quantity {\(X\)} has
  therefore lower ``overall importance''.
\item
  In the third scenario, we have around 16.7\% probability each of
  observing any one of the values of {\(X\).}

  This scenario is in between the first two. We expect to make an exact
  inference about {\(Y\)} half of the time, and to be equally undecided
  between two values of {\(Y\)} half of the time. The quantity {\(X\)}
  has therefore some ``overall importance'': not as low as in the second
  scenario, not as high as in the first scenario.
\end{enumerate}

What determines the ``overall importance'' of the quantity or feature
{\(X\)} is therefore \emph{its probability distribution}.

We conclude:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={The importance of a quantity depends on its probability distribution}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

The importance of a quantity is not only determined by the relation
between its possible values and what we need to infer, but also by the
probability with which its values can occur.

{\textbf{A quantitative measure of ``importance'' of a quantity must
therefore take the probability distribution for that quantity into
account}}.

\end{tcolorbox}

\section{Entropies and mutual information}\label{sec-entropy-mutualinfo}

The thought-experiments above suggest that a quantitative measure of the
importance of a quantity must have at least these three properties:

\begin{itemize}
\item
  \textbf{Context-dependence}: take the context somehow into account.
\item
  \textbf{Non-additivity}: do not calculate the importance of two
  quantities as the sum of their importance.
\item
  \textbf{Probability-awareness}: take the probability distribution for
  the quantity into account.
\end{itemize}

Do measures with such properties exist? They do. Indeed they are
regularly used in Communication Theory and Information Theory, owing to
the properties above. They even have
\href{https://www.iso.org/obp/ui/en/\#!iso:std:63598:en}{international
standards} on their definitions and measurement units.

Before presenting them, let's briefly present the mother of them all:

\subsection{Shannon entropy}\label{shannon-entropy}

Consider an agent with background knowledge {\(\mathsfit{I}\)} and a
belief distribution
{\(\mathrm{P}(Y\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})\)}
about the finite quantity {\(Y\).} The agent's uncertainty about the
value of {\(Y\)} can be quantified by the {\textbf{Shannon entropy}}:

\[
\mathrm{H}(Y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) \coloneqq-\sum_y \mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\, \log_2 \mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\;\mathrm{Sh}
\]

whose unit is the \emph{shannon} (symbol {\(\mathrm{Sh}\))} when the
logarithm is in base~2, as above.\footnote{With the logarithm is in
  base~10, the unit is the \emph{hartley} ({\(\mathrm{Hart}\));} with
  the natural logarithm, the unit is the \emph{natural unit of
  information} ({\(\mathrm{nat}\)).}
  {\(1\,\mathrm{Sh} \approx 0.301\,\mathrm{Hart} \approx 0.693\,\mathrm{nat}\).}}

Shannon entropy lies at the foundation of the whole fields of
Information Theory and Communication Theory, and would require a lengthy
discussion. Let's just mention some of its properties and meanings:

\begin{itemize}
\item
  It also quantifies the information that would be \emph{gained} by the
  agent, if it learned the value of {\(Y\).}
\item
  It is always positive or zero.
\item
  It is zero if, and only if, the agent knows the value of {\(Y\),} that
  is, if the probability distribution for {\(Y\)} gives 100\% to one
  value and 0\% to all others.
\item
  Its maximum possible value is {\(\log_2 N\;\mathrm{Sh}\),} where
  {\(N\)} is the number of possible values of {\(Y\).} This maximum is
  attained by the uniform belief distribution about {\(Y\).}
\item
  The value in shannons of the Shannon entropy can be interpreted as the
  number of binary digits that we lack for correctly identifying the
  value of {\(Y\),} if the possible values were listed as integers in
  binary format. Alternatively, a Shannon entropy equal
  to~~{\(h\,\mathrm{Sh}\)~~is} equivalent to being equally uncertain
  among {\(2^h\)} possible alternatives.
\end{itemize}

A Shannon entropy of 1\,Sh quantifies the uncertainty of an agent that
gives 50\%/50\% probability to two possibilities. An entropy of 3\,Sh
quantifies an equal 12.5\% uncertainty among eight possibilities.

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{shannon.png}
Plot of the Shannon entropy for a binary quantity {\(Y\in\set{1,2}\),}
for different distributions
{\(\mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)}

\end{footnotesize}}

As a curiosity, an entropy of 0.5\,Sh quantifies the uncertainty of an
agent giving 89\% probability to one possibility and 11\% to another. So
we can say that an 89\%/11\% belief distribution is half as uncertain as
a 50\%/50\% one.

\hfill\break
Here are two useful measures of ``informativeness'' or ``relevance'' or
``importance'' of a quantity about another quantity. Both are based on
the Shannon entropy:

\subsection{Conditional entropy}\label{conditional-entropy}

The {\textbf{conditional entropy}}\footnote{or ``equivocation''
  according to ISO standard.} of a quantity {\(Y\)} conditional on a
quantity {\(X\)} and additional knowledge {\(\mathsfit{I}\),} is defined
as

\begin{figure*}

\[
\mathrm{H}(Y \nonscript\:\vert\nonscript\:\mathopen{} X\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) \coloneqq
-\sum_x \sum_y 
\mathrm{P}( X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\cdot
\mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\, 
\log_2 \mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\;\mathrm{Sh}
\]

\end{figure*}%

It satisfies the three requirements above:

\begin{description}
\tightlist
\item[Context-dependence]
Different background knowledge \(\mathsfit{I}\), corresponding to
different contexts, leads to different probabilities and therefore to
different values of the conditional entropy.
\item[Non-additivity]
If the quantity \(X\) can be split into two component quantities, then
the conditional entropy conditional on them jointly is more than the sum
of the conditional entropies conditional on them individually.
\item[Probability-awareness]
The probability distribution for \(X\) appears explicitly in the
definition of the conditional entropy.
\end{description}

The conditional entropy has additional, remarkable properties:

\begin{itemize}
\item
  If knowledge of {\(Y\)} is completely determined by that of {\(X\),}
  that is, if {\(Y\)} is a function of {\(X\),} then the conditional
  entropy
  {\(\mathrm{H}(Y \nonscript\:\vert\nonscript\:\mathopen{} X\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\)}
  is zero. Vice versa, if the conditional entropy is zero, then {\(Y\)}
  is a function of {\(X\).}
\item
  If knowledge of {\(X\)} is irrelevant, in the sense of
  §~\ref{sec-indep-quantities}, to knowledge of {\(Y\),} then the
  conditional entropy
  {\(\mathrm{H}(Y \nonscript\:\vert\nonscript\:\mathopen{} X\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\)}
  takes on its maximal value, determined by the marginal probability for
  {\(Y\).} Vice versa, if the conditional entropy takes on its maximal
  value, then {\(X\)} is irrelevant to {\(Y\).}
\item
  The value in shannons of the conditional entropy has the same meaning
  as for the Shannon entropy: if the conditional entropy amounts to
  {\(h\,\mathrm{Sh}\),} then after learning {\(X\)} an agent's
  uncertainty about {\(Y\)} is the same as if the agent were equally
  uncertain among {\(2^h\)} possible alternatives.
\end{itemize}

For instance, in the case of an agent with belief distribution of
table\,~\ref{tbl-distr-entropy}, the conditional entropy has the
following values in the three scenarios:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\mathrm{H}(Y \nonscript\:\vert\nonscript\:\mathopen{} X\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_1) = 0.01\,\mathrm{Sh}\)\,,
  almost zero. Indeed {\(Y\)} can almost be considered a function of
  {\(X\)} in this case.
\item
  \(\mathrm{H}(Y \nonscript\:\vert\nonscript\:\mathopen{} X\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_2) = 0.99\,\mathrm{Sh}\)\,,
  almost 1. Indeed in this case the agent is approximately uncertain
  between two values of {\(Y\).}
\item
  \(\mathrm{H}(Y \nonscript\:\vert\nonscript\:\mathopen{} X\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_3) = 0.5\,\mathrm{Sh}\)\,.
  Indeed this case is intermediate between the previous two.
\end{enumerate}

\subsection{Mutual information}\label{mutual-information}

Suppose that, according to background knowledge {\(\mathsfit{I}\),} for
\emph{any} value of {\(X\)} there's a 100\% probability that {\(Y\)} has
one and the same value, say
{\(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1\).}
The conditional entropy
{\(\mathrm{H}(Y \nonscript\:\vert\nonscript\:\mathopen{} X\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\)}
is then zero. In this case it is true that {\(Y\)} is formally a
function of {\(X\).} But it is also true that we could perfectly predict
{\(Y\)} without any knowledge of {\(X\).} Learning the value of {\(X\)}
doesn't really help an agent in forecasting {\(Y\).} In other words,
{\(X\)} is not relevant for inference about {\(Y\).}\footnote{There's no
  contradiction with the second remarkable property previously
  discussed: in this case the maximal value that the conditional entropy
  can take is zero.}

If we are interested in quantifying how much learning {\(X\)} ``helped''
in inferring {\(Y\),} we can subtract the conditional entropy for
{\(Y\)} conditional on {\(X\)} from the maximum value it would have if
{\(X\)} were not learned.

This is the definition of {\textbf{mutual information}}\footnote{or
  ``mean transinformation content'' according to ISO standard.} between
a quantity {\(Y\)} and a quantity {\(X\),} given background knowledge
{\(\mathsfit{I}\).} It is defined as

\begin{figure*}

\[
\mathrm{H}(Y : X\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) \coloneqq
\sum_x \sum_y 
\mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \mathbin{\mkern-0.5mu,\mkern-0.5mu}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\,
\log_2 \frac{\mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \mathbin{\mkern-0.5mu,\mkern-0.5mu}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})}{
\mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\cdot
\mathrm{P}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
} \;\mathrm{Sh}
\]

\end{figure*}%

It also satisfies the three requirements -- \emph{context-dependece},
\emph{non-additivity}, \emph{probability-awareness} -- for a measure of
``informativeness'' or ``importance''. Its properties are somehow
complementary to those of the conditional entropy:

\begin{itemize}
\item
  \textbf{If \(Y\) and \(X\) are informationally independent}, in the
  sense of §~\ref{sec-indep-quantities}, \textbf{then their mutual
  information is zero}. Vice versa, if their mutual information is zero,
  then these quantities are informationally independent.
\item
  If knowledge of {\(Y\)} is completely determined by that of {\(X\),}
  that is, if {\(Y\)} is a function of {\(X\),} then their mutual
  information attains its maximal value (which could be zero). Vice
  versa, if their mutual information attains its maximal value, then
  {\(Y\)} is a function of {\(X\).}
\item
  If the mutual information between {\(Y\)} and {\(X\)} amounts to
  {\(h\,\mathrm{Sh}\),} then learning {\(X\)} \emph{reduces, on average,
  \(2^h\)-fold times} the possibilities regarding the value of {\(Y\).}
\item
  Mutual information is symmetric in the roles of {\(X\)} and {\(Y\),}
  that is,
  {\(\mathrm{H}(Y : X\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) = \mathrm{H}(X : Y\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\).}
\end{itemize}

In the case of an agent with belief distribution as in
table\,~\ref{tbl-distr-entropy}, the mutual information has the
following values in the three scenarios:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\mathrm{H}(Y : X\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_1) = 1.61\,\mathrm{Sh}\)\,,
  almost equal to the maximal value achievable in this scenario
  ({\(1.62\,\mathrm{Sh}\)).} Indeed {\(Y\)} can almost be considered a
  function of {\(X\)} in this case. Since {\(2^{1.61}\approx 2.1\),}
  learning {\(X\)} roughly halves the number of possible values of
  {\(Y\).}
\item
  \(\mathrm{H}(Y : X\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_2) = 0.81\,\mathrm{Sh}\)\,;
  this means that learning {\(X\)} reduces by {\(2^{0.81}\approx 1.8\)}
  or almost 2~times the number of possible values of {\(Y\).}
\item
  \(\mathrm{H}(Y : X\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_3) = 1.5\,\mathrm{Sh}\)\,;
  learning {\(X\)} reduces by {\(2^{1.5} \approx 2.8\)} or almost 3
  times the number of possible values of {\(Y\).}
\end{enumerate}

\subsection{Uses}\label{uses}

Let's emphasize that Shannon entropy, conditional entropy, and mutual
information are not just fancy theoretical ways of quantifying
uncertainty and informativeness. Their numerical values have concrete
technological importance; for instance they determine the maximal
communication speed of a communication channel. See references on the
margin for concrete applications.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Information
  Theory, Inference, and Learning Algorithms}}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Probability
  and Information Theory, with Applications to Radar}}
\end{itemize}

\end{tcolorbox}

\end{footnotesize}}

\hfill\break
Whether to use the conditional entropy
{\(\mathrm{H}(Y \nonscript\:\vert\nonscript\:\mathopen{} X\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\)}
or the mutual information
{\(\mathrm{H}(Y : X\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)}
depends on the question we are asking.

Conditional entropy is the right choice if we want to quantify to what
degree {\(Y\)} can be considered a function of {\(X\)} -- including the
special case of a constant function. It is also the right choice if we
want to know how many binary-search iterations it would take to find
{\(Y\),} on average, once {\(X\)} is learned.

Mutual information is the right choice if we want to quantify how much
learning {\(X\)} helps, on average, for inferring {\(Y\).} Or
equivalently how many \emph{additional} binary-search iterations it
would take to find {\(Y\),} if {\(X\)} were not known. Mutual
information is therefore useful for quantifying ``correlation'' or
``association'' of two quantities.

If we simply want to rank the relative importance of alternative
quantities {\(X_1\),} {\(X_2\),} etc. in inferring {\(Y\),} then
conditional entropy and mutual information are equivalent in the sense
that they yield the same ranking, since they basically differ by a zero
point that would be constant in this scenario.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Mutual information is superior to the
correlation coefficient}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

The
\href{https://mathworld.wolfram.com/CorrelationCoefficient.html}{Pearson
correlation coefficient} is actually a very poor measure of correlation
or association. It is more a measure of ``linearity'' than correlation.
It can be very dangerous to rely on in data-science problems, where we
can expect non-linearity and peculiar associations in large-dimensional
data. The Pearson correlation coefficient is widely used not because
it's good, but because of (1) computational easiness, (2) intellectual
inertia.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Chapter~8 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Information
  Theory, Inference, and Learning Algorithms}}
\item
  §12.4 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}
\end{itemize}

\end{tcolorbox}

\section{Utility Theory to quantify relevance and
importance}\label{sec-utility-importance}

The entropy-based measures discussed in the previous section originate
from, and have deep connections with, the problem of repeated
communication or signal transmission. They do not require anything else
beside joint probabilities.

In a general decision problem -- where an agent has probabilities
\emph{and utilities} -- another approach may be required, however.

Consider questions like {``What happens if I discard quantity \(X\) in
this inference?''} or ``If I have to choose between learning either
quantity {\(U\)} or quantity {\(V\),} which one should I
{choose?{}``.}~~Such questions are \emph{decision-making problems}. They
must therefore be solved using Decision Theory (this is an example of
the recursive capabilities of Decision Theory, discussed in
§~\ref{sec-decision-theory}). The application of decision theory in
these situations if often intuitively understandable. For example, if we
need to rank the importance of quantities {\(U\)} and {\(V\),} we can
calculate how much the expected utility would decrease if we discarded
the one or the other.

We'll come back to these questions in chapters
\ref{sec-ML-utility-limitation} and \ref{sec-eval-decision}.

\chapter{\texorpdfstring{{Third connection with machine
learning}}{Third connection with machine learning}}\label{sec-3-connection-ML}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\ys}{\se{s}}
\providecommand*{\yh}{\se{h}}
\providecommand*{\yf}{\se{f}}
\providecommand*{\yv}{\se{v}}
\providecommand*{\yJ}{\se{J}}
\providecommand*{\yZ}{\se{Z}}
\providecommand*{\yH}{\se{H}}

In chapter~~\ref{sec-2-connection-ML} we made a second \emph{tentative}
connection between the notions about probability explored until then,
and notions from machine learning. We considered the possibility that a
machine-learning algorithm is like an agent that has some {built-in
background information (corresponding to the algorithm's architecture)},
has received {pieces of information (corresponding to the data about
perfectly known instances of the task, and possibly partial data about a
new instance)}, and is assessing a {not-previously known piece of
information (other partial aspects of a new task instance)}:

\[
\mathrm{P}(\underbracket[0ex]{\color[RGB]{238,102,119}\mathsfit{D}_{N+1}}_{\mathclap{\color[RGB]{238,102,119}\text{outcome?}}} \nonscript\:\vert\nonscript\:\mathopen{} 
\color[RGB]{34,136,51}\underbracket[0ex]{\mathsfit{D}_N \land \dotsb \land \mathsfit{D}_2 \land \mathsfit{D}_1}_{\mathclap{\color[RGB]{34,136,51}\text{training data?}}} 
\color[RGB]{0,0,0}\land \underbracket[0ex]{\color[RGB]{204,187,68}\mathsfit{I}}_{\mathrlap{\color[RGB]{204,187,68}\uparrow\ \text{architecture?}}})
\]

The correspondence about {training data} and {architecture} seems
somewhat convincing, the one about {outcome} needs more exploration.

Having introduced the notion of quantity in the latest chapters
\ref{sec-quantities-types-basic} and \ref{sec-quantities-types-multi},
we recognize that ``training data'' are just quantities, the values of
which the agent has learned. So a datum {\(\mathsfit{D}_i\)} can be
expressed by a sentence like
{\(Z_i\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_i\),}
where

\begin{itemize}
\tightlist
\item
  \(i\) is the instance: \(1,2,\dotsc,N, N+1\).
\item
  \(Z_i\), a quantity, describes the type of data at instance \(i\), for
  example ``128\,×\,128 image with 24-bit colour depth, with a character
  label''.
\item
  \(z_i\) is the value of the quantity \(Z_i\) at instance \(i\), for
  example the specific image \&~label displayed here:
\end{itemize}

\marginnote{\begin{footnotesize}

\begin{figure}[H]

{\centering \includegraphics[width=1.33333in,height=\textheight,keepaspectratio]{saitama_smile.png}

}

\caption{label\,=\,``Saitama''}

\end{figure}%

\end{footnotesize}}

We can therefore rewrite the correspondence above as follows:

\[
\mathrm{P}(\underbracket[0ex]{\color[RGB]{238,102,119}Z_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N+1}}_{\mathclap{\color[RGB]{238,102,119}\text{outcome?}}} \nonscript\:\vert\nonscript\:\mathopen{} 
\color[RGB]{34,136,51}\underbracket[0ex]{ Z_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}Z_2 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_2 \mathbin{\mkern-0.5mu,\mkern-0.5mu}Z_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1}_{\mathclap{\color[RGB]{34,136,51}\text{training data?}}} 
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\underbracket[0ex]{\color[RGB]{204,187,68}\mathsfit{I}}_{\mathrlap{\color[RGB]{204,187,68}\uparrow\ \text{architecture?}}})
\]

This is the kind of inference that we explored in the
``next-three-patients'' scenario of §~\ref{sec-conditional-joint-sim}
and in some of the subsequent sections. In chapter~~\ref{sec-beyond-ML},
after a review of conventional machine-learning methods and terminology,
we shall discuss with more care what these inferences are about, what
kind of information they use, and how they can be concretely calculated.

\hfill\break
In the last sections we have often been speaking about ``instances'',
``instances of similar quantities'', ``task instances'', and similar
expression. What do with mean with ``instance'', more exactly? It is
time that we make this and related notions more precise: the whole idea
of ``learning from examples'' hinges on them. In the next few chapters
we shall therefore make these ideas more rigorous and quantifiable.
\emph{Statistics} is the theory that deals with these ideas. As a bonus
we shall find out that a rigorous analysis of the notion of
``instances'' also leads to concrete formulae for calculating the kind
of probabilities discussed in the present chapter.

\part{{\textbf{Data II}}}

\chapter{\texorpdfstring{{Populations and
variates}}{Populations and variates}}\label{sec-variates}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\yy}{{\green\cat{Y}}}
\providecommand*{\yn}{{\red\cat{N}}}
\providecommand{\vRI}{\mathit{RI}}
\providecommand{\vNa}{\mathit{Na}}
\providecommand{\vMg}{\mathit{Mg}}
\providecommand{\vAl}{\mathit{Al}}
\providecommand{\vSi}{\mathit{Si}}
\providecommand{\vK}{\mathit{K}}
\providecommand{\vCa}{\mathit{Ca}}
\providecommand{\vBa}{\mathit{Ba}}
\providecommand{\vFe}{\mathit{Fe}}
\providecommand{\vType}{\mathit{Type}}
\providecommand{\ypl}{{\green\cat{+}}}
\providecommand{\ymi}{{\red\cat{-}}}
\providecommand{\ywo}{{\green\cat{work}}}
\providecommand{\yfa}{{\red\cat{fail}}}

\providecommand{\hi}{{\green\cat{high}}}
\providecommand{\me}{{\yellow\cat{medium}}}
\providecommand{\lo}{{\red\cat{low}}}
\providecommand*{\yJ}{\se{J}}
\providecommand{\yva}{{\lblue-1}}
\providecommand{\yvb}{{\midgrey0}}
\providecommand{\yvc}{{\yellow1}}
\providecommand*{\yK}{\se{K}}

\section{Collections of similar quantities:
motivation}\label{sec-collections}

In the latest chapters we gradually narrowed our focus on a particular
kind of inferences: inferences that involve collections of
\emph{similar} quantities, each of which can be simple, joint, or
complex. ``Similar'' means that all these quantities have a similar
meaning and measurement procedure, and therefore have the same domain.
For instance, each quantity might have possible values
{\(\set{{\small\verb;urgent;}, {\small\verb;non-urgent;}}\);} or
possible values between {\(0\,\mathrm{\textcelsius}\)} and
{\(100\,\mathrm{\textcelsius}\).} These quantities can be considered
different ``instances'' of the same quantity, so to speak. We saw an
example in the three-patient hospital scenario of
§~\ref{sec-conditional-joint-sim}, with the three ``urgency'' quantities
{\(U_1\),} {\(U_2\),} {\(U_3\),} corresponding to the urgency of three
consecutive patients. Here are other examples:

\begin{itemize}
\item
  \begin{description}
  \tightlist
  \item[\href{https://www.britannica.com/money/topic/stock-exchange-finance}{Stock
  exchange}]
  We are interested in the daily change in
  \href{https://www.investor.gov/introduction-investing/investing-basics/glossary/closing-price}{closing
  price} of a stock, during 1000 days. Each day the change can be
  {positive (or zero)}, or {negative}.
  \end{description}

  The daily change on any day can be considered as a binary quantity,
  say with domain
  \(\set{{\color[RGB]{34,136,51}{\small\verb;+;}}, {\color[RGB]{204,187,68}{\small\verb;-;}}}\).
  The daily changes in 1000 days are a set of 1000 binary quantities
  with exactly the same domain; but note that each one can have a
  different value.
\end{itemize}

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{stock_course.jpg}

\end{footnotesize}}

\hfill\break

\begin{itemize}
\item
  \begin{description}
  \tightlist
  \item[Mars
  \href{https://www.britannica.com/technology/prospecting-mining}{prospecting}]
  Some robot examines 1000 similar-sized rocks in a large crater on
  Mars. Each rock either {contains
  \href{https://www.jpl.nasa.gov/news/nasas-perseverance-rover-scientists-find-intriguing-mars-rock}{haematite}},
  or it {doesn't}.
  \end{description}

  The haematite-content of any rock can be considered as a binary
  quantity, say with domain
  \(\set{{\color[RGB]{34,136,51}{\small\verb;Y;}}, {\color[RGB]{238,102,119}{\small\verb;N;}}}\).
  The haematite contents of the 1000 rocks are a set of 1000 binary
  quantities with exactly the same domain; note again that each one can
  have a different value.
\end{itemize}

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{mars_crater2.jpg}

\end{footnotesize}}

\hfill\break

\begin{itemize}
\item
  \begin{description}
  \tightlist
  \item[\href{https://www.fbi.gov/about-us/lab/forensic-science-communications/fsc/april2009/review/2009_04_review01.htm}{Glass
  forensics}]
  A criminal forensics department has 215 glass fragments collected from
  many different crime scenes. Each fragment is characterized by a
  \href{https://www.feynmanlectures.caltech.edu/I_26.html\#Ch26-S2}{refractive
  index} (between \(1\) and \(\infty\)), a percentage of
  \href{https://pubchem.ncbi.nlm.nih.gov/element/Calcium}{Calcium}
  (between \(0\%\) and \(100\%\)), a percentage of
  \href{https://pubchem.ncbi.nlm.nih.gov/element/Silicon}{Silicon}
  (ditto), and a type of origin (for example ``from window of
  building'', ``from window of car'', and similar).
  \end{description}

  The refractive index, Calcium percentage, Silicon percentage, and type
  of origin of \emph{one} fragment constitute a joint quantity, having a
  joint domain. The refractive index, Calcium percentage, Silicon
  percentage, and type of origin of the 215 fragments are a set of 215
  joint quantities, having identical domains.
\end{itemize}

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{glass_fragments.jpg}

\end{footnotesize}}

It is easy to think of many other and very diverse examples, with even
more complex variates, such as images or words. We shall now try to
abstract and generalize this similarity.

\section{Units, variates, statistical
populations}\label{sec-variates-populations}

Consider a large collection of entities that are somehow similar to one
another, as in the preceding examples. We shall call these entities
{\textbf{units}}. Units could be, for instance:

\begin{itemize}
\tightlist
\item
  physical objects such as cars, windmills, planets, or rocks from a
  particular place;
\item
  creatures such as animals of a particular species, or human beings,
  maybe with something in common such as geographical region; or plants
  of a particular kind;
\item
  automatons having a particular application;
\item
  software objects such as images;
\item
  abstract objects such as functions or graphs;
\item
  the rolls of a particular die or the tosses of a particular coin;
\item
  the weather conditions on several different days.
\end{itemize}

These units are similar to one another in that they have some set of
attributes\footnote{The term {\emph{features}} is frequently used in
  machine learning} common to all. These attributes can present
themselves in a specific number of mutually-exclusive guises. For
instance, the attributes could be:

\begin{itemize}
\tightlist
\item
  ``colour'', each unit being, say, {green}, {blue}, or {yellow};
\item
  ``mass'', each unit having a mass between \(0.1\,\mathrm{kg}\) and
  \(10\,\mathrm{kg}\);
\item
  ``health condition'', each unit (an animal or human in this case)
  being \texttt{healthy} or \texttt{ill}; or maybe being affected by one
  of a specific set of diseases;
\item
  containing something, for instance a particular chemical substance;
\item
  ``having a label'', each unit having one of the labels \texttt{A},
  \texttt{B}, \texttt{C};
\item
  a complex combination of several simpler attributes like the ones
  above.
\end{itemize}

The units may also have additional attributes which we simply don't
consider or can't measure.

\hfill\break
From the definition above it's clear that the attributes of each unit
are a \emph{quantity}, as defined in §~\ref{sec-quant-value-dom}; often
a joint quantity. Once the units and their attributes are specified, we
have a set of as many quantities as there are units. All these
quantities have identical domains.

We call {\textbf{variate}} the \emph{collection} of all similar
quantities of all the units. When we speak about a ``variate'', it is
understood that there is some set of units, each having a similar
quantity.

Note the difference between a \emph{variate} and a \emph{quantity}. For
example, suppose we have three patients A, B, C, and we consider their
\emph{health condition}, which can be \texttt{healthy} or \texttt{ill}.
Then ``health condition'' is a \emph{variate}, while ``the health
condition of patient B'' is a \emph{quantity}. There's a difference
because the sentence ``the health condition is \texttt{ill}'' cannot be
said to be true or false, while the sentence ``the health condition of
patient B is \texttt{ill}'' can. If I ask you ``is the health condition
\texttt{healthy}? or \texttt{ill}?'', you'll ask me ``the health
condition of which patient?''.

\hfill\break
We call a collection of units characterized by a variate, as discussed
above, a {\textbf{statistical population}}, or just \textbf{population}
when there's no ambiguity. The number of units is called the {size} of
the population.

The notion of statistical population is extremely general. Many
different things and collections can be thought of as a statistical
population. When we speak of ``data'', what we often mean, more
precisely, is a particular statistical population.

The specification of a population requires precision, especially when it
is used to draw inferences, as we shall see later. A statistical
population \emph{has not been properly specified} until two things are
precisely specified:

\begin{itemize}
\tightlist
\item
  A way to determine whether something is a unit or not: inclusion and
  exclusion criteria, means of collection, and so on.
\item
  A definition of the variate considered, its possible values, and how
  it is measured.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Which of the following descriptions does properly define a statistical
  population? explain why it does or does not.

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
    People.
  \item
    Electronic components produced in a specific assembly line, since
    the line became operational until its discontinuation, and measured
    for their electric resistance, with possible values in
    {\([0\,\mathrm{\Omega}, \infty\,\mathrm{\Omega}]\),} and for their
    result on a shock test, with possible values
    {\(\set{{\small\verb;pass;}, {\small\verb;fail;}}\).}
  \item
    People born in Norway between 1st January 1990 and 31st December
    2010.
  \item
    The words contained in all websites of the internet.
  \item
    Rocks, of volume between 1\,cm³ and 1\,m³, found in the
    \href{https://www.esa.int/ESA_Multimedia/Images/2015/11/On_the_rim_of_Schiaparelli_crater}{Schiaparelli
    crater} (as defined by contours on a map), and tested to contain
    haematite, with possible values
    {\(\set{{\small\verb;Y;}, {\small\verb;N;}}\).}
  \end{enumerate}
\item
  Browse some \href{https://archive.ics.uci.edu/datasets}{datasets at
  the UC Irvine Machine Learning repository}. Each dataset is a
  statistical population. The variate in most of these populations is a
  joint variate (to be discussed below), that is, a collection of
  several variates.

  Examine and discuss the specification of some of those datasets:

  \begin{itemize}
  \tightlist
  \item
    Is it well-specified what constitutes a ``unit''? Are the criteria
    for including or excluding datapoints, their origin, and so on, well
    explained?
  \item
    Are the variates well-defined? Is it explained what they mean, how
    they were measured, what is their domain, and so on?
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Subtleties in the notion of statistical
population}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  A statistical population is only a conceptual device for simplifying
  and facing some decision or inference problem. There is no
  objectively-defined population ``out there''.

  Any entity, object, person, and so on has some characteristics that
  makes it completely unique (say, its space-time coordinates).
  Otherwise we wouldn't be able to distinguish it from other entities.
  From this point of view any entity is just a one-member population in
  itself. If we consider two or more entities as being ``similar'' and
  belonging to the same population, it's because we have decided to
  disregard some characteristics of these entities, and only focus on
  some other characteristics. This decision is arbitrary, a matter of
  convention, and depends on the specific inference and decision
  problem.

  To test whether an entity belongs to a given population, we have to
  check whether that entity satisfies the agreed-upon definition of that
  population.
\item
  Any physical entity, object, person, etc. can be a ``unit'' in very
  different and even statistical populations. For instance, a 100\,cm³
  rock found in the Schiaparelli crater on Mars could be a unit in these
  populations:

  A. Rocks, of volume between 1\,cm³ and 1\,m³, found in the
  Schiaparelli crater and tested for haematite

  B. Rocks, of volume between 10\,cm³ and 200\,cm³, found in the
  Schiaparelli crater and tested for haematite

  C. Rocks, of volume between 10\,cm³ and 200\,m³, found in any crater
  on any planet of the solar system, and tested for haematite

  D. Rocks, of volume between 1\,cm³ and 1\,m³, found in the
  Schiaparelli crater and measured for the magnitude of their
  \href{https://www.feynmanlectures.caltech.edu/II_34.html}{magnetic
  field}.

  Note the following differences. Populations A, B, C above have the
  same variate but differ in their definition of ``unit''. Populations A
  and D have the same definition of unit but different variates.
  Population B is a subset of population A: they have the same variate,
  and any unit in B is also a unit in A; but not every unit in A is also
  a unit in B. Populations A and C have some overlap: they have the same
  variate, and some units of A are also units of C, and vice versa.
\end{itemize}

\end{tcolorbox}

\section{Populations with joint variates}\label{sec-joint-variates}

The quantity associated with each unit of a statistical population can
be of arbitrary complexity. In particular it could be a joint quantity
(§~\ref{sec-data-multiv}), that is, a collection of quantities of a
simpler type.

We saw an example at the beginning of this chapter, with a population
relevant for
\href{https://www.fbi.gov/about-us/lab/forensic-science-communications/fsc/april2009/review/2009_04_review01.htm}{glass
forensics}. The statistical population was defined as follows:

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{glass_fragments.jpg}

\end{footnotesize}}

\begin{itemize}
\item
  \emph{units:} glass fragments (collected at specific locations)
\item
  \emph{variate:} the joint variate
  {\((\mathit{RI}, \mathit{Ca}, \mathit{Si}, \mathit{Type})\)}
  consisting of four variates of a simple kind:

  \begin{itemize}
  \tightlist
  \item
    \href{https://www.feynmanlectures.caltech.edu/I_26.html\#Ch26-S2}{\(\mathit{R}\)efractive
    \(\mathit{I}\)ndex} of the glass fragment (interval continuous
    variate), with domain from \(1\) (included) to \(+\infty\)
  \item
    weight percent of
    \href{https://pubchem.ncbi.nlm.nih.gov/element/Calcium}{\(\mathit{Ca}\)lcium}
    in the fragment (interval discrete variate), with domain from \(0\)
    to \(100\) in steps of 0.01
  \item
    weight percent of
    \href{https://pubchem.ncbi.nlm.nih.gov/element/Silicon}{\(\mathit{Si}\)licon}
    in the fragment (interval discrete variate), with domain from \(0\)
    to \(100\) in steps of 0.01
  \item
    \(\mathit{Type}\) of glass fragment (nominal variate), with seven
    possible values \texttt{building\_windows\_float\_processed},
    \texttt{building\_windows\_non\_float\_processed},
    \texttt{vehicle\_windows\_float\_processed},
    \texttt{vehicle\_windows\_non\_float\_processed},
    \texttt{containers}, \texttt{tableware}, \texttt{headlamps}
  \end{itemize}
\end{itemize}

Here is a table with the values of the joint variate
{\((\mathit{RI}, \mathit{Ca}, \mathit{Si}, \mathit{Type})\)} for ten
units:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0615}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1385}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1077}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1077}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.5846}}@{}}
\caption{Glass fragments}\label{tbl-glass}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{RI}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Type}\)
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{RI}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Type}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{1} & \(1.51888\) & \(9.95\) & \(72.50\) & \texttt{tableware} \\
{2} & \(1.51556\) & \(9.41\) & \(73.23\) & \texttt{headlamps} \\
{3} & \(1.51645\) & \(8.08\) & \(72.65\) &
\texttt{building\_windows\_non\_float\_processed} \\
{4} & \(1.52247\) & \(9.76\) & \(70.26\) & \texttt{headlamps} \\
{5} & \(1.51909\) & \(8.78\) & \(71.81\) &
\texttt{building\_windows\_float\_processed} \\
{6} & \(1.51590\) & \(8.22\) & \(73.10\) &
\texttt{building\_windows\_non\_float\_processed} \\
{7} & \(1.51610\) & \(8.32\) & \(72.69\) &
\texttt{vehicle\_windows\_float\_processed} \\
{8} & \(1.51673\) & \(8.03\) & \(72.53\) &
\texttt{building\_windows\_non\_float\_processed} \\
{9} & \(1.51915\) & \(10.09\) & \(72.69\) & \texttt{containers} \\
{10} & \(1.51651\) & \(9.76\) & \(73.61\) & \texttt{headlamps} \\
\end{longtable}

The variate value for {unit 4}, for instance, is

\[
\mathit{RI}_{\color[RGB]{204,187,68}4}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1.52247 \land
\mathit{Ca}_{\color[RGB]{204,187,68}4}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}9.76 \land
\mathit{Si}_{\color[RGB]{204,187,68}4}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}70.26 \land
\mathit{Type}_{\color[RGB]{204,187,68}4}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;headlamps;}
\]

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Remember the difference between \emph{variate} and \emph{quantity},
  discussed previously. Consider the population of glass fragments
  introduced above, and suppose I say
  {``\(\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}8.1\)''}.
  Can you check if what I said is true? No, because you don't know which
  unit I'm referring to.

  The variate \emph{for a specific unit} is a quantity instead. We can
  indicate this by appending the unit label to the variate symbol, as we
  did with {``\(\mathit{Ca}_{\color[RGB]{204,187,68}4}\)''} above. If I
  tell you
  {``\(\mathit{Ca}_{\color[RGB]{204,187,68}4}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}8\)''},
  you can check that what i said is false; therefore
  {\(\mathit{Ca}_{\color[RGB]{204,187,68}4}\)} is a \emph{quantity}.
\item
  The units' IDs don't need to be consecutive numbers; in fact they
  don't even need to be numbers: any label that completely distinguishes
  all units will do.
\end{itemize}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Download the dataset\footnotemark{}
  \href{datasets/income_data_nominal_nomissing.csv}{\texttt{income\_data\_nominal\_nomissing.csv}}
  (4\,MB):

  \begin{itemize}
  \tightlist
  \item
    How many variates does this population have?
  \item
    What types of variate (binary, nominal, etc.) do they seem to be?
  \item
    What are their domains?
  \end{itemize}
\item
  Explore datasets from the
  \href{https://archive.ics.uci.edu/datasets}{UC Irvine Machine Learning
  Repository}, answering the three questions above.
\end{itemize}

\end{tcolorbox}

\footnotetext{This is an adapted version of the
\href{https://archive.ics.uci.edu/dataset/2/adult}{UCI ``adult-income''
dataset}}

\chapter{\texorpdfstring{{Statistics}}{Statistics}}\label{sec-statistics}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand{\yXv}[1]{X^{(#1)}}
\providecommand{\vRI}{\mathit{RI}}
\providecommand{\vCa}{\mathit{Ca}}
\providecommand{\vSi}{\mathit{Si}}
\providecommand{\vType}{\mathit{Type}}

\providecommand{\vage}{\mathit{age}}
\providecommand{\vrace}{\mathit{race}}
\providecommand{\vsex}{\mathit{sex}}
\providecommand{\vincome}{\mathit{income}}
\providecommand{\owhite}{\cat{White}}
\providecommand{\oblack}{\cat{Black}}
\providecommand{\oesk}{\cat{Amer-Indian-Eskimo}}
\providecommand{\oM}{\cat{M}}
\providecommand{\oF}{\cat{F}}
\providecommand{\ohi}{\cat{`>50K'}}
\providecommand{\olo}{\cat{`<=50K'}}

\providecommand{\vOut}{\mathit{\red Outcome}}
\providecommand{\vMet}{\mathit{\green Method}}
\providecommand{\vLoc}{\mathit{\lblue Location}}

\providecommand{\osuccess}{\red\cat{success}}
\providecommand{\ofailure}{\red\cat{fail}}
\providecommand{\onew}{{\green\cat{new}}}
\providecommand{\oold}{{\green\cat{old}}}
\providecommand{\oonsite}{{\lblue\cat{onsite}}}
\providecommand{\oremote}{{\lblue\cat{remote}}}

\section{What's the difference between Probability Theory and
Statistics?}\label{sec-diff-prob-stat}

``Probability theory'' and ``statistics'' are often mentioned together.
We shall soon see why, and what are the relationship between them. But
first let's try to define them more precisely:

\begin{description}
\tightlist
\item[{\textbf{Probability theory}}]
is the theory that describes and norms the quantification and
propagation of uncertainty, as we saw in §~\ref{sec-probability-def}.
\item[{\textbf{Statistics}}]
is the study of collective properties of the variates of populations or,
more generally, of collections of data.
\end{description}

There are clear and crucial differences between the two:

\begin{itemize}
\tightlist
\item
  The fact that we are uncertain about something doesn't mean that there
  are populations or replicas involved. We can apply probability theory
  in situations that don't involve any statistics.
\item
  If we have full information about a population -- the value of each
  variate for each unit -- then we can calculate summaries and other
  properties of the variates. And there's no uncertainty involved: at
  all times we can exactly calculate any information we like about any
  variates. So we do statistics, but probability theory plays no role.
\end{itemize}

Many texts do not clearly distinguish between probability and
statistics. The distinction is important for us because we will have to
solve problems involving the \emph{uncertainty} about particular
\emph{statistics}, so the two must be kept clearly separate. This
distinction was observed by
\href{https://clerkmaxwellfoundation.org/html/about_maxwell.html}{James~Clerk~Maxwell}
who used it to develop the theories of statistical mechanics and kinetic
theory.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Maxwell explains the statistical method and its use in the molecular
description of matter:

\begin{itemize}
\tightlist
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Introductory
  Lecture on Experimental Physics}}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Molecules}}
\end{itemize}

\end{tcolorbox}

\end{footnotesize}}

In many concrete problems, however, probability theory and statistics do
go hand in hand and interact. This happens mainly in two ways:

\begin{itemize}
\item
  The statistics of a population give information that can be used in
  the conditional of an inference.
\item
  We want to draw inferences about some statistics of a population,
  whose values we don't know.
\end{itemize}

\hfill\break
Let's now discuss some important statistics.

\section{Frequencies and frequency distributions}\label{sec-freq-distr}

Consider a statistical population of {\(N\)} units, with a variate
{\(X\)} having a finite set of {\(K\)} values as domain. To keep things
simple let's just say these values are {\(\set{1, 2, \dotsc, K}\)}
(without any ordering implied). Our discussion applies for any finite
set. The variate {\(X\)} could be of any non-continuous type: nominal,
ordinal, interval, binary (§~\ref{sec-basic-types}), or of a joint or
complex type (§~\ref{sec-quantities-types-multi}). Let's denote the
variate associated with unit {\(i\)} by {\(X_i\).} For instance, we
express that unit \#3 has {\(X\)-variate} value {\(5\)} and unit \#7 has
{\(X\)-variate} value {\(1\)} by writing

\[
X_3 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}5 \land X_7 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1
\quad\text{\small or equivalently}\quad
X_3 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}5 \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_7 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1
\]

For each value {\(a\)} in the domain of the variate {\(X\),} we count
how many units have that particular value. Let's call the number we find
{\(n_a\).} This is the {\textbf{absolute frequency} of the value \(a\)
in this population}. Obviously {\(n_a\)} must be an integer between
{\(0\)} (included) and {\(K\)} (included). The set of absolute
frequencies of all values is called the {\textbf{absolute frequency
distribution}} of the variate in the population. We must have

\[\sum_{a=1}^K n_a = N \ .\]

It is often useful to give the \emph{fraction} of counts with respect to
the population size, which we denote by {\(f_a\):}

\[f_a \coloneqq n_a/N\]

This is called the {\textbf{relative frequency}} of the value {\(a\).}
Obviously {\(0 \le f_a \le 1\).} The collection of relative frequencies
for all values, {\(\set{f_1, f_2, \dotsc, f_K}\),} satisfies

\[\sum_{a=1}^K f_a = 1 \ .\]

We call this collection of relative frequencies the {\textbf{relative
frequency distribution}}. We shall denote it with the boldface symbol
{\(\boldsymbol{f}\)} (boldface indicates that it is a tuple of numbers):

\(\boldsymbol{f} \coloneqq(f_1, f_2, \dotsc, f_K)\)

with an analogous convention if other letters are used instead of
{``\(f\)''}.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

In the following we shall call relative frequencies simply
``frequencies'', and explicitly use the word ``absolute'' when we speak
about absolute frequencies.

\end{tcolorbox}

\hfill\break
The frequency distribution of values in a population does not give us
full information about the population, because it doesn't tell which
unit has which value. In many situations, however, the frequencies are
all we need to know, or all we can hope to know.

Frequencies and frequency distributions are \emph{quantities} in the
technical sense of §~\ref{sec-quant-value-dom}. In fact we can say, for
instance, ``The frequency of the value \texttt{C} is 0.3'', or {``The
frequency distribution for the values \texttt{A}, \texttt{B}, \texttt{C}
is \((0.2, 0.7, 0.1)\)''}. We shall denote the quantity, as separate
from its value, by the corresponding capital letter, for example
{\(F_1\),} so that we can write sentences about frequencies in our usual
abbreviated form. For instance

\[
F_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}f_3
\]

means ``{The frequency of the variate value \(3\) is equal to
\(f_3\)}'', where {\(f_3\)} must be a specific number.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Consider the statistical population defined as follows:

\begin{itemize}
\tightlist
\item
  \emph{units:} the bookings at a specific hotel during a specific time
  period
\item
  \emph{variate:} the market segment of the booking
\item
  \emph{variate domain:} the set of five values
  \(\set{{\small\verb;Aviation;}, {\small\verb;Complementary;},  {\small\verb;Corporate;}, {\small\verb;Offline;},  {\small\verb;Online;}}\)
\end{itemize}

The population data is stored in the file
\href{extra_datasets/hotel_bookings-market.csv}{\texttt{hotel\_bookings-market.csv}}.
Each row of the file corresponds to a unit, and lists the unit id (this
is not a variate in the present population) and the market segment.

Use any method you like (a script in your favourite programming
language, counting by hand, or whatever) to answer these questions:

\begin{itemize}
\tightlist
\item
  What is the size of the population?
\item
  What are the absolute frequencies of the five values?
\item
  What are their relative frequencies?
\item
  Which units have the value \({\small\verb;Corporate;}\)?
\end{itemize}

\end{tcolorbox}

\subsection{Differences between frequencies and
probabilities}\label{differences-between-frequencies-and-probabilities}

The fact that frequencies are non-negative and sum up to 1 makes them
somewhat similar to probabilities, \emph{from a purely numerical point
of view}. The two notions, however, are completely different and have
different uses. Here is a list of some important differences:

\marginnote{\begin{footnotesize}

Not few works in machine learning tend to call ``probabilities'' any set
of positive numbers that sum up to one. Be careful when reading them.
Mentally replace \emph{probability} with \emph{degree of belief} and see
if the text mentioning ``probabilities'' still makes sense.

\end{footnotesize}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \begin{itemize}
  \tightlist
  \item
    {\emph{A probability expresses a \textbf{degree of belief}.}}
  \item
    {\emph{A frequency is the \textbf{count} of how many times something
    occurs.}}
  \end{itemize}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \begin{itemize}
  \tightlist
  \item
    {\emph{The probability of a sentence depends on an agent's state of
    knowledge and background information.}} Two agents can assign
    different probabilities to the same sentence.
  \item
    {\emph{The frequency of a value in a population is an objective
    physical quantity.}} All agents agree on the frequency (if they have
    the possibility of counting the occurrences).
  \end{itemize}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \begin{itemize}
  \tightlist
  \item
    {\emph{Probabilities refer to \textbf{sentences}.}}
  \item
    {\emph{Frequencies refer to \textbf{values} in a population}}, not
    to sentences.
  \end{itemize}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \begin{itemize}
  \tightlist
  \item
    {\emph{A probability can refer to a specific unit in a population.}}
    An agent can consider, for instance, the probability that a variate
    for unit~\#7 has value \texttt{3}.
  \item
    {\emph{A frequency cannot refer to a specific unit in a
    population.}} It is meaningless to ``count how many times the value
    \texttt{3} appears in unit~\#7''.
  \end{itemize}
\end{enumerate}

\section{Joint frequencies}\label{sec-joint-freq}

Consider the following population consisting of ten units with joint
variate
{\((\mathit{age}, \mathit{race}, \mathit{sex}, \mathit{income})\),}
whose component variates have the following properties:

\begin{itemize}
\tightlist
\item
  \(\mathit{age}\):~~ interval discrete with domain
  \(\set{17, 18, \dotsc, 90+}\)
\item
  \(\mathit{race}\):~~ nominal with domain
  \(\set{{\small\verb;Amer-Indian-Eskimo;}, {\small\verb;Asian-Pac-Islander;} , {\small\verb;Black;}, {\small\verb;Other;}, {\small\verb;White;}}\)
\item
  \(\mathit{sex}\):~~ binary with domain
  \(\set{{\small\verb;F;}, {\small\verb;M;}}\)
\item
  \(\mathit{income}\):~~ binary with domain
  \(\set{{\small\verb;`<=50K';}, {\small\verb;`>50K';}}\)
\end{itemize}

\begin{longtable}[]{@{}cccc@{}}
\caption{Income}\label{tbl-income-ten}\tabularnewline
\toprule\noalign{}
\(\mathit{age}\) & \(\mathit{race}\) & \(\mathit{sex}\) &
\(\mathit{income}\) \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\(\mathit{age}\) & \(\mathit{race}\) & \(\mathit{sex}\) &
\(\mathit{income}\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
53 & \({\small\verb;White;}\) & \({\small\verb;M;}\) &
\({\small\verb;`>50K';}\) \\
53 & \({\small\verb;Black;}\) & \({\small\verb;F;}\) &
\({\small\verb;`<=50K';}\) \\
48 & \({\small\verb;White;}\) & \({\small\verb;M;}\) &
\({\small\verb;`>50K';}\) \\
53 & \({\small\verb;White;}\) & \({\small\verb;F;}\) &
\({\small\verb;`>50K';}\) \\
53 & \({\small\verb;White;}\) & \({\small\verb;M;}\) &
\({\small\verb;`<=50K';}\) \\
26 & \({\small\verb;White;}\) & \({\small\verb;M;}\) &
\({\small\verb;`<=50K';}\) \\
48 & \({\small\verb;White;}\) & \({\small\verb;F;}\) &
\({\small\verb;`>50K';}\) \\
53 & \({\small\verb;White;}\) & \({\small\verb;M;}\) &
\({\small\verb;`>50K';}\) \\
53 & \({\small\verb;Black;}\) & \({\small\verb;M;}\) &
\({\small\verb;`<=50K';}\) \\
48 & \({\small\verb;Amer-Indian-Eskimo;}\) & \({\small\verb;M;}\) &
\({\small\verb;`>50K';}\) \\
\end{longtable}

The {\textbf{joint frequency distribution}} for the joint variate of the
population above gives the frequencies of all possible joint variate
values, for instance the value

\(\mathit{age}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}53 \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{race}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Black;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{sex}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;F;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;`<=50K';}\)

In this population, most joint values appear each only once, and the
remaining values never appear; this is because of the population's small
size and the large number of possible variate values. A couple of joint
values appear twice. We have for example

\[\begin{aligned}
&f(\mathit{age}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}53 \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{race}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;White;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{sex}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;M;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;`>50K';}
) = \frac{2}{10}
\\[2ex]
&f(\mathit{age}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}53 \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{race}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Black;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{sex}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;F;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;`<=50K';}
) = \frac{1}{10}
\\[2ex]
&f(\mathit{age}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}48 \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{race}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Amer-Indian-Eskimo;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{sex}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;F;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;`>50K';}
) = 0
\end{aligned}\]

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Try to write a function that takes as input a dataset with a small
number of variates and outputs the joint frequency distribution for all
combinations of variate values. The best output format is a
multidimensional array having one dimension per variate, and for each
dimension a length equal to the number of possible values of that
variate. The value of the array in each cell is the corresponding
frequency.

For instance, consider the case of the income dataset above but
\emph{without the age variate}. The output of the function would then be
an array with {\(5 \times 2 \times 2\)} dimensions

\end{tcolorbox}

\section{Marginal frequencies}\label{sec-marginal-freq}

When a population has a joint variate, we may be interested in only a
subset of the simpler variates that constitute the joint one. In the
population of the example above, for instance, we might be interested
only in the {\(\mathit{age}\)} and {\(\mathit{income}\)} variates. These
two variates together are then called {\textbf{marginal variates}} and
define what we can call a {\textbf{marginal population}} of the original
one. A marginal population has the same units as the original one, but
only a subset of the variates of the original. It is a statistical
population in its own right.

The notion of ``marginalization'' is a relative notion. Any population
can often be considered as the marginal of a population with the same
units but additional attributes.

\hfill\break

Given a statistical population with joint variates
{\({\color[RGB]{34,136,51}X}, {\color[RGB]{238,102,119}Y}\),} we define
the {\textbf{marginal frequency}} of the value
{\({\color[RGB]{238,102,119}y}\)} of {\({\color[RGB]{238,102,119}Y}\)}
as the frequency of the value {\({\color[RGB]{238,102,119}y}\)} in the
marginal population with the variate {\({\color[RGB]{238,102,119}Y}\)}
alone. This frequency is simply written

\[
f({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y})
\]

A conditional frequency can be calculated as the sum of the joint
frequencies for all values {\({\color[RGB]{34,136,51}x}\),} in a way
analogous to marginal probabilities (§~\ref{sec-marginal-probs}):

\[
f({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y}) = \sum_{\color[RGB]{34,136,51}x} f({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x})
\]

For example, if from the population of table~~\ref{tbl-income-ten} we
consider the marginal population with variates
{\((\mathit{age}, \mathit{income})\),} some of the marginal frequencies
are

\[\begin{aligned}
&f(\mathit{age}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}53 \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;`<=50K';}
) = \frac{3}{10}
\\[2ex]
&f(\mathit{age}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}26 \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;`<=50K';}
) = \frac{1}{10}
\\[2ex]
&f(\mathit{age}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}48 \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;`>50K';}
) = \frac{3}{10}
\end{aligned}\]

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Download again the dataset
  \href{datasets/income_data_nominal_nomissing.csv}{\texttt{income\_data\_nominal\_nomissing.csv}}:

  \begin{itemize}
  \tightlist
  \item
    Calculate the marginal frequencies of some of its variates.
  \item
    Does any variate have a value appearing with \emph{marginal absolute
    frequency} equal to 1?
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\section{Summary statistics}\label{sec-summary-stat}

In communicating statistics about a population it is always best to
report and, when possible, visually show (for instance as marginal
distributions) the full joint frequency distribution of the population's
variates.

Sometimes one wants to share some sort of ``summary'' of the frequency
distribution, emphasizing particular aspects of it; because these are
also aspects of the population. Different kinds of aspects can be
chosen; some of them are only defined for specific types of variates.
They are often called ``summary statistics'' or ``descriptive
statistics''. Below we give a brief description of some common ones,
emphasizing when they are appropriate and when they are not. These
summaries can also be used for probability distributions.

\subsection{Mode}\label{mode}

The {\textbf{mode}} is the value having the highest frequency (or
probability, if we're speaking about an agent's beliefs rather than a
population). There can be more than one mode.

The mode is defined for any distribution over discrete values, also for
nominal quantities.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Be careful in relying too much on the ``mode'' for a continuous
quantity. Continuous quantities can be transformed in a one-to-one way
into other, equivalent ones; and such a transformation also give the
equivalent frequency or probability \emph{density} for the new quantity.
\textbf{There is no general relationship} between the modes of the
densities for the two equivalent quantities. In fact, the density for
one quantity can have one mode, whereas the density for the equivalent
quantity can have no mode, or many modes. This is true for all kinds of
distributions represented by densities, for example a continuous
distribution of energy.

\marginnote{\begin{footnotesize}

\begin{quote}
\textbf{\faIcon{rocket} For the extra curious}

\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Some
paradoxes, errors, and resolutions concerning the spectral optimization
of human vision}}
\end{quote}

\end{footnotesize}}

\end{tcolorbox}

\subsection{Median and quartiles}\label{median-and-quartiles}

Recall (§~\ref{sec-basic-types}) that an \emph{ordinal} or an
\emph{interval} quantity or variate have values that can be ranked in a
specific order. If there is a value for which the sum of the frequencies
of all values of rank lower than that value equals the sum of the
frequencies of all values of rank higher than that value, then that
value is called the {\textbf{median}} of the distribution. See the
following histogram as an example:

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{median_example.png}
The value {\({\small\verb;e;}\)} is the median of this frequency
distribution, because
{\(f({\small\verb;c;})+f({\small\verb;d;}) = f({\small\verb;f;})+f({\small\verb;g;})+f({\small\verb;h;})+f({\small\verb;i;})= 47.6\%\)}

If there is no such separating value, then sightly different definitions
of median exist in the literature; but the approximate idea is the same:
a value that somehow divides the domain into two parts of roughly equal
(50\%) total frequency. This idea can be also applied to continuous
distributions represented by densities.

The notion of median can be generalized to that of a value that
separates the domain into a lower-rank part with total frequency 1/4,
and a higher-rank part with total frequency 3/4; and also to that of a
value separating into a 3/4 vs 1/4 proportion instead. These values are
called the {\emph{first quartile}} and {\emph{third quartile}}. The two
quartiles and the median (also called second quartile) divide the domain
into four parts of roughly equal 25\% frequencies.

\emph{If} the variate or quantity under consideration is of interval
type, then it's possible to take the difference between the third and
first quartile, called the {\emph{interquartile range}}.

\subsection{Mean and standard
deviation}\label{mean-and-standard-deviation}

For an interval quantity {\(X\)} with values
{\(\set{x_1, x_2, \dotsc}\)} for which it makes sense to take the sum,
it is possible to define the {\textbf{mean}} and {\textbf{standard
deviation}}:

\[
\bar{X} \coloneqq\sum_i x_i\cdot f(x_i)
\qquad
\sigma(X) \coloneqq\sqrt{\sum_i (x_i-\bar{X})^2\cdot f(x_i)}
\]

we assume that their meaning is more or less familiar to you.

\subsection{Uses and pitfalls}\label{uses-and-pitfalls}

For a nominal variate or quantity it doesn't make sense to speak of
median, quartiles, mean, standard deviation, because its possible values
cannot be ranked or added.

For an ordinal variate or quantity it doesn't make sense to speak of
mean or standard deviation, because its possible values cannot be added.

\hfill\break

The mean and standard deviation can make sense and can be useful in some
circumstances. But note that even if the values of a quantity can be
summed, their mean (and standard deviation) may not quite make sense.

Consider the number of patients visiting a hospital in 100 consecutive
days. It is possible to consider the mean number of patients per day.
This number has a meaning: if this number of patients visited the
hospital every day for 100 days, then the total number of visits would
be equal to the actual total. The same reasoning can be made for the
number of nurses working in the hospital every day for 100 days, and
their mean.

Now consider the daily ratios of patients to nurses, for those 100 days.
These ratios are numbers, so we can take their mean. But what does such
a mean represent? if we multiply it by 100, we don't obtain the total of
anything. Also, if we consider the total number of patients and total
number of nurses in 100 days, their ratio will \emph{not} be equal to
the ``mean ratio'' we calculated.

The example above is not meant to say that a mean of ratios never makes
sense, but to point out that mean and standard deviation are often
overused. In chapter~~\ref{sec-pop-samples} we will discuss other
problems that may arise in using mean and standard deviation.

In general, when in doubt, we recommend to use median and quartiles or
median and interquartile range, which are more generally meaningful and
enjoy several other properties (for example so-called ``robustness'')
useful in doing statistics.

\hfill\break

Note, in any case, that the present discussion regards the question of
how to provide summary information \emph{besides} the full frequency (or
probability) distribution. If our problem is to \textbf{choose one
value} out of the possible ones, then that's a \emph{decision-making
problem}, which must be solved by specifying utilities and maximizing
the expected utility, as preliminary discussed in
chapter~~\ref{sec-framework} and as will be discussed more in detail
towards the final chapters.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  §2.6 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Risk
  Assessment and Decision Analysis with Bayesian Networks}}
\item
  §~``\textbf{The median estimate}'' of
  \href{https://doi.org/10.1007/s00769-021-01485-5}{\emph{Meaningful
  expression of uncertainty in measurement}}
\item
  \href{https://doi.org/10.1001/virtualmentor.2013.15.1.mnar1-1301}{\emph{The
  Median Isn't the Message}}
\end{itemize}

\end{tcolorbox}

\section{Outliers vs out-of-population units}\label{sec-outliers}

The term ``outlier'' frequently appears in problems related to
statistics and probability, often in conjunction with some summary
statistics described above. Unfortunately the definitions of this term
can be confusing or misleading. With the notion of outlier often there
also comes a barrage of ``methods'' or rules meant to ``deal'' with
outliers. Some such rules, for instance the rule of discarding any
datapoints lying at more than three standard deviations from the mean,
are often mindless and dangerous.

So let's avoid the term ``outlier'' for the moment, and let's take a
different perspective.

\hfill\break

One reason why we consider a population of units is that we are
interested in making inferences about some units in this population, for
which we lack the values of some variates. As we shall see in the
forthcoming chapters, such inferences can be made if we first try to
infer the full joint frequency distribution for the variates of the
population of interest.

This kind of inference becomes more difficult if we have reckoned into
the population \emph{some units that actually don't belong there}.

Suppose for instance that a hospital is interested in the age of female
patients admitted in a year. In collecting data, some \emph{male}
patients are counted in. Then obviously the age frequencies obtained
from the collected data will not reflect the age frequencies among
females. The problem is that some {\emph{out-of-population}} units have
been counted in by mistake.

The way out-of-population units affect and distort the frequency count
can be different from problem to problem.

In our example, suppose that the wast majority of female patients could
have age between 45--55 years, and that the male patients erroneously
counted in also have age in the same range. Then the \emph{bulk} of the
frequency distribution will appear more inflated than it should be. Or
suppose instead that the male patients erroneously reckoned have age
between 80--90 years. In this case the old-age tail of the distribution
will appear more inflated. As you see we can't a priori point to any
``tail'' or ``bulk'' as a problem.

Low frequencies are relatively affected by out-of-population units more
than high frequencies. Suppose 10 female patients out of 100 have age
52; frequency 10\%. If one 52-year-old male patient is now included by
mistake, the frequency becomes 11/101\,≈\,10.1\%, or a 1\% relative
error. But if one female patient out of 100 has age 96 (1\% frequency),
and a male patient of the same age is now included by mistake, the
frequency becomes 2/101\,≈\,1.98\%, with a 98\% relative error. This is
the reason some people focus on distribution tails and ``outliers'',
defined as data having with low-frequency values. (Note that this
reasoning would concern any regions of low frequency, for example among
two modes; not just tails.)

Yet we cannot mindlessly attack low-frequency regions and data just
because they could be more affected by out-of-population units. In many
problems of data science, engineering, medicine, low-frequency cases are
the most important ones (think of rare diseases, rare mineral elements,
rare astronomical events, and so on). So if we alter or eliminate
low-frequency data only because they \emph{might} be out-of-population
units, then we have dangerously affected all our inferences about such
rare events.

Moreover, how could we judge what the ``correct'' frequency should be?
Many outlier methods \emph{assume} that the true frequency of the
population has a Gaussian shape, and alter or cut the tails based on
this assumption. But how can we know if such an assumption is correct?
It turns out that the tails of a distribution are important for checking
such assumption. Then you see the full circularity behind such mindless
methods.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

§2.1 of
\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Risk
Assessment and Decision Analysis with Bayesian Networks}}

\end{tcolorbox}

Which method should one use to face this problem, then? -- The answer is
that there's no universal method. The approach depends on the specific
problem. A data scientist must carefully examine all possible sources of
out-of-population units, make inferences about them, and integrate these
inferences in the general inference about the population of interest.

There is literature discussing first-principle approaches of this kind
for different scenarios, but we cannot discuss them in the present
course.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Ch.~21 of
\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Probability
Theory}}

\end{tcolorbox}

\end{footnotesize}}

\chapter{\texorpdfstring{{Subpopulations and conditional
frequencies}}{Subpopulations and conditional frequencies}}\label{subpopulations-and-conditional-frequencies}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand{\yXv}[1]{X^{(#1)}}
\providecommand{\vRI}{\mathit{RI}}
\providecommand{\vCa}{\mathit{Ca}}
\providecommand{\vSi}{\mathit{Si}}
\providecommand{\vType}{\mathit{Type}}

\providecommand{\vage}{\mathit{age}}
\providecommand{\vrace}{\mathit{race}}
\providecommand{\vsex}{\mathit{sex}}
\providecommand{\vincome}{\mathit{income}}
\providecommand{\owhite}{\cat{White}}
\providecommand{\oblack}{\cat{Black}}
\providecommand{\oesk}{\cat{Amer-Indian-Eskimo}}
\providecommand{\oM}{\cat{M}}
\providecommand{\oF}{\cat{F}}
\providecommand{\ohi}{\cat{`>50K'}}
\providecommand{\olo}{\cat{`<=50K'}}

\providecommand{\vOut}{\mathit{\red Outcome}}
\providecommand{\vMet}{\mathit{\green Method}}
\providecommand{\vLoc}{\mathit{\lblue Location}}

\providecommand{\osuccess}{\red\cat{success}}
\providecommand{\ofailure}{\red\cat{fail}}
\providecommand{\onew}{{\green\cat{new}}}
\providecommand{\oold}{{\green\cat{old}}}
\providecommand{\oonsite}{{\lblue\cat{onsite}}}
\providecommand{\oremote}{{\lblue\cat{remote}}}

\section{Subpopulations}\label{sec-subpopulations}

When we have a statistical population with a joint variate, it is often
of interest to focus on a subset of units that share the same value of a
particular variate.

Consider for instance the following population, related to the
glass-forensics example we encountered before:

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{glass_fragments.jpg}

\end{footnotesize}}

\begin{itemize}
\tightlist
\item
  \emph{units:} glass fragments (collected at specific locations)
\item
  \emph{variate:} the joint variate
  \((\mathit{Ca}, \mathit{Si}, \mathit{Type})\) consisting of three
  simple variates:

  \begin{itemize}
  \tightlist
  \item
    weight fraction of \(\mathit{Ca}\)lcium in the fragment (ordinal
    variate), with three possible values
    \(\set{{\small\verb;low;}, {\small\verb;medium;}, {\small\verb;high;}}\)
  \item
    weight fraction of \(\mathit{Si}\)licon in the fragment (ordinal
    variate), with three possible values
    \(\set{{\small\verb;low;}, {\small\verb;medium;}, {\small\verb;high;}}\)
  \item
    \(\mathit{Type}\) of glass fragment (nominal variate), with seven
    possible values
    \(\{{\small\verb;building_windows_float_processed;}\),
    \({\small\verb;building_windows_non_float_processed;}\),
    \({\small\verb;containers;}\), \({\small\verb;tableware;}\),
    \({\small\verb;headlamps;}\}\)
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0690}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1379}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1379}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.6552}}@{}}
\caption{Simplified glass-fragment population
data}\label{tbl-glass-simple}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Type}\)
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Type}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{1} & \({\small\verb;low;}\) & \({\small\verb;high;}\) &
\({\small\verb;headlamps;}\) \\
{2} & \({\small\verb;low;}\) & \({\small\verb;medium;}\) &
\({\small\verb;building_windows_non_float_processed;}\) \\
{3} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;tableware;}\) \\
{4} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;building_windows_float_processed;}\) \\
{5} & \({\small\verb;low;}\) & \({\small\verb;medium;}\) &
\({\small\verb;headlamps;}\) \\
{6} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;containers;}\) \\
{7} & \({\small\verb;low;}\) & \({\small\verb;medium;}\) &
\({\small\verb;building_windows_non_float_processed;}\) \\
{8} & \({\small\verb;low;}\) & \({\small\verb;high;}\) &
\({\small\verb;tableware;}\) \\
{9} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;tableware;}\) \\
{10} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;tableware;}\) \\
\end{longtable}

Let's say we are interested only in units that have the
{\(\mathit{Type}\)} variate equal to {\({\small\verb;tableware;}\).}
Discarding all others we obtain a new, smaller population with four
units:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0690}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1379}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1379}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.6552}}@{}}
\caption{Selection according to
\(\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;tableware;}\)}\label{tbl-glass-tableware}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\nonscript\:\vert\nonscript\:\mathopen{}}\mathit{Type}\)
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\nonscript\:\vert\nonscript\:\mathopen{}}\mathit{Type}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{3} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;tableware;}\) \\
{8} & \({\small\verb;low;}\) & \({\small\verb;high;}\) &
\({\small\verb;tableware;}\) \\
{9} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;tableware;}\) \\
{10} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;tableware;}\) \\
\end{longtable}

were a bar
{``\(\boldsymbol{\nonscript\:\vert\nonscript\:\mathopen{}}\)''}
indicates the variate used for the selection.

As another example, we could be interested instead in those units that
have \emph{both} {\(\mathit{Ca}\)} \emph{and} {\(\mathit{Si}\)} variates
equal to {\({\small\verb;medium;}\).} We obtain a smaller population
with five units:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0690}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1379}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1379}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.6552}}@{}}
\caption{Selection according to
\(\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;medium;}\)
and
\(\mathit{Si}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;medium;}\)}\label{tbl-glass-ca-si-medium}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\nonscript\:\vert\nonscript\:\mathopen{}}\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\nonscript\:\vert\nonscript\:\mathopen{}}\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Type}\)
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\nonscript\:\vert\nonscript\:\mathopen{}}\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\nonscript\:\vert\nonscript\:\mathopen{}}\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Type}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{3} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;tableware;}\) \\
{4} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;building_windows_float_processed;}\) \\
{6} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;containers;}\) \\
{9} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;tableware;}\) \\
{10} & \({\small\verb;medium;}\) & \({\small\verb;medium;}\) &
\({\small\verb;tableware;}\) \\
\end{longtable}

Populations formed in this way are called {\textbf{subpopulations}} of
the original one. They are statistical populations in their own right.
The notion of ``subpopulation'' is a relative notion. Any population can
often be considered as a subpopulation of some larger population having
additional variates.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  From the population of table~~\ref{tbl-glass-simple}:

  \begin{itemize}
  \tightlist
  \item
    Construct the \emph{marginal} population with variate
    \(\mathit{Ca}\)
  \item
    Report the frequency distribution for the marginal population above
    (remember that \(\mathit{Ca}\) has \emph{three} possible values)
  \item
    Construct the subpopulation with variate \(\mathit{Si}\) equal to
    \({\small\verb;high;}\)
  \item
    Construct the subpopulation with variate \(\mathit{Type}\) equal to
    \({\small\verb;headlamps;}\) and the variate \(\mathit{Si}\) equal
    to \({\small\verb;medium;}\)
  \end{itemize}
\end{itemize}

\emph{Check your understanding of the reasoning behind the notions of
marginal population and subpopulation with this exercise:}

\begin{itemize}
\tightlist
\item
  From the population of table~~\ref{tbl-glass-simple}, construct the
  subpopulation with variate \(\mathit{Type}\) equal to \emph{either}
  \({\small\verb;headlamps;}\) \emph{or} \({\small\verb;tableware;}\).
\end{itemize}

\end{tcolorbox}

\section{Conditional frequencies}\label{sec-conditional-freqs}

Given a statistical population with joint variates
{\({\color[RGB]{34,136,51}X}, {\color[RGB]{238,102,119}Y}\)} (and
possibly others), we define the {\textbf{conditional frequency}} of the
value {\({\color[RGB]{238,102,119}y}\)} of
{\({\color[RGB]{238,102,119}Y}\),} given or ``conditional on'' the value
{\({\color[RGB]{34,136,51}x}\)} of {\({\color[RGB]{34,136,51}X}\),} as
the frequency of the value {\({\color[RGB]{238,102,119}y}\)} in the
subpopulation selected by
{\({\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x}\).}
This frequency is usually written

\[
f({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x})
\]

where {\(f\)} is the symbol for the joint frequency of the population.

Consider for instance the glass-fragment population of
table~~\ref{tbl-glass-simple}. The conditional frequency of
{\({\color[RGB]{238,102,119}\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;}}\)}
given
{\({\color[RGB]{34,136,51}\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;tableware;}}\)}
is the (marginal) frequency of
{\(\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;}\)}
in the subpopulation of table~~\ref{tbl-glass-tableware}, from which we
find

\[
f({\color[RGB]{238,102,119}\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;}} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;tableware;}}) = \frac{1}{4}
\]

The collection of these conditional frequencies for all values of
{\({\color[RGB]{238,102,119}Y}\)} constitutes the {conditional frequency
distribution} of {\({\color[RGB]{238,102,119}Y}\)} conditional on
{\({\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x}\).}
In our example this distribution has three conditional frequencies:

\[\begin{aligned}
&f({\color[RGB]{238,102,119}\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;}} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;tableware;}}) = \frac{1}{4}
\\
&f({\color[RGB]{238,102,119}\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;medium;}} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;tableware;}}) = \frac{3}{4}
\\
&f({\color[RGB]{238,102,119}\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;high;}} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;tableware;}}) = 0
\end{aligned}\]

which sum up to {\(1\)} as they should.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Conditional on a \emph{value} of a variate}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

It doesn't make sense to speak of the conditional frequency distribution
of {\(Y\)} ``conditional {on \(X\)''}. Conditional frequencies and
frequency distributions are always conditional on some value of a
variate. If we consider all possible values of {\(Y\)} \emph{and} of
{\(X\)} we obtain a collection of frequencies that is \emph{not} a
distribution.

\end{tcolorbox}

A conditional frequency can be calculated as the ratio of a joint and a
marginal frequencies, in a way analogous to conditional probabilities
(§~\ref{sec-conditional-probs}):

\[
f({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x}) =
\frac{f({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x})}{f({\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x})} =
\frac{f({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x})}{
\sum_{\color[RGB]{238,102,119}y} f({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x})}
\]

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Calculate the conditional frequency distributions corresponding to the
subpopulations of tables \ref{tbl-glass-tableware} and
\ref{tbl-glass-ca-si-medium}. For example, for
table~~\ref{tbl-glass-tableware} this means calculating

\[\begin{aligned}
&f(\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{Si}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;} \nonscript\:\vert\nonscript\:\mathopen{} \mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;tableware;})\ ,
\\
&f(\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{Si}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;medium;} \nonscript\:\vert\nonscript\:\mathopen{} \mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;tableware;})\ ,
\\
&\dotsc\ ,
\\
&f(\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;high;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{Si}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;high;} \nonscript\:\vert\nonscript\:\mathopen{} \mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;tableware;})
\end{aligned}\]

\end{tcolorbox}

\section{Associations}\label{sec-association}

The analysis of subpopulations and conditional frequencies is important
because it often reveals peculiar {\emph{associations}}\footnote{In
  everyday language this is the same as ``correlation''. The term
  ``association'' is used in statistics to avoid confusion with the
  Pearson correlation coefficient (see §~\ref{sec-entropy-mutualinfo})}
among different variates and groups of variates. Let's illustrate what
we mean by ``association'' with an example.

Extract the subpopulation having variate {\(\mathit{Type}\)} equal to
{\({\small\verb;headlamps;}\)} from the population of
table~~\ref{tbl-glass-simple}:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0690}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1379}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1379}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.6552}}@{}}
\caption{Selection according to
\(\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;headlamps;}\)}\label{tbl-glass-headlamps}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\nonscript\:\vert\nonscript\:\mathopen{}}\mathit{Type}\)
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\nonscript\:\vert\nonscript\:\mathopen{}}\mathit{Type}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{1} & \({\small\verb;low;}\) & \({\small\verb;high;}\) &
\({\small\verb;headlamps;}\) \\
{5} & \({\small\verb;low;}\) & \({\small\verb;medium;}\) &
\({\small\verb;headlamps;}\) \\
\end{longtable}

we notice that all units have variate {\(\mathit{Ca}\)} equal to
{\({\small\verb;low;}\).} In terms of conditional frequencies, this
means

\[
\begin{aligned}
&f(\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;} \nonscript\:\vert\nonscript\:\mathopen{} \mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;headlamps;}) = 1
\\
&f(\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;medium;} \nonscript\:\vert\nonscript\:\mathopen{} \mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;headlamps;}) = 0
\\
&f(\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;high;} \nonscript\:\vert\nonscript\:\mathopen{} \mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;headlamps;}) = 0
\end{aligned}
\]

It is therefore impossible to observe other values of {\(\mathit{Ca}\)}
in this new population.\footnote{We are not claiming that this fact will
  be true if new units are considered; this important question will be
  discussed later.}

On the other hand, if we extract the subpopulation having variate
{\(\mathit{Ca}\)} equal to {\({\small\verb;low;}\)} we obtain

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0690}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1379}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1379}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.6552}}@{}}
\caption{Selection according to
\(\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;}\)}\label{tbl-glass-ca-low}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\nonscript\:\vert\nonscript\:\mathopen{}}\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Type}\)
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\nonscript\:\vert\nonscript\:\mathopen{}}\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Type}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{1} & \({\small\verb;low;}\) & \({\small\verb;high;}\) &
\({\small\verb;headlamps;}\) \\
{2} & \({\small\verb;low;}\) & \({\small\verb;medium;}\) &
\({\small\verb;building_windows_non_float_processed;}\) \\
{5} & \({\small\verb;low;}\) & \({\small\verb;medium;}\) &
\({\small\verb;headlamps;}\) \\
{7} & \({\small\verb;low;}\) & \({\small\verb;medium;}\) &
\({\small\verb;building_windows_non_float_processed;}\) \\
{8} & \({\small\verb;low;}\) & \({\small\verb;high;}\) &
\({\small\verb;tableware;}\) \\
\end{longtable}

with conditional frequencies such as

\[
\begin{aligned}
&f(\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;headlamps;} \nonscript\:\vert\nonscript\:\mathopen{} \mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;}) = \frac{2}{5}
\\[1ex]
&f(\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;tableware;} \nonscript\:\vert\nonscript\:\mathopen{} \mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;}) = \frac{1}{5}
\end{aligned}
\]

and so on. The reverse is therefore \emph{not} true: if
{\(\mathit{Ca}\)} is equal to {\({\small\verb;low;}\),} that does
\emph{not} mean that it's impossible to observe other
{\(\mathit{Type}\)} values besides {\({\small\verb;headlamps;}\).} Note
especially how these frequencies differ:

\[
\begin{gathered}
f(\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;} \nonscript\:\vert\nonscript\:\mathopen{} \mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;headlamps;}) = 1
\\[1ex]
f(\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;headlamps;} \nonscript\:\vert\nonscript\:\mathopen{} \mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;}) = \frac{2}{5}
\end{gathered}
\]

In the original population we have, figuratively speaking, the following
interesting association:

\[
\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;headlamps;}\ \mathrel{\color[RGB]{34,136,51}\Rightarrow}\ 
\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;}
\qquad\text{\small but}\qquad
\mathit{Ca}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;low;}\  \mathrel{\color[RGB]{238,102,119}\nRightarrow}\ 
\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;headlamps;}
\]

This kind of associations is often useful. Suppose for instance that you
are asked to pick a unit with {\(\mathit{Ca}\)} equal to
{\({\small\verb;low;}\)} in the original population; but it's difficult
to measure a unit's {\(\mathit{Ca}\)} value, while it's easy to measure
its {\(\mathit{Type}\)} value. Then you could instead search for a unit
having {\(\mathit{Type}\)} equal to {\({\small\verb;headlamps;}\)}
(easier search), and you would be sure that the unit you found also has
{\(\mathit{Ca}\)} equal to {\({\small\verb;low;}\).}

\hfill\break

The example above, where some values of a variate completely exclude
some values of another, is a special one. More often we find that there
are small or large changes in the frequency distribution of some
variate, depending on the subpopulation considered.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Calculate the (marginal) frequency distribution for the
  {\(\mathit{Ca}\)} variate for the glass-fragment population of
  table~~\ref{tbl-glass-simple}. Is the value {\({\small\verb;low;}\)}
  more frequent than {\({\small\verb;medium;}\)?} or vice versa?
\item
  Calculate the frequency distribution for {\(\mathit{Ca}\),}
  conditional on
  {\(\mathit{Type}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;tableware;}\)}
  (see table~~\ref{tbl-glass-tableware}). How does this frequency
  distribution differ from the one you calculated above? Come up with
  possible ways to exploit this difference in concrete applications.
\end{itemize}

\end{tcolorbox}

\subsection{Associations can be very
counter-intuitive}\label{associations-can-be-very-counter-intuitive}

It is usually best to assess associations by explicitly calculating all
relevant conditional frequencies, rather than jumping to intuitive
conclusions after having examined just a few. Here's an example.

\hfill\break

Consider the statistical population defined as follows:

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{component_repair.jpg}

\end{footnotesize}}

\begin{itemize}
\item
  \emph{units:} all reparations done by a repair company on a particular
  kind of electronic components, which is extremely delicate and usually
  very difficult to repair. The population has 26 units (every unit
  actually represents a batch 100 reparations, so the population really
  refers to 2600 reparations).
\item
  a joint \emph{variate}, consisting in three binary ones:

  \begin{itemize}
  \item
    \(\mathit{\color[RGB]{102,204,238}Location}\) of the repair
    procedure, with values
    {\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\)} and
    {\({\color[RGB]{102,204,238}{\small\verb;remote;}}\);}
  \item
    repair {\(\mathit{\color[RGB]{34,136,51}Method}\),} with values
    {\({\color[RGB]{34,136,51}{\small\verb;old;}}\)} and
    {\({\color[RGB]{34,136,51}{\small\verb;new;}}\),} representing a
    traditional reparation method and one introduced more recently;
  \item
    \(\mathit{\color[RGB]{238,102,119}Outcome}\) of the repair
    procedure, with values
    {\(\color[RGB]{238,102,119}{\small\verb;success;}\)} and
    {\(\color[RGB]{238,102,119}{\small\verb;fail;}\).}
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}ccc@{}}
\caption{Reparations (each row is one unit, representing 100
reparations).\\
file
\href{datasets/repair_data.csv}{\texttt{repair\_data.csv}}}\label{tbl-reparations}\tabularnewline
\toprule\noalign{}
\(\mathit{\color[RGB]{238,102,119}Outcome}\) &
\(\mathit{\color[RGB]{34,136,51}Method}\) &
\(\mathit{\color[RGB]{102,204,238}Location}\) \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\(\mathit{\color[RGB]{238,102,119}Outcome}\) &
\(\mathit{\color[RGB]{34,136,51}Method}\) &
\(\mathit{\color[RGB]{102,204,238}Location}\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;remote;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;success;}\) &
\({\color[RGB]{34,136,51}{\small\verb;old;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\(\color[RGB]{238,102,119}{\small\verb;fail;}\) &
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) &
\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\) \\
\end{longtable}

\textbf{The repair company claims that, in this population, the
\({\color[RGB]{34,136,51}{\small\verb;new;}}\) repair method is more
effective than the \({\color[RGB]{34,136,51}{\small\verb;old;}}\).} Can
you back up their claims?:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise (one of the most fun of the course!)}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Use the population data above. The calculations can be done with any
tools you like.

\begin{itemize}
\item
  Examine the whole population first:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
    Calculate the frequency distribution of the
    {\(\mathit{\color[RGB]{238,102,119}Outcome}\)} variate, conditional
    on
    {\(\mathit{\color[RGB]{34,136,51}Method}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;new;}}\)}
    (note that we are disregarding the
    {\(\mathit{\color[RGB]{102,204,238}Location}\)).}
  \item
    Calculate the frequency distribution of the
    {\(\mathit{\color[RGB]{238,102,119}Outcome}\)} variate, conditional
    on
    {\(\mathit{\color[RGB]{34,136,51}Method}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;old;}}\).}
  \item
    Compare the two conditional frequency distributions above. Which of
    the two repair methods seems more effective?\\
    Are the claims of the repair company justified?
  \end{enumerate}
\item
  Now examine the reparations that have been done
  {\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\):}

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{3}
  \item
    Before doing any calculations, what do you expect to find? should
    the {\({\color[RGB]{34,136,51}{\small\verb;new;}}\)} repair method
    be more effective than the
    {\({\color[RGB]{34,136,51}{\small\verb;old;}}\)} one, for onsite
    reparations?
  \item
    Calculate the frequency distribution of the
    {\(\mathit{\color[RGB]{238,102,119}Outcome}\)} variate, conditional
    on
    {\(\mathit{\color[RGB]{34,136,51}Method}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;new;}}\)}
    and
    {\(\mathit{\color[RGB]{102,204,238}Location}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{102,204,238}{\small\verb;onsite;}}\).}
  \item
    Calculate the frequency distribution of the
    {\(\mathit{\color[RGB]{238,102,119}Outcome}\)} variate, conditional
    on
    {\(\mathit{\color[RGB]{34,136,51}Method}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;old;}}\)}
    and
    {\(\mathit{\color[RGB]{102,204,238}Location}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{102,204,238}{\small\verb;onsite;}}\).}
  \item
    Compare the two conditional frequency distributions for this
    {\({\color[RGB]{102,204,238}{\small\verb;onsite;}}\)} case. Which of
    the two repair methods seems more effective?\\
    How do you explain this result in the light of what you found in
    step 3.?
  \end{enumerate}
\item
  Now examine the reparations that have been done
  {\({\color[RGB]{102,204,238}{\small\verb;remote;}}\)ly:}

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{7}
  \item
    Before doing any calculations, what do you expect to find? should
    the {\({\color[RGB]{34,136,51}{\small\verb;new;}}\)} repair method
    be more effective than the
    {\({\color[RGB]{34,136,51}{\small\verb;old;}}\)} one, for
    reparations done remotely?
  \item
    Calculate the frequency distribution of the
    {\(\mathit{\color[RGB]{238,102,119}Outcome}\)} variate, conditional
    on
    {\(\mathit{\color[RGB]{34,136,51}Method}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;new;}}\)}
    and
    {\(\mathit{\color[RGB]{102,204,238}Location}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{102,204,238}{\small\verb;remote;}}\).}
  \item
    Calculate the frequency distribution of the
    {\(\mathit{\color[RGB]{238,102,119}Outcome}\)} variate, conditional
    on
    {\(\mathit{\color[RGB]{34,136,51}Method}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;old;}}\)}
    and
    {\(\mathit{\color[RGB]{102,204,238}Location}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{102,204,238}{\small\verb;remote;}}\).}
  \item
    Compare the two conditional frequency distributions for this
    {\({\color[RGB]{102,204,238}{\small\verb;remote;}}\)} case. Which of
    the two repair methods seems more effective?\\
    How do you explain this result in the light of what you found in
    steps 3. and 7.?
  \end{enumerate}
\item
  Summarize and explain all your findings.\\
  Can the repair company claim that the
  {\({\color[RGB]{34,136,51}{\small\verb;new;}}\)} repair method is
  better than the {\({\color[RGB]{34,136,51}{\small\verb;old;}}\)?}\\
\item
  Suppose you need to send an electronic component for repair to this
  company.

  \begin{enumerate}
  \def\labelenumi{\alph{enumi}.}
  \item
    If you could choose both the
    {\(\mathit{\color[RGB]{102,204,238}Location}\)} and the
    {\(\mathit{\color[RGB]{34,136,51}Method}\)} of the repair, which
    would you choose? why?
  \item
    If you could only choose the repair
    {\(\mathit{\color[RGB]{34,136,51}Method}\),} but have no control
    over the {\(\mathit{\color[RGB]{102,204,238}Location}\),} which
    method would you choose? why?
  \end{enumerate}

  Is there other information, missing from the description of the
  population, that should be known before answering the questions above?
\end{itemize}

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{lego_paradox.jpg}

\end{footnotesize}}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  §§2.2--2.4 and 2.7--2.10 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Risk
  Assessment and Decision Analysis with Bayesian Networks}}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{The
  role of exchangeability in inference}} This can be a difficult
  reading. Try to get the main message.
\item
  \href{https://plato.stanford.edu/archives/fall2016/entries/paradox-simpson/}{\emph{Simpson's
  paradox}}
\end{itemize}

\end{tcolorbox}

\chapter{\texorpdfstring{{Infinite populations and
samples}}{Infinite populations and samples}}\label{sec-pop-samples}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand{\yXv}[1]{X^{(#1)}}
\providecommand{\vRI}{\mathit{RI}}
\providecommand{\vCa}{\mathit{Ca}}
\providecommand{\vSi}{\mathit{Si}}
\providecommand{\vType}{\mathit{Type}}

\providecommand{\vage}{\mathit{age}}
\providecommand{\vrace}{\mathit{race}}
\providecommand{\vsex}{\mathit{sex}}
\providecommand{\vincome}{\mathit{income}}
\providecommand{\owhite}{\cat{White}}
\providecommand{\oblack}{\cat{Black}}
\providecommand{\oesk}{\cat{Amer-Indian-Eskimo}}
\providecommand{\oM}{\cat{M}}
\providecommand{\oF}{\cat{F}}
\providecommand{\ohi}{\cat{`>50K'}}
\providecommand{\olo}{\cat{`<=50K'}}

\providecommand{\vOut}{\mathit{\red Outcome}}
\providecommand{\vMet}{\mathit{\green Method}}
\providecommand{\vLoc}{\mathit{\lblue Location}}

\providecommand{\osuccess}{\red\cat{success}}
\providecommand{\ofailure}{\red\cat{fail}}
\providecommand{\onew}{{\green\cat{new}}}
\providecommand{\oold}{{\green\cat{old}}}
\providecommand{\oonsite}{{\lblue\cat{onsite}}}
\providecommand{\oremote}{{\lblue\cat{remote}}}

\providecommand{\yA}{\se{A}}
\providecommand{\yB}{\se{B}}
\providecommand{\fail}{\cat{fail}}
\providecommand{\work}{\cat{work}}
\providecommand{\high}{\cat{high}}
\providecommand{\medium}{\cat{medium}}
\providecommand{\low}{\cat{low}}
\providecommand{\HH}{\mathrm{H}}

\section{Infinite populations}\label{sec-infinite-populations}

The examples of populations that we explored so far comprised a small
number of units, and all their data were exactly and fully known. In
concrete inference and decision problems of the kind we have been
focusing on in chapters~\ref{sec-learning}
and~\ref{sec-3-connection-ML}, we usually deal with populations that are
much larger or potentially infinite; and data are known only for a small
collection of their units.

In the glass-forensic example (table~~\ref{tbl-glass}), for instance,
many more glass fragments could be examined beyond the 10 units reported
there, with no clear bound on the total number. We could even extend
that population considering glass fragments from past and future crime
scenes:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0444}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0778}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0778}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.4222}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2778}}@{}}
\caption{Glass fragments, extended}\label{tbl-glass-ext}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{RI}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Type}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{\emph{notes}}
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
{unit}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{RI}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Ca}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Si}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathit{Type}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
{\emph{notes}}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{1} & \(1.51888\) & \(9.95\) & \(72.50\) & \({\small\verb;tableware;}\)
& \\
{2} & \(1.51556\) & \(9.41\) & \(73.23\) & \({\small\verb;headlamps;}\)
& \\
{3} & \(1.51645\) & \(8.08\) & \(72.65\) &
\({\small\verb;building_windows_non_float_processed;}\) & \\
{4} & \(1.52247\) & \(9.76\) & \(70.26\) & \({\small\verb;headlamps;}\)
& \\
{5} & \(1.51909\) & \(8.78\) & \(71.81\) &
\({\small\verb;building_windows_float_processed;}\) & \\
{6} & \(1.51590\) & \(8.22\) & \(73.10\) &
\({\small\verb;building_windows_non_float_processed;}\) & \\
{7} & \(1.51610\) & \(8.32\) & \(72.69\) &
\({\small\verb;vehicle_windows_float_processed;}\) & \\
{8} & \(1.51673\) & \(8.03\) & \(72.53\) &
\({\small\verb;building_windows_non_float_processed;}\) & \\
{9} & \(1.51915\) & \(10.09\) & \(72.69\) &
\({\small\verb;containers;}\) & \\
{10} & \(1.51651\) & \(9.76\) & \(73.61\) & \({\small\verb;headlamps;}\)
& \\
\ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} \\
{351} & \(1.52101\) & \(8.75\) & \(71.78\) & {?} & {\emph{from
unsolved-crime scene in 1963}} \\
\ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} \\
{1027} & \(1.51761\) & \(7.83\) & \(72.73\) & {?} & {\emph{crime scene
in 2063}} \\
\ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} \\
\end{longtable}

the imaginary example above also shows that the values of some variates
for some units might be unknown; this is a situation we shall discuss in
depth later.

\hfill\break

We shall henceforth focus on statistical populations with a number of
units that is \emph{in principle infinite}, or so large that it can be
considered \emph{practically infinite}. ``Practically'' means that the
number of units we'll use as data or draw inferences about is a very
small fraction, say less than 0.1\%, of the total population size.

{This is often the case. Consider for example (as in
§~\ref{sec-quant-value-dom}) the collection of all possible 128\,×\,128
images with 24-bit
\href{https://www.cambridgeincolour.com/tutorials/bit-depth.htm}{colour
depth}. This collection has
\(2^{24 \times 128 \times 128} \approx 10^{118 370}\) units. Even if we
used 100~billions of such images as data, and wanted to draw inferences
on another 100~billions, these would constitute only
\(10^{-118 357}\,\%\) of the whole collection. This collection is
practically infinite.}

Note that we can't say whether a population, per se, is ``practically
infinite'' or not. It could be practically infinite for a particular
inference problem, but not for another.

When we use the term ``population'' it will often be understood that
we're speaking about a statistical population that is practically
infinite with respect to the inference or decision problem under
consideration.

\section{Limit frequencies}\label{sec-limit-freqs}

In §~\ref{sec-freq-distr} we defined relative frequencies. Relative
frequencies are ratios of two integers, the denominator being the
population size {\(N\).} So a frequency {\(f\)} can only take on
{\(N+1\)} rational values {\(0/N, \dotsc, N/N\)} between {\(0\)} and
{\(1\).} As the population size increases, the number of distinct,
possible frequencies increases and eventually can be considered
practically continuous. Frequencies in this case are sometimes called
\textbf{limit frequencies} and they are treated as real numbers between
{\(0\)} and {\(1\).}

\section{Samples}\label{sec-samples}

\subsection{Learning from samples}\label{learning-from-samples}

In chapters~\ref{sec-learning} and~\ref{sec-3-connection-ML} we
considered an agent that must draw an inference about some units from a
population. The agent's degrees of belief in that inference relied (that
is, were conditional on) units already observed in the population, the
``learning'' or ``training'' data. We saw that the agent's degrees of
belief changed, often becoming sharper, thanks to the information about
the observed units.

Units for which we have full (or almost full) information, and that an
agent can use to update its beliefs, are called a {\textbf{population
sample}} or ``sample'' for short. Almost all data considered in
engineering and data-science problems can be considered to be population
samples.

It is extremely important to \textbf{specify how a sample is extracted
or collected} from a population. For instance, if we consider
table~~\ref{tbl-glass} to be a full population, we could extract a
sample in such a way that {\(\mathit{Type}\)} only has value
{\({\small\verb;headlamps;}\)} (similarly to when we construct a
subpopulation, §~\ref{sec-subpopulations}, but for a subpopulation we
would select \emph{all} units having that variate value). The marginal
frequency of the value {\({\small\verb;headlamps;}\)} in the sample
would then be {\(1\),} whereas in the original population it is
{\(3/10 \approx 0.333\)} -- two very different frequencies.

\subsection{``Representative'' and biased
samples}\label{representative-and-biased-samples}

If samples from a population are used as conditional information to
calculate probabilities about other units, then they should of course be
``relevant'', in some sense (not the technical sense of
chapter~~\ref{sec-info-chapter}), for the inference. The very
\emph{definition} of statistical population
(§~\ref{sec-variates-populations}) is meant to have such a relevance
built-in: the ``similarity'' of the units makes each of them relevant
for inferences about any other.

Still, the procedure with which samples are selected from a population
may lead to quirky and unreasonable inferences. For instance suppose we
are interested in prognosing a disease for a person from a particular
population, having observed a sample of people from the same population.
If the sample was \emph{chosen} to consist only of people having the
disease, then it is obviously meaningless for our inference.

The specific problem in this example is that our inference is based on
guessing a frequency distribution in the full population (as we'll see
more in detail in later chapters), but the sample, owing to the way it
was chosen, cannot show a frequency distribution similar to the
full-population frequency distribution.

\hfill\break

A sampling procedure may generate a sample that is pointless for some
inferences, but still useful for others.

In the inference and decision problems under our focus we would like to
use a sample for which particular frequencies -- most often the full
joint frequency -- don't differ very much from those in the full
population. We'll informally call this a ``{representative sample}''.
This is a difficult notion; the International Organization for
Standardization for instance
\href{https://www.iso.org/obp/ui/\#iso:std:iso:3534:-4:ed-1:v1:en}{warns
(item~3.1.14)}:

\begin{quote}
The notion of representative sample is fraught with controversy, with
some survey practitioners rejecting the term altogether.
\end{quote}

\hfill\break

In many cases it is \emph{impossible} for a sample of given size to be
fully ``representative'':

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Consider the following population of 16 units, with four binary variates
{\(W,X,Y,Z\),} each with values {\(0\)} and {\(1\):}

\begin{longtable}[]{@{}cccc@{}}
\caption{Four-bit population}\label{tbl-four-bit}\tabularnewline
\toprule\noalign{}
\(W\) & \(X\) & \(Y\) & \(Z\) \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\(W\) & \(X\) & \(Y\) & \(Z\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
1 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
1 & 0 & 1 & 0 \\
0 & 1 & 1 & 0 \\
1 & 1 & 1 & 0 \\
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 1 \\
0 & 1 & 0 & 1 \\
1 & 1 & 0 & 1 \\
0 & 0 & 1 & 1 \\
1 & 0 & 1 & 1 \\
0 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 \\
\end{longtable}

The joint variate {\((W,X,Y,Z)\)} has 16 possible values, from
{\((0,0,0,0)\)} to {\((1,1,1,1)\).} Each of these values appear exactly
once in the population, so it has frequency {\(1/16\).} The marginal
frequency distribution for each binary variate is also uniform, with
frequencies of 50\% for both {\(0\)} and {\(1\).}

\begin{itemize}
\tightlist
\item
  Extract a \textbf{representative} sample of size \textbf{four} units.
  In particular, the marginal frequency distributions of the four
  variates should be as close to 50\%/50\% as possible.
\end{itemize}

\end{tcolorbox}

Luckily, the probability calculus allows an agent to draw inferences
also when the sample is too small to correctly reflect full-population
frequencies, if appropriate \emph{background information} is provided.

\hfill\break

Obviously we cannot expect a population sample to exactly reflect all
frequency distributions -- joint, marginal, conditional -- of the
original population; some discrepancy is to be expected. How much
discrepancy should be allowed? And what is the minimal size for a sample
not to exceed such discrepancy?

Information Theory, briefly mentioned in
chapter~~\ref{sec-info-chapter}, can give reasonable answers to these
questions. Let us summarize some examples here.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Chapters~1--10 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Information
  Theory, Inference, and Learning Algorithms}}
\item
  Video lectures~1--9 from the
  \href{http://videolectures.net/course_information_theory_pattern_recognition/}{\emph{Course
  on Information Theory, Pattern Recognition, and Neural Networks}}
\end{itemize}

\end{tcolorbox}

\end{footnotesize}}

First we need to introduce the Shannon entropy of a discrete
\emph{frequency} distribution. It is defined in a way analogous to the
Shannon entropy for a discrete \emph{probability} distribution,
discussed in §~\ref{sec-entropy-mutualinfo}. Lets say the distribution
is {\(\boldsymbol{f} \coloneqq(f_1,f_2, \dotsc)\).} Its Shannon entropy
{\(\mathrm{H}(\boldsymbol{f})\)} is

\[
\mathrm{H}(\boldsymbol{f}) \coloneqq-\sum_{i} f_i\ \log_2 f_i
\qquad\text{\color[RGB]{119,119,119}\small(with \(0\cdot\log 0 \coloneqq 0\))}
\]

and is measured in \textbf{shannons} when the base of the logarithm is
2.

If we have a population with joint frequency distribution
{\(\boldsymbol{f}\),} then a representative sample from it must have at
least size

\[
2^{\mathrm{H}(\boldsymbol{f})} \equiv
\frac{1}{{f_1}^{f_1}\cdot {f_2}^{f_2}\cdot {f_3}^{f_3}\cdot \dotsb}
\]

This particular number has important practical consequences; for example
it is related to the maximum rate at which a communication channel can
send symbols (which can be considered as values of a variate) with an
error as low as we please.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Calculate the Shannon entropy of the joint frequency distribution for
  the four-bit population of table~~\ref{tbl-four-bit}.
\item
  Calculate the minimum representative-sample size according to the
  Shannon-entropy formula. Is the result intuitive?
\end{itemize}

\end{tcolorbox}

\hfill\break

If we are only interested in a smaller number of variates of a
population, then the representative sample can be smaller as well: its
size would be given by the entropy of the corresponding \emph{marginal}
frequency distribution of the variates of interest. In the example of
table~~\ref{tbl-four-bit}, if we are only interested in the variate
{\(X\),} then any sample consisting of two units, one having
{\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}0\)}
and the other having
{\(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}1\),}
would be a representative sample of the marginal frequency distribution
{\(f(X)\).}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Representative
Sampling, I}}

\end{tcolorbox}

A sample that presents some aspects, such as frequency distributions,
which are at variance with the original population, is sometimes called
{biased}. This term is used in many different ways by different authors.
Unfortunately, most samples are ``biased'' in this sense.

The only way to counteract the misleading information given by a biased
sample is to specify appropriate \textbf{background information}, which
comes not from data samples but from a general meta-analysis, often
based on physical, medical, and similar principles, of the problem and
population.

\hfill\break

\subsection{Quirks of samples for mean and standard
deviation}\label{quirks-of-samples-for-mean-and-standard-deviation}

For some populations, the mean and standard deviation calculated in a
sample can be wildly different from those of the full population -- even
when the sample comprises half of the full population! This does not
happen with the median and quartiles. Here is a demonstration in
\texttt{R}. Try it out in your favourite programming language.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Guided exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

We imagine to have a population of 1\,000\,000 units. These units have
continuous interval variates {\(X\)} and {\(Y\),} each with an
approximately standard Gaussian frequency distribution. These variates
are not actual part of the population definition, however. Rather, an
agent only has access to, or maybe it's only interested in, the ratio of
these two variates {\(Z \coloneqq X/Y\).}

The agent is in particular interested in the \emph{mean} of the variate
{\(Z\)} in the full population, but has only access to the values of
{\(Z\)} in a sample. How does the mean calculated from a sample of
increasing size compare with the actual mean of the full population? For
comparison, we also study the \emph{median} of the full population and
of the samples.

First let's create the values of the variates {\(X\)} and {\(Y\),} and
construct {\(Z\)} from them:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Load custom plot functions}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}code/tplotfunctions.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1000}\NormalTok{) }\CommentTok{\# to reproduce results}

\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{1000000} \CommentTok{\# population size}

\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(N) }\CommentTok{\# variate invisible to agent}
\NormalTok{Y }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(N) }\CommentTok{\# variate invisible to agent}

\NormalTok{Z }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{/}\NormalTok{ Y }\CommentTok{\# variate considered by agent}

\DocumentationTok{\#\# mean and median of Z in the full population}
\NormalTok{popmean }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Z)}
\FunctionTok{cat}\NormalTok{(}\StringTok{\textquotesingle{}}\SpecialCharTok{\textbackslash{}n}\StringTok{The full{-}population mean is\textquotesingle{}}\NormalTok{, popmean, }\StringTok{\textquotesingle{}(unknown to the agent)}\SpecialCharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

The full-population mean is -8.04481 (unknown to the agent)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{popmedian }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(Z)}
\FunctionTok{cat}\NormalTok{(}\StringTok{\textquotesingle{}}\SpecialCharTok{\textbackslash{}n}\StringTok{The full{-}population median is\textquotesingle{}}\NormalTok{, popmedian, }\StringTok{\textquotesingle{}(unknown to the agent)}\SpecialCharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

The full-population median is 0.00188701 (unknown to the agent)
\end{verbatim}

Now we imagine that the agent accumulates samples from the population,
starting from 100, increasing by 100 units, until half of the population
has been sampled. At each sample increase the agent calculates the
sample mean. We plot how the sample mean changes with the sample size.
We also plot indicate the full-population mean, which the agent doesn't
know and is trying to guess:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# sizes of successive samples}
\NormalTok{samplesizes }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{100}\NormalTok{, }\AttributeTok{to =}\NormalTok{ N }\SpecialCharTok{/} \DecValTok{2}\NormalTok{, }\AttributeTok{by =} \DecValTok{100}\NormalTok{)}

\DocumentationTok{\#\# empty vectors to contain the means and medians of the increasing samples}
\NormalTok{samplemeans }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\FunctionTok{length}\NormalTok{(samplesizes))}
\NormalTok{samplemedians }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\FunctionTok{length}\NormalTok{(samplesizes))}

\DocumentationTok{\#\# loop through the increasing samples, calculate mean for each}
\ControlFlowTok{for}\NormalTok{(sample }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(samplesizes))\{}
\NormalTok{    samplemeans[sample] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Z[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{samplesizes[sample]])}
\NormalTok{    samplemedians[sample] }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(Z[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{samplesizes[sample]])}

\NormalTok{\}}

\DocumentationTok{\#\# plot how sample means change with sample size, and the actual population mean}
\NormalTok{commonmax }\OtherTok{\textless{}{-}} \FloatTok{1.01} \SpecialCharTok{*} \FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(}\FunctionTok{c}\NormalTok{(popmean, popmedian, samplemeans, samplemedians)))}
\FunctionTok{myflexiplot}\NormalTok{(}\AttributeTok{x =}\NormalTok{ samplesizes, }\AttributeTok{y =}\NormalTok{ samplemeans,}
      \AttributeTok{xlab =} \StringTok{\textquotesingle{}sample size\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}sample mean\textquotesingle{}}\NormalTok{,}
      \AttributeTok{col =} \DecValTok{2}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{4}\NormalTok{,}
      \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{commonmax, commonmax))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ popmean, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{3}\NormalTok{, }\AttributeTok{col =} \DecValTok{7}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\AttributeTok{y =}\NormalTok{ popmean, }\AttributeTok{x =} \FunctionTok{max}\NormalTok{(samplesizes),}
    \AttributeTok{labels =} \StringTok{\textquotesingle{}population mean (unknown to agent)\textquotesingle{}}\NormalTok{,}
    \AttributeTok{adj =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{col =} \DecValTok{7}\NormalTok{, }\AttributeTok{cex =} \FloatTok{1.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{samples_files/figure-pdf/unnamed-chunk-2-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# plot how sample medians change with sample size, and the actual population median}
\FunctionTok{myflexiplot}\NormalTok{(}\AttributeTok{x =}\NormalTok{ samplesizes, }\AttributeTok{y =}\NormalTok{ samplemedians,}
      \AttributeTok{xlab =} \StringTok{\textquotesingle{}sample size\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}sample median\textquotesingle{}}\NormalTok{,}
      \AttributeTok{col =} \DecValTok{3}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{4}\NormalTok{,}
      \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{commonmax, commonmax))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ popmedian, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{3}\NormalTok{, }\AttributeTok{col =} \DecValTok{7}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\AttributeTok{y =}\NormalTok{ popmedian, }\AttributeTok{x =} \FunctionTok{max}\NormalTok{(samplesizes),}
    \AttributeTok{labels =} \StringTok{\textquotesingle{}population median (unknown to agent)\textquotesingle{}}\NormalTok{,}
    \AttributeTok{adj =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{col =} \DecValTok{7}\NormalTok{, }\AttributeTok{cex =} \FloatTok{1.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{samples_files/figure-pdf/unnamed-chunk-2-2.pdf}}

Test this again with several pseudorandom seeds.

\hfill\break

\begin{itemize}
\tightlist
\item
  Now try a similar exercise but for the standard deviation of \(Z\)
\end{itemize}

\end{tcolorbox}

\part{{\textbf{Machine learning}}}

\chapter{Introduction to machine learning}\label{sec-ml-introduction}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

So far we have learned about concepts of doing inference, and about
various properties of data, and probability distributions. Now it is
time to combine them into a simplified mathematical {\textbf{model}},
that can use data from the past to make predictions about the unknown.
Note that for the chapters in this part we are not building an
\emph{optimal} predictor machine anymore, but rather a
\emph{approximate} one, which serves the common operational constraint
of being fast to compute.

Machine learning methods can be wildly different both in terms of
operation and complexity. But they all behave as functions that take in
a data point {\(x\),} a set of values {\(\mathbf{w}\)} which we call
{\textbf{parameters}}, and returns the prediction {\(\hat{y}\):}

\begin{equation}\phantomsection\label{eq-model-as-function}{ 
    \hat{y} = f(x, \mathbf{w}).
}\end{equation}

The prediction {\(\hat{y}\)} can be any quantity discussed in
section~\ref{sec-basic-types} -- most commonly we want to classify the
data (and we say we are doing {\emph{classification}}), or we want to
estimate some value (in which case we call it {\emph{regression}}).

It has been pointed out already -- and we will see it also in the coming
chapters -- that often there \emph{is actually not} a functional
relationship between the inputs {\(\mathbf{x}\),} and the property we
want to predict. This leaves us with two possibilities for a solution:

\begin{itemize}
\tightlist
\item
  If there is an \emph{approximate} functional relationship, we can
  write an analytical function to model that. More specifically, we can
  write a \textbf{deterministic} function, which for a given input \(x\)
  will repeatedly give an output \(y\). Common machine learning methods
  will work well here.
\item
  If there is \emph{no} functional relationship, it does not make sense
  to make a model that tries to enforce one. Instead of having a model
  that outputs a deterministic value, we need instead, is one that
  outputs a probability distribution.
\end{itemize}

Because of the second point above, when we describe equation
\ref{eq-model-as-function}, we will use the word ``function'' in the
wide sense where we allow it to be non-deterministic. An example is
\href{https://chat.openai.com/}{ChatGPT}, which will answer you
differently if you ask it the same exact question twice. If you prefer
more mathematical rigour, we could call {\(f\)} a \emph{process}
instead, which is a more loose term.

Let us break down equation \ref{eq-model-as-function}. As engineers,
when faced with the task of using data to model the behaviour of some
system, our job is twofold. First, we need to select a suitable method
to serve as the function {\(f\),} and second, we need to find the
optimal values for the parameters {\(\mathbf{w}\).} In
\href{https://www.hvl.no/en/studies-at-hvl/study-programmes/courses/2023/ADA501}{ADA501}
we will see how to choose an analytical {\(f\)} that corresponds to
certain physical systems, while in our course, we will look at methods
where {\(f\)} can be practically anything.

Finding the parameters {\(\mathbf{w}\)} is what takes us from a general
method, to the specific solution to a problem. As we will see, the way
of finding them differs between the various machine learning methods,
but the principle is always the same: We need to choose a {\textbf{loss
function}}, and then iteratively adjust {\(\mathbf{w}\)} so that the
loss, when computed on known data, becomes as small as possible. The
loss function should represent the difference between what the model
outputs, and the correct answer -- the better the model, the smaller the
difference. The choice of this loss function depends on what kind of
problem we wish to solve, and we will look at the common ones shortly.
But at this point we can already define the three main types of machine
learning:

\begin{itemize}
\tightlist
\item
  If we know the ``correct answers'' (the labels) for all entries in our
  data set, this is what the model should aim to learn, and we call it
  \textbf{supervised learning}.
\item
  If we do not have the data labels, we can still write a loss function
  corresponding to what we want the model to do with the data. Most
  commonly, we want to find groups, or \emph{clusters}, of
  similar-looking data points. If we provide a way of computing scores
  for good clusters, the model is left to find cluster labels by it
  self, and we call it \textbf{unsupervised learning}.
\item
  If the decision of a model on one data point affects the value of
  future data points, like for a self-driving car that may turn left and
  crash, or turn right and follow the road, we need a loss function that
  penalises certain actions and rewards others. This is called
  \textbf{reinforcement learning}.
\end{itemize}

Having decided on a method to represent {\(f\)} and found a set of
parameters {\(\mathbf{w}\),} we say that these combined now constitute
our {\textbf{model}}. The model should have internalised the important
correlations in the data and thereby allows us to make predictions,
i.e.~do {\emph{modelling}}. If we do decision-making based on the output
of the model as well, we typically call in an {\textbf{agent}}, since
there is now some level of autonomy involved. In this chapter, however,
we will stick to modelling problems in a supervised fashion.

\section{Hyperparameters and model
complexity}\label{hyperparameters-and-model-complexity}

You may have heard the quote by statistician George Box:

\begin{quote}
All models are wrong, but some are useful.
\end{quote}

Although coming off as a somewhat negative view on things, the quote
still captures an important point about statistical modelling -- our
goal is not to make a complete, 100\% accurate description of reality,
but rather a simplified description that is meaningful in the context of
our task at hand. The ``correct'' level of simplicity, in other words
the optimal number of parameters {\(\mathbf{w}\),} can be hard to find.
Often it will be influenced by practical considerations such as time and
computing power, but it is \emph{always} governed by the amount of data
we have available. We will look at the theory of model selection later,
but let us first consider a visual example, from which we can define
some important concepts.

Imagine that you don't have a thermometer that shows the outside
temperature. Never knowing whether you should wear a jacket or not when
leaving the house, you get a great idea: If you can construct a
mathematical model for the outside temperature as a function of the time
of day, then a look at the clock yould be enough to decide for or
against bringing a jacket. You manage to borrow a thermometer for a day,
and make ten measurements at different times, which will form the basis
for the model:

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{machine_learning_overview_files/figure-latex/over_and_underfitting-fig-simple-measurements-output-1.png}}

}

\caption{\label{fig-simple-measurements}Temperature measurements over
the course of 24 hours.}

\end{figure}%

The next step is to choose a function {\(f\).} For one-dimensional data
like this, we could for instance select among the group of polynomials,
of the form

\[
    f (x, \mathbf{w}) = w_0 + w_1 x + w_2 x^2 + \dots + w_M x^M = \sum_{j=0}^{M} w_j x^j \,,
\]

where {\(M\)} is the order of the polynomial. Recall that a zero'th
order polymonial is just a constant value, so such a model would be
represented with one single parameter. A first-order polynomial is a
linear function (two parameters), and the higher in order (and number of
parameters) we go, the more ``curves'' the function can have. This
already presents us with a problem. Which order polynomial (i.e.~which
value of {\(M\))} should we choose? Let us try different ones, and for
each case, \emph{fit} the parameters, meaning we find the parameter
values that yield the smallest difference from the measured data points:

\begin{figure}

\begin{minipage}{0.50\linewidth}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{machine_learning_overview_files/figure-latex/over_and_underfitting-fig-polynomial-fit-output-1.png}}

}

\subcaption{\label{fig-polynomial-fit-1}Zeroth-order polymonial}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{machine_learning_overview_files/figure-latex/over_and_underfitting-fig-polynomial-fit-output-2.png}}

}

\subcaption{\label{fig-polynomial-fit-2}First-order polymonial}

\end{minipage}%
\newline
\begin{minipage}{0.50\linewidth}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{machine_learning_overview_files/figure-latex/over_and_underfitting-fig-polynomial-fit-output-3.png}}

}

\subcaption{\label{fig-polynomial-fit-3}Fourth-order polymonial}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{machine_learning_overview_files/figure-latex/over_and_underfitting-fig-polynomial-fit-output-4.png}}

}

\subcaption{\label{fig-polynomial-fit-4}Ninth-order polymonial}

\end{minipage}%

\caption{\label{fig-polynomial-fit}Fitting polymonials (red lines) of
different orders to the set of measurements (blue circles).}

\end{figure}%

Obviously, the constant function does a poor job of describing our data,
and likewise for the linear function. A fourth-order polynomial, on the
other hand, looks very reasonable. Now consider the ninth-order
polynomial: it matches the measurements \emph{perfectly}, but surely,
this does not match our expectation for what the temperature should look
like.

We say that the first and second model \textbf{underfit} the data. This
can happen for two reasons: Either the model has too little complexity
to be able to describe the data (which is the case in this example), or,
potentially, the optimal parameter values have not been found. The
opposite case is \textbf{overfitting}, as shown for the last model,
where the complexity is too high and the model adapts to artifacts in
the data.

This concept is also called the {\textbf{bias-variance tradeoff}}. We
will not go into too much detail on this yet, but qualitatively, we can
say that {\emph{bias}} (used in this setting) is the difference between
the predicted value and the true value, when averaging over different
data sets. {\emph{Variance}} (again when used in this setting) indicates
how big the change in parameters, and hence in model predictions, we get
from fitting to different data sets. Let us say you measure the
temperature on ten different days, and for each day, you fit a model,
like before. These may be the results:

\begin{figure}

\begin{minipage}{0.33\linewidth}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{machine_learning_overview_files/figure-latex/over_and_underfitting-fig-bias-variance-tradeoff-output-1.png}}

}

\subcaption{\label{fig-bias-variance-tradeoff-1}Large bias, low
variance}

\end{minipage}%
%
\begin{minipage}{0.33\linewidth}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{machine_learning_overview_files/figure-latex/over_and_underfitting-fig-bias-variance-tradeoff-output-2.png}}

}

\subcaption{\label{fig-bias-variance-tradeoff-2}Resonably low bias and
variance}

\end{minipage}%
%
\begin{minipage}{0.33\linewidth}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{machine_learning_overview_files/figure-latex/over_and_underfitting-fig-bias-variance-tradeoff-output-3.png}}

}

\subcaption{\label{fig-bias-variance-tradeoff-3}Low bias, large
variance}

\end{minipage}%

\caption{\label{fig-bias-variance-tradeoff}Red lines: Different models
fitted to separate datasets, where each dataset is drawn from the same
distribution as the original one. The original dataset shown in blue
circles.}

\end{figure}%

The blue dots are our ``original'' data points, plotted for reference,
while the red lines corresponds to models fitted for each day's
measurements. Due to fluctuations in the measurements, they are
different, but note how the difference is related to the model
complexity. Our linear models ({\(M=1\))} are all quite similar, but
neither capture the pattern in the data very well, so they all have high
bias. The overly complex models ({\(M=9\))} have zero bias on their
repective dataset, but high variance. The optimal choice is likely
somewhere in-between (hence the \emph{tradeoff}), as for the {\(M=4\)}
models, which perform well without being overly sensitive to
fluctuations in data. Since the value of {\(M\)} is chosen by us, we
call it a {\textbf{hyperparameter}}, to separate it from the regular
parameters which are optimised by minimising the loss function.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{14}
\item
  Our simple temperature model relies on a series of assumptions, some
  which might be good, and some which might be (very) bad. State the
  ones you can think of, and evaluate if they are sensible. \emph{Hints:
  are polynomials a good choice for \(f\)? Is the data representative?}
\item
  For the different models in figure~\ref{fig-polynomial-fit} we started
  by choosing polymonial degree {\(M\),} and then computed the
  parameters that minimized the difference between the data points and
  the model. Then we had a look at the results, compared them to our
  expectations, and decided that {\(M=0\)} and {\(M=9\)} were both
  unlikely. Can you think of a way to incorporate our initial
  expectations into the computation?
\end{enumerate}

\end{tcolorbox}

\section{Model selection (in
practice)}\label{model-selection-in-practice}

As alluded to in the exercises above, there are ways of including both
the data and our prior expectations when building a model, but it is, in
fact, not very common to do so. In this section we will have a look at
the typical \emph{data science} approach, which relies on splitting the
data in different sets. Starting from all our available data on a given
problem that we wish to model, we divide it into

\begin{itemize}
\tightlist
\item
  the {\emph{training set}}, which is the data we will use to determine
  the model parameters \(\mathbf{w}\),
\item
  the {\emph{validation set}}, which is used to evaluate the model
  complexity (i.e.~finding the optimal bias-variance tradeoff), and
\item
  the {\emph{test set}}, which is used to evaluate the final performance
  of the model.
\end{itemize}

The benefit of this approach is that it is very simple to do. The
downside, on the other hand, is that each set is necessarily smaller
than the total, which subjects us to increased statistical uncertainty.
The final parameters will be slightly less optimal than they could have
been, and the measurement of the performance will be slightly less
accurate. Still, it is common practice, and for the ``standard'' machine
learning methods there is no direct way of simultaneously optimising for
the model complexity.

\section{Machine learning taxonomy}\label{machine-learning-taxonomy}

Machine learning has been around for many decades, and the list of
methods that fit under our simple definition of looking like equation
\ref{eq-model-as-function} and learning their parameters from data, is
very long. For a (non-exhaustive) systematic list, have a look at the
methods that are implemented in
\href{https://scikit-learn.org/stable/supervised_learning.html\#supervised-learning}{scikit-learn},
a Python library dedicated to data analysis.

In this course we will not try to go through all of them, but rather
focus on the fundamentals of what they all have in common. With this
fundamental understanding, learning about new methods is like learning a
new programming language -- each has their specific syntax and specific
uses, but the underlying mechanism is the same. We will look at two
important methods, that are inherently very different, but still
accomplish the same end result. The first is decision trees (and the
extension into \emph{random forests}), while the second is neural
networks.

\chapter{Neural networks}\label{neural-networks}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

Neural networks are performing extremely well on complex tasks such as
language modelling and realistic image generation, although the
principle behind how they work, is quite simple.

The basic building block is a \textbf{node}, which receives some values
as input, and computes a single output:

\begin{figure}

\centering{

\includegraphics[width=4.16667in,height=\textheight,keepaspectratio]{fig_neural_network_node.png}

}

\caption{\label{fig-neural-network-node}}

\end{figure}%

The output is computed from the inputs {\(x_0, x_1, \dots, x_N\),} each
of which is multiplied by a weight {\(w_1, w_2, \dots w_N\),} and summed
together along with an additional parameter {\(b\),} which is typically
called a \emph{bias}. You can probably identify this step as good old
linear regression:

\[
a = b + \sum_{i=0}^N w_i x_i \,.
\]

A key property to neural networks, however, is to introduce
\emph{nonlinear} relationships. This is done by evaluating the output
from each node by an \textbf{activation function} {\(h\).} The final
output {\(z\)} from the node is then

\[
z = h(a) = h \left( b + \sum_{i=0}^N w_i x_i \right)
\]

The activation function is typically rather simple -- the most popular
is the rectified linear unit (ReLU), which propagates positive values
but sets all negative values to zero:

\[
\text{ReLU}(x) = \max(0, x) \,.
\]

Various other possibilities for choice of activation function exists, as
we will explore in the exercises later.

Armed with our simple node, let us assemble several of them into a
network. Starting with, say, four nodes, all the input data will be used
by each of them: (todo) mention layers

Neural networks are great for several reasons. They can be arranged to
work with practically any type of data, including \emph{unstructured}
data such as images or text, which is not neatly organised into a table
of explicit feature values. Granted, this flexibility does not appear by
(FIGURE) alone, but is due to clever additions to the network structure
that is beyond the scope of our lectures. A more theoretical argument
for neural networks comes from the {\emph{universal approximation
theorem}}, which states that

\begin{quote}
A neural network with a single hidden layer can be used to approximate
\emph{any} continuous function to \emph{any} precision.
\end{quote}

This is a very powerful property, which is explained in understandable
terms \href{http://neuralnetworksanddeeplearning.com/chap4.html}{here}
(the proof (CITE) is rather technical). But, as we know already, this
only helps if we are trying to model something which has a functional
relationship.

\section{Training neural networks}\label{training-neural-networks}

Finding the optimal values of the model's parameters {\(\mathbf{w}\)} is
usually called to \emph{train} the model. When we looked at polynomials
in the machine learning introduction (Chapter~\ref{sec-ml-introduction})
we did not talk about this yet, partly because polynomial models have a
closed-form solution for the best parameters, meaning they can be
computed directly. Since neural networks are nonlinear by design, we
need a different approach, which it to start with random parameter
values and iteratively try to improve them.

\subsection{Loss functions}\label{loss-functions}

The first step towards improving the parameters, is to define what
improvement is. Ultimately, our goal is to make predictions about the
data that equal the true values, which is to say, we want to minimise
the difference between predictions {\(f(\mathbf{x}, \mathbf{w}\)} and
true values {\(y\).} This difference can be formulated in several
different ways, but in the case of regression, the most common is the
sum of squared errors:

\[
L(\mathbf{w}) = \sum_{\text{data points } i} (f(\mathbf{x}_i, \mathbf{w}) - y_i)^2
\]

\(L\) is called a {\textbf{loss function}}, alternatively a \emph{cost}
function or an \emph{error} function. With this in place, the training
process becomes a minimisation problem:

\begin{equation}\phantomsection\label{eq-loss-minimisation}{
\underset{\mathbf{w}}{\mathrm{arg\,min}}\, L(\mathbf{w}) \,,
}\end{equation}

To minimise the loss function we still need to apply it to some data
{\(\mathbf{x}\),} but we have not made this dependence explicit, since
the data are ``unchanged'' throughout the minimisation process.

As for any bounded function, the minimum can be found either where the
\href{https://mathworld.wolfram.com/Gradient.html}{gradient}
{\(\nabla L(\mathbf{w})\)} is zero, or where it does not exist. Solving
this analytically is usually impossible, so we resort to a numerical
solution -- iteratively taking steps in the direction of smaller loss.
The crucial point in neural network training is that the loss function
is differentiable with respect to the network parameters, meaning we can
compute {\(\nabla L(\mathbf{w})\)} and take steps in the negative
(downwards) direction:

\begin{equation}\phantomsection\label{eq-gradient-descent}{
    \mathbf{w}^{n+1} = \mathbf{w}^{n} - \eta \nabla L(\mathbf{w}^{n}) \,.
}\end{equation}

This is the method of {\textbf{gradient descent}}. Here we have
introduced a new hyperparameter {\(\eta\)} called the \emph{learning
rate}, which controls how large each step will be.

The process of actually adjusting the parameters in the correct
direction is called {\textbf{backpropagation}}, and involves first
computing the value of {\(f(\mathbf{x}, \mathbf{w})\),} and then
stepping backwards through each layer of the network, recursively
updating the parameters by using the derivative. This sounds very
tedious, but can be done efficiently by \emph{automatic
differentiation}, i.e.~letting a computer do it. Modern frameworks for
neural network models require only to know the layout of the network,
and will, as we shall see in the exercises, figure out the rest
automatically.

\subsection{Gradient descent}\label{gradient-descent}

While we did not get into it earlier, the concept of defining a loss
function and doing gradient descent, is in fact how the majority of
machine learning algorithms are trained. Even for decision trees, which
had their dedicated algorith, we ended up with a loss minimisation task
once we introduced boosting.

Straight-forward gradient descent as shown in equation
\{\ref{eq-gradient-descent}\} can work fine for relatively simple
models, but will stop at the first minimum it encounters. For a
reasonably complicated network, the loss function landscape can be
expected to have several local minima or saddle points, causing the
method to get stuck in places with suboptimal parameters. Several
improved algorithms aim to tackle this.

\begin{itemize}
\tightlist
\item
  \emph{Stochastic} gradient descent updates the parameters through
  equation \{\ref{eq-gradient-descent}\} for only a subset of data at a
  time. This is more computationally efficient, and the stochastic
  element helps against getting stuck in a local minimum, since a local
  minimum for some subset of data might not be a minimum for a different
  subset.
\item
  \emph{Adaptive} gradient methods use different learning rates per
  parameter, which is updated for each iteration.
\item
  \emph{Momentum} methods remember the previous gradients and keeps
  moving in the same direction even through flat or uphill parts, like a
  massive rolling ball.
\end{itemize}

All of the above can be combined, and the most common method of doing so
is the Adaptive Moment Estimation (Adam) algorithm.

\chapter{\texorpdfstring{Preventing overfitting -
\emph{regularisation}}{Preventing overfitting - regularisation}}\label{preventing-overfitting---regularisation}

In the previous chapter, we had several ways of limiting decision trees
so they would not overfit to the training data. Many apply also here,
but having introduced the concept of loss functions, we will add a
general approach.

First, limiting complexity by tuning hyperparameters, is always an
option. For a standard network, we can adjust the number of layers and
the number of nodes per layer. Making good guesses about the
architecture of the network is difficult, so a \emph{hyperparameter
search} if often necessary to develop a performant model.

Secondly, similar to random forests, one can make ensembles of models,
trained on subsets (with replacement) of the data. For neural networks,
however, this is less common, since the network is sort of an ensemble
by itself. But remember that for random forests we also randomly dropped
some of the features during training. The equivalent for neural networks
is to randomly drop \emph{nodes}, by zeroing their output for a single
training iteration. This is called \textbf{dropout}.

Lastly, let us introduce general regularisation, which is based on
modifying the loss function. This means it can be applied to any machine
learning algorithm that minimises loss, and is not specific to the
algorithm itself. What we want to do is to add a term in the loss
function that penalises large parameter values. This way we do not need
to restrict the explicit complexity of the model by changing the
structure, but we rather restrict the ``volume'' the parameters can span
out. The minimisation problem in equation \{\ref{eq-loss-minimisation}\}
then becomes

\begin{equation}\phantomsection\label{eq-loss-with-regularisation}{
\underset{\mathbf{w}}{\mathrm{arg\,min}}\, L(\mathbf{w}) + \alpha ||\mathbf{w}||_p \,,
}\end{equation}

where the last part is the regularisation term, whose strength is
controlled by a new hyperparameter, {\(\alpha\).} There are different
ways of quantifying the values of the parameters {\(\mathbf{w}\)} -- in
the above equation we have written it generally as an {\(p\)-norm,} but
to actually compute the value, we need to decide on which norm to use.
The options are

\begin{itemize}
\tightlist
\item
  \(L^0\), or the zero norm: Defined as the number of parameters with
  non-zero values. Minimizing this would be similar to going into the
  model and removing parameters by hand. Unfortunately, as an
  optimisation task, this is extremely difficult and is just not a
  practical option.
\item
  \(L^1\), which is the sum of the absolute values of the parameters:
  \(||\mathbf{w}||_1 = \sum_i |w_i|\). This is in statistics known as
  \emph{Lasso} regularisation.
\item
  \(L^2\), which is the Euclidean distance:
  \(||\mathbf{w}||_2 = \sum_i w_i^2\). This is also known as
  \emph{ridge} regularisation, and is perhaps the most commonly used.
\end{itemize}

The \texttt{scikit-learn}
\href{https://scikit-learn.org/stable/modules/neural_networks_supervised.html}{User
Guide} has a nice example showing the effect of {\(L^2\)} regularisation
for varying regularisation strength:

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{mlp_regularisation_sklearn.png}}

}

\caption{\label{fig-mlp-regularisation-sklearn}}

\end{figure}%

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises:}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{16}
\item
  \textbf{Regression}: Follow the code examples in this notebook:
  \href{https://github.com/pglpm/ADA511/blob/master/code/neural_network_regression.ipynb}{neural\_network\_regression.ipynb}
\item
  \textbf{Classification}: Follow the code examples in this notebook:
  \href{https://github.com/pglpm/ADA511/blob/master/code/neural_network_classification.ipynb}{neural\_network\_classification.ipynb}
\item
  \textbf{Real-world dataset classification}: Make another attempt on
  the {Adult Income} dataset, this time using neural networks. Can you
  beat the tree-based models from last week? The training data are here:
  \texttt{https://github.com/pglpm/ADA511/raw/master/datasets/train-income\_data\_nominal\_nomissing.csv},
  while the test data are here:
  \texttt{https://github.com/pglpm/ADA511/raw/master/datasets/test-income\_data\_nominal\_nomissing.csv}
\end{enumerate}

\end{tcolorbox}

\chapter{}\label{section-18}

\part{{\textbf{Inference III}}}

\chapter{\texorpdfstring{{Beyond machine
learning}}{Beyond machine learning}}\label{sec-beyond-ML}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\ys}{\se{s}}
\providecommand*{\yh}{\se{h}}
\providecommand*{\yf}{\se{f}}
\providecommand*{\yv}{\se{v}}
\providecommand*{\yJ}{\se{J}}
\providecommand*{\yZ}{\se{Z}}
\providecommand*{\yH}{\se{H}}

\providecommand*{\bZ}{{\blue Z}}
\providecommand*{\bz}{{\blue z}}
\providecommand*{\rY}{{\red Y}}
\providecommand*{\bY}{{\blue Y}}
\providecommand*{\ry}{{\red y}}
\providecommand*{\gX}{{\green X}}
\providecommand*{\bX}{{\blue X}}
\providecommand*{\gx}{{\green x}}

\section{Machine learning from a bird's-eye
view}\label{sec-ML-birds-eye}

The last few chapters gave a brief introduction to and overview of
popular machine-learning methods, their terminology, and the points of
view that they typically adopt. Now let's try to look at them keeping in
mind our main goal in this course: \href{index.html}{exploring new
inference methods, understanding their foundations, and thinking out of
the box}.

In this and the next few chapters we shall focus on the following
question: {\emph{to what purpose do we use machine-learning
algorithms?}}. After answering this question and clarifying what the
purpose is, we shall try to achieve it in an \emph{optimal way},
according to the methods and concepts we studied in the initial part of
the course. Remember that they are guaranteed to give the optimal
solution (chapter~~\ref{sec-framework}). But we shall keep an eye open
to see where our optimal methods seem to be similar or dissimilar to
machine-learning methods.

Thereafetr, in the last chapters, we shall examine where the optimal
solution and machine-learning methods converge and diverge, try to
understand what machine-learning methods do from the point of view of
our optimal solution, and think of ways to improve them.

\section{A task-oriented categorization of some machine-learning
problems}\label{sec-cat-problems}

For our goal, the common machine-learning categorization and terminology
discussed in chapter~~\ref{sec-ml-introduction} are somewhat inadequate.
Distinctions such as ``supervised learning'' vs ``unsupervised
learning'' are of secondary importance to a data engineer (as opposed to
a \href{preface.html}{``data mechanic''}) for several reasons:

\begin{itemize}
\item
  \faIcon{shuffle}~~They group together some types of tasks that are
  actually quite different from an inferential or decision-making
  viewpoint; and conversely they separate types of tasks that are quite
  similar.
\item
  \faIcon{bullseye}~~They focus on procedures rather than on purposes.
\end{itemize}

The important questions for us, in fact, are: {\emph{What do we wish to
infer or choose?}} and {\emph{From which kind of information?}} These
questions define the problem we want to solve.

Let's introduce a different categorization of the kind of tasks that we
want to accomplish; a categorization that tries to focus on the purpose
or task, and on the types of desired information and of available
information, rather than on the procedure.

The categorization below is informal. It only provides a starting point
from which to examine a new kind of task we may face. Many tasks will
fall in between categories: every data-engineering or data-science
problem is unique.

\hfill\break
We \emph{exclude} from the start all tasks that require an agent to
continuously and actively interact with its environment for acquiring
information, making choices, getting feedback, and so on. Clearly these
tasks are the domain of Decision Theory in its most complex form, with
ramified decisions, \emph{strategies}, and possibly the interaction with
other decision-making agents. To explore and analyse this kind of tasks
is beyond the purpose of this course.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Decision
  Analysis}}
\item
  Chapters 16--18 in
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Games
  and Decisions}}
\end{itemize}

\end{tcolorbox}

\end{footnotesize}}

\hfill\break
We focus on tasks where multiple ``instances'' with similar
characteristics are involved, and the agent has some question related to
a ``new instance''. According to the conceptual framework developed in
part {Data~II}, we can view these ``instances'' as \emph{units} of a
practically infinite population. The ``characteristics'' that the agent
has observed or must guess are \emph{variates} common to all these
units.

\marginnote{\begin{footnotesize}

Remember that you can adopt any terminology you like. If you prefer
``instance'' and ``characteristics'' or some other words to ``unit'' and
``variate'', then use them. What's important is that you understand the
ideas and methods behind these words

\end{footnotesize}}

\subsection{New unit: given vs
generated}\label{new-unit-given-vs-generated}

A first distinction can be made between

\begin{itemize}
\item
  {\faIcon{sign-out-alt} \faIcon{cube}~~Tasks where an agent must itself
  \emph{generate} a new unit}
\item
  {\faIcon{cube} \faIcon{question}~~Tasks where a new unit is given to
  an agent, who must \emph{guess} some of its variates}
\end{itemize}

An example of the first type of task is image generation: an algorithm
is given a collection of images and is asked to generate a new image
based on them.

We shall see that these two types of task are actually quite close to
each other, from the point of view of Decision Theory and Probability
Theory.

The terms ``discriminative'' and ``generative'' are sometimes associated
in machine learning with the two types of task. This association,
however, is quite loose, because some tasks typically called
``generative'' actually belong to the first type. We shall therefore
avoid these terms. It's enough to keep in mind the distinction between
the two types of task above.

\subsection{Guessing variates: all or
some}\label{guessing-variates-all-or-some}

Focusing on the second type of task (a new unit is given to the agent),
we can further divide it into two subtypes:

\begin{itemize}
\item
  {\faIcon{star}~~The agent must guess \emph{all} variates of the new
  unit}
\item
  {\faIcon{star-half-alt}~~The agent must guess \emph{some} variates of
  the new unit, but can observe other variates of the new unit}
\end{itemize}

An example of the first subtype of task is the ``urgent vs non-urgent''
problem of §~\ref{sec-conditional-joint-sim}: having observed incoming
patients, some of which where urgent and some non-urgent, the agent must
guess whether the next incoming patient will be urgent or not. No other
kinds of information (transport, patient characteristics, or others) are
available.

We shall call {\textbf{predictands}}\footnote{literally ``what has to be
  predicted''} the variates that the agent must guess in a new unit, and
{\textbf{predictors}} those that the agent can observe.\footnote{In
  machine learning and other fields, the terms ``dependent variable'',
  ``class'' or ``label'' (for nominal variates) are often used for
  ``predictand''; and the terms ``independent variable'' or ``features''
  are often used for ``predictor''.} The first subtype above can be
viewed as a special case of the second where all variates are
predictands, and there are no predictors.

The terms ``unsupervised learning'' and ``supervised learning'' are
sometimes associated in machine learning with these two subtypes of
task. But the association is loose and can be misleading. ``Clustering''
tasks, for example, are usually called ``unsupervised'' but they are
examples of the second subtype above, where the agent has some
predictors.

\subsection{Information available in previous
units}\label{information-available-in-previous-units}

Finally we can further divide the second subtype above into two or three
subsubtypes, depending on the information available to the agent about
\emph{previous units}:

\begin{itemize}
\item
  {\faIcon{star-half-alt} \faIcon{star-half-alt}~~All predictors and
  predictands of previous units are known to the agent}
\item
  {\faIcon{star-half} \faIcon{star-half}~~All predictors of previous
  units, but not the predictands, are known to the agent}
\item
  {\faIcon{star-half} \faIcon{star-half}~~All predictands of previous
  units, but not the predictors, are known to the agent}
\end{itemize}

\hfill\break

An example of the first subsubtype of task is image classification. The
agent is for example given the following 128\,×\,128-pixel images and
character-labels from the \href{https://onepunchman.fandom.com}{One
Punch Man} series:

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{saitama_images.png}

and is then given one new 128\,×\,128-pixel image:

\begin{center}
\includegraphics[width=1.33333in,height=\textheight,keepaspectratio]{saitama_new.png}
\end{center}

of which it must guess the character-label.

In the example just given, the image is the predictor, the
character-label is the predictand.

\hfill\break

A slight modification of the example above gives us a task of the second
subsubtype. A different agent is given the images above, \emph{but
without labels}:

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{saitama_images_nolabels.png}

and must then guess some kind of ``label'' or ``group'' for the new
image above; and possibly also for the images already given. The kind of
``group'' requested depends on the specific problem.

In this example the image is the predictor, and the label or group is
the predictand. The difference from the previous example is that the
agent doesn't have the predictand values of previous units.

The term ``supervised learning'' typically refer to the first subsubtype
above.

The term ``unsupervised learning'' can refer to the second subsubtype,
for instance in ``clustering'' tasks. In a clustering task, the agent
tries to guess which group or ``cluster'' a unit belong to, given a
collection of similar units, whose groups are not known either. The
cluster effectively is the \emph{predictand} variate. In some cases the
agent may want to guess the cluster not only of a new unit, but also of
all previous units.

The third subsubtype is very rarely considered in machine learning, yet
it is not an unrealistic task.

The types, subtypes, subsubtypes above are obviously not mutually
exclusive or comprehensive. We can easily imagine scenarios where an
agent has some predictors \& predictands available about \emph{some}
previous units, but only predictors or only predictands available for
other previous units. This scenario falls in between the three
subsubtypes above. In machine learning, hybrid situations like these are
categorized as ``missing data'' or ``imputation''.

\section{Flexible categorization using probability
theory}\label{sec-categ-probtheory}

We have been speaking about the agent's guessing the values of some
variates. ``Guessing'' means that there's a state of \emph{uncertainty}:
the agent can't simply say something like ``the value of the label is
\texttt{Saitama}'', because that could be false. Uncertainty means that
the most honest thing that the agent can do is to express \emph{degrees
of belief} about each of the possible values. Probability theory enters
the scene.

In fact it turns out that the categorization above into subtypes and
subsubtypes of tasks can be presented in a more straightforward and
flexible way using probability-theory notation.

\subsection{Notation}\label{notation-1}

First let's introduce some symbol conventions to be used in the next
chapters.

\begin{itemize}
\tightlist
\item
  We shall denote with \({\color[RGB]{68,119,170}Z}\) all variates that
  are of interest to the agent: those to be guessed as well as those
  that may be already known.
\item
  The variates to be guessed in a new unit (the predictands) will be
  collectively denoted with \({\color[RGB]{68,119,170}Y}\).
\item
  The variates that can be observed in a new unit (the predictors) will
  be collectively denoted with \({\color[RGB]{68,119,170}X}\). In cases
  where there are no predictors, \({\color[RGB]{68,119,170}X}\) is
  empty.
\end{itemize}

Therefore we have
{\({\color[RGB]{68,119,170}Z}= ({\color[RGB]{68,119,170}Y}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{68,119,170}X})\).}
In cases where there are no predictors we have
{\({\color[RGB]{68,119,170}Z}= {\color[RGB]{68,119,170}Y}\).}

\begin{itemize}
\tightlist
\item
  \({\color[RGB]{68,119,170}Z}_i\)~~denote all variates for unit
  {\#\(i\).}
\item
  \({\color[RGB]{68,119,170}Y}_i\)~~denote all predictands for unit
  {\#\(i\).}
\item
  \({\color[RGB]{68,119,170}X}_i\)~~denote all predictors for unit
  {\#\(i\).}
\end{itemize}

As usual we number from~~{\(i=1\)~~to~~}{\(i=N\)~~the} units that serve
for learning, and~~{\(i=N+1\)~~is} the \emph{new} unit of interest to
the agent.

Recall (§~\ref{sec-basic-elements-inference}) that in probability
notation

\[\mathrm{P}(\text{\color[RGB]{238,102,119}\small[proposal]}\nonscript\:\vert\nonscript\:\mathopen{}\text{\color[RGB]{34,136,51}\small[conditional]} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\]

the {proposal} contains what the agent's belief is about, and the
{conditional} contains what's supposed to be known to the agent,
together with the background {information \(\mathsfit{I}\).}

\hfill\break
Finally let's see how to express different typologies of tasks in
probability notation.

\hfill\break

\subsection{\texorpdfstring{{\faIcon{star}}~~The agent must guess
\emph{all} variates of the new
unit}{~~The agent must guess all variates of the new unit}}\label{the-agent-must-guess-all-variates-of-the-new-unit}

This kinds of guess is represented by the probability distribution

\[
\mathrm{P}(\color[RGB]{238,102,119}
Z_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
Z_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]

for all possible values {\(\color[RGB]{238,102,119}z\)} in the domain of
{\({\color[RGB]{68,119,170}Z}\).} The specific values
{\(\color[RGB]{34,136,51}z_N, \dotsc, z_1\)} of the variate
{\({\color[RGB]{68,119,170}Z}\)} for the previous units are known to the
agent.

\hfill\break

\subsection{\texorpdfstring{{\faIcon{star-half-alt}}~~The agent must
guess \emph{some} variates of the new unit, having observed other
variates of the new
unit}{~~The agent must guess some variates of the new unit, having observed other variates of the new unit}}\label{the-agent-must-guess-some-variates-of-the-new-unit-having-observed-other-variates-of-the-new-unit}

This kind of guess is represented by the probability distribution

\[
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
\dotsb \,
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]

for all possible values {\(\color[RGB]{238,102,119}y\)} in the domain of
the predictands {\({\color[RGB]{68,119,170}Y}\).} The value
{\(\color[RGB]{34,136,51}x\)} of the predictors
{\({\color[RGB]{68,119,170}X}\)} for the new unit is known to the agent.

The remaining information {``\(\dotsb\)''} contained in the conditional
depends on the subsubtype of task:

\hfill\break

\subsubsection{\texorpdfstring{{\faIcon{star-half-alt}
\faIcon{star-half-alt}}~~All predictors and predictands of previous
units are known to the
agent}{ ~~All predictors and predictands of previous units are known to the agent}}\label{all-predictors-and-predictands-of-previous-units-are-known-to-the-agent}

This corresponds to the probability distribution

\[
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]

for all possible {\(\color[RGB]{238,102,119}y\).} All information about
predictands {\({\color[RGB]{68,119,170}Y}\)} and predictors
{\({\color[RGB]{68,119,170}X}\)} for previous units appears in the
conditional.

In the example with image classification, a pictorial representation of
this probability would be

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{saitama_example2.png}

where
{\({\color[RGB]{238,102,119}y} \in \set{\color[RGB]{238,102,119}{\small\verb;Saitama;}, {\small\verb;Fubuki;}, {\small\verb;Genos;}, {\small\verb;MetalBat;}, \dotsc \color[RGB]{0,0,0}}\).}

\hfill\break

\subsubsection{\texorpdfstring{{\faIcon{star-half}
\faIcon{star-half}}~~All predictors of previous units, but not their
predictands, are known to the
agent}{ ~~All predictors of previous units, but not their predictands, are known to the agent}}\label{all-predictors-of-previous-units-but-not-their-predictands-are-known-to-the-agent}

This corresponds to the probability distribution

\[
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]

for all possible {\(\color[RGB]{238,102,119}y\).} All information about
predictors {\({\color[RGB]{68,119,170}X}\)} for the previous units, but
\emph{not} that about their predictands
{\({\color[RGB]{68,119,170}Y}\),} appears in the conditional.

\hfill\break

\subsection{More general and hybrid
tasks}\label{more-general-and-hybrid-tasks}

Consider a task that doesn't fit into any of the types discussed above:
The agent wants to guess the predictands for a new unit, say \#3, after
observing that its predictors have value {\(\color[RGB]{34,136,51}x\).}
Of two previous units, the agent knows the predictor value
{\(\color[RGB]{34,136,51}x_1\)} of the first, and the predictand value
{\(\color[RGB]{34,136,51}y_2\)} of the second. This task is expressed by
the probability

\[
\mathrm{P}(\color[RGB]{238,102,119}
Y_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
Y_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{2}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]

\hfill\break

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Write down the general probability expression for the task of
  subsubtype ``{all predictands of previous units, but not their
  predictors, are known to the agent}''.
\item
  What kind of task does the following probability express?:

  \[
  \mathrm{P}(\color[RGB]{238,102,119}
  Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1}
  \mathbin{\mkern-0.5mu,\mkern-0.5mu}Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
  \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
  Y_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{2}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
  \color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
  \color[RGB]{34,136,51}
  X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
  \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
  \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  X_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{2}
  \mathbin{\mkern-0.5mu,\mkern-0.5mu}
  X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
  \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
  \]

  What kind of task could it represent in machine-learning terminology?
\end{itemize}

\end{tcolorbox}

\end{figure*}%

\subsection{\texorpdfstring{{\faIcon{sign-out-alt} \faIcon{cube}}~~Tasks
where an agent must itself \emph{generate} a new
unit}{ ~~Tasks where an agent must itself generate a new unit}}\label{tasks-where-an-agent-must-itself-generate-a-new-unit}

Our very first categorization included the task of generating a new
unit, given previous examples. In this kind of task there are possible
alternatives that the agent could generate. How should one alternative
be chosen? A moment's thought shows that the \emph{probabilities} for
the possible alternatives should enter the choice.

Suppose, as a very simple example, that a generative agent has been
shown, in an unsystematic order, 30 copies of the symbol
{\faIcon{circle-up}} and 10 copies of the symbol {\faIcon{circle-down}},
and is asked to generate a new symbol out of these examples. Intuitively
we expect that it will generate {\faIcon{circle-up}}, but we cannot and
don't want to exclude the possibility that it will generate
{\faIcon{circle-down}}. These two generation possibilities should simply
have different probabilities and, in the long run, appear with different
frequencies.

Also in this kind of task, therefore, we have the probability
distribution

\[
\mathrm{P}(\color[RGB]{238,102,119}
Z_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
Z_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]

the difference from before is that the sentence
{\(\color[RGB]{238,102,119}Z_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z\)}
represents not the hypothesis that a \emph{given} new unit has value
{\(\color[RGB]{238,102,119}z\),} but the possibility of
\emph{generating} a new unit with that value. In other words, the symbol
{``\(\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\)''}
here means ``\emph{must be set to\ldots{}}'' rather than ``\emph{would
be observed to be\ldots{}}''. Remember the discussion and warnings in
§~\ref{sec-sentence-notation}?

\hfill\break

Our general conclusion is this:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Probability distribution such as those discussed above should
intrinsically enter all types of machine-learning algorithms.

\end{tcolorbox}

This is the condition for machine-learning algorithms to be optimal and
self-consistent. The less an algorithm satisfies that condition, the
less optimal and less consistent it is.

\hfill\break

\section{The underlying distribution}\label{sec-underlying-distribution}

A remarkable feature of all the probabilities discussed in the above
task categorization is that they can all be calculated from \emph{one}
and the same probability distribution. We briefly discussed and used
this feature in chapter~~\ref{sec-learning}.

A conditional probability such as
{\(\mathrm{P}(\mathsfit{\color[RGB]{238,102,119}A}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{\color[RGB]{34,136,51}B} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\)}
can always be written, by the \texttt{and}-rule, as the ratio of two
probabilities:

\[
\mathrm{P}(\mathsfit{\color[RGB]{238,102,119}A}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{\color[RGB]{34,136,51}B} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
=
\frac{
\mathrm{P}(\mathsfit{\color[RGB]{238,102,119}A}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}B} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\mathrm{P}(\mathsfit{\color[RGB]{34,136,51}B} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\]

Therefore we have, for the probabilities of some of the tasks above,

\begin{figure*}

\[
\begin{aligned}
&\mathrm{P}(\color[RGB]{238,102,119}
Z_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
Z_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
=
\frac{
\mathrm{P}(\color[RGB]{238,102,119}
Z_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
Z_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\mathrm{P}(
\color[RGB]{34,136,51}
Z_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\\[2em]
&\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&\qquad{}=
\frac{
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\mathrm{P}(
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\\[2em]
&\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&\qquad{}=
\frac{
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\mathrm{P}(
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\end{aligned}
\]

\end{figure*}%

\hfill\break

We also know the marginalization rule
(chapter~~\ref{sec-marginal-probs}): any quantity
{\(\color[RGB]{204,187,68}C\)} with values
{\(\color[RGB]{204,187,68}c\)} can be introduced into the proposal of a
probability via the \texttt{or}-rule:

\[
\mathrm{P}( {\color[RGB]{34,136,51}\boldsymbol{\dotsb}} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) =
\sum_{\color[RGB]{204,187,68}c}\mathrm{P}({\color[RGB]{204,187,68}C\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}c} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}\boldsymbol{\dotsb}} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

Using the marginalization rule we find these final expressions for the
probabilities of some machine-learning tasks discussed so far:

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  {\faIcon{star}} Guess all variates:
\end{itemize}

\[
\mathrm{P}(\color[RGB]{238,102,119}
Z_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
Z_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
=
\frac{
\mathrm{P}(\color[RGB]{238,102,119}
Z_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
Z_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\sum_{\color[RGB]{170,51,119}z}
\mathrm{P}(
\color[RGB]{238,102,119}
Z_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}z}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
Z_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\]

\hfill\break

\begin{itemize}
\tightlist
\item
  {\faIcon{star-half-alt} \faIcon{star-half-alt}} All previous
  predictors and predictands known:
\end{itemize}

\[
\begin{aligned}
&\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&\qquad{}=
\frac{
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\sum_{\color[RGB]{170,51,119}y}
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}y}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\end{aligned}
\]

\hfill\break

\begin{itemize}
\tightlist
\item
  {\faIcon{star-half} \faIcon{star-half}} Previous predictors known,
  previous predictands unknown:
\end{itemize}

\[
\begin{aligned}
&\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&\quad{}=
\frac{
\sum_{\color[RGB]{204,187,68}y_{N}, \dotsc, y_{1}}
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\color[RGB]{0,0,0}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
\color[RGB]{204,187,68}
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{204,187,68}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\sum_{{\color[RGB]{170,51,119}y}, \color[RGB]{204,187,68}y_{N}, \dotsc, y_{1}}
\mathrm{P}(\color[RGB]{238,102,119}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}y}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\color[RGB]{0,0,0}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
\color[RGB]{204,187,68}
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{204,187,68}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\end{aligned}
\]

\end{tcolorbox}

\end{figure*}%

\textbf{All these formulae, even for hybrid tasks, involve sums and
ratios of only one distribution:}

\[\boldsymbol{
\mathrm{P}(\color[RGB]{68,119,170}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\]

Stop for a moment and contemplate some of the consequences of this
remarkable fact:

\begin{itemize}
\item
  {\faIcon{arrows-spin}~~\emph{An agent that can perform one of the
  tasks above can, in principle, also perform all other tasks.}}

  This is why a perfect agent, working with probability, in principle
  does not have to worry about ``supervised'', ``unsupervised'',
  ``missing data'', ``imputation'', and similar situations. This also
  shows what was briefly mentioned before: all these task typologies are
  much closer to one another than it might look like from the
  perspective of current machine-learning methods.
\end{itemize}

\marginnote{\begin{footnotesize}

The acronym {\emph{OPM}}
\includegraphics[width=\linewidth,height=2em,keepaspectratio]{opm_fist2.png}
can stand for {\emph{Optimal Predictor Machine}} or
{\emph{Omni-Predictor Machine}}

\end{footnotesize}}

\begin{itemize}
\item
  {\faIcon{microchip}~~\emph{The probability distribution above encodes
  the agent's background knowledge and assumptions; different agents
  differ only in the values of that distribution.}}

  If two agents yield different probability values in the same task,
  with the same variates and same training data, the difference must
  come from the joint probability distribution above. And, since the
  data given to the two agents are exactly the same, the difference must
  lie in the agents' background {information \(\mathsfit{I}\).}
\item
  {\faIcon{user-secret}~~\emph{Data cannot ``speak for themselves''}}

  Given some data, we can choose two different joint distributions for
  these data, and therefore get different results in our inferences and
  tasks. This means that the data alone cannot determine the result:
  specific background information and assumptions, whether acknowledged
  or not, always affect the result.
\end{itemize}

The qualification ``in principle'' in the first consequence is
important. Some of the sums that enter the formulae above are
computationally extremely expensive and, with current technologies and
maths techniques, cannot be performed within a reasonable time. But
\emph{new technologies and new maths discoveries could make these
calculations possible}. This is why a data engineer cannot simply brush
them aside and forget them.

As regards the third consequence, we shall see that there are different
states of knowledge which can converge to the same results, as the
number of training data increases.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

In a previous example of ``hybrid'' task we had the probability
distribution

\[
\mathrm{P}(\color[RGB]{238,102,119}
Y_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
Y_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{2}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]

Rewrite it in terms of the underlying joint distribution.

\end{tcolorbox}

\section{Plan for the next few
chapters}\label{plan-for-the-next-few-chapters}

Our goal in building an ``Optimal Predictor Machine'' is now clear: we
must find a way to

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{optimal_predictor_machine.png}

\end{footnotesize}}

\begin{itemize}
\item
  \emph{assign} the joint probability distribution above, in such a way
  that it reflects some reasonable background information
\item
  \emph{encode} the distribution in a computationally useful way
\end{itemize}

The ``encode'' goal sounds quite challenging, because the number {\(N\)}
of units can in principle be infinite; we have an infinite probability
distribution.

In the next {Inference~III} part we shall see that partially solving the
``assign'' goal actually makes the ``encode'' goal feasible.

\hfill\break
One question arises if we now look at machine-learning methods from our
Probability Theory perspective. Some machine-learning methods, including
many popular ones, don't give us probabilities about values. They return
\emph{one} definite value. How do we reconcile this with the
probabilistic point of view above? We shall answer this question in full
in the last chapters; but a short, intuitive answer can already be given
now.

If there are several possible correct answers to a given guess, but a
machine-learning algorithm gives us only one answer, then the algorithm
must have internally \emph{chosen} one of them. In other words, the
machine-learning algorithm is internally doing decision-making. We know
from chapters~Chapter~\ref{sec-framework}
and~Chapter~\ref{sec-basic-decisions} that this process should obey
Decision Theory and therefore \emph{must} involve:

\begin{itemize}
\item
  {\faIcon{scale-unbalanced-flip}~~the probabilities of the possible
  correct answers}
\item
  {\faIcon{sack-dollar}~~the utilities of the possible answer choices}
\end{itemize}

Non-probabilistic machine-learning algorithms must therefore be
approximations of an Optimal Predictor Machine that, after computing
probabilities, selects one particular answer by using utilities.

\chapter{\texorpdfstring{{Exchangeable
beliefs}}{Exchangeable beliefs}}\label{sec-exchangeable-beliefs}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\yon}{{\green\cat{on}}}
\providecommand*{\yof}{{\red\cat{off}}}
\providecommand*{\yy}{{\lblue\cat{Y}}}
\providecommand*{\yn}{{\yellow\cat{N}}}
\providecommand{\ypl}{{\green\cat{+}}}
\providecommand{\ymi}{{\red\cat{-}}}
\providecommand{\ypa}{{\green\cat{pass}}}
\providecommand{\yfa}{{\red\cat{fail}}}

\providecommand{\hi}{{\green\cat{high}}}
\providecommand{\me}{{\yellow\cat{medium}}}
\providecommand{\lo}{{\red\cat{low}}}
\providecommand*{\yJ}{\se{J}}
\providecommand{\yva}{{\lblue-1}}
\providecommand{\yvb}{{\midgrey0}}
\providecommand{\yvc}{{\yellow1}}
\providecommand*{\yK}{\se{K}}
\providecommand*{\yL}{\se{L}}

\providecommand*{\yR}{R}

\providecommand*{\bZ}{{\blue Z}}
\providecommand*{\bz}{{\blue z}}
\providecommand*{\rY}{{\red Y}}
\providecommand*{\bY}{{\blue Y}}
\providecommand*{\ry}{{\red y}}
\providecommand*{\gX}{{\green X}}
\providecommand*{\bX}{{\blue X}}
\providecommand*{\gx}{{\green x}}
\providecommand*{\vf}{\vec{f}}

\providecommand*{\yut}{\se{K}_{\textsf{3}}}
\providecommand*{\yul}{\se{K}}

\providecommand*{\bA}{{\blue A}}
\providecommand*{\bB}{{\blue B}}
\providecommand*{\bC}{{\blue C}}

\providecommand*{\vfa}{\vf'}
\providecommand*{\vfb}{\vf''}

\section{Recap}\label{sec-recap-before-exchang}

In the chapters of part {Inference~I} we had an overview of how an agent
can draw inferences and make predictions of the most general kind,
expressed by general sentences, using the four fundamental rules of
inference.

Then, in part {Inference~II}, we successively narrowed our focus on more
and more specialized kinds of inference, typical of engineering and
data-science problems and of machine-learning algorithms. First we
considered inferences about measurements and observations, then
inferences about multiple instances of similar measurements and
observations. The idea was that an agent can arrive at sharper degrees
of belief -- that is, it can \emph{learn} -- by using information about
``similar instances''.

For these purposes we introduced a specialized language about quantities
and data types in part {Data~I}, and about ``populations'' of similar
``units'' in part {Data~II}.

In the {Machine~learning} part we took an overview of current
machine-learning methods, and then focused on several types of tasks
that popular machine-learning algorithms, such as deep networks and
random forests, purport to solve. We found a remarkable result: a
perfect agent -- one that operates according to Probability Theory --
can in principle perform \emph{any and all} of those tasks by using the
joint probability distribution

\[
\mathrm{P}(\color[RGB]{68,119,170}
Y_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

The agent only needs to do some calculations with this joint
distribution, involving sums and divisions. This distribution must be
specified for all possible values of
{\(\color[RGB]{68,119,170}x_{1}, \dotsc, x_{N+1}\),}
{\(\color[RGB]{68,119,170}y_{1}, \dotsc, y_{N+1}\),} and {\(N\).}

Take ``supervised learning'' for example, that is, the task of
predicting some variates (predictands) for a new unit, from knowledge of
other variates (predictors) for the same unit and of all variates for
{\(N\)} other units. Solving this task corresponds to calculating

\begin{figure*}

\[
\begin{aligned}
    &\mathrm{P}\bigl(
    {\color[RGB]{238,102,119}Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y}
    \pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} 
    {\color[RGB]{34,136,51}X_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
    \color[RGB]{34,136,51}Y_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    Y_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_1 
    \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\mathsfit{I}} \bigr)
    \\[2ex]
    &\qquad{}=
    \frac{
        \mathrm{P}\bigl(
    \color[RGB]{238,102,119}Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \color[RGB]{34,136,51}X_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
    \color[RGB]{0,0,0}
        \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \color[RGB]{34,136,51}Y_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_N
    \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \color[RGB]{34,136,51}Y_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_1 
    \color[RGB]{0,0,0}\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} {\mathsfit{I}} \bigr)
}{
     \sum_{\color[RGB]{238,102,119}y} \mathrm{P}\bigl(
    {\color[RGB]{238,102,119}Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    {\color[RGB]{34,136,51}X_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}}
        \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \color[RGB]{34,136,51}Y_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    Y_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_1 
    \color[RGB]{0,0,0}\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}}  {\mathsfit{I}} \bigr)
}
\end{aligned}
\]

\end{figure*}%

\hfill\break
To build an AI agent that deals with these kinds of task we must: (1)
choose a joint distribution according to reasonable assumptions and
background information, (2) encode it in a computationally feasible way.

In order to reach these two goals we shall now narrow our focus further,
upon inferences satisfying a condition that greatly simplifies the
calculations, and that is also reasonable in many real inference
problems -- and it is moreover typical of many ``supervised'' and
``unsupervised'' machine-learning applications.

\hfill\break

\section{States of knowledge with
symmetries}\label{sec-excheable-beliefs}

An agent's degrees of belief about a particular population may satisfy a
special symmetry called {\textbf{exchangeability}}. This symmetry can be
understood from different points of view. Let's start from one of these
viewpoints, and then make connections with alternative ones.

Take again two populations briefly mentioned in §~\ref{sec-collections}:

\begin{itemize}
\item
  \begin{description}
  \tightlist
  \item[Stock exchange]
  The daily change in closing price of a stock during 1000 consecutive
  days. Each day the change can be positive or zero:
  \({\color[RGB]{34,136,51}{\small\verb;+;}}\), or negative:
  \({\color[RGB]{238,102,119}{\small\verb;-;}}\).
  \end{description}
\end{itemize}

\marginnote{\begin{footnotesize}

\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{stock_course.jpg}

\end{footnotesize}}

\begin{itemize}
\item
  \begin{description}
  \tightlist
  \item[Mars prospecting]
  A collection of 1000 similar-sized rocks gathered from a specific,
  large crater on Mars. Each rock either contains haematite:
  \({\color[RGB]{34,136,51}{\small\verb;Y;}}\), or it doesn't:
  \({\color[RGB]{238,102,119}{\small\verb;N;}}\).
  \end{description}
\end{itemize}

\marginnote{\begin{footnotesize}

\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{mars_crater2.jpg}

\end{footnotesize}}

\hfill\break
Suppose that, in each of these populations, you (the agent) don't know
the variate value for unit {\#735}, and for some reason would like to
infer it. You are given the variate values for 100 other units, which
you can use to improve your inference. Now consider this question:

\begin{quote}
{\emph{How much does the relative order of the 100 known units and the
unknown unit matter to you, for drawing your inference?}}
\end{quote}

We know, from information theory, that it never hurts having extra
information, such as the units' order. But you probably judge the units'
order to be much more important for your inference in the stock-exchange
case than in the Mars-prospecting one. In the stock-exchange case it
would be more informative to have data from units temporally close to
unit {\#735}; for example units {\#635--\#734}, or {\#736--\#835}, or
{\#685--\#734} \& {\#736--\#785}, or similar ranges. But in the
Mars-prospecting case you might find it acceptable if the 100 known
units were picked up in some unsystematic way from the catalogue of
remaining 999 units. There are reasons, boiling down to physics, behind
this kind of judgement.

The question above could also be replaced by others, slightly different
but still connected to the same issue. For example:

\begin{quote}
{\emph{How strongly would you like to be able to choose which 100 units
you can have data from, in order to draw your inference?}}
\end{quote}

or

\begin{quote}
{\emph{How much would you be upset if the original order of the
population units were destroyed by accidental shuffling?}}
\end{quote}

or

\begin{quote}
{\emph{Would it be acceptable to you if only the \textbf{frequencies} of
the values
(\(\set{{\color[RGB]{34,136,51}{\small\verb;+;}},{\color[RGB]{238,102,119}{\small\verb;-;}}}\)
in one case,
\(\set{{\color[RGB]{34,136,51}{\small\verb;Y;}},{\color[RGB]{238,102,119}{\small\verb;N;}}}\)
in the other) for the 100 known units were given to you?}}
\end{quote}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Find examples of populations where the units have some kind of
  ordering that you think would be \emph{very} important for drawing
  inferences about some units, given other units. Examine why you judge
  such ordering to be important. (The ordering doesn't need to be
  one-dimensional. For instance, the pixel intensities of an image also
  have a two-dimensional relative order or position: is that important
  if you want to draw inferences about the intensities of some pixels
  from those of other pixels?)
\item
  Find examples of populations where any potential ordering of the units
  would \emph{not} be very important for drawing inferences about some
  units, given other units. Or, put it otherwise, you wouldn't be
  excessively upset or worried if such order were lost owing to
  accidental shuffling of the units.
\end{itemize}

\end{tcolorbox}

Many kinds of inference considered in data science and engineering, and
all inferences done with ``supervised'' or ``unsupervised''
machine-learning algorithms, are examples where \emph{any ordering of
the data used for learning is deemed irrelevant} and is, in fact, often
lost. This irrelevance is clear from the data-shuffling involved in many
procedures that accompany these algorithms.

We shall thus restrict our attention to situations and kinds of
background information where this judgement of irrelevance is considered
appropriate. In reality this is not a black-or-white situation: it is
possible that some kind of ordering information would improve our
inferences; what we are assuming here is that this improvement is so
small that it can be neglected altogether.

\section{Exchangeable probability
distributions}\label{sec-exchaneable-distr}

Let's take the Mars-prospecting problem as a concrete example. Denote by
{\(H\)} the variate expressing haematite presence, with domain
{\(\set{{\color[RGB]{34,136,51}{\small\verb;Y;}}, {\color[RGB]{238,102,119}{\small\verb;N;}}}\).}

If an agent's background information or assumption {\(\mathsfit{I}\)}
says that the relative order of units -- rocks in this case -- is
irrelevant for inferences about other units, then it means that a
probability such as

\[
\mathrm{P}(R_{735}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}
R_{734}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{733}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{732}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{731}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{730}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I})
\]

must be equal to the probability

\[
\mathrm{P}(R_{735}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}
R_{87}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{7}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{16}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{52}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{988}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I})
\]

and in fact to any probability like

\[
\mathrm{P}(R_{i}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}
R_{j}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{k}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{l}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{m}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{n}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I})
\]

for instance

\[
\mathrm{P}(R_{356}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}
R_{952}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{103}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{69}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{740}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{679}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I})
\]

where {\(i\),} {\(j\),} and so on are different but otherwise arbitrary
indices.

In other words, the probability depends on whether we are inferring
{\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)} or
{\({\color[RGB]{238,102,119}{\small\verb;N;}}\),} and on how many
{\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)} and
{\({\color[RGB]{238,102,119}{\small\verb;N;}}\)} appear in the
conditional; in the example above, {three
\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)} and {two
\({\color[RGB]{238,102,119}{\small\verb;N;}}\).} This property should
also apply if the agent makes inferences about more than one unit,
conditional on any number of units. It can be proven that this property
is equivalent, in our present example, to this general requirement:

\begin{quote}
The value of a joint probability such as

\[\mathrm{P}(R_{\scriptscriptstyle\dotso}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\ 
\dotso\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{\scriptscriptstyle\dotso}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\ \dotso \nonscript\:\vert\nonscript\:\mathopen{}
\mathsfit{I})
\]

depends only on the \textbf{total number of
\({\color[RGB]{34,136,51}{\small\verb;Y;}}\) values} and \textbf{total
number of \({\color[RGB]{238,102,119}{\small\verb;N;}}\) values} that
appear in it, or, equivalently, on the \textbf{absolute frequencies} of
the values that appear in it.
\end{quote}

\hfill\break

Leaving the Mars-specific example and generalizing, we can define the
following property, called {\textbf{exchangeability}}:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

A joint probability distribution is called {\textbf{exchangeable}} if
the probabilities for any number of units depend only on the absolute
frequencies of the values appearing in them.

\end{tcolorbox}

Let's see a couple more examples.

\marginnote{\begin{footnotesize}

{Don't forget that\\
\(\mathrm{P}(X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \mathbin{\mkern-0.5mu,\mkern-0.5mu}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)\\
and\\
\(\mathrm{P}(Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \mathbin{\mkern-0.5mu,\mkern-0.5mu}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)\\
\textbf{mean exactly the same}, because \texttt{and} (symbol
{{``\(,\)''})} is commutative!}

\end{footnotesize}}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  Consider an infinite population with variate {\(Y\)} having domain
  {\(\set{{\color[RGB]{238,102,119}{\small\verb;low;}},{\color[RGB]{204,187,68}{\small\verb;medium;}},{\color[RGB]{34,136,51}{\small\verb;high;}}}\).}
  If the background information {\(\mathsfit{J}\)} guarantees
  exchangeability, then these three joint probabilities must have the
  same value:

  \[\begin{aligned}
   &\quad\mathrm{P}(
   Y_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;high;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{4}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;low;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{5}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{204,187,68}{\small\verb;medium;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{6}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;low;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{J}
   )
   \\[2ex]
   &=\mathrm{P}(
   Y_{6}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{204,187,68}{\small\verb;medium;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{5}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;high;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;low;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{4}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;low;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{J}
   )
   \\[2ex]
   &=\mathrm{P}(
   Y_{283}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;high;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{91}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;low;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{72}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{204,187,68}{\small\verb;medium;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{1838}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;low;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{J}
   )
   \end{aligned}
  \]

  because they all have {one
  \({\color[RGB]{34,136,51}{\small\verb;high;}}\)}, {one
  \({\color[RGB]{204,187,68}{\small\verb;medium;}}\)}, {two
  \({\color[RGB]{238,102,119}{\small\verb;low;}}\)}. The same is true
  for these two probabilities:

  \[\begin{aligned}
   &\quad\mathrm{P}(
   Y_{99}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{204,187,68}{\small\verb;medium;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{204,187,68}{\small\verb;medium;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{3024}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;low;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{J}
   )
   \\[2ex]
   &=\mathrm{P}(
   Y_{26}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{204,187,68}{\small\verb;medium;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{611}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;low;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   Y_{78}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{204,187,68}{\small\verb;medium;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{J}
   )
   \end{aligned}
  \]

  because both have {zero
  \({\color[RGB]{34,136,51}{\small\verb;high;}}\)}, {two
  \({\color[RGB]{204,187,68}{\small\verb;medium;}}\)}, {one
  \({\color[RGB]{238,102,119}{\small\verb;low;}}\)}.
\end{enumerate}

\begin{figure*}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\item
  Consider an infinite population with variates {\((U,V)\)} having joint
  domain
  {\(\set{{\color[RGB]{238,102,119}{\small\verb;fail;}},{\color[RGB]{34,136,51}{\small\verb;pass;}}} \times \set{{\color[RGB]{102,204,238}-1}, {\color[RGB]{119,119,119}0}, {\color[RGB]{204,187,68}1}}\)~~(six}
  possible joint values). If the background information
  {\(\mathsfit{K}\)} guarantees exchangeability, then these two joint
  probabilities must have the same value:

  \[\begin{aligned}
   &\quad\mathrm{P}(
   U_{14}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;pass;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{14}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{204,187,68}1}\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}\ 
   U_{337}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;pass;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{337}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{102,204,238}-1}\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}\ 
   U_{8}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;fail;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{8}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{119,119,119}0}\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}\ 
   U_{43}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;fail;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{43}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{102,204,238}-1}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{}
   \\
   &\qquad\qquad\qquad\quad
   U_{825}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;pass;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{825}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{102,204,238}-1}\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}\ 
   U_{66}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;pass;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{66}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{102,204,238}-1}\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}\ 
   U_{700}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;fail;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{700}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{119,119,119}0}
   \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
   \\[3ex]
   &=\mathrm{P}(
   U_{421}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;pass;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{421}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{102,204,238}-1}\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}\ 
   U_{55}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;fail;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{55}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{119,119,119}0}\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}\ 
   U_{43}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;pass;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{43}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{204,187,68}1}\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}\ 
   U_{14}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;fail;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{14}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{102,204,238}-1}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{}
   \\
   &\qquad\qquad\qquad\quad
   U_{928}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;pass;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{928}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{102,204,238}-1}\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}\ 
   U_{700}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;fail;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{700}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{119,119,119}0}\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}\ 
   U_{39}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;pass;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}V_{39}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{102,204,238}-1}
   \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
   \end{aligned}
   \]

  because both have: {one
  \(({\color[RGB]{238,102,119}{\small\verb;fail;}},{\color[RGB]{102,204,238}-1})\),}~~{two
  \(({\color[RGB]{238,102,119}{\small\verb;fail;}},{\color[RGB]{119,119,119}0})\),}~~{zero
  \(({\color[RGB]{238,102,119}{\small\verb;fail;}},{\color[RGB]{204,187,68}1})\),}~~{three
  \(({\color[RGB]{34,136,51}{\small\verb;pass;}},{\color[RGB]{102,204,238}-1})\),}~~{zero
  \(({\color[RGB]{34,136,51}{\small\verb;pass;}},{\color[RGB]{119,119,119}0})\),}~~{one
  \(({\color[RGB]{34,136,51}{\small\verb;pass;}},{\color[RGB]{204,187,68}1})\).}
  From this example, note that it's important to count the occurrences
  of the \emph{joint} values, not of the values of the single variates
  independently.
\end{enumerate}

\end{figure*}%

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  First let's check that you haven't forgotten the basics about
  connectives (§~\ref{sec-connecting-sentences}), Boolean algebra
  §~\ref{sec-boolean}), and the four fundamental rules of inference
  (§~\ref{sec-fundamental}):

  \begin{itemize}
  \item
    How much
    is~~{\(\mathrm{P}(Y_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;low;}}\nonscript\:\vert\nonscript\:\mathopen{} Y_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;low;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{J})\)\,?}
  \item
    Simplify the probability
  \end{itemize}

  \[\mathrm{P}(X_{9}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}X_{28}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}X_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}X_{28}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\]

  what are the absolute frequencies of the values
  {\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)} and
  {\({\color[RGB]{238,102,119}{\small\verb;N;}}\)} among the units in
  the probability above?
\end{itemize}

\hfill\break

\begin{itemize}
\item
  For each collection of probabilities below (the sentences
  {\(\mathsfit{I'}, \mathsfit{I''}, \mathsfit{J'}\dotsc\)} indicate
  different states of knowledge), say whether they \emph{cannot} come
  from an exchangeable probability distribution, or if they \emph{might}
  {(to guarantee exchangeability, one has to check an infinite number of
  inequalities, so we can't be sure about it unless they give us a
  general formula for the joint probabilities)}:

  \begin{itemize}
  \item
    \(\begin{aligned}[c]
      &\mathrm{P}(C_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}-1 \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I'}) = 31.6\%
      \\
      &\mathrm{P}(C_{7}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}-1\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I'}) = 24.8\%
      \end{aligned}\)
  \item
    \(\begin{aligned}[c]
      &\mathrm{P}(Z_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;off;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}Z_{53}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;on;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I''}) = 9.7\%
      \\
      &\mathrm{P}(Z_{3904}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;on;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}Z_{29}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;off;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I''}) = 9.7\%
      \end{aligned}\)
  \item
    \(\begin{aligned}[c]
      &\mathrm{P}(A_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}A_{87}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}A_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{J'}) = 6.2\%
      \\
      &\mathrm{P}(A_{99}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}A_{10}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}A_{13}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{J'}) = 8.9\%
      \end{aligned}\)
  \item
    \(\begin{aligned}[c]
      &\mathrm{P}(W_{4}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;-;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}W_{97}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;+;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}W_{300}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;-;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{J''}) = 6.2\%
      \\
      &\mathrm{P}(W_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;-;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}W_{86}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;-;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}W_{107}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;-;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{J''}) = 8.9\%
      \end{aligned}\)
  \item
    \(\begin{aligned}[c]
      &\mathrm{P}(B_{1190}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;+;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}B_{1152}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;-;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}B_{233}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;-;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K'}) = 7.5\%
      \\
      &\mathrm{P}(B_{1185}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;+;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}B_{424}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;-;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}B_{424}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;-;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K'}) = 12.3\%
      \end{aligned}\)
  \item
    \(\begin{aligned}[c]
      &\mathrm{P}(S_{21}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;+;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_{21}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;low;}}\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}\  S_{33}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;-;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_{33}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;high;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K''}) = 5.0\%
      \\
      &\mathrm{P}(S_{5}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;-;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_{5}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;low;}}\ \mathbin{\mkern-0.5mu,\mkern-0.5mu}\  S_{102}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;+;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_{102}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;high;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K''}) = 2.9\%
      \end{aligned}\)
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\subsection{Further constraints}\label{further-constraints}

The exchangeability property greatly reduces the number of probabilities
that an agent needs to specify. For a population with a binary variate,
a joint probability distribution for 1000 units would require the
specification of around {\(2^{1000} \approx 10^{300}\)} probabilities.
But if this distribution is exchangeable, only {\(1000\)} probabilities
need to be specified (the absolute frequency of one of the two values,
ranging between 0 and 1000; minus one because of
normalization).\footnote{For the general case of a variate with {\(n\)}
  values, and {\(k\)} units,
  \href{https://mathworld.wolfram.com/Multichoose.html}{the number of
  independent probabilities is \(\binom{n+k-1}{k}\)}.}

Moreover, the exchangeable joint distributions for different numbers of
units satisfy additional restrictions, owing to the fact that each of
them is the marginal distribution of all distributions with a larger
number of units. In the Mars-prospecting case, for instance, if
{\(\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})\)}
is the degree of belief that rock~\#1 contains haematite, we must also
have

\[
\begin{aligned}
\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})
&=\mathrm{P}(R_{a}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})
\\
&= \mathrm{P}(R_{a}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{b}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) + \mathrm{P}(R_{a}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{b}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\end{aligned}
\]

for any two different units {\#\(a\)} and {\#\(b\)}. Therefore, if the
agent has specified
{\(\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})\),}
then three of these four probabilities

\[
\begin{gathered}
\mathrm{P}(R_{a}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{b}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\qquad
\mathrm{P}(R_{a}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{b}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\\[1ex]
\mathrm{P}(R_{a}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{b}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\qquad
\mathrm{P}(R_{a}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{b}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\end{gathered}
\]

are completely determined if we specify just one of them.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Assume that the state of knowledge {\(\mathsfit{I}\)} implies
exchangeability, and a population has binary variate
{\(R\in \set{{\color[RGB]{238,102,119}{\small\verb;N;}},{\color[RGB]{34,136,51}{\small\verb;Y;}}}\).}

If

\[\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}) = 0.75 \qquad \mathrm{P}(R_{4}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{9}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}) = 0.60\]

Then how much are the probabilities

\[\mathrm{P}(R_{15}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}) = \mathord{?} \qquad
\mathrm{P}(R_{7}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{11}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}) = \mathord{?}\]

\end{tcolorbox}

\chapter{\texorpdfstring{{Inferences from
frequencies}}{Inferences from frequencies}}\label{sec-inference-from-freqs}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\yon}{{\green\cat{on}}}
\providecommand*{\yof}{{\red\cat{off}}}
\providecommand*{\yy}{{\lblue\cat{Y}}}
\providecommand*{\yn}{{\yellow\cat{N}}}
\providecommand{\ypl}{{\green\cat{+}}}
\providecommand{\ymi}{{\red\cat{-}}}
\providecommand{\ypa}{{\green\cat{pass}}}
\providecommand{\yfa}{{\red\cat{fail}}}

\providecommand{\hi}{{\green\cat{high}}}
\providecommand{\me}{{\yellow\cat{medium}}}
\providecommand{\lo}{{\red\cat{low}}}
\providecommand*{\yJ}{\se{J}}
\providecommand{\yva}{{\lblue-1}}
\providecommand{\yvb}{{\midgrey0}}
\providecommand{\yvc}{{\yellow1}}
\providecommand*{\yK}{\se{K}}
\providecommand*{\yL}{\se{L}}

\providecommand*{\yR}{R}

\providecommand*{\bZ}{{\blue Z}}
\providecommand*{\bz}{{\blue z}}
\providecommand*{\rY}{{\red Y}}
\providecommand*{\bY}{{\blue Y}}
\providecommand*{\ry}{{\red y}}
\providecommand*{\gX}{{\green X}}
\providecommand*{\bX}{{\blue X}}
\providecommand*{\gx}{{\green x}}
\providecommand*{\vf}{\vec{f}}

\providecommand*{\yut}{\se{K}_{\textsf{3}}}
\providecommand*{\yul}{\se{K}}

\providecommand*{\bA}{{\blue A}}
\providecommand*{\bB}{{\blue B}}
\providecommand*{\bC}{{\blue C}}

\providecommand*{\vfa}{\vf'}
\providecommand*{\vfb}{\vf''}

\section{If the population frequencies were
known}\label{sec-pop-freq-known}

Let's now see how the exchangeability of an agent's degrees of belief
allows it to calculate probabilities about the units of a population. We
shall do this calculation in two steps. First, in the case where
\emph{the agent knows the joint frequency distribution}
(§§\ref{sec-freq-distr}, \ref{sec-joint-freq}, \ref{sec-limit-freqs})
\emph{for the full population}. Second, in the more general case where
the agent lacks this population-frequency information.

When the full-population frequency distribution is known, the
calculation of probabilities is very intuitive and analogous to the
stereotypical ``drawing balls from an urn''. We shall rely on this
intuition; keep in mind, however, that the probabilities are not
assigned ``by intuition'', but actually fully determined by the two
basic pieces of knowledge or assumptions: \emph{exchangeability} and
\emph{known population frequencies}. Some simple proof sketches of this
will also be given.

We consider an infinite population with any number of variates. For
concreteness we assume these variates to have finite, discrete domains;
but the formulae we obtain can be easily generalized to other kinds of
variates. In this and the following chapters we shall often use the
simplified {income} dataset (file
\href{datasets/income_data_nominal_nomissing.csv}{\texttt{income\_data\_nominal\_nomissing.csv}}
and its underlying population as an example. This population has nine
nominal variates. The variates, their domain sizes, and their possible
values are listed
\href{https://github.com/pglpm/ADA511/blob/master/datasets/meta_income_data_nominal_nomissing.csv}{at
this link}.

\subsection{Notation recap}\label{notation-recap}

We shall mainly use the notation introduced in
§~\ref{sec-categ-probtheory}:

All population variates, jointly, are denoted
{\({\color[RGB]{68,119,170}Z}\).} In the case of the income dataset, for
instance, the variate {\({\color[RGB]{68,119,170}Z}\)} stands for the
joint variate with nine components:

\[
\begin{aligned}
{\color[RGB]{68,119,170}Z}&\coloneqq(\color[RGB]{68,119,170}
\mathit{workclass} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{education} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{marital\_status} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{occupation} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
{}\\ &\qquad
\color[RGB]{68,119,170}\mathit{relationship} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{race} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{sex} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{native\_country} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathit{income}
\color[RGB]{0,0,0})
\end{aligned}
\]

When we write
{\(\color[RGB]{68,119,170}Z \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z\),}
the symbol {\(\color[RGB]{68,119,170}z\)} stands for some definite joint
values, for instance
{\(({\color[RGB]{68,119,170}{\small\verb;Without-pay;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;Doctorate;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;Ireland;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;>50K;}})\).}

In applications where the agent wants to infer the values of some
predictand variates, given the observation of predictor variates, the
former are denoted {\({\color[RGB]{68,119,170}Y}\),} the latter
{\({\color[RGB]{68,119,170}X}\).} In the {income} problem, for instance,
the agent (some USA census agency) would like to infer the
{\(\color[RGB]{68,119,170}\mathit{income}\)} variate of a person from
the other eight demographic characteristics
{\(\color[RGB]{68,119,170}\mathit{workclass} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{education} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\)}
of that person. So in this inference problem we define

\[
\begin{aligned}
{\color[RGB]{68,119,170}Y}&\coloneqq{\color[RGB]{68,119,170}\mathit{income}}
\\[1ex]
{\color[RGB]{68,119,170}X}&\coloneqq({\color[RGB]{68,119,170}\mathit{workclass} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{education} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{sex} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{native\_country}})
\end{aligned}
\]

We shall, however, also consider slightly different inference problems,
for example with
{\(({\color[RGB]{68,119,170}\mathit{race} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{sex}})\)}
as predictand and the remaining seven variates
{\(({\color[RGB]{68,119,170}\mathit{workclass} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{income}})\)}
as predictors.

Often we shall use {red} for quantities that are not known in the
problem, and {green} for quantities that are known.

\section{Knowing the full-population frequency
distribution}\label{sec-know-freq}

Now suppose that the agent knows the \emph{full-population joint
frequency distribution}. Let's make clearer what this means. In the
{income} problem, for instance, consider these two different joint
values for the joint variate {\({\color[RGB]{68,119,170}Z}\):}

\[
\begin{aligned}
{\color[RGB]{68,119,170}z^{*}}&\coloneqq(
{\small\verb;Private;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;HS-grad;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;Married-civ-spouse;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;Machine-op-inspct;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{}
\\
&\qquad{\small\verb;Husband;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;White;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;Male;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;United-States;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;<=50K;}
)
\\[2ex]
{\color[RGB]{68,119,170}z^{**}}&\coloneqq(
{\small\verb;Self-emp-not-inc;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;HS-grad;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;Married-civ-spouse;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{}
\\
&\qquad {\small\verb;Farming-fishing;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;Husband;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;White;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;Male;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;United-States;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\small\verb;<=50K;}
)
\end{aligned}
\]

The agent knows that the value
{\(\color[RGB]{68,119,170}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z^{*}\)}
occurs in the full population of interest (in this case all 340 millions
or so USA citizens, considered in a short period of time) with a
relative frequency {\(0.860 369\%\);} it also knows that the value
{\(\color[RGB]{68,119,170}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z^{**}\)}
occurs with a relative frequency {\(0.260 058\%\).} We write this as
follows:

\[
f({\color[RGB]{68,119,170}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z^{*}}) = 0.860 369\% \ ,
\qquad
f({\color[RGB]{68,119,170}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z^{**}}) = 0.260 058\%
\]

The agent knows not only the frequencies of the two particular joint
values {\(\color[RGB]{68,119,170}z^{*}\),}
{\(\color[RGB]{68,119,170}z^{**}\),} but for \emph{all possible} joint
values, that is, for all possible combinations of values from the single
variate. In the {income} example there are 54\,001\,920 possible
combinations, and therefore just as many relative frequencies. All these
frequencies together form the full-population frequency distribution for
{\({\color[RGB]{68,119,170}Z}\),} which we denote collectively with
{\(\boldsymbol{f}\)} (note the boldface). Let's introduce the quantity
{\(F\),} denoting the full-population frequency distribution. Knowledge
that the frequencies are {\(\boldsymbol{f}\)} is then expressed by the
sentence
{\(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\).}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Don't confuse the full population with a
sample from it}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Note that the frequencies reported above are \emph{not} the ones found
in the
\href{datasets/income_data_nominal_nomissing.csv}{\texttt{income\_data\_nominal\_nomissing.csv}}
dataset, because that dataset is only a \emph{sample} from the full
population, not the full population. The frequency values reported above
are purely hypothetical (but not inconsistent with the frequencies
observed in the sample).

\end{tcolorbox}

In other cases, these hypothetically known frequencies would refer to
the full population of units: maybe even past, present, future, if they
span a possibly unlimited time range.

\section{Inference about a single unit}\label{sec-1unit-freq-known}

Now imagine that the agent, given the information
{\(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\)}
about the frequencies and some background information
{\(\mathsfit{I}\),} must infer all {\({\color[RGB]{68,119,170}Z}\)}
variates for a specific unit {\(u\).} In the {income} case, it would be
an inference about a specific USA citizen. This unit {\(u\)} could have
any particular combination of variate values; in the {income} case it
could have any one of the 54\,001\,920 possible combined values. The
agent must assign a probability to each of these
possibilities.\footnote{Remember that this is what we mean when we say
  ``drawing an inference''! (See chap.\,~\ref{sec-what-inference} and
  §~\ref{sec-distribute-prob})} Which probability values should it
assign?

Intuitively we would say that the probability for a particular value
{\(\color[RGB]{68,119,170}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z\)}
should be equal to the frequency of that value in the full population:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

if {\(\mathsfit{I}\)} leads to an exchangeable probability distribution,
then

\[
\mathrm{P}({\color[RGB]{68,119,170}Z}_{u}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z} \nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) = f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z})
\]

for any unit {\(u\).}

\end{tcolorbox}

For instance, the probabilities that unit {\(u\)} has the values
{\(\color[RGB]{68,119,170}z^{*}\)} or
{\(\color[RGB]{68,119,170}z^{**}\)} above is

\[
\begin{aligned}
&\mathrm{P}({\color[RGB]{68,119,170}Z}_{u}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z^{*}} \nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) =
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z^{*}}) = 0.860 369\%
\\[1ex]
&\mathrm{P}({\color[RGB]{68,119,170}Z}_{u}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z^{**}} \nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) =
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z^{**}}) = 0.260 058\%
\end{aligned}
\]

This intuition is the same as in drawing balls, which may have different
sets of labels, from a collection, given that we know the proportion of
balls with each possible label set.

But the equality above can actually be proven mathematically in this
specific case: it follows from the assumption of exchangeability. Let's
examine a very simple case to get an idea of how this proof works.

\subsection{Exact calculation of the probabilities in a simple
case}\label{exact-calculation-of-the-probabilities-in-a-simple-case}

Suppose we have three rocks from our Mars-prospecting collection. They
are marked \#1, \#2, \#3. They look alike, but we know that two of them
have haematite, so
{\(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\)}
for them, and one doesn't, so
{\(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\)}
for that rock. This background information -- let's call it
{\(\mathsfit{K}_{\textsf{3}}\)} -- is a simple case of a finite
population with three units and a binary variate {\(R\).} We know that
the frequency distribution for this population is

\marginnote{\begin{footnotesize}

\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{mars_crater2.jpg}

\end{footnotesize}}

\[f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) = 2/3 \qquad f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}) = 1/3\]

Our information
{\(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\)}
about the frequencies corresponds to the following composite sentence:

\begin{figure*}

\[
 F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\ \Longleftrightarrow\ 
(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}})
\lor
(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}})
\lor
(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}})
\]

\end{figure*}%

Given
{\(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\),}
we know that
{\(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\)}
is true:
{\(\mathrm{P}( F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})=1\),}
which means

\begin{figure*}

\[
\mathrm{P}\bigl[(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}})
\lor
(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}})
\lor
(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}})
\nonscript\:\big\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}, \mathsfit{K}_{\textsf{3}}\bigr] = 1
\]

\end{figure*}%

Now use the \texttt{or}-rule, considering that the three \texttt{or}ed
sentences are mutually exclusive:

\begin{figure*}

\[
\begin{aligned}
1&=\mathrm{P}\bigl[(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}})
\lor
(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}})
\lor
(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}})
\nonscript\:\big\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}}\bigr]
\\[2ex]
&=
\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})
+{}
\\&\qquad
\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})
+{}
\\&\qquad
\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})
\end{aligned}
\]

\end{figure*}%

According to our background information {\(\mathsfit{K}_{\textsf{3}}\),}
our degrees of belief are exchangeable. This means that the three
probabilities summed up above must all have the same value, because in
each of them {\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)} appears
twice and {\({\color[RGB]{238,102,119}{\small\verb;N;}}\)} once. But if
we are summing the same value thrice, and the sum is {\(1\),} that that
value must be {\(1/3\).} Hence we find that

\[
\begin{aligned}
&\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})
= 1/3
\\
&\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})
= 1/3
\\
&\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})
= 1/3
\\[1ex]
&\text{all other probabilities are zero}
\end{aligned}
\]

Now let's find the probability that a rock, say \#1, has haematite
({\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)),} given that we haven't
observed any other rocks:
{\(\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})\).}
This is a marginal probability (§~\ref{sec-marginal-probs}), so it's
given by the sum

\[
\begin{aligned}
\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}}) &=
\sum_{i={\color[RGB]{34,136,51}{\small\verb;Y;}}}^{{\color[RGB]{238,102,119}{\small\verb;N;}}}\sum_{j={\color[RGB]{34,136,51}{\small\verb;Y;}}}^{{\color[RGB]{238,102,119}{\small\verb;N;}}}
\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}i \mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}j \nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})
\\[1ex]
&=
\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}}) + {}
\\ &\qquad
\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}}) + {}
\\ &\qquad
\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}}) + {}
\\ &\qquad
\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})
\\[1ex]
&= 0 + 1/3 + 1/3 + 0
\\[1ex]
&= 2/3
\end{aligned}
\]

which is indeed equal to
{\(f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}})\).}

\hfill\break

This simple example gives you an idea why our intuition for equating --
in specific circumstances -- probability with full-population
frequencies, is actually a mathematical theorem: it follows from (1)
knowledge of the full-population frequencies, and (2)
\textbf{exchangeability}.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Calculate
  {\(\mathrm{P}(R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})\),}
  that is, the probability that rock~\#2 has haematite, given that we
  don't know the haematite content of any other rock. Is it different
  from
  {\(\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})\),}
  or not? Why?
\item
  Build a similar proof for a slightly different case; for example four
  rocks; or two units from a population with a variate having three
  possible values (instead of just the two
  {\(\set{{\color[RGB]{34,136,51}{\small\verb;Y;}},{\color[RGB]{238,102,119}{\small\verb;N;}}}\)).}
\item
  Consider the same calculation we did above, but in the case of
  background knowledge {\(\mathsfit{K}_{\text{NE}}\)} where our degrees
  of belief are {\textbf{\(\text{N}\)ot \(\text{E}\)xchangeable}.} For
  instance, give three \emph{different} values to the probabilities

  \[
  \begin{gathered}
  \mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\text{NE}})
  \\
  \mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\text{NE}})
  \\
  \mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  R_{3}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\text{NE}})
  \end{gathered}
  \]

  in such a way that they still sum up to {\(1\).} Then find by
  marginalization the probability that rock~\#1 contains haematite
  ({\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)).} Is this probability
  still equal to the relative frequency of
  {\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)?}
\end{itemize}

\end{tcolorbox}

\section{Inference about several units}\label{sec-moreunit-freq-known}

Let's continue with the Mars-prospecting example of the previous
section, with just three rocks. We found that the probability that
rock~\#1 has haematite ({\({\color[RGB]{34,136,51}{\small\verb;Y;}}\))}
was {\(2/3\),} given that we haven't observed any other rocks. This
probability was equal to the frequency of
{\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)-rocks} in the urn.

Now suppose that we observe rock~\#2, and it turns out to have haematite
({\(R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\)).}
What is the probability that rock~\#1 has haematite?

The probability we are asking about is
{\(\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}})\),}
and it can be calculated with the usual rules. The result is again the
same as the frequency of the
{\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)-rocks,} but \emph{with
respect to the new situation}: there are now two rocks left in front of
us, and one must contain haematite, while the other doesn't. The
probability is therefore {\(1/2\),} a value different from that we found
before, {\(2/3\):}

\[
\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}}) = 2/3
\qquad
\mathrm{P}(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}_{\textsf{3}}) = 1/2
\]

This situation is quite general: in a collection of many rocks, the
probabilities for new observations change accordingly to information
about previous observations (and also subsequent ones, if already
known).

\hfill\break

But consider now the case {\(\mathsfit{K}\)} of a large collection of
3\,000\,000 rocks, 2\,000\,000 of which have haematite and the rest
doesn't.\footnote{Note how this scenario becomes very similar to that of
  coin tosses.} The population's relative frequencies are exactly as in
the case with three rocks, and for the probability that rock~\#1
contains haematite we still have

\[
\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) = 
f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) = \frac{2 000 000}{3 000 000} = 2/3
\]

Now suppose we examine rock~\#2 and find haematite. What is the
probability that rock~\#1 also contains haematite? In this case we find

\[
\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) = 
\frac{1 999 999}{2 999 999} \approx 2/3
\]

with an absolute error of only {\(0.000 000 1\).} That is, the
probability and frequency are almost the same as before examining
rock~\#2. The reason is clear: the number of rocks is so large that
observing some of them doesn't practically change the content and
proportions of the whole collection.

The joint probability that rock~\#2 contains haematite and rock~\#1
doesn't is therefore, by the \texttt{and}-rule,

\begin{figure*}

\[
\begin{aligned}
\mathrm{P}(R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) &=
\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) \cdot
\mathrm{P}(R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
\\[1ex]
&\approx f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) \cdot f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}})
\end{aligned}
\]

\end{figure*}%

the approximation being the better, the larger the collection of rocks.

It is easy to see that this will hold for more observations, and for
different and more complex variate domains, as long as the number of
units considered is enough small compared with the population size. For
instance

\begin{figure*}

\[
\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
\approx 
f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) \cdot f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}) \cdot f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}) \cdot f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}})
\]

\end{figure*}%

where {\(\boldsymbol{f}\)} is the \emph{initial} frequency distribution
for the population.

\hfill\break

This situation applies to more general populations: if the
full-population frequencies are known, the agent's beliefs are
exchangeable, and the population is practically infinite, then the joint
probability that some units have a particular set of values is equal to
the product of the frequencies of those values.

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

If an agent:

\begin{itemize}
\tightlist
\item
  has background information \(\mathsfit{I}\) about a population saying
  that

  \begin{itemize}
  \tightlist
  \item
    beliefs about units are exchangeable
  \item
    the population size is practically infinite
  \end{itemize}
\item
  has full information
  \(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\)
  about the population frequencies \(\boldsymbol{f}\) for the variate
  \({\color[RGB]{68,119,170}Z}\)
\end{itemize}

then

\[
\mathrm{P}(
{\color[RGB]{68,119,170}Z}_{u'}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z'} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
{\color[RGB]{68,119,170}Z}_{u''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z''} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
{\color[RGB]{68,119,170}Z}_{u'''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z'''} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb
\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) 
\approx
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z'}) \cdot
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z''}) \cdot
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z'''}) \cdot
\dotsb
\]

for any (different) units {\(u', u'', u''', \dotsc\)} and any (even
equal) values {\(\color[RGB]{68,119,170}z', z'', z''', \dotsc\).}

\end{tcolorbox}

\end{figure*}%

The formula above solves our initial problem: \emph{How to calculate and
encode the joint probability distribution for the full population?},
although it does so only in the case where the full-population
frequencies {\(\boldsymbol{f}\)} are known. In this case this
probability is encoded in the {\(\boldsymbol{f}\)} itself (which can be
represented as a multidimensional array), and can be calculated for any
desired joint probability distribution just by a multiplication.

In the {income} example from §~\ref{sec-know-freq}, the probability that
two units (citizens) {\#\(a\),} {\#\(c\)} have value
{\(\color[RGB]{68,119,170}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z^{**}\)}
and one unit {\#\(b\)} has value
{\(\color[RGB]{68,119,170}Z \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z^{*}\)}
is

\begin{figure*}

\[
\begin{aligned}
\mathrm{P}(
{\color[RGB]{68,119,170}Z}_{a}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z^{**}} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
{\color[RGB]{68,119,170}Z}_{b}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z^{*}} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
{\color[RGB]{68,119,170}Z}_{c}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z^{**}}
\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
&\approx
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z^{**}}) \cdot
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z^{*}}) \cdot
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z^{**}})
\\[1ex]
&=
0.260 058\% \cdot
0.860 369\% \cdot
0.260 058\%
\\
&= 0.000 005 818 7\%
\end{aligned}
\]

\end{figure*}%

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Always check whether the approximate
formula above is appropriate}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

As we have seen, the product formula above is strictly speaking
\emph{only approximate}. In situations where the full population has
practically infinite size compared to (1) the number of units that the
agent uses for learning, and (2) the number of units the agent will draw
inferences about, then the formula can be used as if it were exact.

But how much is ``practically infinite''? No general answer is possible:
it depends on the precision required in the specific problem. In some
problems, even if learning and inference involve 10\% of the units from
the full population, the approximation might still be acceptable; but in
other problems it might not be. If learning and inference involve 50\%
or more units from the full population, then the formula above is hardly
acceptable.

The probability calculus and the four fundamental rules allow us to
handle problems with any population size exactly (see the {Study
reading} below), but the exact computation becomes involved and
expensive. This is why the approximate product formula above is
valuable, when it can be properly used.

\end{tcolorbox}

\section{No learning when full-population frequencies are
known}\label{sec-no-learn-freqs}

Imagine an agent with exchangeable beliefs {\(\mathsfit{I}\)} and
knowledge
{\(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\)}
of the full-population frequencies, who also has observed several units
with values (possibly some identical)
{\(\color[RGB]{68,119,170}Z_{u'}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z' \mathbin{\mkern-0.5mu,\mkern-0.5mu}Z_{u''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z'' \mathbin{\mkern-0.5mu,\mkern-0.5mu}Z_{u'''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z''' \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\).}
What is this agent's degree of belief that a new unit {\#\(u\)} has
value
{\(\color[RGB]{68,119,170}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z\)?}

From our basic formula for this question,

\[
\begin{aligned}
&\mathrm{P}(\color[RGB]{238,102,119}
Z_{u}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z 
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}\color[RGB]{34,136,51}
Z_{u'}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z' \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{u''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z'' \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{u'''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z''' \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&\qquad{}=\frac{
\mathrm{P}(\color[RGB]{238,102,119}
Z_{u}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z 
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}Z_{u'}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z' \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{u''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z'' \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{u'''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z''' \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb \color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) 
}{
\sum_{\color[RGB]{170,51,119}z}
\mathrm{P}(
\color[RGB]{238,102,119}Z_{u}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\color[RGB]{170,51,119}z 
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}Z_{u'}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z' \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{u''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z'' \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{u'''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z''' \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb \color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}) 
}
\\[2ex]
&\qquad{}\approx\frac{
f({\color[RGB]{238,102,119}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z}) \cdot
f({\color[RGB]{68,119,170}{\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z'}}) \cdot 
f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z''}) \cdot 
f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z'''}) \cdot
\dotsb
}{
\sum_{\color[RGB]{170,51,119}z}
f({\color[RGB]{238,102,119}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\color[RGB]{170,51,119}z}) \cdot
f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z'}) \cdot 
f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z''}) \cdot 
f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z'''}) \cdot
\dotsb
}
\\[2ex]
&\qquad{}=\frac{
f({\color[RGB]{238,102,119}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z}) \cdot
\cancel{f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z'})} \cdot 
\cancel{f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z''})} \cdot 
\cancel{f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z'''})} \cdot
\cancel{\dotsb}
}{
\underbracket[0.2ex]{\sum_{\color[RGB]{170,51,119}z}
f({\color[RGB]{238,102,119}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\color[RGB]{170,51,119}z})}_{{}=1} \cdot
\cancel{f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z'})} \cdot 
\cancel{f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z''})} \cdot 
\cancel{f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z'''})} \cdot
\cancel{\dotsb}
}
\\[2ex]
&\qquad{}=
f({\color[RGB]{238,102,119}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z})
\\[3ex]
&\qquad{}\equiv
\mathrm{P}(\color[RGB]{238,102,119}Z_{u}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z \color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\end{aligned}
\]

so the information from the units {\(u'\),} {\(u''\),} and so on is
\emph{irrelevant} to this agent. In other words, this agent's inferences
about some units are not affected by the observation of other units.

The reason for this irrelevance is that the agent \emph{already knows
the full-population frequencies}. So the observation of the frequencies
of some values provides no new information to the agent.

Obviously this is not what we desire. But it is not a problem: the
crucial point is that knowledge of full-population frequencies is only a
hypothetical, idealized situation. In the next chapter we shall see that
learning occurs when we go beyond this idealization.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} ``Learning'' about what?}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

In this and the following sections, and sometimes in the following
chapters, when we say ``the agent is learning'' or ``the agent is not
learning'' we mean specifically the change in an agent's beliefs
{\textbf{about observation of variates of some units which had not yet
been observed}}.

Note that there is always learning about something whenever we put new
information in the conditional of a probability. In the Mars-prospecting
example above, for example, we have

\[
\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}  \mathsfit{K}) = 2/3
\qquad
\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) = 2/3
\]

and the agent has (practically) not learned anything {about the sentence
\(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\)}
from the sentence
{\(R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\).}

But we also have

\[
\mathrm{P}(R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}  \mathsfit{K}) = 2/3
\qquad
\mathrm{P}(R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) = 0
\]

the probability for the sentence
{\(R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\)}
has changed. So the agent has learned something: that rock~\#2 doesn't
contain haematite ({\({\color[RGB]{238,102,119}{\small\verb;N;}}\)).}

\end{tcolorbox}

\hfill\break

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Ch.~3 of
\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Probability
Theory}}. This chapter is extremely instructive in general to understand
how probability theory works.

\end{tcolorbox}

\chapter{\texorpdfstring{{Inference about
frequencies}}{Inference about frequencies}}\label{sec-inference-exch}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\yon}{{\green\cat{on}}}
\providecommand*{\yof}{{\red\cat{off}}}
\providecommand*{\yy}{{\lblue\cat{Y}}}
\providecommand*{\yn}{{\yellow\cat{N}}}
\providecommand{\ypl}{{\green\cat{+}}}
\providecommand{\ymi}{{\red\cat{-}}}
\providecommand{\ypa}{{\green\cat{pass}}}
\providecommand{\yfa}{{\red\cat{fail}}}

\providecommand{\hi}{{\green\cat{high}}}
\providecommand{\me}{{\yellow\cat{medium}}}
\providecommand{\lo}{{\red\cat{low}}}
\providecommand*{\yJ}{\se{J}}
\providecommand{\yva}{{\lblue-1}}
\providecommand{\yvb}{{\midgrey0}}
\providecommand{\yvc}{{\yellow1}}
\providecommand*{\yK}{\se{K}}
\providecommand*{\yL}{\se{L}}

\providecommand*{\yR}{R}

\providecommand*{\bZ}{{\blue Z}}
\providecommand*{\bz}{{\blue z}}
\providecommand*{\rY}{{\red Y}}
\providecommand*{\bY}{{\blue Y}}
\providecommand*{\ry}{{\red y}}
\providecommand*{\gX}{{\green X}}
\providecommand*{\bX}{{\blue X}}
\providecommand*{\gx}{{\green x}}
\providecommand*{\vf}{\vec{f}}

\providecommand*{\yut}{\se{K}_{\textsf{3}}}
\providecommand*{\yul}{\se{K}}

\providecommand*{\bA}{{\blue A}}
\providecommand*{\bB}{{\blue B}}
\providecommand*{\bC}{{\blue C}}

\providecommand*{\vfa}{\vf'}
\providecommand*{\vfb}{\vf''}

\section{Inference when population frequencies aren't
known}\label{sec-freq-not-known}

In chapter~~\ref{sec-inference-from-freqs} we considered an agent that
has exchangeable beliefs and that knows the full-population frequencies.
The degrees of belief of such an agent have a very simple form: products
of frequencies. But for such an agent the observations of units
\emph{doesn't give any useful information} for drawing inferences about
new units: such observations provide frequencies which the agent already
knows.

Situations where we have complete frequency knowledge can be common in
engineering problems, where the physical laws underlying the phenomena
involved are known and computable. They are far less common in
data-science and machine-learning applications: here we must consider
agents that do not know the full-population frequencies.

How does such an agent calculate probabilities about units? The answer
is actually a simple application of the ``extension of the
conversation'' (§~\ref{sec-extension-conversation}, which boil down to
applications of the \texttt{and} and \texttt{or} rules). A probability
given that the frequency distribution is not known is equal to the
average of the probabilities given each possible frequency distribution,
weighted by the probabilities of the frequency distributions:

\[
\begin{aligned}
&\mathrm{P}(
{\color[RGB]{68,119,170}Z}_{u'}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z'} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
{\color[RGB]{68,119,170}Z}_{u''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z''} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb
\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}
)
\\[2ex]
&\qquad{}=
\sum_{\boldsymbol{f}}
\mathrm{P}(
{\color[RGB]{68,119,170}Z}_{u'}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z'} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
{\color[RGB]{68,119,170}Z}_{u''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z''} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb
\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}
)
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\end{aligned}
\]

But we saw in §~\ref{sec-moreunit-freq-known} that the probability for a
sequence of values given a known frequency is just the product of the
value's frequencies. We thus have our long-sought formula:

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={de~Finetti's representation theorem}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

If an agent has background information {\(\mathsfit{I}\)} about a
population saying that

\begin{itemize}
\tightlist
\item
  beliefs about units are exchangeable
\item
  the population size is practically infinite
\end{itemize}

then

\[
\mathrm{P}(
{\color[RGB]{68,119,170}Z}_{u'}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z'} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
{\color[RGB]{68,119,170}Z}_{u''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z''} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb
\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}
)
\approx
\sum_{\boldsymbol{f}}
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z'}\color[RGB]{0,0,0}) \cdot
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z''}\color[RGB]{0,0,0}) \cdot
\,\dotsb\ 
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

for any (different) units {\(u', u'', \dotsc\)} and any (even equal)
values {\(\color[RGB]{68,119,170}z', z'', \dotsc\).}

In the sum above, {\(\boldsymbol{f}\)} runs over all possible frequency
distributions for the full population.

{Properly speaking the sum is an integral, because \(F\) is a continuous
quantity. We should write \(\mathrm{P}(
{\color[RGB]{68,119,170}Z}_{u'}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z'} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb
\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}
) = \int
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z'})  \cdot
\,\dotsb\ 
\cdot
\mathrm{p}(\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\,\mathrm{d}\boldsymbol{f}\)}

\end{tcolorbox}

\end{figure*}%

This result is called {\textbf{de~Finetti's representation theorem}} for
exchangeable belief distributions. It must be emphasized that
\textbf{this result is actually independent of any real or imaginary
population frequencies}. We took a route to it through the idea of
population frequencies only to help our intuition. If for any reason you
find the idea of a ``limit frequency for an infinite population''
somewhat suspicious, then don't worry: the formula above actually does
not rely on it. The formula results from the assumption has exchangeable
beliefs about a collection of units that can potentially be continued
without end.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Foresight:
Its logical laws, its subjective sources}}. This essay gives much
insight on our reasoning process in making forecasts and learning from
experience.

\end{tcolorbox}

\end{footnotesize}}

\hfill\break

Let's see how this formula works in the simple Mars-prospecting example
(with 3~million rocks or more) from §~\ref{sec-moreunit-freq-known}.
Suppose that the agent:

\marginnote{\begin{footnotesize}

\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{mars_crater2.jpg}

\end{footnotesize}}

\begin{itemize}
\item
  knows that the rock collection consists of:

  \begin{itemize}
  \item
    either a proportion 2/3 of
    {\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)-rocks} and 1/3 of
    {\({\color[RGB]{238,102,119}{\small\verb;N;}}\)-rocks;} denote these
    frequencies {with \(\boldsymbol{f}'\)}
  \item
    or a proportion 1/2 of
    {\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)-rocks} and 1/2 of
    {\({\color[RGB]{238,102,119}{\small\verb;N;}}\)-rocks;} denote these
    frequencies {with \(\boldsymbol{f}''\)}
  \end{itemize}
\item
  assigns a {\(75\%\)} degree of belief to the first hypothesis, and
  {\(25\%\)} to the second (so the sentence
  {\((F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}') \lor (F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'')\)}
  has probability {\(1\)):}

  \[
  \mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K}) = 75\%
  \qquad 
  \mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K}) = 25\%
  \]
\end{itemize}

What is the agent's degree of belief that rock~\#1 contains haematite?
According to the derived rule of extension of the conversation, that is,
the main formula written above, we find:

\[
\begin{aligned}
\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
&=
\sum_{\boldsymbol{f}}
f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) \cdot \mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
\\[1ex]
&=
f'(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) \cdot \mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K}) +
f''(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) \cdot \mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
\\[1ex]
&=
{\color[RGB]{102,204,238}\frac{2}{3}}\cdot 75\% +
{\color[RGB]{102,204,238}\frac{1}{2}}\cdot 25\%
\\[1ex]
&= \boldsymbol{62.5\%}
\end{aligned}
\]

In an analogous way we can calculate, for instance, the agent's belief
that rock~\#1 contains haematite, rock~\#2 doesn't, and rock~\#3 does:

\begin{figure*}

\[
\begin{aligned}
\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{3} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
&\approx
\sum_{\boldsymbol{f}}
f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) \cdot f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}) \cdot f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) \cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
\\[2ex]
&=
f'(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) \cdot f'(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}) \cdot  f'(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) \cdot 
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K}) + {}
\\[1ex]
&\qquad
f''(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) \cdot f''(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}) \cdot  f''(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) \cdot 
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
\\[2ex]
&=
{\color[RGB]{102,204,238}\frac{2}{3}}\cdot {\color[RGB]{204,187,68}\frac{1}{3}}\cdot {\color[RGB]{102,204,238}\frac{2}{3}}\cdot 75\% +
{\color[RGB]{102,204,238}\frac{1}{2}}\cdot {\color[RGB]{204,187,68}\frac{1}{2}}\cdot {\color[RGB]{102,204,238}\frac{1}{2}}\cdot 25\%
\\[2ex]
&\approx \boldsymbol{14.236\%}
\end{aligned}
\]

\end{figure*}%

\hfill\break

This formula generalizes to any population, any variates, and any number
of hypotheses about the frequencies.

Mathematical and, even more, computational complications arise when we
consider \emph{all possible} frequency distributions, since there is a
practically infinite number of them; they form a continuum in fact. But
do not let these practical difficulties affect the intuitive picture
behind them, which is simple to grasp once you've considered some simple
examples.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Consider a state of knowledge {\(\mathsfit{K}'\)} according to which:

\begin{itemize}
\tightlist
\item
  The rock collection may have a proportion \(0/10\) of
  \({\color[RGB]{34,136,51}{\small\verb;Y;}}\)-rocks (and \(9/10\) of
  \({\color[RGB]{238,102,119}{\small\verb;N;}}\)-rocks); call this
  frequency distribution \(\boldsymbol{f}_0\)
\item
  The rock collection may have a proportion \(1/10\) of
  \({\color[RGB]{34,136,51}{\small\verb;Y;}}\)-rocks; call this
  \(\boldsymbol{f}_1\)
\item
  and so on\ldots{} up to
\item
  a proportion \(10/10\) of
  \({\color[RGB]{34,136,51}{\small\verb;Y;}}\)-rocks; call this
  \(\boldsymbol{f}_{10}\)
\end{itemize}

\begin{itemize}
\item
  The probability of each of these frequency hypotheses is {\(1/11\),}
  that is:

  \[
    \begin{aligned}
    &\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}_{0} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K}') = 1/11 \\[1ex]
    &\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}_{1} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K}') = 1/11 \\[1ex]
    &\dotso\\[1ex]
    &\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}_{10} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K}') = 1/11
    \end{aligned}
    \]
\end{itemize}

Calculate the probabilities

\[
\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{K}') \qquad
\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{K}') \qquad
\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{K}')
\]

Do they all have the same value? Try to explain why or why not.

\end{tcolorbox}

\section{Learning from observed units}\label{sec-learning-general}

Staying with the same Mars-prospecting scenario, let's now ask what's
the agent's degree of belief that rock~\#1 contains haematite,
\emph{given that the agent has found that rock~\#2 doesn't contain
haematite}. In the case of an agent that knows the full-population
frequencies we saw §~\ref{sec-no-learn-freqs} that this degree of belief
is actually unaffected by other observations. What happens when the
population frequencies are not known?

The calculation is straightforward:

\[
\begin{aligned}
\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
&=
\frac{
\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
}{
\mathrm{P}(R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
}
\\[2ex]
&\approx
\frac{
\sum_{\boldsymbol{f}}
f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}) \cdot f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}) \cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
}{
\sum_{\boldsymbol{f}}
f(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}) \cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
}
\\[2ex]
&=
\frac{
{\color[RGB]{102,204,238}\frac{2}{3}}\cdot {\color[RGB]{204,187,68}\frac{1}{3}}\cdot 75\% +
{\color[RGB]{102,204,238}\frac{1}{2}}\cdot {\color[RGB]{204,187,68}\frac{1}{2}}\cdot 25\%
}{
{\color[RGB]{204,187,68}\frac{1}{3}}\cdot 75\% +
{\color[RGB]{204,187,68}\frac{1}{2}}\cdot 25\%
}
\\[2ex]
&\approx\frac{
22.9167\%
}{
37.5000\%
}
\\[2ex]
&= \boldsymbol{61.111\%}
\end{aligned}
\]

Knowledge that
{\(R_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\)}
thus \emph{does} affect the agent's belief about
{\(R_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\):}

\[
\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}  \mathsfit{K}) = 62.5\%
\qquad
\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) \approx 61.1\%
\]

In particular, the observation of one
{\({\color[RGB]{238,102,119}{\small\verb;N;}}\)-rock} has somewhat
decreased the probability of observing a new
{\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)-rock.}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Calculate the minimal number of
  {\({\color[RGB]{238,102,119}{\small\verb;N;}}\)} observations needed
  for lowering the agent's degree of belief of observing a
  {\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)} to {\(55\%\)} or less.

  Does it seem possible to lower the agent's belief to less than
  {\(50\%\)?} Explain why.
\item
  Calculate the minimal number of
  {\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)} observations needed for
  increasing the agent's degree of belief of observing a
  {\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)} to {\(65\%\)} or more.

  Does it seem possible to increase the agent's belief to more than
  {\(2/3\)?} Explain why.
\end{itemize}

\end{tcolorbox}

\section{How learning works: learning about
frequencies}\label{sec-learn-freqs}

An agent having full-population frequency information does not
learn\footnote{remember the warning of §~\ref{sec-no-learn-freqs} about
  ``learning''} from observation of units, whereas an agent not having
such information does learn from observation of units. This fact shows
how learning from observed to unobserved units actually works. Crudely
speaking, observations do not directly affect the beliefs about
unobserved units, but instead affect the \textbf{beliefs about the
population frequencies}. And these in turn affect the beliefs about
unobserved units. Graphically this could be represented as follows:

\pandocbounded{\includegraphics[keepaspectratio]{learning_flow.png}}

as opposed to this:

\pandocbounded{\includegraphics[keepaspectratio]{learning_flow2.png}}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Information connections}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

The graphs above represent {\textbf{informational}} connections, not
``causal''. The directed arrows roughly mean ``\ldots provides
information about\ldots{}''; they do not mean ``\ldots causes\ldots{}''.

In the first graph, the lack of an arrow from {\emph{observed units}} to
{\emph{unobserved units}} means that all information provided by the
observed units for the unobserved ones is fully contained in the
information about frequencies.

\end{tcolorbox}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/32045/modules}{\emph{On the
notion of cause}}

\end{tcolorbox}

\end{footnotesize}}

\hfill\break

The informational relation between observed units, frequencies, and
unobserved units becomes clear if we check how the agent's beliefs about
the frequency hypotheses change as observations are made. In the
Mars-prospecting example of §~\ref{sec-freq-not-known}, the agent has
initial probabilities

\[
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K}) = 75\%
\qquad 
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K}) = 25\%
\]

where {\(\boldsymbol{f}'\)} gives frequency {\(2/3\)} to
{\({\color[RGB]{34,136,51}{\small\verb;Y;}}\),} and
{\(\boldsymbol{f}''\)} gives frequency {\(1/2\)} to
{\({\color[RGB]{34,136,51}{\small\verb;Y;}}\).} How do these
probabilities change, conditional on the agent's observing that rock~\#2
doesn't contain haematite? We just need to use Bayes's theorem. For the
first hypothesis
{\(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\):}

\begin{figure*}

\[
\begin{aligned}
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\nonscript\:\vert\nonscript\:\mathopen{} R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) &=
\frac{
\mathrm{P}(R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) \cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
}{
\mathrm{P}(R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) \cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
+
\mathrm{P}(R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) \cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
}
\\[1ex]
&=
\frac{
f'(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}) \cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
}{
f'(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}) \cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
+
f''(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}) \cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
}
\\[1ex]
&=
\frac{
\frac{1}{3} \cdot
75\%
}{
\frac{1}{3} \cdot
75\%
+
\frac{1}{2} \cdot
25\%
}
\\[2ex]
&=
\boldsymbol{66.667\%}
\end{aligned}
\]

\end{figure*}%

and an analogous calculation yields
{\(\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\nonscript\:\vert\nonscript\:\mathopen{} R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})=33.333\%\).}

This result makes sense, because according to the hypothesis
{\(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\)}
there is a higher proportion of
{\({\color[RGB]{238,102,119}{\small\verb;N;}}\)-rocks} than according to
{\(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\),}
and a {\({\color[RGB]{238,102,119}{\small\verb;N;}}\)-rock} has been
observed. The hypothesis
{\(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\)}
therefore becomes slightly more plausible, and
{\(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\)}
slightly less.

The updated degree of belief above for the frequencies also gives us an
alternative (yet equivalent) way to calculate the conditional
probability
{\(\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})\).}
Use the derived rule of ``extension of the conversation'' in a different
manner:

\begin{figure*}

\[
\begin{aligned}
\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
&=
\sum_{\boldsymbol{f}}
\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
\\[2ex]
\text{\color[RGB]{187,187,187}\scriptsize(no learning if frequencies are known)}\enspace
&=\sum_{\boldsymbol{f}}
\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}  F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
\\[2ex]
&=
\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}  F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
+{}
\\[1ex]
&\qquad\mathrm{P}(R_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{}  F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
\\[2ex]
&=
f'(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}'\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
+{}
\\[1ex]
&\qquad
f''(R\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}''\nonscript\:\vert\nonscript\:\mathopen{} R_{2} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
\\[2ex]
&=
{\color[RGB]{102,204,238}\frac{2}{3}} \cdot 66.667\%
+
{\color[RGB]{102,204,238}\frac{1}{2}} \cdot 33.333\%
\\[2ex]
&= \boldsymbol{61.111\%}
\end{aligned}
\]

\end{figure*}%

The result is exactly as in §~\ref{sec-learning-general} -- as it should
be: remember from chapter~~\ref{sec-probability} that the four rules of
inference are built so as to mathematically guarantee this kind of
logical self-consistency.

\subsection{An intuitive interpretation of population
inference}\label{an-intuitive-interpretation-of-population-inference}

The general expression for the updated belief about frequencies has a
very intuitive interpretation. Again using Bayes's theorem, but omitting
the proportionality constant,

\begin{figure*}

\[
\begin{aligned}
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \color[RGB]{34,136,51}Z_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}Z_N\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_N \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) 
&\propto
\mathrm{P}(\color[RGB]{34,136,51}Z_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}Z_N\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_N \color[RGB]{0,0,0}
\nonscript\:\vert\nonscript\:\mathopen{} F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) 
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})
\\[2ex]
&\propto
\overbracket[0.1ex]{f(\color[RGB]{34,136,51}Z_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1\color[RGB]{0,0,0})  \cdot \,\dotsb\, 
\cdot f(\color[RGB]{34,136,51}Z_N\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_N \color[RGB]{0,0,0})}^{\color[RGB]{119,119,119}\mathclap{\text{how well the frequency "fits" the data}}} 
\ \cdot \ 
\underbracket[0.1ex]{\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})}_{\color[RGB]{119,119,119}\mathclap{\text{how reasonable the frequency is}}}
\end{aligned}
\]

\end{figure*}%

This product can be interpreted as follows.

Take a hypothetical frequency distribution {\(\boldsymbol{f}\).} If the
data have high frequencies according to it, then the product

\[f(\color[RGB]{34,136,51}Z_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1\color[RGB]{0,0,0})  \cdot \,\dotsb\, 
\cdot f(\color[RGB]{34,136,51}Z_N\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_N \color[RGB]{0,0,0})\]

has a large value. Vice versa, if the data have low frequency according
to it, that product has a small value. This product therefore expresses
how well the hypothetical frequency distribution {\(\boldsymbol{f}\)}
``fits'' the observed data.

On the other hand, if the factor

\[\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})\]

has a large value, then the hypothetical {\(\boldsymbol{f}\)} is
probable, or ``reasonable'', according to the background information
{\(\mathsfit{K}\).} Vice versa, if that factor has a low value, then the
hypothetical {\(\boldsymbol{f}\)} is improbable or ``unreasonable'',
owing to reasons expressed in the background information
{\(\mathsfit{K}\).}

The agent's belief in the hypothetical {\(\boldsymbol{f}\)} is a balance
between these two factors, the ``fit'' and the ``reasonableness''. This
has a very important consequence:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Probability inference does \textbf{not} need any ``regularization
methods'' or any procedures against ``over-fitting'' or
``under-fitting''.

In fact, \emph{the very notions of over- or under-fitting refer to the
background information \(\mathsfit{K}\) and the initial belief
\(\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})\)}.

Think about it: How can we judge that an algorithm is over- or
under-fitting, given that we do not know the ``ground truth''? (If we
knew the ground truth we wouldn't be making inferences.) Such judgement
reveals that we have some \emph{preconceived} notion of what a
reasonable distributions would look like -- that's exactly what
{\(\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{K})\)}
encodes.

\end{tcolorbox}

The agent's belief about new data is then an \emph{average} of what the
frequency of the new data would be \emph{for all possible frequency
distributions} {\(\boldsymbol{f}\):}

\[
\begin{aligned}
&\mathrm{P}(\color[RGB]{238,102,119}Z_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N+1} \color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \color[RGB]{34,136,51}Z_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}Z_N\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_N \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K}) 
\\[2ex]
&\qquad{}=
\sum_{\boldsymbol{f}}
f({\color[RGB]{238,102,119}Z_{N+1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N+1}}) \cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \color[RGB]{34,136,51}Z_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}Z_N\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_N \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{K})
\end{aligned}
\]

Each possible {\(\boldsymbol{f}\)} is weighed by its credibility, which
takes into account the fit of the possible frequency to observed data,
and its reasonableness against the agent's background information.

\subsection{Other uses of the belief distribution about
frequencies}\label{other-uses-of-the-belief-distribution-about-frequencies}

The fact that the agent is actually learning about the full-population
frequencies allows it to draw improved inferences not only about units,
but also about characteristics intrinsic to the population itself, and
also about its own performance in future inferences. For instance, the
agent can even forecast the maximal accuracy that can be obtained in
future inferences. We shall quickly explore these possibilities in a
later chapter.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Ch.~4 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Probability
  Theory}}
\item
  §§8.1--8.6 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Probability}}
\item
  Skim through
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{De~finetti's
  theorem on exchangeable variables}}
\end{itemize}

\end{tcolorbox}

\hfill\break

\section{How to assign the probabilities for the
frequencies?}\label{sec-prob-for-freqs}

The general formula we found for the joint probability:

\[
\mathrm{P}(
{\color[RGB]{68,119,170}Z}_{u'}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z'} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
{\color[RGB]{68,119,170}Z}_{u''}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z''} \mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb
\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}
)
\approx
\sum_{\boldsymbol{f}}
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z'}\color[RGB]{0,0,0}) \cdot
f({\color[RGB]{68,119,170}Z}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{68,119,170}z''}\color[RGB]{0,0,0}) \cdot
\,\dotsb\ 
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

allows us to draw many kinds of predictions about units, which we'll
explore in the next chapter.

But how does the agent
assign~~{\(\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)\,,}~~that
is, the probability distribution (in fact, a density) over all possible
frequency distributions? There is no general answer to this important
question, for two main reasons.

First, a proper answer is obviously problem-dependent. In
fact~~{\textbf{\(\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)~~is
the place where the agent encodes any background information relevant to
the problem}}.

Take the simple example of the tosses of a coin. If you (the agent)
examines the coin and the tossing method and they seem ordinary to you,
then you might assign probabilities like these:

\[
\begin{aligned}
&\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\textsf{\small`always heads'} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{o}}) \approx 0
\\
&\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\textsf{\small`always tails'} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{o}}) \approx 0
\\
&\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\textsf{\small`50\% heads 50\% tails'} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{o}}) \approx \text{\small very high}
\end{aligned}
\]

But if you are told that the coin is a magician's one, with either two
heads or two tails, and you don't know which, then you might assign
probabilities like these:

\[
\begin{aligned}
&\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\textsf{\small`always heads'} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{m}}) = 1/2
\\
&\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\textsf{\small`always tails'} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{m}}) = 1/2
\\
&\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\textsf{\small`50\% heads 50\% tails'} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{m}}) = 0
\end{aligned}
\]

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Assume the state of knowledge {\(\mathsfit{I}_{\text{m}}\)} above and
calculate:

\begin{itemize}
\item
  \(\mathrm{P}(\textsf{\small`heads 1st toss'} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\text{m}})\),
  the probability of heads at the first toss.
\item
  \(\mathrm{P}(\textsf{\small`heads 2nd toss'} \nonscript\:\vert\nonscript\:\mathopen{} \textsf{\small`heads 1st toss'} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\text{m}})\),
  the probability of heads at the second toss, given that heads was
  observed at the first.
\end{itemize}

Explain your findings.

\end{tcolorbox}

Second, for complex situations with many variates of different types it
is may be mathematically and computationally difficult to write down and
encode~~{\(\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)\,.}~~Moreover,
the multidimensional characteristics and quirks of this belief
distribution can be difficult to grasp and understand.

Yet it is a result of probability theory (§~\ref{sec-inference-origin})
that \textbf{we cannot avoid specifying
\(\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)}.
Any ``methods'' that claim to avoid the specification of that
probability distribution \emph{are} covertly specifying one instead, and
hiding it from sight. It is therefore best to have this distribution at
least open to inspection rather than hidden.

Luckily,
if~~{\(\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\)~~is}
``open-minded'', that is, if it doesn't exclude a priori any frequency
distribution {\(\boldsymbol{f}\),} or in other words if it doesn't
assign strictly zero belief to any {\(\boldsymbol{f}\),} then with
enough data the updated belief distribution
~~{\(\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{data} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\)~~will}
actually converge to the true frequency distribution of the full
population. The tricky word here is ``enough''. In some problems a dozen
observed units might be enough; in other problems a million observed
units might not be enough yet.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Bayesian
statistical inference for psychological research}}

\end{tcolorbox}

\end{footnotesize}}

\hfill\break

In chapter~~\ref{sec-dirichlet-mix} we shall discuss and implement a
mathematically concrete belief distribution
{\(\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{D})\)}
appropriate to task involving nominal variates.

\chapter{\texorpdfstring{{Final inference
formulae}}{Final inference formulae}}\label{sec-summary-formulae}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\yon}{{\green\cat{on}}}
\providecommand*{\yof}{{\red\cat{off}}}
\providecommand*{\yy}{{\lblue\cat{Y}}}
\providecommand*{\yn}{{\yellow\cat{N}}}
\providecommand{\ypl}{{\green\cat{+}}}
\providecommand{\ymi}{{\red\cat{-}}}
\providecommand{\ypa}{{\green\cat{pass}}}
\providecommand{\yfa}{{\red\cat{fail}}}

\providecommand{\hi}{{\green\cat{high}}}
\providecommand{\me}{{\yellow\cat{medium}}}
\providecommand{\lo}{{\red\cat{low}}}
\providecommand*{\yJ}{\se{J}}
\providecommand{\yva}{{\lblue-1}}
\providecommand{\yvb}{{\midgrey0}}
\providecommand{\yvc}{{\yellow1}}
\providecommand*{\yK}{\se{K}}
\providecommand*{\yL}{\se{L}}

\providecommand*{\yR}{R}

\providecommand*{\bZ}{{\blue Z}}
\providecommand*{\bz}{{\blue z}}
\providecommand*{\rY}{{\red Y}}
\providecommand*{\bY}{{\blue Y}}
\providecommand*{\ry}{{\red y}}
\providecommand*{\gX}{{\green X}}
\providecommand*{\bX}{{\blue X}}
\providecommand*{\gx}{{\green x}}
\providecommand*{\vf}{\vec{f}}

\providecommand*{\yut}{\se{K}_{\textsf{3}}}
\providecommand*{\yul}{\se{K}}

\providecommand*{\bA}{{\blue A}}
\providecommand*{\bB}{{\blue B}}
\providecommand*{\bC}{{\blue C}}

\providecommand*{\vfa}{\vf'}
\providecommand*{\vfb}{\vf''}

We finally have all theoretical ingredients and formulae to use the
probability calculus for drawing many kinds of inferences about some
units in a population, given observations from other units. Keep in mind
the minimal assumptions we are making in these formulae -- which also
underlie all machine-learning algorithms for ``supervised'' and
``unsupervised'' learning:

\begin{itemize}
\tightlist
\item
  beliefs about units are exchangeable,
\item
  the population size is practically infinite.
\end{itemize}

In the next part, {An Optimal Predictor Machine}, we shall
computationally implement these formulae and use them in a couple of
simple and not-so-simple inference problems.

Here we collect the main formulae for exchangeable beliefs and tasks
about

\begin{itemize}
\item
  \faIcon{star}~~forecasting all variates (no predictors)
\item
  \faIcon{star-half-alt}~~forecasting predictands given predictors; all
  previous predictors and predictands known
\end{itemize}

We still use the general scenario and notation of
§~\ref{sec-categ-probtheory}.

\hfill\break

All inferences about units of a population rely on the joint probability
for any number of units, which is given by the following formula
(§~\ref{sec-freq-not-known}):

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={Main formulae for some inference tasks under exchangeable beliefs}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{description}
\tightlist
\item[de~Finetti's representation]
\end{description}

\[
\begin{aligned}
&\mathrm{P}\bigl(
\color[RGB]{68,119,170}Z_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N+1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_N
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1 
\color[RGB]{0,0,0}\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} \mathsfit{I}\bigr)
\\[2ex]
&\qquad{}=
\sum_{\boldsymbol{f}}
f({\color[RGB]{68,119,170}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N+1}}\color[RGB]{0,0,0}) \cdot
f({\color[RGB]{68,119,170}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}}\color[RGB]{0,0,0}) \cdot
\, \dotsb\, \cdot
f({\color[RGB]{68,119,170}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}}\color[RGB]{0,0,0})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\end{aligned}
\]

or, in terms of predictand {\({\color[RGB]{68,119,170}Y}\)} and
predictors {\({\color[RGB]{68,119,170}X}\)} variates:

\[
\begin{aligned}
&\mathrm{P}\bigl(
\color[RGB]{68,119,170}Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} \mathsfit{I}\bigr)
\\[2ex]
&\qquad{}=
\sum_{\boldsymbol{f}}
f({\color[RGB]{68,119,170}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}}) \cdot
\, \dotsb\, \cdot
f({\color[RGB]{68,119,170}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\end{aligned}
\]

\(\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})\)
is problem-dependent and must be specified by the agent.

\hfill\break

\hfill\break

\begin{description}
\tightlist
\item[\faIcon{star} Inferences about all variates
\({\color[RGB]{68,119,170}Z}\) of a new unit, given observed units]
\end{description}

\[
\begin{aligned}
    &\mathrm{P}\bigl(
    {\color[RGB]{238,102,119}Z_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N+1}}
    \pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} 
    \color[RGB]{34,136,51}Z_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    Z_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1 
    \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\mathsfit{I}} \bigr)
    \\[2ex]
    &\qquad{}
    =
    \frac{
        \mathrm{P}\bigl(
    \color[RGB]{238,102,119}Z_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N+1}
    \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \color[RGB]{34,136,51}Z_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_N
    \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \color[RGB]{34,136,51}Z_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1 
    \color[RGB]{0,0,0}\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} {\mathsfit{I}} \bigr)
}{
     \sum_{\color[RGB]{170,51,119}z} \mathrm{P}\bigl(
    {\color[RGB]{238,102,119}Z_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}z}} 
        \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \color[RGB]{34,136,51}Z_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    Z_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1 
    \color[RGB]{0,0,0}\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}}  {\mathsfit{I}} \bigr)
}
    \\[3ex]
    &\qquad{}
    =
    \frac{
\sum_{\boldsymbol{f}}
f({\color[RGB]{238,102,119}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N+1}}\color[RGB]{0,0,0}) \cdot
f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}}\color[RGB]{0,0,0}) \cdot
\, \dotsb\, \cdot
f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}}\color[RGB]{0,0,0})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\sum_{\boldsymbol{f}}
f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}}\color[RGB]{0,0,0}) \cdot
\, \dotsb\, \cdot
f({\color[RGB]{34,136,51}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}}\color[RGB]{0,0,0})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\end{aligned}
\]

\hfill\break

\hfill\break

\begin{description}
\tightlist
\item[\faIcon{star-half-alt} Inferences about predictands
\({\color[RGB]{68,119,170}Y}\) of a new unit, given its predictors
\({\color[RGB]{68,119,170}X}\) and given both predictands \& predictors
of observed units]
\end{description}

\[
\begin{aligned}
    &\mathrm{P}\bigl(
    \color[RGB]{238,102,119}Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1}
\color[RGB]{0,0,0}\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} 
    \color[RGB]{34,136,51}X_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\,
    Y_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    Y_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_1 
    \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}\bigr)
    \\[2ex]
    &\qquad{}=
    \frac{
        \mathrm{P}\bigl(
    \color[RGB]{238,102,119}Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1} \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \color[RGB]{34,136,51}X_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
        \mathbin{\mkern-0.5mu,\mkern-0.5mu}
 Y_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_N
    \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
 Y_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_1 
    \color[RGB]{0,0,0}\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} {\mathsfit{I}} \bigr)
}{
     \sum_{\color[RGB]{170,51,119}y} \mathrm{P}\bigl(
    \color[RGB]{238,102,119}Y_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}y} \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \color[RGB]{34,136,51}X_{N+1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}
        \mathbin{\mkern-0.5mu,\mkern-0.5mu}
 Y_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_N \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_N \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    \dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
    Y_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_1 \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_1 
    \color[RGB]{0,0,0}\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}}  {\mathsfit{I}} \bigr)
}
    \\[3ex]
    &\qquad{}=
    \frac{
\sum_{\boldsymbol{f}}
f({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N+1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N+1}}) \cdot
f({\color[RGB]{34,136,51}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N} \mathbin{\mkern-0.5mu,\mkern-0.5mu}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}}) \cdot
\, \dotsb\, \cdot
f({\color[RGB]{34,136,51}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\sum_{\boldsymbol{f}}
f({\color[RGB]{34,136,51}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N} \mathbin{\mkern-0.5mu,\mkern-0.5mu}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}}) \cdot
\, \dotsb\, \cdot
f({\color[RGB]{34,136,51}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\end{aligned}
\]

\end{tcolorbox}

\end{figure*}%

\part{{\textbf{A prototype Optimal Predictor Machine}}}

\chapter{\texorpdfstring{{The Dirichlet-mixture belief
distribution}}{The Dirichlet-mixture belief distribution}}\label{sec-dirichlet-mix}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\yon}{{\green\cat{on}}}
\providecommand*{\yof}{{\red\cat{off}}}
\providecommand*{\yy}{{\lblue\cat{Y}}}
\providecommand*{\yn}{{\yellow\cat{N}}}
\providecommand{\ypl}{{\green\cat{+}}}
\providecommand{\ymi}{{\red\cat{-}}}
\providecommand{\ypa}{{\green\cat{pass}}}
\providecommand{\yfa}{{\red\cat{fail}}}

\providecommand{\hi}{{\green\cat{high}}}
\providecommand{\me}{{\yellow\cat{medium}}}
\providecommand{\lo}{{\red\cat{low}}}
\providecommand*{\yJ}{\se{J}}
\providecommand{\yva}{{\lblue-1}}
\providecommand{\yvb}{{\midgrey0}}
\providecommand{\yvc}{{\yellow1}}
\providecommand*{\yK}{\se{K}}
\providecommand*{\yL}{\se{L}}

\providecommand*{\yR}{R}

\providecommand*{\bZ}{{\blue Z}}
\providecommand*{\bz}{{\blue z}}
\providecommand*{\rY}{{\red Y}}
\providecommand*{\bY}{{\blue Y}}
\providecommand*{\ry}{{\red y}}
\providecommand*{\gX}{{\green X}}
\providecommand*{\bX}{{\blue X}}
\providecommand*{\gx}{{\green x}}
\providecommand*{\vf}{\vec{f}}

\providecommand*{\yut}{\se{K}_{\textsf{3}}}
\providecommand*{\yul}{\se{K}}

\providecommand*{\bA}{{\blue A}}
\providecommand*{\bB}{{\blue B}}
\providecommand*{\bC}{{\blue C}}

\providecommand*{\vfa}{\vf'}
\providecommand*{\vfb}{\vf''}

\providecommand*{\data}{\se{\green data}}
\providecommand*{\yD}{\se{I}_{\textrm{d}}}
\providecommand*{\ya}{k}
\providecommand*{\amin}{\ya_{\text{mi}}}
\providecommand*{\amax}{\ya_{\text{ma}}}

\providecommand{\urge}{\cat{urgent}}
\providecommand{\nonu}{\cat{non-urgent}}
\providecommand{\heli}{\cat{helicopter}}
\providecommand{\ambu}{\cat{ambulance}}
\providecommand{\othe}{\cat{other}}
\providecommand{\yJ}{\se{J}}
\providecommand{\yK}{\se{K}}

We have finally collected all we need to build a real, prototype

\includegraphics[width=0.75\linewidth,height=\textheight,keepaspectratio]{optimal_predictor_machine.png}

up from ground principles. This will be done in the present and
following chapters of this part. In this chapter we specify and discuss
a concrete belief distribution representing an agent with exchangeable
beliefs about nominal variates. In the next we put it into code. Then we
apply it to some real datasets.

\hfill\break

\section{A belief distribution for frequency distributions over nominal
variates}\label{sec-intro-dirichlet-mix}

In this course we sadly shall not examine in depth many mathematical
expressions for belief distributions
{\(\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I})\)}
over frequencies. We briefly discuss one, called the
{\textbf{Dirichlet-mixture}} belief distribution. The state of knowledge
underlying this distribution will be denoted
{\(\mathsfit{I}_{\textrm{d}}\).}

The Dirichlet-mixture distribution is appropriate for statistical
populations with \emph{nominal}, discrete variates, or joint variates
with all nominal components. It is not appropriate to discrete ordinal
variates, because it implicitly assumes that there is no natural order
to the variate values.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Some of the theoretical basis for the choice of this belief distribution
can be found in chapters~4--5 of
\href{https://hvl.instructure.com/courses/32045/modules}{\emph{The
Estimation of Probabilities}}.

\end{tcolorbox}

\end{footnotesize}}

Suppose we have a simple or joint nominal variate
{\({\color[RGB]{68,119,170}Z}\)} which can assume {\(M\)} different
values (these can be joint values, as in the examples of
§~\ref{sec-know-freq}). As usual {\(\boldsymbol{f}\)} denotes a specific
frequency distribution for the variate values. For a specific value
{\({\color[RGB]{68,119,170}z}\),} {\(f({\color[RGB]{68,119,170}z})\)} is
the relative frequency with which that value occurs in the full
population.

The Dirichlet-mixture distribution assigns to {\(\boldsymbol{f}\)} a
probability density given by the following formula:

\[\mathrm{p}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}) =
\frac{1}{k_{\text{ma}}-k_{\text{mi}}+1}
\sum_{k=k_{\text{mi}}}^{k_{\text{ma}}}
\Biggl[\prod_{{\color[RGB]{68,119,170}z}} f({\color[RGB]{68,119,170}z})^{\frac{2^k}{M} -1} \Biggr]
\cdot
\frac{
\bigl(2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{M} - 1\bigr)!}^M
}
\]

Besides some multiplicative constants, the probability is simply
proportional to the product of all frequencies, raised to some powers.
The product {``\(\prod_{{\color[RGB]{68,119,170}z}}\)''} is over all
{\(M\)} possible values of {\({\color[RGB]{68,119,170}Z}\).} The sum
{``\(\sum_{k}\)''} is over an \emph{integer} (positive or negative)
index {\(k\)} that runs between the minimum value {\(k_{\text{mi}}\)}
and the maximum value {\(k_{\text{ma}}\).} In the applications of the
next chapters these minimum and maximum are chosen as follows:

\[
k_{\text{mi}}=0
\qquad
k_{\text{ma}}=20
\]

so the sum {\(\sum_k\)} runs over 21 terms.

In most applications it does not matter if we take a lower
{\(k_{\text{mi}}\)} or a higher {\(k_{\text{ma}}\).}

\subsection{\texorpdfstring{Meaning of the
\(k_{\text{mi}}, k_{\text{ma}}\)
parameters}{Meaning of the k\_\{\textbackslash text\{mi\}\}, k\_\{\textbackslash text\{ma\}\} parameters}}\label{meaning-of-the-k_textmi-k_textma-parameters}

The parameters {\(k_{\text{mi}}, k_{\text{ma}}\)} encode, approximately
speaking, the agent's prior belief about how many data are needed to
change its initial beliefs. More precisely, {\(2^{k_{\text{mi}}}\)} and
{\(2^{k_{\text{ma}}}\)} represent a lower and an upper bound on the
amount of data necessary to overcome initial beliefs.
Values~~{\(k_{\text{mi}}=0\),~~}{\(k_{\text{ma}}=20\)~~represent} the
belief that such amount could be anywhere between 1 unit and
approximately 1\,million units. The belief is spread out uniformly
across the orders of magnitude in between.

If {\(2^{k_{\text{mi}}}\)} is larger than the amount of training data,
the agent will consider these data insufficient, and tend to give
uniform probabilities to its inferences, for example a 50\%/50\%
probability to a binary variate.

If the amount of data that should be considered ``enough'' is known, for
example from previous studies on similar populations, the parameters
{\(k_{\text{mi}},k_{\text{ma}}\)} can be set to that order of magnitude
(in base\,2), minus or plus some magnitude range.

Note that if such an order of magnitude is not known, then it does
\emph{not} make sense to ``estimate'' it from training data with other
methods, because an agent with a Dirichlet-mixture distribution will
already do that internally (and in an optimal way), provided an ample
range is given with {\(k_{\text{mi}}, k_{\text{ma}}\).}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

In the calculations and exercises that follow, you're welcome to do them
also with other {\(k_{\text{mi}}\)} and {\(k_{\text{ma}}\)} values, and
see what happens.

\end{tcolorbox}

\hfill\break

Let's see how this formula looks like in a concrete, simple example: the
Mars-prospecting scenario (which has many analogies with coin tosses).

The variate {\(R\)} can assume two values
{\(\set{{\color[RGB]{34,136,51}{\small\verb;Y;}},{\color[RGB]{238,102,119}{\small\verb;N;}}}\),}
so {\(M=2\)} in this case. The frequency distribution consists in two
frequencies:

\[f({\color[RGB]{34,136,51}{\small\verb;Y;}}) \qquad f({\color[RGB]{238,102,119}{\small\verb;N;}})\]

of which only one can be chosen independently, since they must sum up to
1. For instance we could consider
{\(f({\color[RGB]{34,136,51}{\small\verb;Y;}})=0.5, f({\color[RGB]{238,102,119}{\small\verb;N;}})=0.5\),~~or}
{\(f({\color[RGB]{34,136,51}{\small\verb;Y;}})=0.84, f({\color[RGB]{238,102,119}{\small\verb;N;}})=0.16\),~~and}
so on.

\emph{Only for this example} we choose

\[k_{\text{mi}}=0 \qquad k_{\text{ma}}=2\]

so that the sum {\(\sum_k\)} runs over 3 terms.

The agent's belief distribution for the frequencies is

\[
\begin{aligned}
\mathrm{p}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}) &=
\frac{1}{2-0+1}
\sum_{k=0}^{2}
\Biggl[\prod_{{\color[RGB]{68,119,170}z}={\color[RGB]{34,136,51}{\small\verb;Y;}}}^{{\color[RGB]{238,102,119}{\small\verb;N;}}} f({\color[RGB]{68,119,170}z})^{\frac{2^k}{2} -1} \Biggr]
\cdot
\frac{
\bigl(2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{2} - 1\bigr)!}^2
}
\\[2ex]
&=
\frac{1}{3}
\Biggl[
f({\color[RGB]{34,136,51}{\small\verb;Y;}})^{\frac{2^{0}}{2}-1}\cdot f({\color[RGB]{238,102,119}{\small\verb;N;}})^{\frac{2^{0}}{2}-1}
\cdot
\frac{
\bigl(2^{0} -1 \bigr)!
}{
{\bigl(\frac{2^{0}}{2} - 1\bigr)!}^2
}
+{} \\[1ex]&\qquad
f({\color[RGB]{34,136,51}{\small\verb;Y;}})^{\frac{2^{1}}{2}-1}\cdot f({\color[RGB]{238,102,119}{\small\verb;N;}})^{\frac{2^{1}}{2}-1}
\cdot
\frac{
\bigl(2^{1} -1 \bigr)!
}{
{\bigl(\frac{2^{1}}{2} - 1\bigr)!}^2
}
+{} \\[1ex]&\qquad
f({\color[RGB]{34,136,51}{\small\verb;Y;}})^{\frac{2^{2}}{2}-1}\cdot f({\color[RGB]{238,102,119}{\small\verb;N;}})^{\frac{2^{2}}{2}-1}
\cdot
\frac{
\bigl(2^{2} -1 \bigr)!
}{
{\bigl(\frac{2^{2}}{2} - 1\bigr)!}^2
}
\Biggr]
\\[2ex]
&=
\frac{1}{3}
\Biggl[
\frac{1}{\sqrt{f({\color[RGB]{34,136,51}{\small\verb;Y;}})}}\cdot \frac{1}{\sqrt{f({\color[RGB]{238,102,119}{\small\verb;N;}})}}
\cdot \frac{1}{\pi}
+{} \\[1ex]&\qquad
1 \cdot 1 \cdot \frac{1}{1}
+{} \\[1ex]&\qquad f({\color[RGB]{34,136,51}{\small\verb;Y;}})\cdot f({\color[RGB]{238,102,119}{\small\verb;N;}})
\cdot \frac{6}{1}
\Biggr]
\end{aligned}
\]

\hfill\break

We can visualize this belief distribution (with
{\(k_{\text{mi}}=0, k_{\text{ma}}=2\))} with a generalized scatter plot
(§~\ref{sec-repr-general-distr}) of 100 frequency distributions, each
represented by a line histogram (§~\ref{sec-discr-prob-distr}):

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{samples_rocks.png}

Alternatively we can represent the probability density of the frequency
{\(f({\color[RGB]{34,136,51}{\small\verb;Y;}})\):}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{dirmix_pdf_rocks.png}

You can see some characteristics of this belief:

\begin{itemize}
\item
  all possible frequency distributions are taken into account, that is,
  no frequency is judged impossible and given zero probability
\item
  a higher probability is given to frequency distributions that are
  almost 50\%/50\%, or that are almost 0\%/100\% or 100\%/0\%
\end{itemize}

The second characteristic expresses the belief that the agent may more
often deal with tasks where frequencies are almost symmetric (think of
coin toss), or the opposite: tasks where, once you observe a phenomenon,
you're quite sure you'll keep observing it. This latter case is typical
of some physical phenomena; an example is given by Jaynes:

\begin{quote}
For example, in a chemical laboratory we find a jar containing an
unknown and unlabeled compound. We are at first completely ignorant as
to whether a small sample of this compound will dissolve in water or
not. But having observed that one small sample does dissolve, we infer
immediately that all samples of this compound are water soluble, and
although this conclusion does not carry quite the force of deductive
proof, we feel strongly that the inference was justified.
\end{quote}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/32045/modules/items/723829}{\emph{Prior
probabilities}}

\end{tcolorbox}

\end{footnotesize}}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Calculate the formula above for these three frequency distributions:

\begin{itemize}
\item
  \(f({\color[RGB]{34,136,51}{\small\verb;Y;}})=0.5\quad f({\color[RGB]{238,102,119}{\small\verb;N;}})=0.5\)
\item
  \(f({\color[RGB]{34,136,51}{\small\verb;Y;}})=0.75\quad f({\color[RGB]{238,102,119}{\small\verb;N;}})=0.25\)
\item
  \(f({\color[RGB]{34,136,51}{\small\verb;Y;}})=0.99\quad f({\color[RGB]{238,102,119}{\small\verb;N;}})=0.01\)
\end{itemize}

\end{tcolorbox}

\section{Formula for joint probabilities about units with the
Dirichlet-mixture distribution}\label{sec-joint-prob-dirichlet}

A mathematical advantage of the Dirichlet-mixture belief distribution is
that some formulae where it enters can be computed exactly. The most
important formula is de~Finetti's representation theorem
(§~\ref{sec-freq-not-known}), where the sum {\(\sum_{\boldsymbol{f}}\)}
(really an integral {\(\int\,\mathrm{d}\boldsymbol{f}\))} can be
calculated analytically in the case of the Dirichlet-mixture:

\[
\begin{aligned}
\mathrm{P}(
\color[RGB]{68,119,170}
Z_{L}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{L}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1
\color[RGB]{0,0,0}
\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}
)
&=
\int
f(\color[RGB]{68,119,170}Z_{L}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{L} \color[RGB]{0,0,0}) \cdot
\,\dotsb\, \cdot
f(\color[RGB]{68,119,170}Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1 \color[RGB]{0,0,0}) \cdot
\mathrm{p}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
\,\mathrm{d}\boldsymbol{f}
\\[2ex]
&=
\frac{1}{k_{\text{ma}}-k_{\text{mi}}+1}
\sum_{k=k_{\text{mi}}}^{k_{\text{ma}}}
\frac{
\prod_{{\color[RGB]{68,119,170}z}} \bigl(\frac{2^{k}}{M} + \#{\color[RGB]{68,119,170}z}- 1\bigr)!
}{
\bigl(2^{k} + L -1 \bigr)!
}
\cdot
\frac{
\bigl(2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{M} - 1\bigr)!}^M
}
\end{aligned}
\]

where {\(\#{\color[RGB]{68,119,170}z}\)} is the multiplicity with which
the specific value {\({\color[RGB]{68,119,170}z}\)} occurs in the
sequence {\(\color[RGB]{68,119,170}z_1,\dotsc,z_{L}\).}

\hfill\break

Let's see how this formula looks like in an example from the
Mars-prospecting scenario.

Take the sequence\footnote{Remember that the agent has exchangeable
  beliefs, so the units' IDs don't matter
  (§~\ref{sec-exchaneable-distr})!}

\[
R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}
\]

in this sequence, value {\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)}
appears thrice and value
{\({\color[RGB]{238,102,119}{\small\verb;N;}}\)} once, that is

\[L=4 \qquad \#{\color[RGB]{34,136,51}{\small\verb;Y;}}= 3 \qquad \#{\color[RGB]{238,102,119}{\small\verb;N;}}= 1\]

In this case we have {\(M=2\),} and we still take
{\(k_{\text{mi}}=0, k_{\text{ma}}=2\).} The formula above then becomes

\[
\begin{aligned}
&\mathrm{P}(
\underbracket[0.1ex]{R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}}_{
\color[RGB]{187,187,187}L=4\quad \#{\small\verb;Y;}=3\quad \#{\small\verb;N;}=1
}
\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}
)
\\
&\qquad{}=
\frac{1}{k_{\text{ma}}-k_{\text{mi}}+1}
\sum_{k=k_{\text{mi}}}^{k_{\text{ma}}}
\frac{
\prod_{{\color[RGB]{68,119,170}z}} \bigl(\frac{2^{k}}{M} + \#{\color[RGB]{68,119,170}z}- 1\bigr)!
}{
\bigl(2^{k} + L -1 \bigr)!
}
\cdot
\frac{
\bigl(2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{M} - 1\bigr)!}^M
}
\\[2ex]
&\qquad{}=
\frac{1}{2-0+1}
\sum_{k=k_{\text{mi}}}^{k_{\text{ma}}}
\frac{
\bigl(\frac{2^{k}}{2} + \#{\color[RGB]{34,136,51}{\small\verb;Y;}}- 1\bigr)!
\cdot \bigl(\frac{2^{k}}{2} + \#{\color[RGB]{238,102,119}{\small\verb;N;}}- 1\bigr)!
}{
\bigl(2^{k} + 4 -1 \bigr)!
}
\cdot
\frac{
\bigl(2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{2} - 1\bigr)!}^2
}
\\[2ex]
&\qquad{}=
\frac{1}{3}
\sum_{k=-1}^{2}
\frac{
\bigl(\frac{2^{k}}{2} + {\color[RGB]{102,204,238}3} - 1\bigr)! \cdot
\bigl(\frac{2^{k}}{2} + {\color[RGB]{204,187,68}1} - 1\bigr)!
}{
\bigl(2^{k} + 3 \bigr)!
}
\cdot
\frac{
\bigl(2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{2} - 1\bigr)!}^2
}
\\[1ex]
&\qquad{}=
\boldsymbol{0.048 735 1}
\end{aligned}
\]

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Using the formula above, calculate:

  \begin{itemize}
  \item
    \(\mathrm{P}(R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})\)\,;
    does the result make sense?
  \item
    \(\mathrm{P}(R_{32}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{102}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_{8}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})\)
  \end{itemize}
\end{itemize}

\begin{itemize}
\tightlist
\item
  Try doing the calculation above on a computer, with
  \(k_{\text{mi}}=0, k_{\text{ma}}=20\). What happens?
\end{itemize}

\end{tcolorbox}

\section{Examples of inference tasks with the Dirichlet-mixture belief
distribution}\label{sec-formulae-with-Dirmix}

With the explicit formula

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\[
\mathrm{P}(
\color[RGB]{68,119,170}
Z_{L}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{L}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1
\color[RGB]{0,0,0}
\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}
)
=
\frac{1}{k_{\text{ma}}-k_{\text{mi}}+1}
\sum_{k=k_{\text{mi}}}^{k_{\text{ma}}}
\frac{
\prod_{{\color[RGB]{68,119,170}z}} \bigl(\frac{2^{k}}{M} + \#{\color[RGB]{68,119,170}z}- 1\bigr)!
}{
\bigl(2^{k} + L -1 \bigr)!
}
\cdot
\frac{
\bigl(2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{M} - 1\bigr)!}^M
}
\]

where {\(\#{\color[RGB]{68,119,170}z}\)} is the number of times some
value {\({\color[RGB]{68,119,170}z}\)} appears in the sequence

\end{tcolorbox}

\end{figure*}%

we can now solve all the kinds of task involving multiple units that
were discussed in §~\ref{sec-categ-probtheory}. Let's see a simple
example of forecasting all variates for a new unit (no predictors), and
another example where we guess a predictand given a predictor. We shall
solve them step by step.

\section{Example~1: Forecast about one variate, given previous
observations}\label{sec-dirmix-example1}

In this task there are no predictors and only one predictand variate
{\(R\):} the presence of haematite. The agent observes the value of this
variate in several rocks, and tries to forecast its value in a new rock.

The agent has exchangeable beliefs represented by a Dirichlet-mixture
distribution. The variate of the population of interest has two possible
values, so in the formulae above we have~~{\(M=2\).} We still take
{\(k_{\text{mi}}=0\),} {\(k_{\text{ma}}=2\).}

The agent has collected three rocks. Upon examination, two of them
contain haematite, one doesn't. The agent's data are therefore

\[\text{\small data:}\quad R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\]

(remember that it doesn't matter how the rocks are labelled, because the
agent's beliefs are exchangeable).

What probability should the agent give to finding haematite in a newly
collected rock? That is, what value should it assign to

\[\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}}) \ ?\]

Our main formula is

\[
\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})
=
\frac{
\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}{
\sum_{{\color[RGB]{170,51,119}r}={\color[RGB]{34,136,51}{\small\verb;Y;}}}^{{\color[RGB]{238,102,119}{\small\verb;N;}}}
\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}r} \mathbin{\mkern-0.5mu,\mkern-0.5mu}R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}
\]

\hfill\break

{\faIcon{1} \faIcon{hand-point-right}}~~~The fraction above requires the
computation of two joint probabilities:

\[
\begin{aligned}
\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}) 
\\[1ex]
\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}) 
\end{aligned}
\]

Note how they are associated with the two possible hypotheses about the
new rock:

\[R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\qquad R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\]

of which the first one interests us.

{\faIcon{2}a \faIcon{hand-point-right}}~~In the first joint probability,
{\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)} appears thrice and
{\({\color[RGB]{238,102,119}{\small\verb;N;}}\)} appears once, so

\[\#{\color[RGB]{34,136,51}{\small\verb;Y;}}= 3 \qquad \#{\color[RGB]{238,102,119}{\small\verb;N;}}= 1 \qquad {\color[RGB]{119,119,119}L} = {\color[RGB]{119,119,119}4}\]

The de~Finetti representation formula gives

\[\begin{aligned}
&\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}) 
\\[1ex]
&\qquad{}=
\frac{1}{2-0+1}
\sum_{k=0}^{2}
\frac{
\bigl(\frac{2^{k}}{2} + {\color[RGB]{102,204,238}3} - 1\bigr)! \cdot
\bigl(\frac{2^{k}}{2} + {\color[RGB]{204,187,68}1} - 1\bigr)!
}{
\bigl(2^{k} + {\color[RGB]{119,119,119}4} -1 \bigr)!
}
\cdot
\frac{
\bigl(2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{2} - 1\bigr)!}^2
}
\\[1ex]
&\qquad{}=
\boldsymbol{0.048 735 1}
\end{aligned}
\]

\hfill\break

{\faIcon{2}b \faIcon{hand-point-right}}~~In the second joint
probability, {\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)} appears
twice and {\({\color[RGB]{238,102,119}{\small\verb;N;}}\)} appears
twice, so

\[\#{\color[RGB]{34,136,51}{\small\verb;Y;}}= 2 \qquad \#{\color[RGB]{238,102,119}{\small\verb;N;}}= 2 \qquad {\color[RGB]{119,119,119}L} = {\color[RGB]{119,119,119}4}\]

We find

\[\begin{aligned}
&\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}) 
\\[1ex]
&\qquad{}=
\frac{1}{2-0+1}
\sum_{k=0}^{2}
\frac{
\bigl(\frac{2^{k}}{2} + {\color[RGB]{102,204,238}2} - 1\bigr)! \cdot
\bigl(\frac{2^{k}}{2} + {\color[RGB]{204,187,68}2} - 1\bigr)!
}{
\bigl(2^{k} + {\color[RGB]{119,119,119}4} -1 \bigr)!
}
\cdot
\frac{
\bigl(2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{2} - 1\bigr)!}^2
}
\\[1ex]
&\qquad{}=
\boldsymbol{0.033 209 3}
\end{aligned}
\]

\hfill\break

{\faIcon{3} \faIcon{hand-point-right}}~~~The probability for the
hypothesis of interest is finally given by the fraction

\begin{figure*}

\[
\begin{aligned}
&\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\nonscript\:\vert\nonscript\:\mathopen{} R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})
\\[1ex]
&\qquad{}=
\frac{
\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}{
\sum_{{\color[RGB]{170,51,119}r}={\color[RGB]{34,136,51}{\small\verb;Y;}}}^{{\color[RGB]{238,102,119}{\small\verb;N;}}}
\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}r} \mathbin{\mkern-0.5mu,\mkern-0.5mu}R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}
\\[1ex]
&\qquad{}=
\frac{
\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}{
\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}) +
\mathrm{P}(R_4\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, R_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}R_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;N;}}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}
\\[1ex]
&\qquad{}=
\frac{0.048 735 1}{0.048 735 1 + 0.033 209 3}
\\[1ex]
&\qquad{}=
\boldsymbol{59.47\%}
\end{aligned}
\]

\end{figure*}%

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  The inference problem above has some analogy with coin tossing:
  there's just one, binary, variate. This agent could have been used to
  make forecasts about coin tosses.

  Consider the result above from the point of view of this analogy.
  Let's say that {\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)} would be
  ``heads'', and {\({\color[RGB]{238,102,119}{\small\verb;N;}}\)}
  ``tails''. Having observed four coin tosses, with three heads and one
  tail, the agent is giving a 58\% probability for heads at the next
  toss.

  \begin{itemize}
  \item
    Do you consider this probability reasonable? Why?
  \item
    In which different coin-tossing circumstances would you consider
    this probability reasonable (given the same previous observation
    data)?
  \end{itemize}
\item
  Try doing the calculation above on a computer, using the
  values~~{\(k_{\text{mi}}=0, k_{\text{ma}}=20\).}

  If you use the formulae above as they're given, you'll probably get
  just \texttt{NaN}s. The formulae above must be rewritten in a
  different way in order not to generate overflow. The result would be
  {\(\boldsymbol{51.42\%}\).}
\end{itemize}

\end{tcolorbox}

\section{Example~2: Forecast about one predictand, given predictor and
previous observations}\label{sec-dirmix-example2}

Let's go back to the hospital scenario of
§~\ref{sec-conditional-joint-general}. The units are patients coming
into a hospital. The population is characterized by two nominal
variates:

\begin{itemize}
\tightlist
\item
  \(T\): the patient's means of transportation at arrival, with domain
  \(\set{{\small\verb;ambulance;}, {\small\verb;helicopter;}, {\small\verb;other;}}\)
\item
  \(U\): the patient's need of urgent care, with domain
  \(\set{{\small\verb;urgent;}, {\small\verb;non-urgent;}}\)
\end{itemize}

The combined variate {\((U \mathbin{\mkern-0.5mu,\mkern-0.5mu}T)\)}
has~~{\(M = 2\cdot 3 = 6\)~~possible} values. We still use parameters
{\(k_{\text{mi}}=0\)} and {\(k_{\text{ma}}=2\)} to use the de~Finetti
formula as-is without causing overflow errors.

The agent's task is to forecast whether the next incoming patient will
require urgent care, given information about the patient's
transportation. So {\(U\)} is the predictand variate, {\(T\)} the
predictor variate.

At the moment the agent has a complete record of two previous patients:

\begin{itemize}
\tightlist
\item
  \(U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\)
\item
  \(U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\)
\end{itemize}

A third patient is incoming by ambulance:

\begin{itemize}
\tightlist
\item
  \(T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\)
\end{itemize}

What is the probability that this patient requires urgent care?

\subsubsection{Initial belief}\label{initial-belief}

First let's get a glimpse of the agent's forecast if it were given
\emph{no} information about previous patients. We therefore want to
calculate the probability

\[\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})\]

\hfill\break

{\faIcon{1} \faIcon{hand-point-right}}~~~We need to calculate the two
joint probabilities

\[
\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
\qquad
\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
\]

corresponding to the two hypotheses of interest,
{\(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\)}
and
{\(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\).}

\hfill\break

{\faIcon{2}a \faIcon{hand-point-right}}~~In the first joint probability
above the value pair
{\((U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;})\)}
appears once, and the remaining five pairs appear zero times:

\[\#({\small\verb;urgent;}, {\small\verb;ambulance;}) = {\color[RGB]{102,204,238}1} \qquad\text{\small five others }\#(\dotsc,\dotsc) = {\color[RGB]{204,187,68}0}
\qquad {\color[RGB]{119,119,119}L} = {\color[RGB]{119,119,119}1}\]

The de~Finetti formula gives

\begin{figure*}

\[
\begin{aligned}
&\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
\\[2ex]
&\qquad{}=
\frac{1}{2-0+1}
\sum_{k=0}^{2}
\frac{
\bigl(\frac{2^{k}}{6} + {\color[RGB]{102,204,238}1} - 1\bigr)! \cdot
\underbracket[0.1ex]{\bigl(\frac{2^{k}}{6} + {\color[RGB]{204,187,68}0} - 1\bigr)! \cdot 
\,\dotsb\, \cdot
\bigl(\frac{2^{k}}{6} + {\color[RGB]{204,187,68}0} - 1\bigr)!}_{\text{\color[RGB]{187,187,187}five factors}}
}{
\bigl( 2^{k} + {\color[RGB]{119,119,119}1} -1 \bigr)!
}
\cdot
\frac{
\bigl( 2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{6} - 1\bigr)!}^6
}
\\[1ex]
&\qquad{}=
\boldsymbol{1/6}
\end{aligned}
\]

\end{figure*}%

\hfill\break

{\faIcon{2}b \faIcon{hand-point-right}}~~In the second joint probability
above the value pair
{\((U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;})\)}
appears once, and the remaining five pairs appear zero times:

\[\#({\small\verb;non-urgent;}, {\small\verb;ambulance;}) = {\color[RGB]{102,204,238}1} \qquad\text{\small five others }\#(\dotsc,\dotsc) = {\color[RGB]{204,187,68}0}
\qquad {\color[RGB]{119,119,119}L} = {\color[RGB]{119,119,119}1}\]

The de~Finetti formula gives an identical result as before:

\begin{figure*}

\[
\begin{aligned}
&\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
\\[2ex]
&\qquad{}=
\frac{1}{2-0+1}
\sum_{k=0}^{2}
\frac{
\bigl(\frac{2^{k}}{6} + {\color[RGB]{102,204,238}1} - 1\bigr)! \cdot
\underbracket[0.1ex]{\bigl(\frac{2^{k}}{6} + {\color[RGB]{204,187,68}0} - 1\bigr)! \cdot 
\,\dotsb\, \cdot
\bigl(\frac{2^{k}}{6} + {\color[RGB]{204,187,68}0} - 1\bigr)!}_{\text{\color[RGB]{187,187,187}five factors}}
}{
\bigl( 2^{k} + {\color[RGB]{119,119,119}1} -1 \bigr)!
}
\cdot
\frac{
\bigl( 2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{6} - 1\bigr)!}^6
}
\\[1ex]
&\qquad{}=
\boldsymbol{1/6}
\end{aligned}
\]

\end{figure*}%

\hfill\break

{\faIcon{3} \faIcon{hand-point-right}}~~~The probability that this
incoming patient is urgent is then

\begin{figure*}

\[
\begin{aligned}
&
\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})
\\[1ex]
&\qquad{}=
\frac{
\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}{
\sum_{\color[RGB]{170,51,119}u}
\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}u} \mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}
\\[1ex]
&\qquad{}=
\frac{
\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}{
\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
+
\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}
\\[1ex]
&\qquad{}=
\frac{1/6 }{1/6 + 1/6}
\\[1ex]
&\qquad{}=
\boldsymbol{50\%}
\end{aligned}
\]

\end{figure*}%

\hfill\break

The agent's background information says that, a priori, urgent and
non-urgent patients are equally plausible. This is a characteristic of
the particular Dirichlet-mixture belief distribution we are using. It
would actually be possible to modify it so as to give a-priori different
probabilities for the {\({\small\verb;urgent;}\)} and
{\({\small\verb;non-urgent;}\)} values; but we shall not pursue this
possibility here.

\hfill\break

\subsubsection{Forecast after learning}\label{forecast-after-learning}

Now let's take into account the information about the previous two
patients. We therefore want to calculate the probability

\begin{figure*}

\[\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I}_{\textrm{d}})
\]

\end{figure*}%

\hfill\break

{\faIcon{1} \faIcon{hand-point-right}}~~~The hypotheses are again
{\(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\)}
and
{\(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\),}
and we need the joint probabilities

\begin{figure*}

\[
\begin{aligned}
&\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{}
\mathsfit{I}_{\textrm{d}})
\\[1ex]
&\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{}
\mathsfit{I}_{\textrm{d}})
\end{aligned}
\]

\end{figure*}%

\hfill\break

{\faIcon{2}a \faIcon{hand-point-right}}~~The first joint probability has
the following counts:

\begin{figure*}

\[
\#({\small\verb;urgent;}, {\small\verb;ambulance;}) = {\color[RGB]{68,119,170}2} \quad
\#({\small\verb;non-urgent;}, {\small\verb;other;}) = {\color[RGB]{102,204,238}1} \quad
\text{\small four others }\#(\dotsc,\dotsc) = {\color[RGB]{204,187,68}0}
\quad {\color[RGB]{119,119,119}L} = {\color[RGB]{119,119,119}3}\]

\end{figure*}%

and therefore

\begin{figure*}

\[
\begin{aligned}
&\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{}
\mathsfit{I}_{\textrm{d}})
\\[2ex]
&\qquad{}=
\frac{1}{3}
\sum_{k=0}^{2}
\frac{
\bigl(\frac{2^{k}}{6} + {\color[RGB]{68,119,170}2} - 1\bigr)! \cdot
\bigl(\frac{2^{k}}{6} + {\color[RGB]{102,204,238}1} - 1\bigr)! \cdot
\underbracket[0.1ex]{\bigl(\frac{2^{k}}{6} + {\color[RGB]{204,187,68}0} - 1\bigr)! \cdot 
\,\dotsb\, \cdot
\bigl(\frac{2^{k}}{6} + {\color[RGB]{204,187,68}0} - 1\bigr)!}_{\text{\color[RGB]{187,187,187}four factors}}
}{
\bigl( 2^{k} + {\color[RGB]{119,119,119}3} -1 \bigr)!
}
\cdot
\frac{
\bigl( 2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{6} - 1\bigr)!}^6
}
\\[1ex]
&\qquad{}=
\boldsymbol{0.005 915 64}
\end{aligned}
\]

\end{figure*}%

\hfill\break

{\faIcon{2}b \faIcon{hand-point-right}}~~Counts for the second joint
probability:

\begin{figure*}

\[
\begin{gathered}
\#({\small\verb;urgent;}, {\small\verb;ambulance;}) = {\color[RGB]{102,204,238}1} \qquad
\#({\small\verb;non-urgent;}, {\small\verb;ambulance;}) = {\color[RGB]{102,204,238}1} \qquad
\#({\small\verb;non-urgent;}, {\small\verb;other;}) = {\color[RGB]{102,204,238}1}
\\[1ex]
\text{\small three others }\#(\dotsc,\dotsc) = {\color[RGB]{204,187,68}0}
\qquad {\color[RGB]{119,119,119}L} = {\color[RGB]{119,119,119}3}
\end{gathered}
\]

\end{figure*}%

and therefore

\begin{figure*}

\[
\begin{aligned}
&\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{}
\mathsfit{I}_{\textrm{d}})
\\[2ex]
&\qquad{}=
\frac{1}{3}
\sum_{k=0}^{2}
\frac{
\underbracket[0.1ex]{
\bigl(\frac{2^{k}}{6} + {\color[RGB]{102,204,238}1} - 1\bigr)!
\cdot\,\dotsb\, \cdot
\bigl(\frac{2^{k}}{6} + {\color[RGB]{102,204,238}1} - 1\bigr)!
}_{\text{\color[RGB]{187,187,187}three factors}}
\cdot
\underbracket[0.1ex]{\bigl(\frac{2^{k}}{6} + {\color[RGB]{204,187,68}0} - 1\bigr)! \cdot 
\,\dotsb\, \cdot
\bigl(\frac{2^{k}}{6} + {\color[RGB]{204,187,68}0} - 1\bigr)!}_{\text{\color[RGB]{187,187,187}three factors}}
}{
\bigl( 2^{k} + {\color[RGB]{119,119,119}3} -1 \bigr)!
}
\cdot
\frac{
\bigl( 2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{6} - 1\bigr)!}^6
}
\\[1ex]
&\qquad{}=
\boldsymbol{0.001 594 65}
\end{aligned}
\]

\end{figure*}%

\hfill\break

{\faIcon{3} \faIcon{hand-point-right}}~~~Finally, the probability that
the third incoming patient is urgent is

\begin{figure*}

\[
\begin{aligned}
&
\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\mathsfit{I}_{\textrm{d}})
\\[1ex]
&\qquad{}=
\frac{0.005 915 64}{0.005 915 64 + 0.001 594 65}
\\[1ex]
&\qquad{}=
\boldsymbol{78.77\%}
\end{aligned}
\]

\end{figure*}%

The agent has learned an association between
{\({\small\verb;ambulance;}\)} and {\({\small\verb;urgent;}\)} from the
first patient. Note that if we had used the parameters
{\(k_{\text{mi}}=0, k_{\text{ma}}=20\),} the result would have been more
conservative: {\(\boldsymbol{54.90\%}\).}

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Do the inverse inference, using urgency {\(U\)} as predictor, and
  transportation {\(T\)} as predictand. That is, calculate the
  probability

  \[\mathrm{P}( T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\nonscript\:\vert\nonscript\:\mathopen{} U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  U_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  \mathsfit{I}_{\textrm{d}})\]
\item
  Imagine that the urgency variate for the first patient, {\(U_1\),} is
  not known (missing data). Using the formula for marginalization (see
  §~\ref{sec-underlying-distribution}), calculate the corresponding
  probability

  \[\mathrm{P}(U_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;urgent;}\nonscript\:\vert\nonscript\:\mathopen{} T_3\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  U_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;non-urgent;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}T_2\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;other;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
   T_1\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;ambulance;}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
  \mathsfit{I}_{\textrm{d}})\]
\item
  Make similar kinds of inferences, freely trying other combinations of
  information about the two previous patients.
\item
  Do the same, but with three previous patients instead of two.
\end{itemize}

\end{tcolorbox}

\end{figure*}%

\section{When is the Dirichlet-mixture belief distribution
appropriate?}\label{sec-critique-dirmix}

The two examples above reveal some characteristics of an agent based on
the Dirichlet-mixture belief distribution:

\begin{itemize}
\item
  In absence of previous data, it assigns uniform probability
  distributions to any variate.
\item
  It can be ``eager'' to learn from previous examples, that is, its
  probabilities may vary appreciably even with only few observations.
  The ``eagerness'' is determined by the parameters
  {\(k_{\text{mi}}, k_{\text{ma}}\).} For a general-purpose agent, the
  values {\(k_{\text{mi}}=0, k_{\text{ma}}=20\)} are more reasonable.
\end{itemize}

There are also other subtle characteristics connected to the two above,
which we won't discuss here.

These characteristics can be appropriate to some inference tasks, but
not to others. It is again a matter of \emph{background information}
about the task one wants to solve.

The background information implicit in the Dirichlet-mixture belief
distribution can be reasonable in situations where:

\begin{itemize}
\tightlist
\item
  There is very little information about the physics or science behind
  the (nominal) variates and population, so one is willing to give a lot
  of weight to observed data. Contrast this with the coin-tossing
  scenario, where our physics knowledge about coin tosses make us
  appreciably change our probabilities only after a large number of
  observations.
\end{itemize}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading (again)}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Dynamical
Bias in the Coin Toss}}

\end{tcolorbox}

\end{footnotesize}}

\begin{itemize}
\item
  A large number of previous observations is available, ``large''
  relative to the domain size {\(M\)} of the joint variate {\(Z\).}
\item
  The joint variate {\(Z\)} has a small domain.
\end{itemize}

It is possible to modify the Dirichlet-mixture belief distribution in
order to alter the characteristics above. Some modifications can assign
more a-priori plausibility to some variate values than others, or make
the initial belief less affected by observed data.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  \href{https://tminka.github.io/papers/dirichlet/minka-dirtree.pdf}{\emph{The
  Dirichlet-tree distribution}}: discusses a more flexible
  generalization of the Dirichlet distribution
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Monkeys,
  kangaroos, and N}}: is an insightful discussion of how to investigate
  and represent prior beliefs.
\end{itemize}

\end{tcolorbox}

\end{footnotesize}}

These possibilities should remind us about the importance of assessing
and specifying appropriate background information. No matter the amount
of data, what the data eventually ``tell'' us acquires meaning only
against the background information from which they are observed.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

In the next chapter we discuss the code implementation of the formulae
for the Dirichlet-mixture agent.

\chapter{\texorpdfstring{{Code
design}}{Code design}}\label{sec-code-design}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\yon}{{\green\cat{on}}}
\providecommand*{\yof}{{\red\cat{off}}}
\providecommand*{\yy}{{\lblue\cat{Y}}}
\providecommand*{\yn}{{\yellow\cat{N}}}
\providecommand{\ypl}{{\green\cat{+}}}
\providecommand{\ymi}{{\red\cat{-}}}
\providecommand{\ypa}{{\green\cat{pass}}}
\providecommand{\yfa}{{\red\cat{fail}}}

\providecommand{\hi}{{\green\cat{high}}}
\providecommand{\me}{{\yellow\cat{medium}}}
\providecommand{\lo}{{\red\cat{low}}}
\providecommand*{\yJ}{\se{J}}
\providecommand{\yva}{{\lblue-1}}
\providecommand{\yvb}{{\midgrey0}}
\providecommand{\yvc}{{\yellow1}}
\providecommand*{\yK}{\se{K}}
\providecommand*{\yL}{\se{L}}

\providecommand*{\yR}{R}

\providecommand*{\bZ}{{\blue Z}}
\providecommand*{\bz}{{\blue z}}
\providecommand*{\rY}{{\red Y}}
\providecommand*{\bY}{{\blue Y}}
\providecommand*{\ry}{{\red y}}
\providecommand*{\gX}{{\green X}}
\providecommand*{\bX}{{\blue X}}
\providecommand*{\gx}{{\green x}}
\providecommand*{\vf}{\vec{f}}

\providecommand*{\yut}{\se{K}_{\textsf{3}}}
\providecommand*{\yul}{\se{K}}

\providecommand*{\bA}{{\blue A}}
\providecommand*{\bB}{{\blue B}}
\providecommand*{\bC}{{\blue C}}

\providecommand*{\vfa}{\vf'}
\providecommand*{\vfb}{\vf''}

\providecommand*{\data}{\se{\green data}}
\providecommand*{\yD}{\se{I}_{\textrm{d}}}
\providecommand*{\ya}{k}
\providecommand*{\amin}{\ya_{\text{mi}}}
\providecommand*{\amax}{\ya_{\text{ma}}}

Before starting, let's agree on some terminology in order not to get
confused in the discussion below.

\begin{itemize}
\tightlist
\item
  We shall call {\emph{task}} a repetitive inference problem with a
  specified set of units and variates. For instance, a task could be the
  consecutive prediction of the urgency of incoming patients, given
  their mean of transportation. We assume that the details of the
  variates, such as their domain, are well specified. Possibly also a
  set of data from other patients is available, which we call ``training
  data''.
\item
  We shall call {\emph{application}} or {\emph{instance}} of the task a
  single inference about a specific new unit, for example a new incoming
  patient.
\end{itemize}

\section{Range of use of the code}\label{sec-code-range}

The concrete formulae discussed in the previous
chapter~~\ref{sec-dirichlet-mix} can be put into code, for use in
different tasks involving only nominal variates. Software of this kind
can in principle be written to allow for some or all of the versatility
discussed in
§§~\ref{sec-categ-probtheory}--\ref{sec-underlying-distribution}, for
example the possibility of taking care (in a first-principled way!) of
partially missing training data. But the more versatile we make the
software, the more memory, processing power, and computation time it
will require.

Roughly speaking, more versatility corresponds to calculations of the
joint probability

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{equation}\phantomsection\label{eq-main-joint}{
\mathrm{P}(
\color[RGB]{68,119,170}
Z_{L}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{L}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_1
\color[RGB]{0,0,0}
\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}
)
=
\frac{1}{k_{\text{ma}}-k_{\text{mi}}+1}
\sum_{k=k_{\text{mi}}}^{k_{\text{ma}}}
\frac{
\prod_{{\color[RGB]{68,119,170}z}} \bigl(\frac{2^{k}}{M} + \#{\color[RGB]{68,119,170}z}- 1\bigr)!
}{
\bigl(2^{k} + L -1 \bigr)!
}
\cdot
\frac{
\bigl(2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{M} - 1\bigr)!}^M
}
\quad
}\end{equation}

\end{tcolorbox}

\end{figure*}%

for more values of the quantities
{\(\color[RGB]{68,119,170}Z_1, Z_2, \dotsc\).} For instance, if data
about unit \#4 are missing, then we need to calculate the joint
probability above for several (possibly all) values of
{\(\color[RGB]{68,119,170}Z_4\).} If data about two units are missing,
then we need to do an analogous calculation for all possible
\emph{combinations} of values; and so on.

For our prototype, let's forgo versatility about units used as training
data. From now on we abbreviate the set of training data as

\marginnote{\begin{footnotesize}

Recall that {\({\color[RGB]{68,119,170}Z}\)} denotes all (nominal)
variates of the population

\end{footnotesize}}

\[
\mathsfit{\color[RGB]{34,136,51}data}\coloneqq
(\color[RGB]{34,136,51}
Z_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N} \land \dotsb \land
Z_{2}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_2 \land
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}
\color[RGB]{0,0,0})
\]

where {\(\color[RGB]{68,119,170}z_N, \dotsc, z_2, z_1\)} are specific
values, stored in some training dataset. No values are missing.

Since the training {\(\mathsfit{\color[RGB]{34,136,51}data}\)} are given
and fixed in a task, we omit the suffix {``\({}_{N+1}\)''} that we have
often used to indicate a ``new'' unit. So
{``\(\color[RGB]{68,119,170}Z\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z\)''}
simply refers to the variate {\({\color[RGB]{68,119,170}Z}\)} in a new
application of the task.

We allow for full versatility in every new instance. This means that we
can accommodate, \emph{on the spot at each new instance}, what the
predictand variates are, and what the predictor variates (if any) are.
For example, if the population has three variates
{\({\color[RGB]{68,119,170}Z}=({\color[RGB]{68,119,170}A}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{68,119,170}B}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{68,119,170}C})\),}
our prototype can calculate, at each new application, inferences such as

\begin{itemize}
\item
  \(P({\color[RGB]{68,119,170}B}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})\):
  any one predictand variate, no predictors
\item
  \(P({\color[RGB]{68,119,170}A}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{68,119,170}C}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})\):
  any two predictand variates, no predictors
\item
  \(P({\color[RGB]{68,119,170}A}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{68,119,170}B}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{68,119,170}C}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})\):
  all three variates
\item
  \(P({\color[RGB]{68,119,170}B}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso\nonscript\:\vert\nonscript\:\mathopen{}{\color[RGB]{68,119,170}A}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})\):
  any one predictand variate, any other one predictor
\item
  \(P({\color[RGB]{68,119,170}B}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso\nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{68,119,170}A}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{68,119,170}C}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})\):
  any one predictand variate, any other two predictors
\item
  \(P({\color[RGB]{68,119,170}A}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{68,119,170}C}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso\nonscript\:\vert\nonscript\:\mathopen{}{\color[RGB]{68,119,170}B}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})\):
  any two predictand variates, any other one predictor
\end{itemize}

\section{Code design and computations
needed}\label{sec-code-computations}

To enjoy the versatility discussed above, the code needs to compute

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{equation}\phantomsection\label{eq-objectP}{
\mathrm{P}(
\color[RGB]{68,119,170}Z \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}\mathsfit{\color[RGB]{34,136,51}data}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
=
\frac{1}{k_{\text{ma}}-k_{\text{mi}}+1}
\sum_{k=k_{\text{mi}}}^{k_{\text{ma}}}
\Biggl(\frac{2^{k}}{M} + {\color[RGB]{34,136,51}\#}{\color[RGB]{68,119,170}z}\Biggr)
\cdot
\frac{
\prod_{{\color[RGB]{68,119,170}z}} \bigl(\frac{2^{k}}{M} + {\color[RGB]{34,136,51}\# z} - 1\bigr)!
}{
\bigl(2^{k} + N \bigr)!
}
\cdot
\frac{
\bigl(2^{k} -1 \bigr)!
}{
{\bigl(\frac{2^{k}}{M} - 1\bigr)!}^M
}
}\end{equation}

for all possible values {\({\color[RGB]{68,119,170}z}\),} where
{\({\color[RGB]{34,136,51}\#}{\color[RGB]{68,119,170}z}\)} is the number
of times value {\({\color[RGB]{68,119,170}z}\)} appears \textbf{in the
training {data}}, and
{\(N = \sum_{\color[RGB]{34,136,51}z}{\color[RGB]{34,136,51}\# z}\)} is
the number of training data

\end{tcolorbox}

\end{figure*}%

This formula is just a rewriting of formula (\ref{eq-main-joint}) for
{\(L=N+1\),} simplified by using the property of the factorial

\[(a+1)! = (a+1) \cdot a!\]

But the computation of formula (\ref{eq-objectP}) (for all values of
{\({\color[RGB]{68,119,170}z}\))} must be done \emph{only once} for a
given task. For a new application we only need to combine these
already-computed probabilities via sums and fractions. For example, in
the three-variate case above, if in a new application we need to
forecast
{\(\color[RGB]{238,102,119}A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}a\)}
given
{\(\color[RGB]{204,187,68}C\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}c\),}
then we calculate

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

(example with
{\(Z \coloneqq({\color[RGB]{238,102,119}A}, {\color[RGB]{68,119,170}B}, {\color[RGB]{204,187,68}C})\))}

\begin{equation}\phantomsection\label{eq-forecast}{
P(\color[RGB]{238,102,119}A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}a \color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}\color[RGB]{204,187,68}C\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}c \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})
=
\frac{
\sum_{\color[RGB]{68,119,170}b}
P(\color[RGB]{238,102,119}A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}a \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{68,119,170}B\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}b \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{204,187,68}C\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}c \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}{
\sum_{\color[RGB]{170,51,119}\alpha}\sum_{\color[RGB]{68,119,170}b}
P(\color[RGB]{238,102,119}A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}\alpha} \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{68,119,170}B\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}b \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{204,187,68}C\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}c \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}
\quad
}\end{equation}

\end{tcolorbox}

\end{figure*}%

where all
{\(P(\color[RGB]{238,102,119}A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{68,119,170}B\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{204,187,68}C\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\dotso \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})\)}
are already computed.

\hfill\break

Our prototype software must therefore include two main functions, which
we can call as follows:

\begin{itemize}
\item
  \begin{description}
  \tightlist
  \item[\texttt{buildagent()}
  (\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/buildagent.R}{see
  code})]
  computes \(\color[RGB]{34,136,51}\#{\color[RGB]{68,119,170}z}\) for
  all values \({\color[RGB]{68,119,170}z}\), as well as the
  multiplicative factors
  \end{description}

  \[
    \frac{
    \bigl(2^{k} -1 \bigr)!
  }{
  \bigl(2^{k} + N \bigr)!
  \cdot
  {\bigl(\frac{2^{k}}{M} - 1\bigr)!}^M
  }
  \]

  for all {\(k\),} in (\ref{eq-objectP}). This computation is done once
  and for all in a given task, using the training
  {\(\mathsfit{\color[RGB]{34,136,51}data}\)} and the metadata
  {\(\mathsfit{I}_{\textrm{d}}\)} provided. The result can be stored in
  an array or similar object, which we shall call an
  \texttt{agent}-class object.
\item
  \begin{description}
  \tightlist
  \item[\texttt{infer()}
  (\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/infer.R}{see
  code})]
  computes probabilities such as (\ref{eq-forecast}) at each new
  instance, using the stored \texttt{agent}-class object as well as the
  predictor variates and values provided with that instance, and the
  predictand variates requested at that instance.
  \end{description}
\end{itemize}

\hfill\break

We shall also include four additional functions for convenience:

\begin{itemize}
\item
  \begin{description}
  \tightlist
  \item[\texttt{guessmetadata()}]
  builds a preliminary metadata file, encoding the background
  information \(\mathsfit{I}_{\textrm{d}}\), from some dataset.
  \end{description}
\item
  \begin{description}
  \tightlist
  \item[\texttt{decide()}]
  makes a decision according to expected-utility maximization
  (chapter~~\ref{sec-basic-decisions}), using probabilities calculated
  with \texttt{infer()} and utilities.
  \end{description}
\item
  \begin{description}
  \tightlist
  \item[\texttt{rF()}]
  draws one or more possible full-population frequency distribution
  \(\boldsymbol{f}\), according to the updated degree of belief
  \(\mathrm{p}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})\)
  \end{description}
\item
  \begin{description}
  \tightlist
  \item[\texttt{plotFsamples1D()}]
  plots, as a generalized scatter plot, the possible full-population
  marginal frequency distributions for a single (not joint) predictand
  variate. If required it also also the final probability obtained with
  \texttt{infer()}.
  \end{description}
\item
  \begin{description}
  \tightlist
  \item[\texttt{mutualinfo()}]
  calculates the mutual information (§~\ref{sec-entropy-mutualinfo})
  between any two sets of variates.
  \end{description}
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Using the \texttt{and}-rule, prove (pay attention to the conditional
{``\(\nonscript\:\vert\nonscript\:\mathopen{}\)''} bar):

\[
\frac{
\sum_{\color[RGB]{68,119,170}b}
P(\color[RGB]{238,102,119}A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}a \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{68,119,170}B\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}b \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{204,187,68}C\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}c \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}{
\sum_{\color[RGB]{170,51,119}\alpha}\sum_{\color[RGB]{68,119,170}b}
P(\color[RGB]{238,102,119}A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}\alpha} \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{68,119,170}B\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}b \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{204,187,68}C\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}c \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})
}
=
\frac{
\sum_{\color[RGB]{68,119,170}b}
P(\color[RGB]{238,102,119}A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}a \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{68,119,170}B\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}b \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{204,187,68}C\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}c \color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})
}{
\sum_{\color[RGB]{170,51,119}\alpha}\sum_{\color[RGB]{68,119,170}b}
P(\color[RGB]{238,102,119}A\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}\alpha} \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{68,119,170}B\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}b \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{204,187,68}C\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}c \color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})
}
\]

\hfill\break

This exercise shows that instead of

\[\mathrm{P}(\color[RGB]{68,119,170}Z \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}\mathsfit{\color[RGB]{34,136,51}data}\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})\]

we could calculate

\[
\mathrm{P}(
\color[RGB]{68,119,170}Z \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}\mathsfit{\color[RGB]{34,136,51}data}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})
\]

once for all possible values {\({\color[RGB]{68,119,170}z}\),} and use
that. Mathematically and logically the two ways are completely
equivalent. Numerically they can be different as regards precision or
possible overflow errors. Using
{\(\mathrm{P}( \color[RGB]{68,119,170}Z \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z \color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \color[RGB]{34,136,51}\mathsfit{\color[RGB]{34,136,51}data}\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})\)}
would be convenient if our basic formula~(\ref{eq-main-joint}) didn't
contain the sum {\(\sum_k\)} over the {\(k\)} index. Our code shall
instead use
{\(\mathrm{P}(\color[RGB]{68,119,170}Z \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z \color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}\mathsfit{\color[RGB]{34,136,51}data}\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}})\)}
because it leads to slightly more precision and speed in some tasks.

\end{tcolorbox}

\section{Code optimization}\label{sec-code-optim}

The formulae of chapter~~\ref{sec-dirichlet-mix}, if used as-written,
easily lead to two kinds of computation problems. First, they generate
overflows and \texttt{NaN}, owing to factorials and their divisions.
Second, the products over variates may involve so many terms as to
require a long computation time. In the end we would have to wait a long
time just to receive a string of \texttt{NaN}s.

The first problem is dealt with by rewriting the formulae in terms of
logarithms, and renormalizing numerators and denominators of fractions.
See for example the lines defining \texttt{auxalphas} in the
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/buildagent.R}{\texttt{buildagent()}}
function, and the line that redefines \texttt{counts} one last time in
the
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/infer.R}{\texttt{infer()}}
function.

The second problem is dealt with by reorganizing the sums as multiples
of identical summands; see the lines working with \texttt{freqscounts}
in the
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/buildagent.R}{\texttt{buildagent()}}
function.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

§6.1 in
\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Numerical
Recipes}}

\end{tcolorbox}

\end{footnotesize}}

\chapter{\texorpdfstring{{Prototype code and
workflow}}{Prototype code and workflow}}\label{sec-code-workflow}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\yon}{{\green\cat{on}}}
\providecommand*{\yof}{{\red\cat{off}}}
\providecommand*{\yy}{{\lblue\cat{Y}}}
\providecommand*{\yn}{{\yellow\cat{N}}}
\providecommand{\ypl}{{\green\cat{+}}}
\providecommand{\ymi}{{\red\cat{-}}}
\providecommand{\ypa}{{\green\cat{pass}}}
\providecommand{\yfa}{{\red\cat{fail}}}

\providecommand{\hi}{{\green\cat{high}}}
\providecommand{\me}{{\yellow\cat{medium}}}
\providecommand{\lo}{{\red\cat{low}}}
\providecommand*{\yJ}{\se{J}}
\providecommand{\yva}{{\lblue-1}}
\providecommand{\yvb}{{\midgrey0}}
\providecommand{\yvc}{{\yellow1}}
\providecommand*{\yK}{\se{K}}
\providecommand*{\yL}{\se{L}}

\providecommand*{\yR}{R}

\providecommand*{\bZ}{{\blue Z}}
\providecommand*{\bz}{{\blue z}}
\providecommand*{\rY}{{\red Y}}
\providecommand*{\bY}{{\blue Y}}
\providecommand*{\ry}{{\red y}}
\providecommand*{\gX}{{\green X}}
\providecommand*{\bX}{{\blue X}}
\providecommand*{\gx}{{\green x}}
\providecommand*{\vf}{\vec{f}}

\providecommand*{\yut}{\se{K}_{\textsf{3}}}
\providecommand*{\yul}{\se{K}}

\providecommand*{\bA}{{\blue A}}
\providecommand*{\bB}{{\blue B}}
\providecommand*{\bC}{{\blue C}}

\providecommand*{\vfa}{\vf'}
\providecommand*{\vfb}{\vf''}

\providecommand*{\data}{\se{\green data}}
\providecommand*{\yD}{\se{I}_{\textrm{d}}}
\providecommand*{\ya}{k}
\providecommand*{\amin}{\ya_{\text{mi}}}
\providecommand*{\amax}{\ya_{\text{ma}}}

A concise documentation is here given of the prototype R functions
designed in chapter~~\ref{sec-code-design} and described in
§~\ref{sec-code-computations}, together with an example workflow for
their use.

The functions can be found in\\
\href{https://github.com/pglpm/ADA511/tree/master/code/OPM-nominal}{\texttt{https://github.com/pglpm/ADA511/tree/master/code/OPM-nominal}}

\section{Function documentation}\label{sec-opm-docs}

Optional arguments are written with \texttt{=...}, which specify their
default values. Some additional optional arguments, mainly used for
testing, are omitted in this documentation.

\begin{description}
\item[\faIcon{code}
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/guessmetadata.R}{\texttt{guessmetadata(data,\ file=NULL)}}]
\begin{description}
\tightlist
\item[Arguments:]
\hfill
\begin{itemize}
\tightlist
\item
  \emph{\texttt{data}}: either a string with the file name of a dataset
  in \texttt{.csv} format (with header line), or a dataset given as a
  \href{https://cran.r-project.org/package=data.table}{\texttt{data.table}
  object}.
\item
  \emph{\texttt{file}}: a string specifying the file name of the
  metadata file. If no \texttt{file} is given and \texttt{data} is a
  file name, then \texttt{file} will be the same name as \texttt{data}
  but with the prefix \texttt{meta\_}. If no \texttt{file} is given and
  \texttt{data} is not a string, then the metadata are output to
  \texttt{stdout}.
\end{itemize}
\item[Output:]
\hfill
\begin{itemize}
\tightlist
\item
  either a \texttt{.csv} file containing the metadata, or a
  \texttt{data.table} object as \texttt{stdout}.
\end{itemize}
\end{description}
\end{description}

\hfill\break

\begin{description}
\item[\faIcon{code}
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/buildagent.R}{\texttt{buildagent(metadata,\ data=NULL,\ kmi=0,\ kma=20)}}]
\begin{description}
\tightlist
\item[Arguments:]
\hfill
\begin{itemize}
\tightlist
\item
  \emph{\texttt{metadata}}: either a string with the name of a metadata
  file in \texttt{.csv} format, or metadata given as a
  \texttt{data.table}.
\item
  \emph{\texttt{data}}: either a string with the file name of a
  \emph{training} dataset in \texttt{.csv} format (with header line), or
  a training dataset given as a \texttt{data.table}.
\item
  \emph{\texttt{kmi}}: the \(k_{\text{mi}}\) parameter of
  formula~(\ref{eq-main-joint}).
\item
  \emph{\texttt{kma}}: the \(k_{\text{ma}}\) parameter of
  formula~(\ref{eq-main-joint}).
\end{itemize}
\item[Output:]
\hfill
\begin{itemize}
\tightlist
\item
  an object of class \texttt{agent}, consisting of a list of an array
  \texttt{counts} and three vectors \texttt{alphas}, \texttt{auxalphas},
  \texttt{palphas}.
\end{itemize}
\end{description}
\end{description}

\hfill\break

\begin{description}
\item[\faIcon{code}
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/infer.R}{\texttt{infer(agent,\ predictand=NULL,\ predictor=NULL)}}]
\begin{description}
\tightlist
\item[Arguments:]
\hfill
\begin{itemize}
\tightlist
\item
  \emph{\texttt{agent}}: an \texttt{agent} object.
\item
  \emph{\texttt{predictand}}: a vector of strings with the names of
  variates.
\item
  \emph{\texttt{predictor}}: either a list of elements of the form
  \texttt{variate=value}, or a corresponding one-row
  \texttt{data.table}.
\end{itemize}
\item[Output:]
\hfill
\begin{itemize}
\tightlist
\item
  the joint probability distribution
  \(\mathrm{P}(\mathit{predictand} \nonscript\:\vert\nonscript\:\mathopen{} \mathit{predictor}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;values;} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})\)
  for all possible values of the predictands.
\end{itemize}
\item[Notes:]
\hfill
\begin{itemize}
\tightlist
\item
  If \emph{\texttt{predictors}} is present, the agent is acting as a
  ``supervised-learning'' algorithm. Otherwise it is acting as an
  ``unsupervised-learning'' algorithm. The obtained probabilities could
  be used to generate a new unit similar to the ones observed.
\item
  If \emph{\texttt{predictand}} is missing, the predictands are taken to
  be all variates not listed among the predictors (hence all variates,
  if no predictors are given).
\item
  The variate names in the \emph{\texttt{predictand}} and
  \emph{\texttt{predictor}} inputs must match some variate names known
  to the agent. Unknown variate names are discarded. The function gives
  an error if predictand and predictor have variates in common.
\end{itemize}
\end{description}
\end{description}

\hfill\break

\begin{description}
\item[\faIcon{code}
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/decide.R}{\texttt{decide(probs,\ utils=NULL)}}]
\begin{description}
\item[Arguments:]
\hfill
\begin{itemize}
\tightlist
\item
  \emph{\texttt{probs}}: a probability distribution for one or more
  variates.
\item
  \emph{\texttt{utils}}: a named matrix or array of utilities. The
  \textbf{rows} of the matrix correspond to the available decisions, the
  \textbf{columns} or remaining array dimensions correspond to the
  possible values of the predictand variates.
\end{itemize}
\item[Output:]
a list of elements \texttt{EUs} and \texttt{optimal}:

\begin{itemize}
\tightlist
\item
  \texttt{EUs} is a vector containing the expected utilities of all
  decisions, sorted from highest to lowest
\item
  \texttt{optimal} is the decision having maximal expected utility, or
  one of them, if more than one, selected with equal probability
\end{itemize}
\item[Notes:]
\hfill
\begin{itemize}
\tightlist
\item
  If \emph{\texttt{utils}} is missing or \texttt{NULL}, a matrix of the
  form
  \(\begin{bsmallmatrix}1&0&\dotso\\0&1&\dotso\\\dotso&\dotso&\dotso\end{bsmallmatrix}\)
  is assumed (which corresponds to using \emph{accuracy} as evaluation
  metric).
\end{itemize}
\end{description}
\end{description}

\hfill\break

{\textbf{(\faIcon{person-digging} Further documentation will be added
\faIcon{person-digging})}}

\begin{description}
\tightlist
\item[\faIcon{code}
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/rF.R}{\texttt{rF(n=1,\ agent,\ predictand=NULL,\ predictor=NULL)}}]
(generate population-frequency samples)
\item[\faIcon{code}
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/rF.R}{\texttt{rF(n=1,\ agent,\ predictand=NULL,\ predictor=NULL)}}]
(generate population-frequency samples)
\item[\faIcon{code}
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/mutualinfo.R}{\texttt{mutualinfo(agent,\ A,\ B,\ base=2)}}]
(calculate mutual information)
\end{description}

\hfill\break

\section{Typical workflow}\label{sec-opm-workflow}

The workflow discussed here is just a guideline and reminder of
important steps to be taken when applying an optimal agent to a given
task. There cannot be more than a guideline, because each data-science
and engineering problem is unique. Literally following some predefined,
abstract workflow typically leads to sub-optimal results. Sub-optimal
results can be acceptable in some unimportant problems, but are
unacceptable in important problems, where, say, people's lives can be
involved, such as medical ones.

We can roughly identify four main stages:

\begin{center}
\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{index_files/mediabag/opm_flow1.pdf}
\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \begin{description}
  \tightlist
  \item[Define the task]
  In this stage we clarify what the task to be solved is -- and
  \emph{why}. Asking ``why'' often reveals the true needs and goals
  underlying the problem. If possible, the task is formalized. For
  example, the formal notions introduced in the parts {Data I} and {Data
  II} might be used: a specific statistical population is specified,
  with well-defined units and variates, and so on.
  \end{description}

  We often have to get back to his initial stage, as the side arrows in
  the above flow diagram indicate. New findings in the data or
  unavoidable limitations in the algorithms used may lead us to
  re-examine our assumptions and facts, or to re-define our goals (and
  sometimes to give up!).
\end{enumerate}

\hfill\break

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \begin{description}
  \tightlist
  \item[Collect \& prepare background info]
  Background and metadata information, as well as auxiliary assumptions,
  are collected, examined, prepared. Remember that this kind of
  information is required in order to make sense of the data
  (§~\ref{sec-underlying-distribution}). In this stage we ask questions
  such as {``Is our belief about the task exchangeable?''}, {``Can the
  statistical population be considered infinite?''}, and similar
  question that make clear which kinds of ready-made methods and
  approximations are acceptable or not. This stage also helps for
  correcting possible deficiencies in the training data used in the next
  stage. For instance, some possible variate values might not appear in
  the training data, owing to their rarity in the statistical
  population.
  \end{description}

  In this stage it is especially important to specify:

  \begin{itemize}
  \tightlist
  \item
    definition of units (what counts as ``unit'' and can be used as
    training data?)
  \item
    definition of variates and their domains
  \item
    initial probabilities
  \item
    possible decisions that may be required in the repeated task
    applications
  \item
    utilities associated with the decisions above
  \end{itemize}
\end{enumerate}

\hfill\break

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  \begin{description}
  \tightlist
  \item[Collect \& prepare training data]
  Units similar to the units of our future inferences, but of which we
  have more complete information, are collected and examined. These are
  the ``training data''. They are used in the next step to make the
  agent learn from examples. The problematic notion of similarity was
  discussed in §~\ref{sec-variates-populations}: what counts as
  ``similar'' is difficult to decide, and often we shall have to revise
  our decision. Sometimes no units satisfactorily similar to those of
  interest are available. In this case we must assess which of their
  informational relationships can be considered similar, which may lead
  us to use the agent in slightly different ways. We must also check
  whether training units with partially missing variates can be used by
  our agent or not.
  \end{description}
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} How many training data?}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

``Data augmentation'' is something necessary with particular
machine-learning algorithms as a way to compensate or correct their
internal background information, but does not apply to an optimal agent.

The question \emph{``how many training data should we use?''} does not
make sense for an optimal agent which works according to probability
theory and decision theory. The answer is simply ``as many as you have
available''.

If no or few training data are available, then the optimal agent will
automatically absorb as much information as possible from them, and
combine it with its background information to draw optimal inferences
and make optimal decisions.

Giving artificial training data to the agent, just to increase the
number of training data, is pointless and dangerous.

Pointless, because the agent is, in fact, automatically ``simulating''
artificial data internally as needed, from its background information
and the real training data available. This is exactly what the belief
distribution
{\(\mathrm{p}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\color[RGB]{34,136,51}data},\mathsfit{I}_{\textrm{d}})\)}
is doing: remember that the agent is internally considering \emph{all
possible populations of data} (chapter~~\ref{sec-inference-exch}).

Dangerous, because artificial data may contain incorrect information,
leading the agent to arrive at sub-optimal and potentially disastrously
deceiving results.

\end{tcolorbox}

\hfill\break

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\item
  \begin{description}
  \tightlist
  \item[Prepare OPM agent]
  The background information and training data (if any available) are
  finally fed to the agent.
  \end{description}
\end{enumerate}

\hfill\break

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\item
  \begin{description}
  \tightlist
  \item[Repeated application]
  Inferences are drawn, and decision made, for each new application
  instance. With our prototype agent, the inferences and the decisions
  can in principle be different from instance to instance.
  \end{description}
\end{enumerate}

\hfill\break

Every new application can be broken down into several steps:

\begin{center}
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{index_files/mediabag/opm_flow2.pdf}
\end{center}

\hfill\break

{\textbf{(\faIcon{person-digging} Remaining steps to be added soon
\faIcon{person-digging})}}

\chapter{\texorpdfstring{{Example application: adult-income
task}}{Example application: adult-income task}}\label{sec-example-opm1}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\yon}{{\green\cat{on}}}
\providecommand*{\yof}{{\red\cat{off}}}
\providecommand*{\yy}{{\lblue\cat{Y}}}
\providecommand*{\yn}{{\yellow\cat{N}}}
\providecommand{\ypl}{{\green\cat{+}}}
\providecommand{\ymi}{{\red\cat{-}}}
\providecommand{\ypa}{{\green\cat{pass}}}
\providecommand{\yfa}{{\red\cat{fail}}}

\providecommand{\hi}{{\green\cat{high}}}
\providecommand{\me}{{\yellow\cat{medium}}}
\providecommand{\lo}{{\red\cat{low}}}
\providecommand*{\yJ}{\se{J}}
\providecommand{\yva}{{\lblue-1}}
\providecommand{\yvb}{{\midgrey0}}
\providecommand{\yvc}{{\yellow1}}
\providecommand*{\yK}{\se{K}}
\providecommand*{\yL}{\se{L}}

\providecommand*{\yR}{R}

\providecommand*{\bZ}{{\blue Z}}
\providecommand*{\bz}{{\blue z}}
\providecommand*{\rY}{{\red Y}}
\providecommand*{\bY}{{\blue Y}}
\providecommand*{\ry}{{\red y}}
\providecommand*{\gX}{{\green X}}
\providecommand*{\bX}{{\blue X}}
\providecommand*{\gx}{{\green x}}
\providecommand*{\vf}{\vec{f}}

\providecommand*{\yut}{\se{K}_{\textsf{3}}}
\providecommand*{\yul}{\se{K}}

\providecommand*{\bA}{{\blue A}}
\providecommand*{\bB}{{\blue B}}
\providecommand*{\bC}{{\blue C}}

\providecommand*{\vfa}{\vf'}
\providecommand*{\vfb}{\vf''}

\providecommand*{\data}{\se{\green data}}
\providecommand*{\yD}{\se{I}_{\textrm{d}}}
\providecommand*{\ya}{k}
\providecommand*{\amin}{\ya_{\text{mi}}}
\providecommand*{\amax}{\ya_{\text{ma}}}

Let's illustrate the example workflow described in
§~\ref{sec-opm-workflow} with a toy, but not too simplistic, example,
based on the
\href{https://archive.ics.uci.edu/dataset/2/adult}{adult-income
dataset}.

All code functions and data files are in the directory\\
\url{https://github.com/pglpm/ADA511/tree/master/code/OPM-nominal}

We start loading the R libraries and functions needed at several stages.
You need to have installed\footnote{This is done with the
  \href{https://rdrr.io/r/utils/install.packages.html}{\texttt{install.packages()}
  function}.} the packages
\href{https://cran.r-project.org/package=extraDistr}{\emph{extraDistr}}
and \href{https://cran.r-project.org/package=foreach}{\emph{foreach}}.
Make sure you have saved all source files and data files in the same
directory.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{\textquotesingle{}extraDistr\textquotesingle{}}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{\textquotesingle{}foreach\textquotesingle{}}\NormalTok{)}

\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}tplotfunctions.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}guessmetadata.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}buildagent.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}infer.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}decide.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}mutualinfo.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}rF.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}plotFsamples1D.R\textquotesingle{}}\NormalTok{)}

\FunctionTok{options}\NormalTok{(}\AttributeTok{repr.plot.width =} \DecValTok{6} \SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{2}\NormalTok{), }\AttributeTok{repr.plot.height =} \DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hfill\break

\section{Define the task}\label{define-the-task}

The main task is to infer whether a USA citizen earns less (≤) or more
(\textgreater) than USD\,50\,000/year, given a set of characteristics of
that citizen. In view of later workflow stages, let's note a couple of
known and unknown facts to delimit this task in a more precise manner:

\begin{itemize}
\item
  Given the flexibility of the agent we shall use, we can generalize the
  task: to infer any subset of the set of characteristics, given any
  other subset. In other words, we can choose the predictand and
  predictor variates for any new citizen. Later on we shall also extend
  the task to making a concrete decision, based on utilities relevant to
  that citizen.

  This flexibility is also convenient because no explanation is given as
  to \emph{what purpose} the income should be guessed.
\item
  The training data come from a 1994~census, and our agent will use an
  exchangeable belief distribution about the population. The value of
  the USD and the economic situation of the country changes from year to
  year, as well as the informational relationships between economic and
  demographic factors. For this reason the agent should be used to draw
  inferences about at most one or two years around 1994. Beyond such
  time range the exchangeability assumption is too dubious and risky.
\item
  The
  \href{https://www.macrotrends.net/countries/USA/united-states/population}{USA
  population in 1994 was around 260\,000\,000}, and we shall use around
  11\,000 training data. The population size can therefore be considered
  approximately infinite.
\end{itemize}

\hfill\break

\section{Collect \& prepare background
info}\label{collect-prepare-background-info}

\subsection{Variates and domains}\label{variates-and-domains}

The variates to be used must be of nominal type, because our agent's
background beliefs (represented by the Dirichlet-mixture distribution)
are only appropriate for nominal variates. In this toy example we simply
discard all original non-nominal variates. These included some, such as
age, that would surely be relevant for this task. As a different
approach, we could have coarsened each non-nominal variate into three or
four range values, so that treating it as nominal would have been an
acceptable approximation.

First, create a preliminary metadata file by running the function
\texttt{guessmetadata()} on the training data
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/train-income_data_example.csv}{\texttt{train-income\_data\_example.csv}}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{guessmetadata}\NormalTok{(}\AttributeTok{data =} \StringTok{\textquotesingle{}train{-}income\_data\_example.csv\textquotesingle{}}\NormalTok{,}
              \AttributeTok{file =} \StringTok{\textquotesingle{}preliminary.csv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Inspect the resulting file \texttt{preliminary.csv} and check whether
you can alter it to add additional background information.

As an example, note that domain of the {\(\mathit{native\_country}\)}
variate does not include {\({\small\verb;Norway;}\)} or
{\({\small\verb;Sweden;}\).} Yet it's extremely likely that there were
some native Norwegian or Swedish people in the USA in 1994; maybe too
few to have been sampled into the training data. Let's add these two
values to the list of domain values, and increase the domain size of
{\(\mathit{native\_country}\)} from 40 to 42. The resulting, updated
metadata file has already been saved as
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/meta_income_data_example.csv}{\texttt{meta\_income\_data\_example.csv}}.

\subsection{\texorpdfstring{Agent's parameters
\(k_{\text{mi}}, k_{\text{ma}}\)}{Agent's parameters k\_\{\textbackslash text\{mi\}\}, k\_\{\textbackslash text\{ma\}\}}}\label{agents-parameters-k_textmi-k_textma}

How many data should the agent learn in order to appreciably change its
initial beliefs about the variates above, for the USA 1994 population?
Let's put an upper bound at around 1\,000\,000 (that's roughly 0.5\% of
the whole population) with {\(k_{\text{ma}}= 20\),} and a lower bound at
1 with {\(k_{\text{mi}}= 0\);} these are the default values. We shall
see later what the agent suggests might be a reasonable amount of
training data.

\hfill\break

\section{Collect \& prepare training
data}\label{collect-prepare-training-data}

The 11\,306 training data have been prepared by including only nominal
variates, and discarding datapoints with partially missing data
(although the function \texttt{buildagent()} discards such incomplete
datapoints automatically). The resulting file is
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/test-income_data_example.csv}{\texttt{test-income\_data\_example.csv}}.

\hfill\break

\section{Prepare OPM agent}\label{prepare-opm-agent}

For the sake of this example we shall prepare two agents with the same
background information:

\begin{itemize}
\item
  \texttt{opm10}, trained with 10 training datapoints
\item
  \texttt{opmall}, trained with all 11\,306 training datapoints
\end{itemize}

Prepare and train each with the \texttt{buildagent()} function:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# temporarily load all training data}
\NormalTok{traindata }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}train{-}income\_data\_example.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{na.strings =} \StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{, }\AttributeTok{stringsAsFactors =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{tryLogical =} \ConstantTok{FALSE}\NormalTok{)}

\DocumentationTok{\#\# feed first 10 datapoints to an agent}
\NormalTok{opm10 }\OtherTok{\textless{}{-}} \FunctionTok{buildagent}\NormalTok{(}\AttributeTok{metadata =} \StringTok{\textquotesingle{}meta\_income\_data\_example.csv\textquotesingle{}}\NormalTok{,}
                    \AttributeTok{data =}\NormalTok{ traindata[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, ])}

\DocumentationTok{\#\# delete training data for memory efficiency}
\FunctionTok{rm}\NormalTok{(traindata)}


\NormalTok{opmall }\OtherTok{\textless{}{-}} \FunctionTok{buildagent}\NormalTok{(}\AttributeTok{metadata =} \StringTok{\textquotesingle{}meta\_income\_data\_example.csv\textquotesingle{}}\NormalTok{,}
                     \AttributeTok{data =} \StringTok{\textquotesingle{}train{-}income\_data\_example.csv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hfill\break

We can peek into the internal structure of these ``agent objects'' with
\texttt{str()}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(opmall)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
List of 4
 $ counts   : num [1:7, 1:16, 1:7, 1:14, 1:6, 1:5, 1:2, 1:42, 1:2] 0 0 0 0 0 0 0 0 0 0 ...
  ..- attr(*, "dimnames")=List of 9
  .. ..$ workclass     : chr [1:7] "Federal-gov" "Local-gov" "Private" "Self-emp-inc" ...
  .. ..$ education     : chr [1:16] "10th" "11th" "12th" "1st-4th" ...
  .. ..$ marital_status: chr [1:7] "Divorced" "Married-AF-spouse" "Married-civ-spouse" "Married-spouse-absent" ...
  .. ..$ occupation    : chr [1:14] "Adm-clerical" "Armed-Forces" "Craft-repair" "Exec-managerial" ...
  .. ..$ relationship  : chr [1:6] "Husband" "Not-in-family" "Other-relative" "Own-child" ...
  .. ..$ race          : chr [1:5] "Amer-Indian-Eskimo" "Asian-Pac-Islander" "Black" "Other" ...
  .. ..$ sex           : chr [1:2] "Female" "Male"
  .. ..$ native_country: chr [1:42] "Cambodia" "Canada" "China" "Columbia" ...
  .. ..$ income        : chr [1:2] "<=50K" ">50K"
 $ alphas   : num [1:21] 1 2 4 8 16 32 64 128 256 512 ...
 $ auxalphas: num [1:21] -160706 -157643 -154588 -151547 -148530 ...
 $ palphas  : num [1:21] 0 0 0 0 0 0 0 0 0 0 ...
 - attr(*, "class")= chr [1:2] "agent" "list"
\end{verbatim}

this shows that each agent is encoded as a list of four objects:

\begin{itemize}
\tightlist
\item
  the array \texttt{counts}, containing the counts
  \(\color[RGB]{34,136,51}\# z\)
\item
  the vector \texttt{alphas}, containing the values of \(2^k\)
\item
  the vector \texttt{auxalphas}, containing the (logarithm of) the
  multiplicative factors (§~\ref{sec-code-computations})
\item
  the vector \texttt{palphas}, containing the updated probabilities
  about the required amount of training data
\end{itemize}

The agent has internally guessed how many training data should be
necessary to affect its prior beliefs. We can peek at its guess by
plotting the \texttt{alphas} parameters against the \texttt{palphas}
probabilities:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mytplot}\NormalTok{(}\AttributeTok{x =}\NormalTok{ opmall}\SpecialCharTok{$}\NormalTok{alphas, }\AttributeTok{y =}\NormalTok{ opmall}\SpecialCharTok{$}\NormalTok{palphas, }\AttributeTok{type =} \StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}
      \AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{10000}\NormalTok{), }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\ConstantTok{NA}\NormalTok{),}
      \AttributeTok{xlab =} \StringTok{\textquotesingle{}required number of training data\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}probability\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{example_opm1_files/figure-pdf/unnamed-chunk-6-1.pdf}}

The most probable amount seems to be of the order of magnitude of 2000
units.

Note that you can see the complete list of variates and their domains by
simply calling \texttt{dimnames(opmall\$counts)} (or any relevant
agent-object name instead of \texttt{opmall}). Here is the beginning of
the list:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(}\FunctionTok{dimnames}\NormalTok{(opmall}\SpecialCharTok{$}\NormalTok{counts))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$workclass
[1] "Federal-gov"      "Local-gov"        "Private"          "Self-emp-inc"    
[5] "Self-emp-not-inc" "State-gov"        "Without-pay"     

$education
 [1] "10th"         "11th"         "12th"         "1st-4th"      "5th-6th"     
 [6] "7th-8th"      "9th"          "Assoc-acdm"   "Assoc-voc"    "Bachelors"   
[11] "Doctorate"    "HS-grad"      "Masters"      "Preschool"    "Prof-school" 
[16] "Some-college"

$marital_status
[1] "Divorced"              "Married-AF-spouse"     "Married-civ-spouse"   
[4] "Married-spouse-absent" "Never-married"         "Separated"            
[7] "Widowed"              

$occupation
 [1] "Adm-clerical"      "Armed-Forces"      "Craft-repair"      "Exec-managerial"  
 [5] "Farming-fishing"   "Handlers-cleaners" "Machine-op-inspct" "Other-service"    
 [9] "Priv-house-serv"   "Prof-specialty"    "Protective-serv"   "Sales"            
[13] "Tech-support"      "Transport-moving" 

$relationship
[1] "Husband"        "Not-in-family"  "Other-relative" "Own-child"     
[5] "Unmarried"      "Wife"          

$race
[1] "Amer-Indian-Eskimo" "Asian-Pac-Islander" "Black"              "Other"             
[5] "White"             
\end{verbatim}

\hfill\break

\section{Application and exploration}\label{application-and-exploration}

\subsection{Application: only
predictands}\label{application-only-predictands}

Our two agents are ready to be applied to new instances.

Before applying them, let's check some of their inferences, and see if
we find anything unconvincing about them. If we find something
unconvincing, it means that the background information we provided to
the agent doesn't match the one in our intuition. Then there are two or
three possibilities: our intuition is misleading us and need correcting;
or we need to go back to stage {\emph{Collect \& prepare background
info}} and correct the background information given to the agent; or a
combination of these two possibilities.

We ask the \texttt{opm10} agent to forecast the {\(\mathit{income}\)} of
the next unit, using the \texttt{infer()} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{infer}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opm10, }\AttributeTok{predictand =} \StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
income
   <=50K     >50K 
0.506288 0.493712 
\end{verbatim}

This agent gives a slightly larger probability to the
{\({\small\verb;<=50K;}\)} case. Using the function
\texttt{plotFsamples1D()} we can also inspect the \texttt{opm10}-agent's
belief about the frequency distribution of {\(\mathit{income}\)} for the
full population. This belief is represented by a generalized scatter
plot of 200 representative frequency distributions, represented as the
{light-blue lines}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotFsamples1D}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opm10,}
               \AttributeTok{n =} \DecValTok{200}\NormalTok{, }\CommentTok{\# number of example frequency distributions}
               \AttributeTok{predictand =} \StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{,}
               \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }\CommentTok{\# y{-}axis range}
               \AttributeTok{main =} \StringTok{\textquotesingle{}opm10\textquotesingle{}}\NormalTok{) }\CommentTok{\# plot title}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{example_opm1_files/figure-pdf/unnamed-chunk-9-1.pdf}}

where the \textbf{black line} is the probability distribution previously
calculated with the \texttt{infer()} function.

This plot expresses the \texttt{opm10}-agent's belief that future
training data might lead to even higher probabilities for
{\({\small\verb;<=50K;}\).} But note that the agent is not excluding the
possibility of lower probabilities.

Let's visualize the beliefs of the \texttt{opmall}-agent, trained with
the full training dataset:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotFsamples1D}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opmall, }\AttributeTok{n =} \DecValTok{200}\NormalTok{, }\AttributeTok{predictand =} \StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{,}
               \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{main =} \StringTok{\textquotesingle{}opmall\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{example_opm1_files/figure-pdf/unnamed-chunk-10-1.pdf}}

The probability that the next unit has
{\(\mathit{income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;<=50;}\)}
is now above 70\%. Also note that the \texttt{opmall}-agent doesn't
believe that this probability would change appreciably if more training
data were provided.

\hfill\break

We can perform a similar exploration for any other variate. Let's take
the {\(\mathit{race}\)} variate for example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotFsamples1D}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opm10, }\AttributeTok{n =} \DecValTok{200}\NormalTok{, }\AttributeTok{predictand =} \StringTok{\textquotesingle{}race\textquotesingle{}}\NormalTok{,}
               \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{main =} \StringTok{\textquotesingle{}opm10\textquotesingle{}}\NormalTok{,}
               \AttributeTok{cex.axis =} \FloatTok{0.75}\NormalTok{) }\CommentTok{\# smaller axis{-}font size}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{example_opm1_files/figure-pdf/unnamed-chunk-11-1.pdf}}

Note again how the little-trained \texttt{opm10}-agent has practically
uniform beliefs. But it's also expressing the fact that future training
data will probably increase the probability of
{\(\mathit{race}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;White;}\).}

This is corroborated by the fully-trained agent:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotFsamples1D}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opmall, }\AttributeTok{n =} \DecValTok{200}\NormalTok{, }\AttributeTok{predictand =} \StringTok{\textquotesingle{}race\textquotesingle{}}\NormalTok{,}
               \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{main =} \StringTok{\textquotesingle{}opmall\textquotesingle{}}\NormalTok{, }\AttributeTok{cex.axis =} \FloatTok{0.75}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{example_opm1_files/figure-pdf/unnamed-chunk-12-1.pdf}}

\hfill\break

These checks are satisfying, but it's good to examine their agreement or
disagreement with our intuition. Examine the last plot for example. The
\texttt{opmall} agent has very firm beliefs (no spread in the
{light-blue lines}) about the full-population distribution of
{\(\mathit{race}\).} Do you think its beliefs are too firm, after
11\,000 datapoints? would you like the agent to be more ``open-minded''?
In that case you should go back to the {\emph{Collect \& prepare
background info}} stage, and for example modify the parameters
{\(k_{\text{mi}}, k_{\text{ma}}\),} then re-check. Or you could even try
an agent with a different initial belief distribution.

In making this kind of considerations it's important to keep in mind
what we learned and observed in previous chapters:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={Note}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

{\textbf{Our goal: optimality, not ``success''}}

Remember (§~\ref{sec-optimality} and §~\ref{sec-probability-def}) that a
probability represents the \emph{rational} degree of belief that an
agent should have \emph{given the particular information available}. We
can't judge a probability from the value it assigns to something we
later learn to be true -- because according to the information available
it could be more rational (and optimal) to consider that something
implausible (recall the example in §~\ref{sec-probability-def} of an
object falling from the sky as we cross the street).

From this point of view we should be wary of comparing the probability
of something with our a-posteriori knowledge about it.

\hfill\break

{\textbf{The data cannot speak for themselves}}

We could build an agent that remains more ``open-minded'' (more spread
in the {light-blue lines}), having received \emph{exactly the same}
training data. This ``open-mindedness'' therefore cannot be determined
by the training data. Once more this shows that data \emph{cannot}
``speak for themselves'' (§~\ref{sec-underlying-distribution}).

\end{tcolorbox}

\marginnote{\begin{footnotesize}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{neverknowsbest.jpg}

\end{footnotesize}}

\hfill\break

\subsection{Application: specifying
predictors}\label{application-specifying-predictors}

Let's now draw inferences by specifying some predictors.

We ask the \texttt{opm10} agent to forecast the {\(\mathit{income}\)} of
a new unit, given that the unit is known to have
{\(\mathit{occupation}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Exec-managerial;}\)}
and
{\(\mathit{sex}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Male;}\)}
(two predictor variates). What would you expect?

The \texttt{opm10}-agent's belief about the unit -- as well as about the
\emph{full subpopulation} (§~\ref{sec-subpopulations}) of units having
those predictors -- is shown in the following plot:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotFsamples1D}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opm10, }\AttributeTok{n =} \DecValTok{200}\NormalTok{,}
               \AttributeTok{predictand =} \StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{,}
               \AttributeTok{predictor =} \FunctionTok{list}\NormalTok{(}\AttributeTok{occupation =} \StringTok{\textquotesingle{}Exec{-}managerial\textquotesingle{}}\NormalTok{,}
                              \AttributeTok{sex =} \StringTok{\textquotesingle{}Male\textquotesingle{}}\NormalTok{),}
               \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{main =} \StringTok{\textquotesingle{}opm10\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{example_opm1_files/figure-pdf/unnamed-chunk-13-1.pdf}}

Note how the \texttt{opm10}-agent still slightly higher probability to
{\(\mathit{income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;<=50;}\),}
but at the same time it is quite uncertain about the subpopulation
frequencies; more than if the predictor had not been specified. That is,
according to this little-trained agent there could be large variety of
possibilities \emph{within this specific subpopulation}.

The \texttt{opmall}-agent's beliefs are shown below:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotFsamples1D}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opmall, }\AttributeTok{n =} \DecValTok{200}\NormalTok{,}
               \AttributeTok{predictand =} \StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{,}
               \AttributeTok{predictor =} \FunctionTok{list}\NormalTok{(}\AttributeTok{occupation =} \StringTok{\textquotesingle{}Exec{-}managerial\textquotesingle{}}\NormalTok{,}
                              \AttributeTok{sex =} \StringTok{\textquotesingle{}Male\textquotesingle{}}\NormalTok{),}
               \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{main =} \StringTok{\textquotesingle{}opmall\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{example_opm1_files/figure-pdf/unnamed-chunk-14-1.pdf}}

it believes with around 55\% probability that such a unit would have
higher, {\({\small\verb;>50K;}\)} income. The representative
subpopulation-frequency distributions in {light-blue} indicate that this
belief is unlikely to be changed by new training data.

\hfill\break

Let's now see an example of our agent's versatility by switching
predictands and predictors. We tell the \texttt{opmall}-agent that the
new unit has
{\(\mathit{income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;>50;}\),}
and ask it to infer the joint variate
{\((\mathit{occupation} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{sex})\);}
let's present the results in rounded percentages:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{infer}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opmall,}
                \AttributeTok{predictand =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}occupation\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}sex\textquotesingle{}}\NormalTok{),}
                \AttributeTok{predictor =} \FunctionTok{list}\NormalTok{(}\AttributeTok{income =} \StringTok{\textquotesingle{}\textgreater{}50K\textquotesingle{}}\NormalTok{))}

\FunctionTok{round}\NormalTok{(result }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# round to one decimal}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                   sex
occupation          Female Male
  Adm-clerical         3.1  4.1
  Armed-Forces         1.0  1.0
  Craft-repair         1.1  9.4
  Exec-managerial      3.6 16.0
  Farming-fishing      1.0  2.1
  Handlers-cleaners    1.0  1.6
  Machine-op-inspct    1.1  3.1
  Other-service        1.6  1.8
  Priv-house-serv      1.0  1.0
  Prof-specialty       4.8 14.7
  Protective-serv      1.0  3.2
  Sales                1.8 10.1
  Tech-support         1.5  3.4
  Transport-moving     1.1  3.7
\end{verbatim}

It returns a 14\,×\,2 table of joint probabilities. The most probable
combinations are
{\(({\small\verb;Exec-managerial;}, {\small\verb;Male;})\)} and
{\(({\small\verb;Prof-specialty;}, {\small\verb;Male;})\).}

\subsection{\texorpdfstring{The \texttt{rF()}
function}{The rF() function}}\label{the-rf-function}

This function generates \textbf{full-population} frequency distributions
(even for subpopulations) that are probable according to the data. It is
used internally by \texttt{plotFsamples1D()}, which plots the generated
frequency distributions as {light-blue lines}.

Let's see, as an example, three samples of how the full-population
frequency distribution for
{\(\mathit{sex} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{income}\)}
(jointly) could be:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{rF}\NormalTok{(}\AttributeTok{n =} \DecValTok{3}\NormalTok{, }\CommentTok{\# number of samples}
             \AttributeTok{agent =}\NormalTok{ opmall, }
             \AttributeTok{predictand =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}sex\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{))}

\DocumentationTok{\#\# name the samples}
\FunctionTok{dimnames}\NormalTok{(result)[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{samples =} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}\#\textquotesingle{}}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{))}

\DocumentationTok{\#\# permute \& print so that samples are the last array dimension}
\FunctionTok{print}\NormalTok{(}\FunctionTok{aperm}\NormalTok{(result) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
, , sample = #1

       sex
income    Female    Male
  <=50K 27.99218 42.6495
  >50K   7.21432 22.1440

, , sample = #2

       sex
income    Female    Male
  <=50K 28.30300 43.1876
  >50K   6.88799 21.6214

, , sample = #3

       sex
income    Female    Male
  <=50K 27.85863 43.1445
  >50K   7.06956 21.9273
\end{verbatim}

These possible full-population frequency distributions can be used to
assess how much the probabilities we find could change, if we collected
a much, much larger amount of training data. Here is an example:

We generate 1000 frequency distributions for
{\((\mathit{occupation} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathit{sex})\)}
given
{\(\mathit{income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;>50K;}\),}
and then take the standard deviations of the samples as a rough measure
of how much the probabilities we calculated a couple of cells above
could change:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{freqsamples }\OtherTok{\textless{}{-}} \FunctionTok{rF}\NormalTok{(}\AttributeTok{n =} \DecValTok{1000}\NormalTok{,}
                  \AttributeTok{agent =}\NormalTok{ opmall,}
                  \AttributeTok{predictand =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}occupation\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}sex\textquotesingle{}}\NormalTok{),}
                  \AttributeTok{predictor =} \FunctionTok{list}\NormalTok{(}\AttributeTok{income =} \StringTok{\textquotesingle{}\textgreater{}50K\textquotesingle{}}\NormalTok{))}

\NormalTok{variability }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(freqsamples,}
                     \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}occupation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}sex\textquotesingle{}}\NormalTok{), }\CommentTok{\# which dimensions to apply}
\NormalTok{                     sd) }\CommentTok{\# function to apply to those dimensions}

\FunctionTok{round}\NormalTok{(variability }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\DecValTok{2}\NormalTok{) }\CommentTok{\# round to two decimals}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                   sex
occupation          Female Male
  Adm-clerical        0.27 0.33
  Armed-Forces        0.16 0.16
  Craft-repair        0.16 0.46
  Exec-managerial     0.29 0.59
  Farming-fishing     0.16 0.23
  Handlers-cleaners   0.16 0.20
  Machine-op-inspct   0.17 0.29
  Other-service       0.20 0.21
  Priv-house-serv     0.17 0.16
  Prof-specialty      0.35 0.58
  Protective-serv     0.17 0.28
  Sales               0.21 0.51
  Tech-support        0.20 0.29
  Transport-moving    0.16 0.31
\end{verbatim}

the agent believes (at around 68\%) that the current probability
wouldn't change more than about ±0.5\%.

\hfill\break

The inferences above were partially meant as checks, but we see that we
can actually ask our agent a wide variety of questions about the full
population, and do all sorts of association studies.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} No ``test'' or ``validation'' datasets
used or needed}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

The tests and explorations above were done without any ``validation'' or
``test'' datasets. This is because our agent is capable of calculating
and showing its beliefs about the \emph{full population} -- and
therefore about future data.

The need for validation or test datasets with common machine-learning
algorithms arise from the fact that full-population beliefs are hidden
or, more commonly, not computed at all, in order to gain speed. The
application of the trained machine-learning algorithm to a validation
dataset is an approximate way of extracting such beliefs.

\end{tcolorbox}

\hfill\break

\subsection{Exploring the population properties: mutual
information}\label{exploring-the-population-properties-mutual-information}

In §~\ref{sec-entropy-mutualinfo} we introduced {\emph{mutual
information}} as the information-theoretic measure of mutual relevance
and association of two quantities or variates. For the present task, the
\texttt{opmall}-agent can tell us the mutual information between any two
sets of variates of our choice, with the function \texttt{mutualinfo()}.

For instance, let's calculate the mutual information between
{\(\mathit{occupation}\)} and {\(\mathit{marital\_status}\).}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mutualinfo}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opmall,}
           \AttributeTok{A =} \StringTok{\textquotesingle{}occupation\textquotesingle{}}\NormalTok{, }\AttributeTok{B =} \StringTok{\textquotesingle{}marital\_status\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0827823
\end{verbatim}

It is a very low association: knowing either variate decreases the
effective number of possible values of the other only
{\(2^{0.0827823\,\mathit{Sh}} \approx 1.06\)} times.

Now let's consider a scenario where, in order to save resources, we can
use \emph{only one} variate to infer the income. Which of the other
variates should we prefer? We can calculate the mutual information
between each of them, in turn, and {\(\mathit{income}\):}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# list of all variates}
\NormalTok{variates }\OtherTok{\textless{}{-}} \FunctionTok{names}\NormalTok{(}\FunctionTok{dimnames}\NormalTok{(opmall}\SpecialCharTok{$}\NormalTok{counts))}

\DocumentationTok{\#\# list of all variates except \textquotesingle{}income\textquotesingle{}}
\NormalTok{predictors }\OtherTok{\textless{}{-}}\NormalTok{ variates[variates }\SpecialCharTok{!=} \StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{]}

\DocumentationTok{\#\# prepare vector to contain the mutual information}
\NormalTok{relevances }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\FunctionTok{length}\NormalTok{(predictors))}
\FunctionTok{names}\NormalTok{(relevances) }\OtherTok{\textless{}{-}}\NormalTok{ predictors}

\DocumentationTok{\#\# calculate, for each variate, the mutual information \textquotesingle{}relevance\textquotesingle{} (in shannons)}
\DocumentationTok{\#\# between \textquotesingle{}income\textquotesingle{} and that variate}
\ControlFlowTok{for}\NormalTok{(var }\ControlFlowTok{in}\NormalTok{ predictors)\{}
\NormalTok{    relevances[var] }\OtherTok{\textless{}{-}} \FunctionTok{mutualinfo}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opmall, }\AttributeTok{A =} \StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{, }\AttributeTok{B =}\NormalTok{ var)}
\NormalTok{\}}

\DocumentationTok{\#\# output the mutual informations in decreasing order}
\FunctionTok{sort}\NormalTok{(relevances, }\AttributeTok{decreasing =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
marital_status   relationship      education     occupation      workclass 
    0.10074130     0.09046621     0.06332052     0.05506897     0.03002995 
native_country            sex           race 
    0.01925227     0.01456655     0.00870089 
\end{verbatim}

If we had to choose \emph{only one} variate to infer the outcome, on
average it would be best to use {\(\mathit{marital\_status}\).} Our last
choice should be {\(\mathit{race}\).}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Now consider the scenario where we must \emph{exclude one variate} from
the eight predictors, or, equivalently, we can only use seven variates
as predictors. Which variate should we exclude?

Prepare a script similar to the one above: it calculates the mutual
information between {\(\mathit{income}\)} and the other predictors but
with one omitted, omitting each of the eight in turn.

{\emph{Warning: this computation might require 10 or more minutes to
complete.}}

\begin{itemize}
\item
  Which single variate should not be omitted from the predictors? which
  single variate could be dropped?
\item
  Do you obtain the same relevance ranking as in the
  ``use-one-variate-only'' scenario above?
\end{itemize}

\end{tcolorbox}

\section{Example application to new
data}\label{example-application-to-new-data}

Let's apply the \texttt{opmall}-agent to a test dataset with 33\,914 new
units. For each new unit, the agent:

\begin{itemize}
\tightlist
\item
  calculates the probability of
  \(\mathit{income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;<=50;}\),
  via the function \texttt{infer()}, using as predictors all variates
  except \(\mathit{income}\)
\item
  chooses one of the two values
  \(\set{{\small\verb;<=50K;}, {\small\verb;>50K;}}\), via the function
  \texttt{decide()} trying to maximizing utilities corresponding to the
  accuracy metric
\end{itemize}

The function \texttt{decide()} will be described in more detail in
chapters~\ref{sec-make-decision} and~\ref{sec-example-opm2}.

At the end we plot a histogram of the probabilities calculated for the
new units, to check for instance for how many of the agent was sure
(beliefs around 0\% or 100\%) or unsure (beliefs around 50\%). We also
report the final utility/accuracy per unit, and the time needed for the
computation:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Load test data}
\NormalTok{testdata }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}test{-}income\_data\_example.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{na.strings =} \StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{, }\AttributeTok{stringsAsFactors =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{tryLogical =} \ConstantTok{FALSE}\NormalTok{)}

\NormalTok{ntest }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(testdata) }\CommentTok{\# size of test dataset}

\DocumentationTok{\#\# Let\textquotesingle{}s time the calculation}
\NormalTok{stopwatch }\OtherTok{\textless{}{-}} \FunctionTok{Sys.time}\NormalTok{()}

\NormalTok{testprobs }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(ntest) }\CommentTok{\# prepare vector of probabilities}
\NormalTok{testhits }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(ntest) }\CommentTok{\# prepare vector of hits}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{ntest)\{}
    
    \DocumentationTok{\#\# calculate probabilities given all variates except \textquotesingle{}income\textquotesingle{}}
\NormalTok{    probs }\OtherTok{\textless{}{-}} \FunctionTok{infer}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opmall,}
        \AttributeTok{predictor =}\NormalTok{ testdata[i, }\FunctionTok{colnames}\NormalTok{(testdata) }\SpecialCharTok{!=} \StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{])}

    \DocumentationTok{\#\# store the probability for \textless{}=50K}
\NormalTok{    testprobs[i] }\OtherTok{\textless{}{-}}\NormalTok{ probs[}\StringTok{\textquotesingle{}\textless{}=50K\textquotesingle{}}\NormalTok{]}

    \DocumentationTok{\#\# decide on one value}
\NormalTok{    chosenvalue }\OtherTok{\textless{}{-}} \FunctionTok{decide}\NormalTok{(}\AttributeTok{probs =}\NormalTok{ probs)}\SpecialCharTok{$}\NormalTok{optimal}

    \DocumentationTok{\#\# check if decision == true\_value, and store result}
\NormalTok{    testhits[i] }\OtherTok{\textless{}{-}}\NormalTok{ (chosenvalue }\SpecialCharTok{==}\NormalTok{ testdata[i, }\StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{])}
\NormalTok{\}}

\DocumentationTok{\#\# Print total time required}
\FunctionTok{print}\NormalTok{(}\FunctionTok{Sys.time}\NormalTok{() }\SpecialCharTok{{-}}\NormalTok{ stopwatch)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Time difference of 4.6795 secs
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Histogram and average accuracy (rounded to one decimal)}
\FunctionTok{myhist}\NormalTok{(testprobs, }\AttributeTok{n =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\AttributeTok{length.out =} \DecValTok{10}\NormalTok{), }\AttributeTok{plot =} \ConstantTok{TRUE}\NormalTok{,}
      \AttributeTok{xlab =} \StringTok{\textquotesingle{}P(income = "\textless{}=50K")\textquotesingle{}}\NormalTok{,}
      \AttributeTok{ylab =} \StringTok{\textquotesingle{}frequency density in test set\textquotesingle{}}\NormalTok{,}
      \AttributeTok{main =} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}accuracy: \textquotesingle{}}\NormalTok{, }\FunctionTok{round}\NormalTok{(}\DecValTok{100}\SpecialCharTok{*}\FunctionTok{mean}\NormalTok{(testhits), }\DecValTok{1}\NormalTok{), }\StringTok{\textquotesingle{}\%\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{example_opm1_files/figure-pdf/unnamed-chunk-20-1.pdf}}

\hfill\break

\section{Comparison}\label{sec-compare-opm}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Now try to use a popular machine-learning algorithm for the same task,
using the same training data, and compare it with the prototype optimal
predictor machine. Examine the differences. For example:

\begin{itemize}
\item
  Can you inform the algorithm that {\(\mathit{native\_country}\)} has
  two additional values {\({\small\verb;Norway;}\),}
  {\({\small\verb;Netherlands;}\)} not present in the training data?
  How?
\item
  Can you flexibly use the algorithm to specify any predictors and any
  predictands on the fly?
\item
  Does the algorithm inform you of how the inferences could change if
  more training data were available?
\item
  Which accuracy does the algorithm achieve on the test set?
\end{itemize}

\end{tcolorbox}

\part{{\textbf{Decision-making}}}

\chapter{\texorpdfstring{{Utilities}}{Utilities}}\label{sec-utilities}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\data}{\se{\green data}}
\providecommand*{\predictor}{\se{\green predictor}}
\providecommand*{\yD}{\se{\yellow D}}
\providecommand*{\yA}{{\yellow A}}
\providecommand*{\yB}{{\yellow B}}
\providecommand*{\yC}{{\yellow C}}
\providecommand*{\dise}{\mathit{\red disease}}
\providecommand*{\yy}{{\red\cat{yes}}}
\providecommand*{\yn}{{\red\cat{no}}}
\providecommand*{\yr}{\,\mathrm{yr}}

\providecommand*{\income}{\mathit{\red income}}
\providecommand*{\yl}{{\red\cat{<=50K}}}
\providecommand*{\yh}{{\red\cat{>50K}}}

\providecommand*{\uu}{\mathrm{U}}
\providecommand*{\uf}{\mathrm{u}}
\providecommand*{\um}{\boldsymbol{\blue U}}
\providecommand*{\Pm}{\boldsymbol{\green P}}

\providecommand*{\pbest}{p^{+}}

\providecommand*{\pworst}{p^{-}}

\providecommand*{\ry}{{\red y}}
\providecommand*{\ryo}{{\red y^{*}}}
\providecommand*{\bu}{{\blue u}}

\providecommand*{\sA}{\se{\yellow A}}
\providecommand*{\sB}{\se{\yellow B}}

\providecommand*{\mA}{\mathcal{A}}
\providecommand*{\mB}{\mathcal{B}}

\providecommand*{\yca}{{\red\alpha}}
\providecommand*{\ycb}{{\red\beta}}
\providecommand*{\cm}{\boldsymbol{\red C}}

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}

\section{From inferences to
decisions}\label{from-inferences-to-decisions}

At long last we have seen how an agent can calculate the probabilities
of any kind of sentence, given any facts and assumptions available to
it. We studied this probability calculation for general problems, and
then more in detail for problems enjoying special properties, for
instance when the agent's beliefs are exchangeable
(chapter~~\ref{sec-exchangeable-beliefs}). Most important, we saw how
previous data and background information can be used to determine, and
at the same time affect, these probabilities. We have even built a real,
prototype agent that can flexibly calculate probabilities in problems
involving nominal variates.

Having rational degrees of belief about all possible hypotheses and
unknowns is useful, and the first step in scientific research. But often
it isn't enough. Often the agent needs to \emph{act}, to do something,
to make a choice, even if its uncertainty has not disappeared and
therefore it can't be sure of what its choice will lead to. Our very
first example of engineering problem (chapter~~\ref{sec-intro}) involved
the decision on whether to accept or discard an electronic component
just produced in an assembly line, not knowing whether it will fail
within a year or not.

In chapter~~\ref{sec-basic-decisions} we met the theory to deal with
this kind of decision-making problem: \emph{Decision Theory}.

Decision Theory requires the decision-making agent to calculate the
probabilities of the unknown outcomes. Now we know how to do that, at
least in some kinds of problems! Most of our discussion so far focused
on the calculation of those probabilities, which often is the most
difficult part of the decision-making task.

So let's face the decision-making problem again at last, and complete
the construction of our prototype agent by implementing the final
decision-making step.\footnote{Please go back to
  chapter~~\ref{sec-basic-decisions} and review the notions and
  terminology introduced there.}

\section{Review of a basic decision problem: outcomes, decisions,
utilities}\label{sec-decisions-utilities}

Recall the structure of a basic decision:

\includegraphics[width=0.75\linewidth,height=\textheight,keepaspectratio]{basic_decision_tree.png}

In order to make a decision, the agent needs:

\begin{itemize}
\item
  \faIcon{cube} The set of possible {\emph{decisions}}, which we
  represent as sentences like {\(\mathsfit{I}_{\textrm{d}}\).}
\item
  \faIcon{cube} The set of possible {\emph{outcomes}}, whose truth is
  unknown to the agent. In the kind of decision problems that we are
  examining, the outcomes correspond to the possible values
  {\(\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y\)}
  of what we have called the {predictand} variate from
  §~\ref{sec-cat-problems} onwards.
\item
  \faIcon{cube} The {\emph{probabilities}} of the
  outcomes~~{\(\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\)}
  which are determined by the agent's background information
  {\(\mathsfit{I}\),} by any other available information, such as
  {\(\mathsfit{\color[RGB]{34,136,51}data}\)} about previously observed
  units and the values of some predictor variates
  {\(\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x\)}
  for the current unit; and possibly also by the agent's decision
  {\(\mathsfit{I}_{\textrm{d}}\)} (see below).
\item
  \faIcon{cube} The {\emph{utilities}} of each pair of decision and
  outcome
  {\((\mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y})\).}
\end{itemize}

Some texts call the joint pair
{\(({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I}_{\textrm{d}})\),}
or equivalently
{\((\mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y})\),}
of a decision and an outcome, a {\textbf{consequence}}. We adopt this
terminology from this chapter onward.

Let's not forget some important points about the notions above:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  We are not assuming any temporal or ``causal'' relationship between
  {decisions} and {outcomes}: \textbf{our framework works independently
  of these relationships}. In some decision-making problems the outcomes
  happen \emph{after} a decision is made, and may be ``influenced'' by
  it or not. In other decision-making problems the outcomes have already
  happened \emph{before} a decision is made.

  In a transportation-choice problem, for instance, the outcome ``{wet
  from rain}'' may happen after we make the decision ``{go on foot}''
  rather than ``{go by bus}''. In an image-classification problem, on
  the other hand, the outcome ``{true label is \({\small\verb;cat;}\)}''
  was already determined before we made the decision ``{classify as
  \({\small\verb;dog;}\)}''.
\end{itemize}

\hfill\break

\begin{itemize}
\item
  In connection with the warning above, in some problems the
  probabilities of the outcomes may depend on the decision; that is,
  knowledge about the decision is \emph{relevant} to the knowledge about
  the outcome (see again §~\ref{sec-info-chapter}):

  \[\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\]

  For instance, in the transportation-choice problem the probability of
  the outcome ``{wet from rain}'' is higher conditional on the decision
  ``{go on foot}'' than on the decision ``{go by bus}''.

  In many decision-making problems typical of machine learning, such as
  classification, information about the decision is \emph{irrelevant} to
  the information about the outcome (which usually has already
  happened), and we have

  \[
    \mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
    = \mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
    \]
\end{itemize}

\end{tcolorbox}

In what follows we shall consider problems, such as classification,
where knowledge of the agent's decision is irrelevant to the outcome's
probability. We shall nevertheless keep the more general
notation~~{\(\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\).}

\section{What are utilities?}\label{sec-what-utilities}

In most decision-making problems the ``gain'' or ``loss'' or
``satisfaction'' or ``desiderability'' of the consequences depends on
many different aspects. A person purchasing some item may have to choose
between something inexpensive but of low quality, or something of high
quality but expensive. A clinical patient may have to choose between a
treatment that increases life expectancy but worsens the quality of
life, or a treatment that improves the quality of life but decreases
life expectancy.

Decision Theory says that whenever an agent makes a decision among
alternatives having heterogeneous decision aspects, then it is
\emph{implicitly} using \emph{only one real number} to summarize and
bring together all those aspects. If this weren't true, the agent would
be deciding in an irrational way, which could even be exploited against
the agent itself.

Such idea is not counter-intuitive in our culture. We are wont, for
example, to exchange \emph{money} for things of wildly different kinds:
food, entertainment, health, work, transport, communication, life
insurance, knowledge, political power. The monetary value of a human
life (``value of statistical life'') for some governments is
\href{https://www.transportation.gov/office-policy/transportation-policy/revised-departmental-guidance-on-valuation-of-a-statistical-life-in-economic-analysis}{about
USD\,10\,000\,000}.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{On
  making life and death decisions}}
\end{itemize}

\end{tcolorbox}

\end{footnotesize}}

{\textbf{Utility}} is the name we give to the real number that encodes
together all heterogeneous desirabilities and gains of a consequence.
The convention is that the higher the utility, the more preferable is
the consequence.\footnote{With the opposite convention we speak of
  \emph{disutility} or \emph{loss}.}

\subsection{Notation}\label{notation-2}

We denote the utility of the consequence
{\((\mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y})\)}
as

\[
\mathrm{U}(\mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

This notation reminds us that the utilities assigned by an agent depend
on the agent's background information {\(\mathsfit{I}\).}

The utilities for all consequences can be encoded in a {\textbf{utility
matrix}} {\(\boldsymbol{\color[RGB]{68,119,170}U}\),} having one row per
decision and one column per outcome:

\[
\boldsymbol{\color[RGB]{68,119,170}U}\coloneqq
\begin{bmatrix}
\mathrm{U}(\mathsfit{I}_{\textrm{d}}' \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y}' \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
&
\mathrm{U}(\mathsfit{I}_{\textrm{d}}' \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y}'' \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
& \dotso
\\
\mathrm{U}(\mathsfit{I}_{\textrm{d}}'' \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y}' \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
&
\mathrm{U}(\mathsfit{I}_{\textrm{d}}'' \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y}'' \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
& \dotso
\\
\dotso&\dotso&\dotso
\end{bmatrix}
\]

\subsection{Continuous case}\label{continuous-case}

In some decision-making problems the set of possible decisions can be
considered as continuous.

A power-plant operator, for example, may have to decide to supply an
amount of power between 100\,MW and 200\,MW to a geographical region in
the next hour. The unknown ``outcome'' {\(\color[RGB]{238,102,119}Y\)}
in this scenario may be the power demand, which could be in the same
range. In this case we can represent a decision by a statement
{\(\color[RGB]{204,187,68}D\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}d\),}
such as

\[\color[RGB]{204,187,68}D\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}175\,\mathrm{MW}\]

(where
{``\(\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\)''}
obviously stands for ``set to'', not ``is observed to be equal to'';
recall §~\ref{sec-sentence-notation}?)

In such continuous cases we speak of a {\textbf{utility function}}

\[\mathrm{u}({\color[RGB]{204,187,68}d} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\]

A typical, extremely abused utility function is the negative squared
loss:

\[
\mathrm{u}({\color[RGB]{204,187,68}d} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{sl}})
= -\abs{{\color[RGB]{204,187,68}d} - {\color[RGB]{238,102,119}y}}^2
\]

stating that the utility decreases as the squared difference between
{\(\color[RGB]{204,187,68}d\)} and {\({\color[RGB]{238,102,119}y}\).} In
concrete problems it is worthwhile to think of more realistic and
problem-specific utility functions. In the power-plant scenario, for
example, the utility could be worse if the power output is \emph{below}
the power demand, than above. This could be expressed by a function like

\[
\mathrm{u}({\color[RGB]{204,187,68}d} \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}y}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{plant}})
=
\begin{cases*}
-2\,\abs{{\color[RGB]{204,187,68}d} - {\color[RGB]{238,102,119}y}}^2 & if ${\color[RGB]{204,187,68}d} < {\color[RGB]{238,102,119}y}$
\\[1ex]
-\abs{{\color[RGB]{204,187,68}d} - {\color[RGB]{238,102,119}y}}^2 &  if ${\color[RGB]{204,187,68}d} \ge {\color[RGB]{238,102,119}y}$
\end{cases*}
\]

or some other asymmetric function.

\section{How to determine utilities?}\label{sec-whence-utilities}

It can be quite difficult to assess the utilities of the decisions and
outcomes in a decision-making problems, because of reasons such as
heterogeneity or uncertainty, discussed below. Yet, Decision Theory says
that any decision is either implicitly using such a number, or is
sub-optimal or logically inconsistent. Moreover, the specification, at
some level, of utilities not derived by further analysis is simply
unavoidable -- just like the specification of some initial
probabilities.

\subsubsection{Heterogeneous factors}\label{heterogeneous-factors}

Many heterogeneous factors can enter the determination of utilities. In
medical decision-making problems, for example, a clinician must choose
one among several possible treatments for a patient, and the utilities
of the outcome must take into account factors such as

\begin{itemize}
\tightlist
\item
  cost of the treatment
\item
  expected life length resulting from the treatment
\item
  quality of life resulting from the treatment
\item
  patient's preferences and attitudes towards life
\end{itemize}

It can be very difficult to combine these factors into a single number.

Several fields, such as medicine, have developed and refined several
methodologies to arrive at utilities that account for all important
factors. Unfortunately we shall not explore any of them in these notes.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Decisions
  with Multiple Objectives}}
\item
  Chapter~8 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Medical
  Decision Making}}
\end{itemize}

\end{tcolorbox}

\end{footnotesize}}

\subsubsection{Uncertainty}\label{uncertainty}

The assessment of utilities can also be affected by uncertainties, and
therefore become an inference problem in itself. The utility of an
outcome may depend on further decisions and further outcomes, whose
utilities in turn depend on further decisions and outcomes. Our basic
decision framework can in this case be applied repeatedly, as briefly
discussed below. In the simplest case, if the agent is uncertain between
utility values
{\(\color[RGB]{68,119,170}\boldsymbol{\color[RGB]{68,119,170}U}'\)} with
probability {\(p'\),} and utility values
{\(\color[RGB]{68,119,170}\boldsymbol{\color[RGB]{68,119,170}U}''\)}
with probability {\(p'' = 1-p'\),} then the utilities to use are the
averages

\[p'\,{\color[RGB]{68,119,170}\boldsymbol{\color[RGB]{68,119,170}U}'} + p''\,{\color[RGB]{68,119,170}\boldsymbol{\color[RGB]{68,119,170}U}''}\]

But the specification, at some level, of utilities not derived by
further inferences is simply unavoidable -- just like the specification
of some initial probabilities.

\subsection{Approximate assignments}\label{approximate-assignments}

An approximate procedure of assigning utilities goes as follows:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Write down all possible consequences
\item
  Sort all consequences from best to worst. Ties are possible, that is,
  there may be several consequences considered to be equally good or
  equally bad.
\item
  Assign utility {\(\color[RGB]{68,119,170}1\)} to the best consequence
  (or to each of the best, if there's a tie), and utility
  {\(\color[RGB]{68,119,170}0\)} to the worst.
\item
  Determine the utility {\({\color[RGB]{68,119,170}u}\)} of each
  intermediate consequence
  {\(({\color[RGB]{238,102,119}y}, \mathsfit{I}_{\textrm{d}})\)} as
  follows:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Consider a \emph{lottery} where you can win the best consequence
    (that with utility \(\color[RGB]{68,119,170}1\)) with some
    probability \(p^{+}\), or the worst consequence with probability
    \(1-p^{+}\).
  \item
    Choose one value of \(p^{+}\in [0,1]\) such that it would be OK if
    you were forced to exchange the lottery with the consequence
    \(({\color[RGB]{238,102,119}y},\mathsfit{I}_{\textrm{d}})\) under
    consideration, \emph{and vice versa}, exchange the consequence under
    consideration with the lottery.
  \item
    That probability value is the utility
    \({\color[RGB]{68,119,170}u}= p^{+}\) of the consequence under
    consideration.
  \end{enumerate}
\item
  Check whether the utilities determined through lotteries respect your
  initial sorting. If they don't, then you have reasoned inconsistently
  somewhere. Repeat the steps above thinking more thoroughly about your
  sorting and lotteries.
\item
  As an additional check, take any three consequences with utilities
  {\({\color[RGB]{68,119,170}u}_1 \ge {\color[RGB]{68,119,170}u}_2 \ge {\color[RGB]{68,119,170}u}_3\).}
  Consider again a lottery where you can win the \emph{first}
  consequence with probability {\(p\)} or the \emph{third} with
  probability {\(1-p\),} and choose {\(p\)} so that it would be OK to be
  forced to exchange this lottery with the \emph{second} consequence,
  and vice versa. Then you should find, at least approximately, that

  \[{\color[RGB]{68,119,170}u}_2 = p\cdot {\color[RGB]{68,119,170}u}_1 + (1-p)\cdot {\color[RGB]{68,119,170}u}_3\]

  If you don't, then there are again inconsistencies or irrational
  biases in your judgements, and you should review them.
\end{enumerate}

\end{tcolorbox}

In the procedure above, the values {\(\color[RGB]{68,119,170}1\)} and
{\(\color[RGB]{68,119,170}0\)} for the best and worst consequences are
arbitrary: they correspond to setting a zero and a measurement unit of
your utility scale. You can choose any other pair of values
{\({\color[RGB]{68,119,170}u_{\textrm{max}}} > {\color[RGB]{68,119,170}u_{\textrm{min}}}\).}
The procedure applies in the same way, but the utility corresponding to
{\(p^{+}\)} is then given by

\[{\color[RGB]{68,119,170}u}= p^{+}\cdot{\color[RGB]{68,119,170}u_{\textrm{max}}} +
(1-p^{+})\cdot {\color[RGB]{68,119,170}u_{\textrm{min}}}
\]

\hfill\break

The assessment of initial utilities constitutes a field under active
development (see references below), usually called {\textbf{utility
elicitation}}.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  §15.3.1 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}
\item
  Final \textbf{Summary} (pp.~234--235) of chapter~8 in
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Medical
  Decision Making}}
\item
  §§~9.14--9.17 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Making
  Decisions}}
\item
  §4.2 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Decisions
  with Multiple Objectives}}
\item
  Skim through
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Attitude
  and opinion measurement}}
\end{itemize}

\end{tcolorbox}

\section{Utilities as evaluation metric}\label{sec-utilities-metric}

The utilities of the consequences not only allow the agent to determine
the optimal decision, as we shall see in the next chapter. They also
allow us to quantify how much utility an agent yielded in a concrete
application or sequence of applications of a specific decision-making
task.

Since the possible gains and losses of a specific problem are encoded in
the problem-specific utilities
{\(\boldsymbol{\color[RGB]{68,119,170}U}\),} these utilities quantify
\emph{by definition} how much has been gained or lost in solving the
problem.

Suppose that in the first instance of a decision-making task the agent
makes decision {\(\mathsfit{I}_{\textrm{d}}_1\),} and in that instance
the outcome {\({\color[RGB]{238,102,119}Y}_1\)} turns out to be
{\({\color[RGB]{238,102,119}y}_1\)} (this may be discovered a long time
after the decision was made). The utility (possibly a loss) gained at
that instance is then, by definition,

\[
\mathrm{U}(\mathsfit{I}_{\textrm{d}}_1 \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y_{\color[RGB]{0,0,0}1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{\color[RGB]{0,0,0}1}} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

Assuming that the utilities are additive over instances\footnote{if they
  weren't, the whole decision-making scheme of the next chapter should
  be changed, but a similar approach would still apply}, then the total
utility yield for instances {\(i=1,2,\dotsc,M\)} is

\[
\sum_{i=1}^{M}
\mathrm{U}(\mathsfit{I}_{\textrm{d}}_i \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y_{\color[RGB]{0,0,0}i}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{\color[RGB]{0,0,0}i}} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

and the average utility yield per instance is

\[
\frac{1}{M}
\sum_{i=1}^{M}
\mathrm{U}(\mathsfit{I}_{\textrm{d}}_i \mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y_{\color[RGB]{0,0,0}i}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{\color[RGB]{0,0,0}i}} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\]

\subsection{Use in a test set}\label{use-in-a-test-set}

The utility yield can be calculated in a test run of the agent, to check
whether its operation meets its specifications and expectations, or even
to compare the performance of different agents.

For the test run we need a set of data {\(i=1,2,\dotsc,M\)} (which
should come from the same population underlying the real application,
see §~\ref{sec-samples}) for which the actual outcomes
{\({\color[RGB]{238,102,119}Y_{\color[RGB]{0,0,0}i}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{\color[RGB]{0,0,0}i}}\)}
are known, and for which any predictors
{\({\color[RGB]{34,136,51}X_{\color[RGB]{0,0,0}i}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{\color[RGB]{0,0,0}i}}\)}
are also available, so that they can be used by the agents under
evaluation.

Each agent is then applied to these data: it is given the predictors
{\({\color[RGB]{34,136,51}X_{\color[RGB]{0,0,0}i}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{\color[RGB]{0,0,0}i}}\),}
and from these it will determine and possibly execute the optimal
decision {\(\mathsfit{I}_{\textrm{d}}_i\),} for all {\(i\).} The total
or average utility yield generated by the agent is then given by the
formula above.

The test utility yield of an agent can be examined to uncover possible
design flaws (say, wrong background information, or programming bugs).
The yields of different agents can be compared to decide which is most
appropriate to the task.

We will return to this use of the utility matrix in
chapter~~\ref{sec-ML-utility-limitation}, when we discuss some
evaluation metrics typical of present-day machine-learning methodology.

\section{Utilities and probabilities must be
independent}\label{sec-indep-axiom}

The \emph{independence} (or \emph{``sure-thing''}) axiom of Decision
Theory says that the utilities cannot be functions of the probabilities.
In other words, an agent cannot assign higher or lower utility to some
outcome just because its probability is higher or lower (or vice versa)
than the probability of another outcome. The converse also holds: the
probability of an outcome cannot be judged higher or lower just because
the outcome is more or less desirable (or vice versa). Note that there
may be some kind of relation between utilities and probabilities, but
only because they refer to the same sentences, not because they are
determined by each other's numerical values.

A dependence of probabilities on utilities we recognize immediately as
``wishful thinking''. But some researchers have from time to time
objected that the dependence of utilities on probabilities could be
rationally justified, and have proposed alleged counterexamples (usually
called ``paradoxes'') to prove their objection. The
\href{https://plato.stanford.edu/entries/rationality-normative-utility/\#MaxExpUtiIrr}{most
famous are Allais's and Ellsberg's paradoxes}.

Examination of these would-be counterexamples show that they actually
contain logical inconsistencies of various kind. Here we want to
emphasize one particular kind of mistake: \emph{they base utilities on
particular aspects of the decision-making problem, but then use the
probabilities of different aspects}. Let's show this inconsistency with
an extreme example that illustrates it clearly.

Suppose a person is asked to make a decision between two bets or
lotteries {\(\mathsfit{\color[RGB]{204,187,68}A}\)} and
{\(\mathsfit{\color[RGB]{204,187,68}B}\):}

\begin{itemize}
\tightlist
\item
  \(\mathsfit{\color[RGB]{204,187,68}A}\): 50\% probability of winning
  or losing nothing, and 50\% probability of losing 10\,000\,\$ (or an
  amount that's high for the person's economy)
\item
  \(\mathsfit{\color[RGB]{204,187,68}B}\): 90\% probability of winning
  100\,\$, and 10\% probability of winning or losing nothing
\end{itemize}

Before applying decision theory to this problem we need to assess which
factors affect the utilities of this person. It turns out that this
person is a gambler: she only cares about the ``thrill \& risk'' of a
consequence, and she doesn't care about losing money.

A hasty and naive application of decision theory could represent the
problem with the following tree:

\includegraphics[width=0.75\linewidth,height=\textheight,keepaspectratio]{decision_tree_gambler_wrong.png}

and the decision with maximal expected utility would be
{\(\mathsfit{\color[RGB]{204,187,68}B}\).} But the gambler obviously
prefers {\(\mathsfit{\color[RGB]{204,187,68}A}\).} A critic of Decision
Theory would then say that this happens because, contrary to the axiom
of independence, we should allow the utilities to depend on the
probabilities, which are more uncertain for
{\(\mathsfit{\color[RGB]{204,187,68}A}\)} than for
{\(\mathsfit{\color[RGB]{204,187,68}B}\).}

But the above application is wrong and illogical. In the representation
above, the probabilities refer to the monetary outcome; but we said that
the gambler doesn't care about losing money. If ``thrill \& risk'' is
the factor that determines the utilities, then the probabilities should
be about that same factor.

For the gambler, choosing {\(\mathsfit{\color[RGB]{204,187,68}B}\)}
leads \emph{for certain} to a situation with little ``thrill'' (the
winning outcome is almost sure) and no risk (no money will be lost in
any case). Choosing {\(\mathsfit{\color[RGB]{204,187,68}A}\)} instead
leads \emph{for certain} to a situation with high ``thrill'' (completely
uncertain outcome) and high risk (huge money loss). The second situation
has higher relative utility than the first. The correct representation
of the decision problem is therefore like this:

\includegraphics[width=0.75\linewidth,height=\textheight,keepaspectratio]{decision_tree_gambler_right.png}

Note that the utilities do \emph{not} depend on the probabilities,
exactly as required by the independence axiom. The principle of maximal
expected utility leads to decision
{\(\mathsfit{\color[RGB]{204,187,68}A}\),} the gambler's favourite. Also
note that the relevant probabilities are not the ones (about money
winnings) mentioned in the initial statement of the problem. Just
because we read or hear the word ``probability'' doesn't mean that
that's the probability we need.

This would-be counterexample therefore vindicates Decision Theory. The
problem was not in the axiom of independence, but in the fact that the
framework was illogically applied. The ``need'' to break the axiom of
independence to recover the intuitively correct solution (basically
correcting an error with another error) was actually a warning sign that
some illogical reasoning was taking place.

In more realistic situations, both utilities and probabilities must
refer to a combination of monetary value and other factors, such as
emotional ones. What's important in any case is that they refer to the
same factors. So to speak: if you say that you like oranges and don't
care about apples, then you should worry about how many oranges, not
apples, there are.

This example, even if somewhat exaggerated, reminds us of two caveats
that we have repeated several times in these notes:

\begin{itemize}
\item
  It is important to enquire what the exact \emph{goals} and \emph{whys}
  of an engineering or data-science problem really are. Otherwise you
  may end up wasting a lot of time developing the correct solution to
  the wrong problem.
\item
  Don't let yourself be deceived by words and technical terms. Try to
  understand the essence of the problem that lies beyond its verbal
  description.
\end{itemize}

In chapter~~\ref{sec-ML-utility-limitation} we shall see that some
common evaluation metrics in machine learning actually break the
independence axiom, and should therefore be avoided.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  \emph{A theory of human behavior} (pp.~30-37) in chapter~2 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Rational
  Decision and Causality}}
\item
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{On the
  consistency of preferences in Allais' paradox}}
\item
  Skim through §9 (pp.~80--86) in chapter~4 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Decision
  Analysis}}
\end{itemize}

\end{tcolorbox}

\chapter{\texorpdfstring{{Making
decisions}}{Making decisions}}\label{sec-making-decisions}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\data}{\se{\green data}}
\providecommand*{\predictor}{\se{\green predictor}}
\providecommand*{\yD}{\se{\yellow D}}
\providecommand*{\yA}{{\yellow A}}
\providecommand*{\yB}{{\yellow B}}
\providecommand*{\yC}{{\yellow C}}
\providecommand*{\dise}{\mathit{\red disease}}
\providecommand*{\yy}{{\red\cat{yes}}}
\providecommand*{\yn}{{\red\cat{no}}}
\providecommand*{\yr}{\,\mathrm{yr}}

\providecommand*{\income}{\mathit{\red income}}
\providecommand*{\yl}{{\red\cat{<=50K}}}
\providecommand*{\yh}{{\red\cat{>50K}}}

\providecommand*{\uu}{\mathrm{U}}
\providecommand*{\uf}{\mathrm{u}}
\providecommand*{\um}{\boldsymbol{\blue U}}
\providecommand*{\Pm}{\boldsymbol{\green P}}

\providecommand*{\pbest}{p^{+}}

\providecommand*{\pworst}{p^{-}}

\providecommand*{\ry}{{\red y}}
\providecommand*{\ryo}{{\red y^{*}}}
\providecommand*{\bu}{{\blue u}}

\providecommand*{\sA}{\se{\yellow A}}
\providecommand*{\sB}{\se{\yellow B}}

\providecommand*{\mA}{\mathcal{A}}
\providecommand*{\mB}{\mathcal{B}}

\providecommand*{\yca}{{\red\alpha}}
\providecommand*{\ycb}{{\red\beta}}
\providecommand*{\cm}{\boldsymbol{\red C}}



\section{Maximization of expected utility}\label{sec-max-exp-utilities}

In the previous chapter we associated utilities to consequences, that
is, pairs
{\((\mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y})\)}
of decisions and outcomes. We can also associated utilities to the
decisions alone -- and these are used to determine the \emph{optimal}
decision.

The {\textbf{expected utility}} of a decision
{\(\mathsfit{I}_{\textrm{d}}\)} is calculated as a weighted average over
all possible outcomes, the weighs being the outcomes' probabilities:

\[\mathrm{U}(\mathsfit{I}_{\textrm{d}}\nonscript\:\vert\nonscript\:\mathopen{}\mathsfit{I}) 
= \sum_{\color[RGB]{238,102,119}y} \mathrm{U}(\mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) \cdot
\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]

\hfill\break

According to Decision Theory the agent's final decision is determined by
the

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={{\textbf{Principle of maximal expected utility}}}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

The optimal decision, which should be made by the agent, is the one
having maximal expected utility:

\[
\mathsfit{I}_{\textrm{d}}_{\text{optimal}} =
\operatorname{argmax}_{\mathsfit{I}_{\textrm{d}}} \sum_{\color[RGB]{238,102,119}y} \mathrm{U}(\mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) \cdot
\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]

(where, in some tasks, the probabilities may not depend on
{\(\mathsfit{I}_{\textrm{d}}\))}

\end{tcolorbox}

\end{figure*}%

In the formula above, {``\(\operatorname{argmax}\limits_z G(z)\)''} is
the value {\(z^*\)} which maximizes the function {\(G(z)\).} Note the
difference:~~{\(\max\limits_z G(z)\)~~is} the value of the maximum
itself (its {\(y\)-coordinate,} so to speak),
whereas~~{\(\operatorname{argmax}\limits_z G(z)\)~~is} the value of the
\emph{argument} that gives the maximum (its {\(x\)-coordinate).} For
instance

\[\max\limits_z (1-z)^2 = 0 \qquad\text{\small but}\qquad \operatorname{argmax}\limits_z (1-z)^2 = 1\]

\hfill\break

It may happen that there are several decisions which have equal, maximal
expected utility. In this case any one of them can be chosen. A useful
strategy is to choose one among them with equal probability. Such
strategy helps minimizing the loss from possible small errors in the
specification of the utilities, or from the presence of an antagonist
agent which tries to predict what our agent is doing.

\subsection{Numerical implementation in simple
cases}\label{numerical-implementation-in-simple-cases}

The principle of maximal expected utility is straightforward to
calculate in many important problems.

In §~\ref{sec-what-utilities} we represented the set of utilities by a
utility matrix {\(\boldsymbol{\color[RGB]{68,119,170}U}\).} If the
probabilities of the outcomes do \textbf{not} depend on the decisions,
we represent them as a column matrix
{\(\boldsymbol{\color[RGB]{34,136,51}P}\),} having one entry per
outcome:

\[
\boldsymbol{\color[RGB]{34,136,51}P}\coloneqq
\begin{bmatrix}
\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y}' \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\
\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y}'' \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\
\dotso
\end{bmatrix}
\]

Then the collection of expected utilities is a column matrix, having one
entry per decision, given by the matrix product
{\(\boldsymbol{\color[RGB]{68,119,170}U}\boldsymbol{\color[RGB]{34,136,51}P}\).}

All that's left is to check which of the entries in this final matrix is
maximal.

\section{Concrete example: targeted
advertisement}\label{sec-max-exp-util-example}

As a concrete example application of the principle of maximal expected
utility, let's keep on using the adult-income task from
chapter~~\ref{sec-example-opm1}, in a typical present-day scenario.

Some corporation, which offers a particular phone app, wants to
\href{https://pluralistic.net/2023/07/24/rent-to-pwn/}{bombard its users
with advertisements}, because advertisement generates much more revenue
than making the users pay for the app. For each user the corporation can
choose one among three ad-types, let's call them
{\(\mathsfit{A}, \mathsfit{B}, {\color[RGB]{204,187,68}C}\).} The
revenue obtained from these ad-types depends on whether the target
user's income is {\({\color[RGB]{238,102,119}{\small\verb;<=50K;}}\)} or
{\(\mathsfit{h}\).} A separate study run by the corporation has shown
that the average revenues (per user per minute) depending on the three
ad-types and the income levels are as follows:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2444}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2444}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2444}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2444}}@{}}
\caption{Revenue depending on ad-type and income
level}\label{tbl-income}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
\multicolumn{2}{@{}>{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4889} + 2\tabcolsep}}{%
\multirow{2}{=}{}} &
\multicolumn{2}{>{\raggedleft\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4889} + 2\tabcolsep}@{}}{%
\(\mathit{\color[RGB]{238,102,119}income}\)} \\
& & \({\color[RGB]{238,102,119}{\small\verb;<=50K;}}\) &
\(\mathsfit{h}\) \\
\multirow{3}{=}{{ad-type}} & \(\mathsfit{A}\) &
\(\color[RGB]{68,119,170}-1\,\$\) & \(\color[RGB]{68,119,170}3\,\$\) \\
& \(\mathsfit{B}\) & \(\color[RGB]{68,119,170}2\,\$\) &
\(\color[RGB]{68,119,170}2\,\$\) \\
& \({\color[RGB]{204,187,68}C}\) & \(\color[RGB]{68,119,170}3\,\$\) &
\(\color[RGB]{68,119,170}-1\,\$\) \\
\end{longtable}

Ad-type {\(\mathsfit{B}\)} is a neutral advertisement type that leads to
revenue independently of the target user's income. Ad-type
{\(\mathsfit{A}\)} targets high-income users, leading to higher revenue
from them; but it leads to a loss if shown to the wrong target (more
money spent on making and deploying the ad than what is gained from
users' purchases). Vice versa, ad-type {\(\mathsfit{B}\)} targets
low-income users, with a reverse effect.

The corporation doesn't have access to its users' income levels, but it
covertly collects, through some other app, all or some of the eight
predictor variates {\(\color[RGB]{34,136,51}\mathit{workclass}\),}
{\(\color[RGB]{34,136,51}\mathit{education}\),}
{\(\color[RGB]{34,136,51}\dotsc\),}
{\(\color[RGB]{34,136,51}\mathit{sex}\),}
{\(\color[RGB]{34,136,51}\mathit{native\_country}\)} from each of its
users. The corporation has also access to the adult-income dataset (or
let's say a more recent version of it).

In this scenario the corporation would like to use an AI agent that can
choose and show the optimal ad-type to each user.

\hfill\break

Our prototype agent from chapters~\ref{sec-code-design},
\ref{sec-code-workflow}, \ref{sec-example-opm1} can be used for such a
task. It has already been trained with the dataset, and can use any
subset (possibly even empty) of the eight predictors to calculate the
probability for the two income levels.

All that's left is to equip our prototype agent with a function that
outputs the optimal decision, given the calculated probabilities and the
set of utilities. In our code this is done by the function
\texttt{decide()} described in chapter~~\ref{sec-code-workflow} and
reprinted here:

\begin{description}
\item[\faIcon{code}
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/decide.R}{\texttt{decide(probs,\ utils=NULL)}}]
\begin{description}
\item[Arguments:]
\hfill
\begin{itemize}
\tightlist
\item
  \emph{\texttt{probs}}: a probability distribution for one or more
  variates.
\item
  \emph{\texttt{utils}}: a named matrix or array of utilities. The
  \textbf{rows} of the matrix correspond to the available decisions, the
  \textbf{columns} or remaining array dimensions correspond to the
  possible values of the predictand variates.
\end{itemize}
\item[Output:]
a list of elements \texttt{EUs} and \texttt{optimal}:

\begin{itemize}
\tightlist
\item
  \texttt{EUs} is a vector containing the expected utilities of all
  decisions, sorted from highest to lowest
\item
  \texttt{optimal} is the decision having maximal expected utility, or
  one of them, if more than one, selected with equal probability
\end{itemize}
\item[Notes:]
\hfill
\begin{itemize}
\tightlist
\item
  If \emph{\texttt{utils}} is missing or \texttt{NULL}, a matrix of the
  form
  \(\begin{bsmallmatrix}1&0&\dotso\\0&1&\dotso\\\dotso&\dotso&\dotso\end{bsmallmatrix}\)
  is assumed (which corresponds to using \emph{accuracy} as evaluation
  metric).
\end{itemize}
\end{description}
\end{description}

\subsection{Example}\label{example}

A new user logs in; all eight predictors are available for this user:

\[\color[RGB]{34,136,51}
\begin{aligned}
&\mathit{workclass} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Private;}
&& \mathit{education} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Bachelors;} 
\\ & \mathit{marital\_status} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Never-married;} 
&& \mathit{occupation} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Prof-specialty;} 
\\ & \mathit{relationship} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Not-in-family;} 
&& \mathit{race} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;White;} 
\\ & \mathit{sex} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Female;} 
&& \mathit{native\_country} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;United-States;}
\end{aligned}
\]

The agent calculates (using the \texttt{infer()} function) the
probabilities for the two income levels, which turn out to be

\[
\begin{aligned}
&\mathrm{P}({\color[RGB]{238,102,119}\mathit{\color[RGB]{238,102,119}income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}{\small\verb;<=50K;}}} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\color[RGB]{34,136,51}predictor}, \mathsfit{\color[RGB]{34,136,51}data}, \mathsfit{I}) = 83.3\%
\\&\mathrm{P}({\color[RGB]{238,102,119}\mathit{\color[RGB]{238,102,119}income}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\mathsfit{h}} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{\color[RGB]{34,136,51}predictor}, \mathsfit{\color[RGB]{34,136,51}data}, \mathsfit{I}) = 16.7\%
\end{aligned}
\]

and can be represented by the column matrix

\[\boldsymbol{\color[RGB]{34,136,51}P}\coloneqq
\color[RGB]{34,136,51}\begin{bmatrix}
0.833\\0.167
\end{bmatrix}
\]

The utilities previously given can be represented by the matrix

\[\boldsymbol{\color[RGB]{68,119,170}U}\coloneqq
\color[RGB]{68,119,170}\begin{bmatrix}
-1&3\\2&2\\3&-1
\end{bmatrix}
\]

Multiplying the two matrices above we obtain the expected utilities of
the three ad-types for the present user:

\[
\boldsymbol{\color[RGB]{68,119,170}U}\boldsymbol{\color[RGB]{34,136,51}P}= 
\color[RGB]{68,119,170}\begin{bmatrix}
-1&3\\2&2\\3&-1
\end{bmatrix}
\,
\color[RGB]{34,136,51}\begin{bmatrix}
0.833\\0.167
\end{bmatrix}\color[RGB]{0,0,0}
=
\begin{bmatrix}
{\color[RGB]{68,119,170}-1}\cdot{\color[RGB]{34,136,51}0.833}
+ {\color[RGB]{68,119,170}3}\cdot{\color[RGB]{34,136,51}0.167}
\\
{\color[RGB]{68,119,170}2}\cdot{\color[RGB]{34,136,51}0.833}
+ {\color[RGB]{68,119,170}2}\cdot{\color[RGB]{34,136,51}0.167}
\\
{\color[RGB]{68,119,170}3}\cdot{\color[RGB]{34,136,51}0.833}
+ ({\color[RGB]{68,119,170}-1})\cdot{\color[RGB]{34,136,51}0.167}
\end{bmatrix}
=
\begin{bmatrix}
-0.332\\
2.000\\
\boldsymbol{2.332}
\end{bmatrix}
\]

The highest expected utility is that of ad-type
{\({\color[RGB]{204,187,68}C}\),} which is therefore shown to the user.

\subsection{Powerful flexibility of the optimal predictor
machine}\label{powerful-flexibility-of-the-optimal-predictor-machine}

In the previous chapters we already emphasized and witnessed the
flexibility of the optimal predictor machine with regard to the
availability of the predictors: it can draw an inference even if some or
all predictors are missing.

Now we can see another powerful kind of flexibility: the optimal
predictor machine can in principle \emph{use different sets of decisions
and different utilities for each new application}. The decision
criterion is not ``hard-coded''; it can be customized on the fly.

The possible number of ad-types and the utilities could even be a
function of the predictor values. For instance, there could be a set of
three ad-types targeting users with
{\(\color[RGB]{34,136,51}\mathit{education}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Bachelors;}\),}
a different set of four ad-types targeting users with
{\(\color[RGB]{34,136,51}\mathit{education}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;Preschool;}\),}
and so on.

\hfill\break

\section{The full extent of Decision
Theory}\label{sec-DT-generalization}

The simple decision-making problems and framework that we have discussed
in these notes are only the basic blocks of Decision Theory. This theory
covers more complicated decision problems. We only mention some
examples:

\begin{itemize}
\tightlist
\item
  \textbf{Sequential decisions}. Many decision-making problems involve
  sequences of possible decisions, alternating with sequences of
  possible outcomes. These sequences can be represented as decision
  trees. Decision theory allows us to find the optimal decision sequence
  for instance through the \emph{averaging out and folding back''
  procedure}.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  §15.5 and chapter~16 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}
\item
  Chapter~2 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Decision
  Analysis}}
\end{itemize}

\end{tcolorbox}

\hfill\break

\begin{itemize}
\item
  \textbf{Uncertain utilities}. It is possible to recast Decision Theory
  and the principle of maximum expected utility in terms, not of utility
  functions
  {\(\mathrm{U}(\mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})\),}
  but of probability distributions over utility values:

  \[\mathrm{P}({\color[RGB]{68,119,170}U\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}u} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})\]

  Formally the two approaches can be shown to be equivalent.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  Chapter~8 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Rational
  Descriptions, Decisions and Designs}}
\item
  Box\,11.1 (p.\,351) of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Risk
  Assessment and Decision Analysis with Bayesian Networks}}
\end{itemize}

\end{tcolorbox}

\hfill\break

\begin{itemize}
\tightlist
\item
  \textbf{Acquiring more information}. In many situations the agent has
  one more possible choice: to gather more information in order to
  calculate sharper probabilities, rather than deciding immediately.
  This kind of decision is also accounted for by Decision Theory, and
  constitutes one of the theoretical bases of ``reinforcement
  learning''.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  §15.6 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}
\item
  §11.5 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Risk
  Assessment and Decision Analysis with Bayesian Networks}}
\end{itemize}

\end{tcolorbox}

\hfill\break

\begin{itemize}
\tightlist
\item
  \textbf{Multi-agent problems}. To some extent it is possible to
  consider situations (such as games) with several agents having
  different and even opposing utilities. This area of Decision Theory is
  apparently still under development.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  Chapter~17 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence}}
\end{itemize}

\end{tcolorbox}

\chapter{\texorpdfstring{{The prototype Optimal Predictor Machine makes
decisions}}{The prototype Optimal Predictor Machine makes decisions}}\label{sec-example-opm2}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\yon}{{\green\cat{on}}}
\providecommand*{\yof}{{\red\cat{off}}}
\providecommand*{\yy}{{\lblue\cat{Y}}}
\providecommand*{\yn}{{\yellow\cat{N}}}
\providecommand{\ypl}{{\green\cat{+}}}
\providecommand{\ymi}{{\red\cat{-}}}
\providecommand{\ypa}{{\green\cat{pass}}}
\providecommand{\yfa}{{\red\cat{fail}}}

\providecommand{\hi}{{\green\cat{high}}}
\providecommand{\me}{{\yellow\cat{medium}}}
\providecommand{\lo}{{\red\cat{low}}}
\providecommand*{\yJ}{\se{J}}
\providecommand{\yva}{{\lblue-1}}
\providecommand{\yvb}{{\midgrey0}}
\providecommand{\yvc}{{\yellow1}}
\providecommand*{\yK}{\se{K}}
\providecommand*{\yL}{\se{L}}

\providecommand*{\yR}{R}

\providecommand*{\bZ}{{\blue Z}}
\providecommand*{\bz}{{\blue z}}
\providecommand*{\rY}{{\red Y}}
\providecommand*{\bY}{{\blue Y}}
\providecommand*{\ry}{{\red y}}
\providecommand*{\gX}{{\green X}}
\providecommand*{\bX}{{\blue X}}
\providecommand*{\gx}{{\green x}}
\providecommand*{\vf}{\vec{f}}

\providecommand*{\yut}{\se{K}_{\textsf{3}}}
\providecommand*{\yul}{\se{K}}

\providecommand*{\bA}{{\blue A}}
\providecommand*{\bB}{{\blue B}}
\providecommand*{\bC}{{\blue C}}

\providecommand*{\vfa}{\vf'}
\providecommand*{\vfb}{\vf''}

\providecommand*{\data}{\se{\green data}}
\providecommand*{\yD}{\se{I}_{\textrm{d}}}
\providecommand*{\ya}{k}
\providecommand*{\amin}{\ya_{\text{mi}}}
\providecommand*{\amax}{\ya_{\text{ma}}}

It is straightforward to implement decision-making in our prototype
Optimal Predictor Machine. Let's continue with the example from
chapter~~\ref{sec-example-opm1}.

\section{Initialization and build of OPM
agent}\label{initialization-and-build-of-opm-agent}

Load the necessary libraries and functions, including the
\texttt{decide()} function, and train the agent as we did previously:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{\textquotesingle{}extraDistr\textquotesingle{}}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{\textquotesingle{}foreach\textquotesingle{}}\NormalTok{)}

\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}tplotfunctions.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}guessmetadata.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}buildagent.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}infer.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}decide.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}mutualinfo.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}rF.R\textquotesingle{}}\NormalTok{)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}plotFsamples1D.R\textquotesingle{}}\NormalTok{)}

\FunctionTok{options}\NormalTok{(}\AttributeTok{repr.plot.width =} \DecValTok{6}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{2}\NormalTok{), }\AttributeTok{repr.plot.height =} \DecValTok{6}\NormalTok{)}

\NormalTok{opmall }\OtherTok{\textless{}{-}} \FunctionTok{buildagent}\NormalTok{(}\AttributeTok{metadata =} \StringTok{\textquotesingle{}meta\_income\_data\_example.csv\textquotesingle{}}\NormalTok{,}
                     \AttributeTok{data =} \StringTok{\textquotesingle{}train{-}income\_data\_example.csv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Decision matrix}\label{decision-matrix}

We use the targeted-advertisement scenario of
§~\ref{sec-max-exp-util-example}, with the following utility matrix for
the three ad-types:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{adutilities }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}
    \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{,}
        \DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{,}
        \DecValTok{3}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{nrow =} \DecValTok{3}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{dimnames =} \FunctionTok{list}\NormalTok{(}\AttributeTok{ad\_type =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{), }\AttributeTok{income =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}\textless{}=50K\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textgreater{}50K\textquotesingle{}}\NormalTok{)))}

\FunctionTok{print}\NormalTok{(adutilities)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       income
ad_type <=50K >50K
      A    -1    3
      B     2    2
      C     3   -1
\end{verbatim}

\section{Example application}\label{example-application}

First let's apply the principle of maximal expected utility
step-by-step.

Consider the example from §~\ref{sec-max-exp-util-example}. The agent
calculates the probabilities for the predictand \texttt{income} from the
given predictor values:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{userpredictors }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{workclass =} \StringTok{\textquotesingle{}Private\textquotesingle{}}\NormalTok{, }\AttributeTok{education =} \StringTok{\textquotesingle{}Bachelors\textquotesingle{}}\NormalTok{,}
                       \AttributeTok{marital\_status =} \StringTok{\textquotesingle{}Never{-}married\textquotesingle{}}\NormalTok{,}
                       \AttributeTok{occupation =} \StringTok{\textquotesingle{}Prof{-}specialty\textquotesingle{}}\NormalTok{,}
                       \AttributeTok{relationship =} \StringTok{\textquotesingle{}Not{-}in{-}family\textquotesingle{}}\NormalTok{, }\AttributeTok{race =} \StringTok{\textquotesingle{}White\textquotesingle{}}\NormalTok{,}
                       \AttributeTok{sex =} \StringTok{\textquotesingle{}Female\textquotesingle{}}\NormalTok{, }\AttributeTok{native\_country =} \StringTok{\textquotesingle{}United{-}States\textquotesingle{}}\NormalTok{)}

\NormalTok{probs }\OtherTok{\textless{}{-}} \FunctionTok{infer}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opmall, }\AttributeTok{predictand =} \StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{,}
               \AttributeTok{predictor =}\NormalTok{ userpredictors)}

\FunctionTok{print}\NormalTok{(probs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
income
   <=50K     >50K 
0.833333 0.166667 
\end{verbatim}

Find the expected utilities of the three possible ad-types by matrix
multiplication:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{adutilities }\SpecialCharTok{\%*\%}\NormalTok{ probs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       
ad_type     [,1]
      A -0.33333
      B  2.00000
      C  2.33333
\end{verbatim}

And we see that ad-type \texttt{C} is optimal.

\hfill\break

The
\href{https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/decide.R}{function
\texttt{decide()}} does the previous calculations. It outputs a list
with elements:

\begin{itemize}
\tightlist
\item
  \texttt{EUs}: the expected utilities of the decisions, sorted from
  highest to lowest
\item
  \texttt{optimal}: one decision unsystematically chosen among the
  optimal ones (if more than one)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{optimalad }\OtherTok{\textless{}{-}} \FunctionTok{decide}\NormalTok{(}\AttributeTok{utils =}\NormalTok{ adutilities, }\AttributeTok{probs =}\NormalTok{ probs)}

\FunctionTok{print}\NormalTok{(optimalad)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$EUs
       C        B        A 
 2.33333  2.00000 -0.33333 

$optimal
[1] "C"
\end{verbatim}

\section{Performance on test set}\label{performance-on-test-set}

Finally let's apply our prototype agent to a test set, as a
demonstration, and see how much utility it yields. This procedure will
be discussed in more detail in §~\ref{sec-eval-decision}.

Load the test dataset; \texttt{M} is the number of test data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{testdata }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}test{-}income\_data\_example.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{na.strings =} \StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{, }\AttributeTok{stringsAsFactors =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{tryLogical =} \ConstantTok{FALSE}\NormalTok{)}

\NormalTok{M }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(testdata)}
\end{Highlighting}
\end{Shaded}

We build the analogous of a ``confusion matrix''
(§~\ref{sec-eval-decision}), telling us how many times the agent chooses
the three ad-types for both income levels.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{confusionmatrix }\OtherTok{\textless{}{-}}\NormalTok{ adutilities }\SpecialCharTok{*} \DecValTok{0}\NormalTok{L}

\DocumentationTok{\#\# Use a for{-}loop for clarity}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{M)\{}
\NormalTok{    userpredictors }\OtherTok{\textless{}{-}}\NormalTok{ testdata[i, }\FunctionTok{colnames}\NormalTok{(testdata) }\SpecialCharTok{!=} \StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{]}
\NormalTok{    probs }\OtherTok{\textless{}{-}} \FunctionTok{infer}\NormalTok{(}\AttributeTok{agent =}\NormalTok{ opmall, }\AttributeTok{predictand =} \StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{,}
                   \AttributeTok{predictor =}\NormalTok{ userpredictors)}
\NormalTok{    decision }\OtherTok{\textless{}{-}} \FunctionTok{decide}\NormalTok{(}\AttributeTok{utils =}\NormalTok{ adutilities, }\AttributeTok{probs =}\NormalTok{ probs)}\SpecialCharTok{$}\NormalTok{optimal}
\NormalTok{    trueincome }\OtherTok{\textless{}{-}}\NormalTok{ testdata[i, }\StringTok{\textquotesingle{}income\textquotesingle{}}\NormalTok{]}

\NormalTok{    confusionmatrix[decision, trueincome] }\OtherTok{\textless{}{-}}\NormalTok{ confusionmatrix[decision, trueincome] }\SpecialCharTok{+} \DecValTok{1}\NormalTok{L}
\NormalTok{\}}

\FunctionTok{print}\NormalTok{(confusionmatrix)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       income
ad_type <=50K >50K
      A   769 2149
      B 11768 5093
      C 12961 1174
\end{verbatim}

The total utility yield is the total sum of the element-wise product of
the \texttt{confusionmatrix} and the \texttt{adutilities} matrix

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{totalyield }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(adutilities }\SpecialCharTok{*}\NormalTok{ confusionmatrix)}
\NormalTok{averageyield }\OtherTok{\textless{}{-}}\NormalTok{ totalyield}\SpecialCharTok{/}\NormalTok{M}

\FunctionTok{cat}\NormalTok{(}\StringTok{\textquotesingle{}}\SpecialCharTok{\textbackslash{}n}\StringTok{Total yield =\textquotesingle{}}\NormalTok{, totalyield, }
\StringTok{\textquotesingle{}}\SpecialCharTok{\textbackslash{}n}\StringTok{Average yield =\textquotesingle{}}\NormalTok{, averageyield, }\StringTok{\textquotesingle{}}\SpecialCharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Total yield = 77109 
Average yield = 2.27366 
\end{verbatim}

Note that:

\begin{itemize}
\item
  This yield is higher than what would be obtained by just choosing the
  neutral ad-type \texttt{B} for all test units (the average yield would
  be exactly \texttt{2}).
\item
  This yield is also higher than would be obtained by always choosing
  ad-type \texttt{C}, targeting the majority of units, which have
  \texttt{income\ =\ \textquotesingle{}\textless{}=50K\textquotesingle{}}.
  This strategy would yield \texttt{2.00737}.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercises}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Try to use some common machine-learning algorithm to perform the same
  task of choosing between the three ad-types. Is it difficult? why?

  If you manage to do this, then compare the performances of the
  machine-learning algorithm and the \texttt{opmall} agent.
\item
  Construct a scenario where the utility matrix is different depending
  on the \texttt{sex} predictor variate. Write a script to apply the
  \texttt{opmall} agent on the test set according to this new scenario.
\end{itemize}

\end{tcolorbox}

\part{{\textbf{Further connections with present-day machine-learning}}}

\chapter{\texorpdfstring{{Decisions: limitations of present-day
machine-learning
algorithms}}{Decisions: limitations of present-day machine-learning algorithms}}\label{sec-ML-utility-limitation}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\data}{\se{\green data}}
\providecommand*{\predictor}{\se{\green predictor}}
\providecommand*{\yD}{\se{\yellow D}}
\providecommand*{\yA}{{\yellow A}}
\providecommand*{\yB}{{\yellow B}}
\providecommand*{\yC}{{\yellow C}}
\providecommand*{\dise}{\mathit{\red disease}}
\providecommand*{\yy}{{\red\cat{yes}}}
\providecommand*{\yn}{{\red\cat{no}}}
\providecommand*{\yr}{\,\mathrm{yr}}

\providecommand*{\income}{\mathit{\red income}}
\providecommand*{\yl}{{\red\cat{<=50K}}}
\providecommand*{\yh}{{\red\cat{>50K}}}

\providecommand*{\uu}{\mathrm{U}}
\providecommand*{\uf}{\mathrm{u}}
\providecommand*{\um}{\boldsymbol{\blue U}}
\providecommand*{\Pm}{\boldsymbol{\green P}}

\providecommand*{\pbest}{p^{+}}

\providecommand*{\pworst}{p^{-}}

\providecommand*{\ry}{{\red y}}
\providecommand*{\ryo}{{\red y^{*}}}
\providecommand*{\bu}{{\blue u}}

\providecommand*{\sA}{\se{\yellow A}}
\providecommand*{\sB}{\se{\yellow B}}

\providecommand*{\mA}{\mathcal{A}}
\providecommand*{\mB}{\mathcal{B}}

\providecommand*{\yca}{{\red\alpha}}
\providecommand*{\ycb}{{\red\beta}}
\providecommand*{\cm}{\boldsymbol{\red C}}



\section{The omnipresence of decision-making in data science and machine
learning}\label{sec-decision-everywhere}

Many machine-learning textbooks say that

\begin{quote}
in supervised learning the algorithm learns a functional relationship
between some kind of input and some kind of output
\end{quote}

Such statement is misleading, because it suggests that there is a
functional relationship from input to output, or from predictor to
predictand -- a functional relationship that's only waiting to be
discovered and ``learned''. But as we discussed in
chapter~~\ref{sec-ml-introduction}, in many important tasks and
applications this is actually not true: \textbf{there isn't any
functional relationship between input and output at all}.\footnote{This
  is one more reason why we use the more general terms ``predictor'' \&
  ``predictand'', rather that ``input'' \& ``output''.} Even if any
possible ``noise'' were removed, there would still \emph{not} be any
functional relationship between the denoised predictor and predictand
(\href{steven-seagal-emotion-chart.jpg}{here is an example from image
classification}).

In many important tasks there's only a \emph{statistical} relationship
between predictands and predictors. ``Statistical'' means that whenever
a predictor has value
{\(\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x\),}
the predictand value may turn out to be
{\(\color[RGB]{34,136,51}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y'\)}
in some units, but also
{\(\color[RGB]{34,136,51}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y''\)}
in some other units, and so on. As a simple example, consider the
\href{https://www.ssb.no/befolkning/folketall/statistikk/befolkning/artikler/slik-ser-befolkningen-i-norge-ut}{Norwegian
population in 2022}. If our predictand is {\(\mathit{sex}\)} and we take
as predictor that a person's {\(\mathit{age}\)} is between
{\(85\)--}{\(89\)} years, then a proportion
{\(43 542/(43 542 + 28 220) \approx 61\%\)} of those persons have
{\(\mathit{sex}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;female;}\),}
and the remaining {\(39\%\)} proportion has
{\(\mathit{sex}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\small\verb;male;}\).}
This doesn't mean that, say, {\({\small\verb;female;}\)} is the ``true''
output, and {\({\small\verb;male;}\)} is just the effect of noise, or
vice versa. That would be nonsense.

Even in tasks where there actually is a functional relation from
predictors to predictands, the agent typically doesn't know what is the
function's output for particular predictor values, because no such
values have been observed in the training data. It must interpolate or
extrapolate what it has learned. Also in this case there are several
possibilities to choose from.

A decision-making step also appears in tasks where the agent must
\emph{generate} a new unit. Obviously there are many candidates for
generation, which agree with what was observed in the training data. If
the agent generates \emph{one} unit, then it must internally have chosen
among the possible candidates.

\section{Where are the probabilities and the utilities? How are they
calculated?}\label{sec-where-prob-util}

The remarks above have a very important consequence. If a
machine-learning algorithm outputs just \emph{one} predictand value (or
generates one unit), among the possible ones that are consistent with
the predictor, then it means that \textbf{the algorithm is internally
choosing one of the possibilities}.

Such a choice is obviously a decision-making problem. We know that the
optimal, logically consistent choice must be determined by Decision
Theory, and its determination requires:

\begin{itemize}
\item
  {\faIcon{circle-info}~~Some kind of background knowledge}
\item
  {\faIcon{scale-unbalanced-flip}~~the probabilities of the possible
  predictand values}
\item
  {\faIcon{arrows-split-up-and-left}~~a list of possible decisions}
\item
  {\faIcon{sack-dollar}~~the utilities of the decisions, depending on
  the predictand's true value}
\end{itemize}

The algorithm internally must -- at least approximately -- be
calculating probabilities and maximizing expected utilities. In
principle its internal workings should be susceptible to an explanation
or interpretation from this point of view.

For some, or maybe many, machine-learning algorithms such an
interpretation is not readily available, and is or can be a very
interesting area of research, leading to improvements or to completely
new algorithms.

Available interpretations of machine-learning algorithms are mostly from
the point of view of Probability Theory; unfortunately very little from
the point of view of Decision Theory. For this reason we now discuss
some limitations of present-day algorithms from the decision-theoretic
viewpoint.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

The book
\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Machine
Learning}} and Part~V of the book
\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Information
Theory, Inference, and Learning Algorithms}} discuss interpretations of
several machine-learning algorithms from the point of view of
Probability Theory, and in few cases also of Decision Theory.

\end{tcolorbox}

\section{Limitations of machine-learning classifiers (and
estimators)}\label{sec-limit-class}

\subsection{Unknowns vs decisions}\label{unknowns-vs-decisions}

Decision Theory makes a distinction between what is \emph{unknown} to an
agent (``outcomes''), and what the agent has to \emph{choose}
(``decisions''). This distinction is common in everyday problems. We may
wonder whether it will rain in the next hour. The point of our wonder,
however, is not (except in some situations) the rain phenomenon per se,
but its implications about what clothes or shoes we should wear, or
about staying indoors or going out, or about going on foot or by car,
and so on.

An important reason for this distinction is that the set of possible
decisions often does \textbf{not} have a correspondence with the set of
unknown possibilities. In fact, the two sets often have different
numbers of elements. You can think of many situations in which you are
unsure whether some event will happen or not, and you have \emph{three}
plans: one if you are almost sure the event will happen, one if you are
almost sure the event will not happen, and a third ``safe'' plan if you
are about 50\%/50\% uncertain. The ``safe'' plan typically has
consequences that are neither too bad or too good, so that losses and
gains are kept to a minimum. This example also shows why the
probabilities of the outcomes are important.

\hfill\break

Many present-day machine-learning algorithms are quite limited in this
respect:

\begin{itemize}
\tightlist
\item
  their output is typically one of the unknown values, not one of the
  decisions
\item
  they don't give the probabilities of the unknown values
\end{itemize}

This limitation may not be important in some tasks, for instance when
you are classifying some images as ``cat'' or ``dog'' for the purpose of
a photo album. But it is extremely important and impairing in serious
applications, such as clinical ones. Let's illustrate this with a simple
example.

\subsection{A typical decision-making problem in
medicine}\label{a-typical-decision-making-problem-in-medicine}

A clinician may be uncertain about the presence or absence of some
medical condition, let's say a disease. This uncertainty cannot be fully
removed. The clinician's task is \textbf{not simply to guess about the
disease, but to choose among different available treatments}. Imagine
you may have broken a bone, and the clinician simply tells you: ``I
guess it's broken, though I'm not fully sure. Goodbye!''.

Two crucial points about treatment choice are these:

\begin{itemize}
\tightlist
\item
  there may be \emph{more than two} possible treatments, even if the
  uncertainty is binary (disease present vs absent)
\item
  which treatment is optimal depends on the \emph{probability} that the
  disease is present, not on a simple ``yes/no guess''
\end{itemize}

Neglecting both points can lead to disastrous consequences.

For example, suppose the clinician has three treatments available:
{\(\mathsfit{A}\),} {\(\mathsfit{B}\),}
{\({\color[RGB]{204,187,68}C}\).} They have different efficacies against
the disease, if it is present; and different damaging side-effects for
the patient, if the disease is not present. Suppose that efficacy and
damage can be measured together as decrease in life expectancy for the
patient. The effects are as follows:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2444}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2444}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2444}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2444}}@{}}
\caption{Change in life expectancy depending on treatment and medical
condition}\label{tbl-treatments}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
& &
\multicolumn{2}{>{\raggedleft\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4889} + 2\tabcolsep}@{}}{%
\(\mathit{\color[RGB]{238,102,119}disease}\)} \\
& & \({\color[RGB]{34,136,51}{\small\verb;Y;}}\) &
\({\color[RGB]{238,102,119}{\small\verb;N;}}\) \\
\multirow{3}{=}{{treatment}} & \(\mathsfit{A}\) &
\(\color[RGB]{204,187,68}-4\,\mathrm{yr}\) &
\(\color[RGB]{204,187,68}0\,\mathrm{yr}\) \\
& \(\mathsfit{B}\) & \(\color[RGB]{204,187,68}-1\,\mathrm{yr}\) &
\(\color[RGB]{204,187,68}-1\,\mathrm{yr}\) \\
& \({\color[RGB]{204,187,68}C}\) &
\(\color[RGB]{204,187,68}0\,\mathrm{yr}\) &
\(\color[RGB]{204,187,68}-4\,\mathrm{yr}\) \\
\end{longtable}

\begin{itemize}
\item
  treatment {\(\mathsfit{A}\)} is mild (it could actually be a
  no-treatment option): under it, the patient is expected to live four
  years shorter if the disease is present, but the life expectancy is
  unaltered if the disease is not present
\item
  treatment {\(\mathsfit{B}\)} is intermediate: under it, the patient is
  expected to live only one year shorter if the disease is present, but
  also if the disease is not present, owing to the damage caused by this
  treatment
\item
  treatment {\({\color[RGB]{204,187,68}C}\)} is intensive: under it, the
  patient is expected not to lose extra years if the disease is present,
  but will lose four years if the disease is not present, owing to the
  heavy damage caused by this treatment.
\end{itemize}

Which of the treatments above should the clinician choose? We now know
how the clinician should make the optimal decision, but let's explore
the possible consequences of not making it, in three different
scenarios. In each scenario, the clinician has prescribed several
clinical tests (the predictors) for the patient, and obtained their
results.

\subsubsection{Scenario 1: 10\%/90\%}\label{scenario-1-1090}

Given the results of the clinical tests, the clinician knows that the
patient is typical of a subpopulation of patients where {10\%} have the
disease, and {90\%} don't. The present patient could be one among the
10\%, or one of among the 90\%.

\begin{itemize}
\item
  If the clinician always chooses treatment {\(\mathsfit{A}\)} for this
  subpopulation, including the present patient, then these patients'
  lives will be shortened in total by

  \[
  {\color[RGB]{204,187,68}-4\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}10} +
  {\color[RGB]{204,187,68}0\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}90}
  = \boldsymbol{-40\,\mathrm{yr}}
  \]
\item
  If the clinician always chooses treatment {\(\mathsfit{B}\)} for this
  subpopulation, including the present patient, then these patients'
  lives will be shortened in total by

  \[
  {\color[RGB]{204,187,68}-1\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}10} +
  {\color[RGB]{204,187,68}-1\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}90}
  = \boldsymbol{-100\,\mathrm{yr}}
  \]
\item
  If the clinician always chooses treatment
  {\({\color[RGB]{204,187,68}C}\),} then the lives will be shortened in
  total by

  \[
  {\color[RGB]{204,187,68}0\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}10} +
  {\color[RGB]{204,187,68}-4\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}90}
  = \boldsymbol{-360\,\mathrm{yr}}
  \]
\end{itemize}

Clearly the best decision is treatment {\(\mathsfit{A}\).} It is
possible that, unfortunately, the present patient's life will be
shortened; but this treatment was the patient's and clinician's best
bet.

In this scenario, a clinician that doesn't choose the optimal treatment
is on average taking away from each patient between 7 months and 3 years
of life more than was necessary or unavoidable.

\subsubsection{Scenario 2: 50\%/50\%}\label{scenario-2-5050}

Given the results of the clinical tests, the clinician knows that the
patient is typical of a subpopulation of patients where {50\%} have the
disease, and {50\%} don't. In this case the present patient could be one
of the first 50\%, or one of the other 50\%.

Calculations similar to those of scenario~1 leads to these results:

\begin{itemize}
\item
  Treatment {\(\mathsfit{A}\)}

  \[
  {\color[RGB]{204,187,68}-4\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}50} +
  {\color[RGB]{204,187,68}0\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}50}
  = \boldsymbol{-200\,\mathrm{yr}}
  \]
\item
  Treatment {\(\mathsfit{B}\):}

  \[
  {\color[RGB]{204,187,68}-1\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}50} +
  {\color[RGB]{204,187,68}-1\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}50}
  = \boldsymbol{-100\,\mathrm{yr}}
  \]
\item
  Treatment {\({\color[RGB]{204,187,68}C}\):}

  \[
  {\color[RGB]{204,187,68}0\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}50} +
  {\color[RGB]{204,187,68}-4\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}50}
  = \boldsymbol{-200\,\mathrm{yr}}
  \]
\end{itemize}

The best decision is treatment {\(\mathsfit{B}\).}

In this scenario, a clinician who chooses treatments {\(\mathsfit{A}\)}
or {\({\color[RGB]{204,187,68}C}\)} for patients having the same
predictors as the present patient is on average taking away one extra
year of life from each patient.

\subsubsection{Scenario 3: 90\%/10\%}\label{scenario-3-9010}

In this scenario {90\%} of patients in the subpopulation with the
observed predictors have the disease, and {10\%} don't. The present
patient could belong to either group.

\begin{itemize}
\item
  Treatment {\(\mathsfit{A}\)}

  \[
  {\color[RGB]{204,187,68}-4\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}90} +
  {\color[RGB]{204,187,68}0\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}10}
  = \boldsymbol{-360\,\mathrm{yr}}
  \]
\item
  Treatment {\(\mathsfit{B}\):}

  \[
  {\color[RGB]{204,187,68}-1\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}90} +
  {\color[RGB]{204,187,68}-1\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}10}
  = \boldsymbol{-100\,\mathrm{yr}}
  \]
\item
  Treatment {\({\color[RGB]{204,187,68}C}\):}

  \[
  {\color[RGB]{204,187,68}0\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}90} +
  {\color[RGB]{204,187,68}-4\,\mathrm{yr}}\cdot{\color[RGB]{34,136,51}10}
  = \boldsymbol{-40\,\mathrm{yr}}
  \]
\end{itemize}

Treatment {\({\color[RGB]{204,187,68}C}\)} is the best decision in this
scenario, for reasons complementary to those of scenario~1.

In this scenario, like in the first, a clinician that doesn't choose the
optimal treatment is on average taking away, from each patient, between
7 months and 3 years of life more than was necessary or unavoidable.

\hfill\break

In each scenario, note that \emph{any} decision strategy different from
``sticking to the optimal decision'' leads to suboptimal results -- that
is, lives shortened more than what was unavoidable. In scenario~1, for
instance, a decision strategy such as ``{choose treatment
\(\mathsfit{A}\) most of the time, and treatment \(\mathsfit{B}\) from
time to time}'' leads to an additional life shortening of several
months. This is clear from the following graph, which shows the average
reduction in life expectancy for each treatment, depending on the
percentage of patients with the disease:

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{utilities_treatments.png}

Consider the vertical line corresponding to probability 0.1. Any
strategy that mixes treatment {\(\mathsfit{A}\)} with any of the other
two will only reduce the life expectancy. This is true for any other
probability values and their corresponding optimal treatments.

From the plot we can see that treatment {\(\mathsfit{A}\)} is optimal if
the probability that the disease is present is below {\(25\%\),}
treatment {\({\color[RGB]{204,187,68}C}\)} is optimal if the probability
is above {\(75\%\),} and treatment {\(\mathsfit{B}\)} for intermediate
probabilities.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

{Although the intuitive reasoning above has somewhat been phrased in
terms of frequency, it's the \emph{probability} -- the clinician's
degree of belief -- that counts.} Try to reason about this point through
the following exercise:

Consider a clinician uncertain with 50\% probability that the present
patient belongs to a 10\%/90\% frequency subpopulation, and with 50\%
that the patient belongs to a 90\%/10\% frequency subpopulation. And
unfortunately this uncertainty cannot be removed by further clinical
tests. Which treatment should this clinician choose? why?

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Chapter~1 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Medical
  Decision Making}}
\item
  Skim through chapter~6 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Medical
  Decision Making}}
\item
  §§~1.5--1.6 of
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Making
  Decisions}}
\end{itemize}

\end{tcolorbox}

\subsection{Sub-optimality of a typical machine-learning
algorithm}\label{sub-optimality-of-a-typical-machine-learning-algorithm}

The clinical example above shows that there isn't any one-to-one
connection between decisions and unknowns. We cannot say, for instance,
that treatment {\({\color[RGB]{204,187,68}C}\)} ``corresponds'' to the
presence of the disease, because the best treatment is actually
{\(\mathsfit{B}\),} not {\({\color[RGB]{204,187,68}C}\),} if the
probability for
{\(\mathit{\color[RGB]{238,102,119}disease}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\)}
is above 50\% but below 75\%.

Now imagine that the clinician inputs the patient's predictors into a
neural network, trained to give an output about the presence or absence
of the disease. The neural network outputs \texttt{yes}, but it's known
that the neural network can err. Which treatment should the clinician
choose?

\begin{itemize}
\item
  Does the output \texttt{yes} mean that the probability for
  {\(\mathit{\color[RGB]{238,102,119}disease}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{34,136,51}{\small\verb;Y;}}\)}
  was above 50\%? Then the clinician doesn't know whether it's above or
  below 75\%, and can't make the optimal choice between
  {\({\color[RGB]{204,187,68}C}\)} and {\(\mathsfit{B}\).} At best the
  clinician can unsystematically alternate between these two treatments,
  but as we saw above this mixture is sub-optimal.
\item
  Is the output \texttt{yes} produced with a particular probability? But
  what is this probability? The output could be
  {\({\color[RGB]{34,136,51}{\small\verb;Y;}}\)} even if the probability
  were less than 50\% or 25\%. Then neither in this case can the
  clinician make the optimal choice between all three treatments. And a
  mixture of all three is again sub-optimal.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-caution-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{user-edit} Exercise}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Could the clinician deduce an approximate probability by looking at the
statistics (confusion matrix) of the neural network on some test set?

Explore and maybe even implement this possibility.

\end{tcolorbox}

\subsection{\texorpdfstring{Output scores or weights are \emph{not}
probabilities!}{Output scores or weights are not probabilities!}}\label{output-scores-or-weights-are-not-probabilities}

Some machine-learning algorithms are capable of giving continuous
``scores'' or ``weights'' between 0 and 1, instead of a simple answer
such as ``yes'' or ``no''. But unfortunately, typically \textbf{such
scores are not probabilities or frequencies}, even if there may be some
association between them and the probability or frequency.

A real-life example of this mismatch is evident in the plot below (see
``for the extra curious'' below for references). It shows the 0--1
output score given by a random forest in a binary-classification task on
a test set, versus the actual frequency of the corresponding class:

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{mismatch_freq_weight.png}

Clearly the output score is different from the frequency; if they were
the same the graphs would be straight lines with ±45° inclination.

Imagine what would happen if the clinician from our example above
\emph{mistook} the output score for a probability:

\begin{itemize}
\item
  {\faIcon{face-grin-beam-sweat}}~~Output score in the {range
  \(0\)--\(0.25\)}: the clinician would choose treatment
  {\(\mathsfit{A}\).} Luckily the upper boundary of this score range
  approximately corresponds to a frequency of {\(25\%\),} so in this
  case the clinician would be choosing the optimal treatment.
\item
  {\faIcon{face-grin-beam-sweat}}~~Output score in the {range
  \(0.25\)--\(0.5\)}: the clinician would choose treatment
  {\(\mathsfit{B}\).} Luckily the upper boundary of this score range
  approximately corresponds to a frequency of {\(75\%\)} (note the
  mismatch), so in this case the clinician would be choosing the optimal
  treatment.
\item
  {\faIcon{frown}}~~Output score in the {range \(0.5\)--\(0.75\)}: the
  clinician would choose treatment {\(\mathsfit{B}\).} But the
  corresponding frequency is approximately between
  {\(75\%\)--}{\(90\%\),} so the optimal treatment is actually
  {\({\color[RGB]{204,187,68}C}\).} As calculated in Scenario~3 above,
  the clinician would be then be shortening the patient's life by 7
  months more than was unavoidable.
\item
  {\faIcon{face-grin-beam-sweat}}~~Output score in the {range
  \(0.75\)--\(1\)}: the clinician would choose treatment
  {\({\color[RGB]{204,187,68}C}\).} Luckily this corresponds to an
  approximate frequency range {\(90\%\)--}{\(92\%\),} where treatment
  {\({\color[RGB]{204,187,68}C}\)} is indeed optimal.
\end{itemize}

Note that we cannot say ``the suboptimal treatment is chosen one out of
four times'', because in this example we don't know how many patients
end up having a score in the {\(0.5\)--\(0.75\)} range. In a concrete
case it could be that 90\% of the patients end up in this range, which
would mean that the misuse of the output score would lead to a
suboptimal treatment in 90\% of cases.

\hfill\break

Another real example of the difference between weights or scores and
probabilities is shown in the plot below, obtained by applying a neural
network to the same binary-classification task on a test set. The
\emph{x}-axis shows the internal output-layer weight that the neural
network assign to one class (more precisely, the diagonal where the two
output-layer weights have equal values). The \emph{y}-axis shows the
frequency of that class. Typically a
\href{https://mathworld.wolfram.com/SigmoidFunction.html}{``softmax'' or
sigmoid function} is applied to the output-layer weights, in order to
obtain positive, normalized scores that are often miscalled
``probabilities''. The softmax in the present case is shown as the
{dashed grey line}.

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{mismatch_freq_weight_NN.png}

We can observe an even worse mismatch that for the random forest. For
instance, if the softmax is between {\(0\)--}{\(0.25\),} then the
output-layer weight must have been less than approximately {\(-0.5\),}
which in turn means that the actual frequency could be anywhere between
{\(0\%\)} and {\(50\%\).} For a softmax between {\(0.75\)--}{\(1\),} the
actual frequency could be anywhere between {\(50\%\)} and {\(92\%\).}

In both plots above, notice how the probability for each class can never
be higher than around {\(92\%\),} yet the weights or scores go up to
{\(1\).}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Don't use misleading terminology}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

Please don't call the score or weight output of a machine-learning
algorithm a ``probability'' or ``frequency'', unless you've first made
sure that it actually is a probability or frequency. Just because some
numbers are positive and sum up to one doesn't mean that they are a
probability or frequency distribution.

Using this kind of mistaken terminology shows downright scientific
incompetence, and its consequences, as you can see from the medical
examples above, are borderline scientific malpractice.

\end{tcolorbox}

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-tip-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{rocket} For the extra curious}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://doi.org/10.31219/osf.io/vct9y}{\emph{Don't guess what's
true: choose what's optimal. A probability transducer for
machine-learning classifiers}}

\end{tcolorbox}

\chapter{\texorpdfstring{{Evaluation practices and
utilities}}{Evaluation practices and utilities}}\label{sec-eval-decision}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\data}{\se{\green data}}
\providecommand*{\predictor}{\se{\green predictor}}
\providecommand*{\yD}{\se{\yellow D}}
\providecommand*{\yA}{{\yellow A}}
\providecommand*{\yB}{{\yellow B}}
\providecommand*{\yC}{{\yellow C}}
\providecommand*{\dise}{\mathit{\red disease}}
\providecommand*{\yy}{{\red\cat{yes}}}
\providecommand*{\yn}{{\red\cat{no}}}
\providecommand*{\yr}{\,\mathrm{yr}}

\providecommand*{\income}{\mathit{\red income}}
\providecommand*{\yl}{{\red\cat{<=50K}}}
\providecommand*{\yh}{{\red\cat{>50K}}}

\providecommand*{\uu}{\mathrm{U}}
\providecommand*{\uf}{\mathrm{u}}
\providecommand*{\um}{\boldsymbol{\blue U}}
\providecommand*{\Pm}{\boldsymbol{\green P}}

\providecommand*{\pbest}{p^{+}}

\providecommand*{\pworst}{p^{-}}

\providecommand*{\ry}{{\red y}}
\providecommand*{\ryo}{{\red y^{*}}}
\providecommand*{\bu}{{\blue u}}

\providecommand*{\sA}{\se{\yellow A}}
\providecommand*{\sB}{\se{\yellow B}}

\providecommand*{\mA}{\mathcal{A}}
\providecommand*{\mB}{\mathcal{B}}

\providecommand*{\yca}{{\red\alpha}}
\providecommand*{\ycb}{{\red\beta}}
\providecommand*{\cm}{\boldsymbol{\red C}}



\section{Confusion matrices and evaluation metrics}\label{sec-confusion}

Machine-learning methodology uses a disconcerting variety of evaluation
metrics to try to quantify, compare, rank the performances of one or
more algorithms.

For machine-learning classifiers many of these metrics are constructed
from the so-called ``confusion matrix''. The basic idea behind it is to
test the algorithms of interest on a test dataset (the same for all),
and then count for how many units the algorithm outputs value
{\(\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{238,102,119}y^{*}}\)}
when the true value of the unknown is
{\(\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y\),}
for all combinations of possible {\({\color[RGB]{238,102,119}y^{*}}\)}
and {\({\color[RGB]{238,102,119}y}\).}

Imagine for instance a binary-classification task with classes
{\({\color[RGB]{238,102,119}\alpha}\)} and
{\({\color[RGB]{238,102,119}\beta}\).} It could be the
electronic-component scenario we met in the first chapters, with class
{\({\color[RGB]{238,102,119}\alpha}\)} being ``{the electronic component
will function for at least a year}'', and class
{\({\color[RGB]{238,102,119}\beta}\)} ``{the electronic component will
fail within a year of use}''.

Application of two algorithms {\(\mathcal{A}\)} and {\(\mathcal{B}\)} to
the same 100 test units results in the following confusion matrices:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3056}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3056}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3056}}@{}}
\caption{Confusion matrix for
\(\mathcal{A}\)}\label{tbl-confusion}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
& true \({\color[RGB]{238,102,119}\alpha}\) & true
\({\color[RGB]{238,102,119}\beta}\) \\
output \({\color[RGB]{238,102,119}\alpha}\) & 27 & 15 \\
output \({\color[RGB]{238,102,119}\beta}\) & 23 & 35 \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3056}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3056}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3056}}@{}}
\caption{Confusion matrix for
\(\mathcal{B}\)}\label{tbl-confusion}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
& true \({\color[RGB]{238,102,119}\alpha}\) & true
\({\color[RGB]{238,102,119}\beta}\) \\
output \({\color[RGB]{238,102,119}\alpha}\) & 43 & 18 \\
output \({\color[RGB]{238,102,119}\beta}\) & 7 & 32 \\
\end{longtable}

These matrices can also be normalized, dividing every entry by the total
number of test units. Various aspects can be read from the confusion
matrices above. Algorithm {\(\mathcal{B}\),} for example, seems better
than {\(\mathcal{A}\)} at inferring class
{\({\color[RGB]{238,102,119}\alpha}\),} but slightly worse at inferring
class {\({\color[RGB]{238,102,119}\beta}\).}

Most evaluation metrics for classification combine the entries of a
confusion matrix in a mathematical formula that yields a single number.

Such metrics and formulae can be quite opaque. Their definitions and
their motivations are often arbitrary or very case-specific. It's common
to find works where several metrics are used because it's unclear which
single one should be used. And the only hope is that most or all of them
will agree at least on the rankings they lead to. However,\ldots{}

\subsection{Majority votes are not a criterion for
correctness}\label{majority-votes-are-not-a-criterion-for-correctness}

Here are the scores that some popular metrics assign to algorithms
{\(\mathcal{A}\)} and {\(\mathcal{B}\),} based on their confusion
matrices above. The better algorithm according to each metric is
indicated in {\textbf{green bold}}. Almost all these evaluation metrics
seem to agree that {\(\mathcal{B}\)} should be the best of the two:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4512}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2683}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2683}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\emph{metric} & \(\mathcal{A}\) & \(\mathcal{B}\) \\
Accuracy & 0.62 & {\textbf{0.75}} \\
Precision & 0.64 & {\textbf{0.70}} \\
Balanced Accuracy & 0.62 & {\textbf{0.75}} \\
\(F_1\) measure & 0.59 & {\textbf{0.77}} \\
Matthews Correlation Coefficient & 0.24 & {\textbf{0.51}} \\
Fowlkes-Mallows index & 0.59 & {\textbf{0.78}} \\
True-positive rate (recall) & 0.54 & {\textbf{0.86}} \\
True-negative rate (specificity) & {\textbf{0.70}} & 0.64 \\
\end{longtable}

Yet, when put to actual use, it turns out that {\(\mathcal{B}\)}
actually leads to a monetary \emph{loss} of 3.5\,\$ per unit, whereas
{\(\mathcal{A}\)} leads to a monetary \emph{gain} of 3.5\,\$ per unit!

\section{Decision theory and utilities as the basis for
evaluation}\label{sec-dt-util-evaluation}

How is the surprising result above possible? Decision Theory tells us
how, and can even correctly select the best algorithm from the confusion
matrices above.

As discussed in the preceding sections, each application to a new unit
is a decision-making problem. Neither making nor evaluating a decision
is possible unless we specify the utilities relevant to the problem. It
turns out that the consequences in the present problem have the
following monetary utilities:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3056}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3056}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3056}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
& \({\color[RGB]{238,102,119}\alpha}\) is true &
\({\color[RGB]{238,102,119}\beta}\) is true \\
\({\color[RGB]{238,102,119}\alpha}\) is chosen &
\(\color[RGB]{68,119,170}15 \$\) & \(\color[RGB]{68,119,170}-335 \$\) \\
\({\color[RGB]{238,102,119}\beta}\) is chosen &
\(\color[RGB]{68,119,170}-35 \$\) & \(\color[RGB]{68,119,170}165 \$\) \\
\end{longtable}

These utility values may be determined by the combination of sale
revenue, disposal costs, warranty refunds, and similar factors.

The utility matrix above says that for every test unit of true class
{\({\color[RGB]{238,102,119}\alpha}\)} (the unit will function for at
least a year) that the algorithm classifies as
{\({\color[RGB]{238,102,119}\alpha}\)} (and therefore sends for sale),
the production company gains {\(\color[RGB]{68,119,170}15 \$\);} for
every test unit of class {\({\color[RGB]{238,102,119}\alpha}\)} that the
algorithm classifies as {\({\color[RGB]{238,102,119}\beta}\)} (and
therefore discards), the production company gains
{\(\color[RGB]{68,119,170}-35 \$\)} (so actually a loss); and so on. The
total yield from each algorithm on the 100 test units can therefore be
calculated by multiplying the four utilities above by the corresponding
counts in the confusion matrix, and then taking the total. The average
yield per unit is obtained dividing the total by the number of units, or
directly using the normalized confusion matrix:

\begin{figure*}

\[
\begin{aligned}
\text{$\mathcal{A}$'s average yield } &= 
\bigl[27 \cdot {\color[RGB]{68,119,170}15 \$} +
23 \cdot ({\color[RGB]{68,119,170}-35 \$}) +
15 \cdot ({\color[RGB]{68,119,170}-335 \$}) +
35 \cdot {\color[RGB]{68,119,170}165 \$}\bigr]/100
\\[1ex]
&= \boldsymbol{\color[RGB]{34,136,51}+3.5 \$}
\\[3ex]
\text{$\mathcal{B}$'s average yield } &= 
\bigl[43 \cdot {\color[RGB]{68,119,170}15 \$} +
7 \cdot ({\color[RGB]{68,119,170}-35 \$}) +
18 \cdot ({\color[RGB]{68,119,170}-335 \$}) +
32 \cdot {\color[RGB]{68,119,170}165 \$}\bigr]/100
\\[1ex]
&= {\color[RGB]{170,51,119}-3.5 \$}
\end{aligned}
\]

\end{figure*}%

This calculation tells us that {\(\mathcal{A}\)} is better, and also
gives us an idea of the actual utilities that the two algorithms would
yield.

\subsection{Utilities as evaluation
metric}\label{utilities-as-evaluation-metric}

The calculation above is exactly the one discussed in
§~\ref{sec-utilities-metric}, where we logically motivated the use of
utilities as an evaluation metric. In the case of common
machine-learning classifiers the logically correct evaluation metric and
procedure are is thus straightforward:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  find the utilities relevant to the specific problem under
  consideration, collect them into a utility matrix
  \(\boldsymbol{\color[RGB]{68,119,170}U}\)
\item
  apply the classifier to a test set and build the confusion matrix
  \(\boldsymbol{\color[RGB]{238,102,119}C}\)
\item
  multiply confusion and utility matrices element-wise and take the
  total
\end{enumerate}

What's remarkable in this procedure is that it is not only logically
well-founded, but also mathematically simple. The formula for the
correct evaluation metric is just a linear combination of the
confusion-matrix entries. This linearity is actually a subtle
consequence of the axiom of independence discussed in
§~\ref{sec-indep-axiom}.

Note something very important:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-important-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{exclamation-triangle} Don't do class balancing!}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

This procedure requires that the test set be a representative,
unsystematic sample of the actual population of interest. In particular,
\textbf{the proportions of classes in the test set should reflect their
frequencies in real application}. No ``class balancing'' should be
performed.

\end{tcolorbox}

The evaluation based on decision theory automatically takes into account
``class balance'' and its interaction with the utilities relevant to the
task.

There are problems for which the simple strategy ``{always choose class
\(\dotso\)}'' is optimal, given the predictors available in the problem.
So this strategy cannot be beaten by ``improving'' or finding a
``better'' algorithm: such endeavour is only a waste of time. The reason
is that the maximal information that the predictors can give about the
predictand is not enough to sharpen probabilities above the thresholds
determined by the utilities. This maximal information is an intrinsic
properties of predictors and predictands, so it cannot be improved by
fiddling with algorithms. The only way for improvement is to find other
predictors.

``Class balancing'' does not solve this problem. It transforms the
actual task into a \emph{different} task, where maybe some algorithm can
show improvement, simply because we have changed the population
statistics and therefore the mutual information between predictors and
predictands. But as soon as we get back to reality, to the actual task,
the situation will be as before.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/32045/modules}{\emph{Severe
Class Imbalance: Why Better Algorithms Aren't the Answer}}

\end{tcolorbox}

\section{Popular evaluation metrics: the good and the
bad}\label{sec-good-bad-metrics}

If an evaluation metric can be rewritten as a linear combination of the
confusion-matrix entries, then it can be interpreted as arising from a
set of utilities (although they might not be the ones appropriate to the
problem).

This is the case, for instance, of

\begin{itemize}
\tightlist
\item
  {\emph{accuracy}}, which turns out to correspond to the utility matrix
  \(\begin{bsmallmatrix}
  1&0\\0&1
  \end{bsmallmatrix}\) or its non-binary analogues;
\item
  {\emph{true-positive rate}}, which corresponds to
  \(\begin{bsmallmatrix}
  1&0\\0&0
  \end{bsmallmatrix}\)
\item
  {\emph{true-negative rate}}, which corresponds to
  \(\begin{bsmallmatrix}
  0&0\\0&1
  \end{bsmallmatrix}\)
\end{itemize}

If an evaluation metric cannot be rewritten in such a linear form, then
it is breaking the axioms of Decision Theory, and is therefore
guaranteed to carry some form of cognitive bias. The axiom of
independence is specifically broken, because non-linearities imply some
functional dependence of utilities on probabilities or vice versa.

Some quite popular evaluation metrics turn out to break Decision Theory
in this way:

\begin{itemize}
\tightlist
\item
  {\emph{precision}}
\item
  {\emph{\(F_1\)-measure}}
\item
  {\emph{Matthews correlation coefficient}}
\item
  {\emph{Fowlkes-Mallows index}}
\item
  {\emph{balanced accuracy}}
\end{itemize}

The {\emph{area under the curve of the receiving operating
characteristic}} (typically denoted ``AUC'') is also an evaluation
metric that breaks the axioms of Decision Theory, although it is not
based on the confusion matrix.

{This fact is actually funny, because the first papers (in the
1960s--1970s, referenced below) that discussed an evaluation method
based on the receiver operating characteristic actually derived it from
Decision Theory. The papers gave the correct procedure to use the
receiver operating characteristic, and pointed out the ``area under the
curve'' only as a quick but possibly erroneous heuristic procedure.}

It goes without saying that you should stay away from the
cognitive-biased metrics above.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-warning-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={\faIcon{book} Study reading}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Skim through \href{https://doi.org/10.31219/osf.io/7rz8t}{\emph{Does
  the evaluation stand up to evaluation?}}
\item
  Skim through
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Decision
  processes in perception}}
\item
  Skim through
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Basic
  principles of ROC analysis}}
\end{itemize}

\end{tcolorbox}

\part{{\textbf{Conclusion}}}

\chapter*{\texorpdfstring{{What next?}}{What next?}}\label{what-next}
\addcontentsline{toc}{chapter}{{What next?}}

\markboth{{What next?}}{{What next?}}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\providecommand*{\ys}{\se{s}}
\providecommand*{\yh}{\se{h}}
\providecommand*{\yf}{\se{f}}
\providecommand*{\yv}{\se{v}}
\providecommand*{\yJ}{\se{J}}
\providecommand*{\yZ}{\se{Z}}
\providecommand*{\yH}{\se{H}}

\providecommand*{\bZ}{{\blue Z}}
\providecommand*{\bz}{{\blue z}}
\providecommand*{\rY}{{\red Y}}
\providecommand*{\bY}{{\blue Y}}
\providecommand*{\ry}{{\red y}}
\providecommand*{\gX}{{\green X}}
\providecommand*{\bX}{{\blue X}}
\providecommand*{\gx}{{\green x}}

\providecommand*{\data}{\se{\green data}}
\providecommand*{\predictor}{\se{\green predictor}}
\providecommand*{\yD}{\se{\yellow D}}
\providecommand*{\yA}{{\yellow A}}
\providecommand*{\yB}{{\yellow B}}
\providecommand*{\yC}{{\yellow C}}
\providecommand*{\dise}{\mathit{\red disease}}
\providecommand*{\yy}{{\red\cat{yes}}}
\providecommand*{\yn}{{\red\cat{no}}}
\providecommand*{\yr}{\,\mathrm{yr}}

\providecommand*{\income}{\mathit{\red income}}
\providecommand*{\yl}{{\red\cat{<=50K}}}
\providecommand*{\yh}{{\red\cat{>50K}}}

\providecommand*{\uu}{\mathrm{U}}
\providecommand*{\uf}{\mathrm{u}}
\providecommand*{\um}{\boldsymbol{\blue U}}
\providecommand*{\Pm}{\boldsymbol{\green P}}

\providecommand*{\pbest}{p^{+}}

\providecommand*{\pworst}{p^{-}}

\providecommand*{\ry}{{\red y}}
\providecommand*{\ryo}{{\red y^{*}}}
\providecommand*{\bu}{{\blue u}}

\providecommand*{\sA}{\se{\yellow A}}
\providecommand*{\sB}{\se{\yellow B}}

\providecommand*{\mA}{\mathcal{A}}
\providecommand*{\mB}{\mathcal{B}}

\providecommand*{\yca}{{\red\alpha}}
\providecommand*{\ycb}{{\red\beta}}
\providecommand*{\cm}{\boldsymbol{\red C}}



\providecommand*{\yon}{{\green\cat{on}}}
\providecommand*{\yof}{{\red\cat{off}}}
\providecommand*{\yy}{{\lblue\cat{Y}}}
\providecommand*{\yn}{{\yellow\cat{N}}}
\providecommand{\ypl}{{\green\cat{+}}}
\providecommand{\ymi}{{\red\cat{-}}}
\providecommand{\ypa}{{\green\cat{pass}}}
\providecommand{\yfa}{{\red\cat{fail}}}

\providecommand{\hi}{{\green\cat{high}}}
\providecommand{\me}{{\yellow\cat{medium}}}
\providecommand{\lo}{{\red\cat{low}}}
\providecommand*{\yJ}{\se{J}}
\providecommand{\yva}{{\lblue-1}}
\providecommand{\yvb}{{\midgrey0}}
\providecommand{\yvc}{{\yellow1}}
\providecommand*{\yK}{\se{K}}
\providecommand*{\yL}{\se{L}}

\providecommand*{\yR}{R}

\providecommand*{\bZ}{{\blue Z}}
\providecommand*{\bz}{{\blue z}}
\providecommand*{\rY}{{\red Y}}
\providecommand*{\bY}{{\blue Y}}
\providecommand*{\ry}{{\red y}}
\providecommand*{\gX}{{\green X}}
\providecommand*{\bX}{{\blue X}}
\providecommand*{\gx}{{\green x}}
\providecommand*{\vf}{\vec{f}}

\providecommand*{\yut}{\se{K}_{\textsf{3}}}
\providecommand*{\yul}{\se{K}}

\providecommand*{\bA}{{\blue A}}
\providecommand*{\bB}{{\blue B}}
\providecommand*{\bC}{{\blue C}}

\providecommand*{\vfa}{\vf'}
\providecommand*{\vfb}{\vf''}

You have finally reached the end of this course.
\textbf{Congratulations!}

\ldots Or maybe we should say: *\textbf{Good luck on your new journey!}
-- Because this is just the beginning.

What we hope you have taken from this course is a big picture of the
science underneath data science and data-driven engineering, with a
clear idea of its main (and few!) principles. You can now apply these
principles to engineering problems similar to those explored in this
course, and to other, more challenging problems. The principles you have
learned are exactly the same.

\hfill\break

Now it is up to you in which directions to continue your journey as a
data scientist. Maybe you want to\ldots{}

\begin{itemize}
\item
  \faIcon{rocket}~~engineer ``optimal predictor machines'' that can deal
  with more complex kind of data
\item
  \faIcon{screwdriver-wrench}~~improve existing machine-learning
  algorithms by analysing how they approximate an optimal predictor
  machine
\item
  \faIcon{magnifying-glass}~~use your understanding of the foundations
  to interpret and explain how present-day algorithms work
\item
  \faIcon{flask-vial}~~look for new technologies that may allow us to do
  the complicated computations required by an optimal predictor machine
\item
  \faIcon{tower-cell}~~disseminate what you have learned here, or
  explore its foundations, or find ways to make it more understandable
\end{itemize}

\ldots and many other possibilities.

It's important to be aware that most of these directions will require
{\emph{more difficult mathematics}}, in order to write working code, to
face more realistic problems, and to find actual solutions to them. In
the part ``{A prototype Optimal Predictor Machine*}'' you saw that we
needed to bring up Dirichlet distributions, factorials, integrals, and
other mathematics in order to build a concrete, working prototype of an
optimal agent. And that agent can only work in a limited and somewhat
simple class of problems. Solving more complicated problems will,
inevitably, require more complicated mathematics. For some this is
actually a fun challenge. In any case, don't forget the ever-positive
side: the basic principles are few and intuitively understandable in
their essence.

\subsection*{Using Probability Theory and Decision Theory as thinking
and organizational
frameworks}\label{using-probability-theory-and-decision-theory-as-thinking-and-organizational-frameworks}
\addcontentsline{toc}{subsection}{Using Probability Theory and Decision
Theory as thinking and organizational frameworks}

We hope that you will use basic probability theory, decision theory, and
their notation as tools to \emph{frame} and \emph{organize} inference,
prediction, and decision problems.

It does not matter whether the problem can then be solved exactly
according to the rules of probability \& decision theory, or whether
only a crude approximation is available. You have seen that these two
theories are extremely useful even just in the beginning stage, when we
ask questions like ``{what do I need to find?}'', ``{why do I need to
find it?}'' ``{what do I know?}'', ``{what am I assuming?}'', ``{what's
are the gains and costs of success and failure?}'' -- and similar
questions.

For example, see again how the basic probability notation helped us
classify different types of machine-learning algorithms in
chapter~~\ref{sec-beyond-ML}. The notation even suggested at once how to
correctly deal with partially missing data
(§~\ref{sec-categ-probtheory}).

\subsection*{The basic, universal formula behind all supervised- and
unsupervised-learning
algorithms}\label{the-basic-universal-formula-behind-all-supervised--and-unsupervised-learning-algorithms}
\addcontentsline{toc}{subsection}{The basic, universal formula behind
all supervised- and unsupervised-learning algorithms}

We also hope that you will not forget, and actually use as much as
possible, the basic formula (chapter~~\ref{sec-beyond-ML}) that
represents how an agent doing any kind of supervised- or
unsupervised-learning works. This formula is what a neural network or a
random forest are doing under the hood, even if just in an approximate
way:

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, left=2mm, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, opacityback=0, titlerule=0mm, colback=white, arc=.35mm, bottomtitle=1mm, opacitybacktitle=0.6, toptitle=1mm, title={~}, coltitle=black, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  All previous predictors and predictands known (supervised learning)
\end{itemize}

\[
\begin{aligned}
&\mathrm{P}(\color[RGB]{238,102,119}
Y_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&\qquad{}=
\frac{
\mathrm{P}(\color[RGB]{238,102,119}
Y_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\sum_{\color[RGB]{170,51,119}y}
\mathrm{P}(\color[RGB]{238,102,119}
Y_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}y}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\end{aligned}
\]

\hfill\break

\begin{itemize}
\tightlist
\item
  ``Guess all variates'' (unsupervised learning, generative algorithms):
\end{itemize}

\[
\mathrm{P}(\color[RGB]{238,102,119}
Z_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
Z_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
=
\frac{
\mathrm{P}(\color[RGB]{238,102,119}
Z_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
Z_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\sum_{\color[RGB]{170,51,119}z}
\mathrm{P}(
\color[RGB]{238,102,119}
Z_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}z}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
Z_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Z_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}z_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\]

\hfill\break

\begin{itemize}
\tightlist
\item
  Previous predictors known, previous predictands unknown (unsupervised
  learning, clustering)
\end{itemize}

\[
\begin{aligned}
&\mathrm{P}(\color[RGB]{238,102,119}
Y_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{}
\color[RGB]{34,136,51}
X_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\\[2ex]
&\quad{}=
\frac{
\sum_{\color[RGB]{204,187,68}y_{N}, \dotsc, y_{1}}
\mathrm{P}(\color[RGB]{238,102,119}
Y_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\color[RGB]{0,0,0}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
\color[RGB]{204,187,68}
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{204,187,68}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}{
\sum_{{\color[RGB]{170,51,119}y}, \color[RGB]{204,187,68}y_{N}, \dotsc, y_{1}}
\mathrm{P}(\color[RGB]{238,102,119}
Y_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}{\color[RGB]{170,51,119}y}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{34,136,51}
X_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\color[RGB]{0,0,0}\, \mathbin{\mkern-0.5mu,\mkern-0.5mu}\, 
\color[RGB]{204,187,68}
Y_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{N}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
X_{N}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{N}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\color[RGB]{204,187,68}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\color[RGB]{0,0,0}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\color[RGB]{34,136,51}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\end{aligned}
\]

\hfill\break

All these formulae, even for hybrid tasks, involve sums and ratios of
only one distribution:

\[\boldsymbol{
\mathrm{P}(\color[RGB]{68,119,170}
Y_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{\text{new}}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{\text{new}}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}\dotsb \mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
}
\]

and if the problem is exchangeable, for instance without time dependence
or memory effects, the distribution can be calculated in a simpler way:

\[
\begin{aligned}
&\mathrm{P}\bigl(
\color[RGB]{68,119,170}Y_{\text{new}} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{\text{new}} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
\dotsb
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
Y_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1}
\mathbin{\mkern-0.5mu,\mkern-0.5mu}
X_{1} \mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}
\color[RGB]{0,0,0}\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} \mathsfit{I}\bigr)
\\[2ex]
&\qquad{}=
\sum_{\boldsymbol{f}}
f({\color[RGB]{68,119,170}Y_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_{\text{new}}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x}) \cdot
\, \dotsb\, \cdot
f({\color[RGB]{68,119,170}Y_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y_{1} \mathbin{\mkern-0.5mu,\mkern-0.5mu}X_{1}\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x_{1}})
\cdot
\mathrm{P}(F\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}\boldsymbol{f}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I})
\end{aligned}
\]

\hfill\break

Possibly there is a final decision about the output (if a single output
is required), using some utilities and the principle of maximal expected
utility:

\[
\mathsfit{I}_{\textrm{d}}_{\text{optimal}} =
\operatorname{argmax}_{\mathsfit{I}_{\textrm{d}}} \sum_{\color[RGB]{238,102,119}y} \mathrm{U}(\mathsfit{I}_{\textrm{d}}\mathbin{\mkern-0.5mu,\mkern-0.5mu}{\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{I}) \cdot
\mathrm{P}({\color[RGB]{238,102,119}Y\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}y} \nonscript\:\vert\nonscript\:\mathopen{} {\color[RGB]{34,136,51}X\mathclose{}\mathord{\nonscript\mkern 0mu\textrm{\small=}\nonscript\mkern 0mu}\mathopen{}x} \mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{\color[RGB]{34,136,51}data}\mathbin{\mkern-0.5mu,\mkern-0.5mu}\mathsfit{I})
\]

\end{tcolorbox}

\end{figure*}%

\hfill\break

\subsection*{Further texts}\label{further-texts}
\addcontentsline{toc}{subsection}{Further texts}

If you are looking for further texts to deepen your understanding of the
probability calculus and decision theory, we recommend the following --
but it's a good idea to explore on your own! Try and skim through texts
you find, you may stumble onto very interesting good ones.

\begin{itemize}
\item
  E. T. Jaynes (1994):
  \href{https://archive.org/details/XQUHIUXHIQUHIQXUIHX2}{\emph{Probability
  Theory: The Logic of Science}}
\item
  D. J. C. MacKay (1995):
  \href{https://www.inference.org.uk/itila/book.html}{\emph{Information
  Theory, Inference, and Learning Algorithms}}
\item
  J.-M. Bernardo, A. F. Smith (1994):
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Bayesian
  Theory}}
\item
  H. Raiffa (1968):
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Decision
  Analysis: Introductory Lectures on Choices under Uncertainty}}
\item
  S. J. Russell, P. Norvig (1995):
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Artificial
  Intelligence: A Modern Approach}} Parts~I--IV (chapters~1--19)
\item
  P. E. Rossi (2014)
  \href{https://doi.org/10.1515/9781400850303}{\emph{Bayesian Non- and
  Semi-parametric Methods and Applications}}
\end{itemize}

\chapter*{\texorpdfstring{{References}}{References}}\label{references}
\addcontentsline{toc}{chapter}{{References}}

\markboth{{References}}{{References}}

\emph{Believe nothing, O monks, merely because you have been told it, or
because it is traditional, or because you yourselves have imagined it.
Do not believe what your teacher tells you merely out of respect for the
teacher.} ~~~~{(Attributed to Gautama Buddha)}

\hfill\break

\emph{But in the natural sciences, whose conclusions are true and
necessary and have nothing to do with human will, one must take care not
to place oneself in the defense of error; for here a thousand
Demostheneses and a thousand Aristotles would be left in the lurch by
every mediocre wit who happened to hit upon the truth for himself.}
~~~~{(\href{https://hvl.instructure.com/courses/32045/modules}{Galileo
Galilei})}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

\hfill\break

The notions, ideas, and rules that you have learned in this course have
been presented in such a way as to appear plausible and intuitively
understandable. In some places we gave sketch of proofs.

But that is not enough.

A ``data mechanic'' (see preface) might be excused for using incorrect
formulae, and might simply say ``this is the procedure is was taught''.
You instead, as a data \emph{engineer} and data \emph{scientist}, have
the duty to check the validity of the theory and principles that you use
in developing new algorithms, code, solutions.

In particular, you cannot accept theories or methods simply because

\begin{itemize}
\item
  \faIcon{thumbs-down}~~they are commonly used, or used by the majority
  of some community
\item
  \faIcon{thumbs-down}~~some ``authority'' or known scientist says they
  are correct
\end{itemize}

In fact, \emph{Science began when the two criteria above were discarded
as not valid}. This is said very explicitly in Galileo's quote above,
for example. Imagine if Einstein had said ``all scientists see no
problem with the notion of simultaneity, so it must be correct'', or
``great scientists like Maxwell or Poincaré did not see any problem with
the notion of simultaneity, so it must be correct''. There is no
scientific progress with this kind of wrong reasoning.

Instead, the only two scientific criteria you have to decide on the
validity of a method or theory are

\begin{itemize}
\item
  \faIcon{thumbs-up}~~experimental corroboration
\item
  \faIcon{thumbs-up}~~logical proof
\end{itemize}

which you must do as much as possible \emph{by yourself}. The more
verification you delegate to others, to majority or ``authority'', the
less you are doing science.

\hfill\break

For this reason you have, at some point, go and check for yourself the
validity of what you've learned in this course. You might in fact find
out that something was not correct! Then you'll correct it and make
science advance. Throughout the course We have given references where
many proofs can be found. Here are some final references containing the
main proofs of what you have learned here; you should check and validate
them at some point.

\subsection*{Foundations of the probability
calculus}\label{foundations-of-the-probability-calculus}
\addcontentsline{toc}{subsection}{Foundations of the probability
calculus}

The four fundamental rules of the Probability Calculus have been at
least since Laplace in the 1700s, essentially in their present form.
Laplace used them to infer properties of planets and their orbit (with
results still valid today). Proof of their logical foundation and
necessity started to appear in the 1940s, a formal milestone being the
proof by R.~T.~Cox in 1946. They have been tightened and reformulated in
different ways since. Here are some old and recent works on the
foundations (as opposed to works that simply mention the rules and apply
them). Cox's and Jaynes's are probably the first ones to be checked:

\begin{itemize}
\item
  J. M. Keynes (1921):
  \href{https://archive.org/details/cu31924014584100}{\emph{A Treatise
  on Probability}}
\item
  W. E. Johnson (1924):
  \href{https://archive.org/details/logic03john}{\emph{Logic. Part~III:
  The Logical Foundations of Science}}
\item
  W. E. Johnson (1932): *Probability:
  \href{https://doi.org/10.1093/mind/XLI.161.1}{The relations of
  proposal to supposal}, \href{10.1093/mind/XLI.163.281}{Axioms},
  \href{https://doi.org/10.1093/mind/XLI.164.409}{The deductive and
  inductive problems}
\item
  H. Jeffreys (1939):
  \href{https://archive.org/details/in.ernet.dli.2015.523592}{\emph{Theory
  of Probability}}
\item
  \textbf{R. T. Cox (1946):
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Probability,
  Frequency, and Reasonable Expectation}}}
\item
  G. Pólya (1949):
  \href{https://doi.org/10.1111/j.1746-8361.1949.tb00852.x}{\emph{Preliminary
  remarks on a logic of plausible inference}}
\item
  G. Pólya (1954):
  \href{https://archive.org/details/Patterns_Of_Plausible_Inference_2_}{\emph{Mathematics
  and Plausible Reasoning. Vol.~II: Patterns of Plausible Inference}}
\item
  M. Tribus (1969):
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Rational
  Descriptions, Decisions and Designs}}
\item
  \textbf{E. T. Jaynes (1994):
  \href{https://archive.org/details/XQUHIUXHIQUHIQXUIHX2}{\emph{Probability
  Theory: The Logic of Science}}}
\item
  J. B. Paris (1994):
  \href{https://doi.org/10.1017/CBO9780511526596}{\emph{The Uncertain
  Reasoner's Companion: A Mathematical Perspective}}
\item
  T. Hailperin (1996):
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Sentential
  Probability Logic: Origins, Development, Current Status, and Technical
  Applications}}
\item
  P. Snow (1998):
  \href{https://doi.org/10.1111/0824-7935.00070}{\emph{On the
  correctness and reasonableness of Cox's theorem for finite domains}}
\item
  P. Snow (2001):
  \href{https://doi.org/10.1111/0824-7935.00138}{\emph{The
  reasonableness of possibility from the perspective of Cox}}
\item
  K. S. Van~Horn (2003):
  \href{https://doi.org/10.1016/S0888-613X(03)}{\emph{Constructing a
  logic of plausible inference: a guide to Cox's theorem}}
\item
  M. J. Dupré, F. J. Tipler (2009):
  \href{https://doi.org/10.1214/09-BA422}{\emph{New axioms for rigorous
  Bayesian probability}}
\end{itemize}

\hfill\break

\subsection*{Foundations of Decision
Theory}\label{foundations-of-decision-theory}
\addcontentsline{toc}{subsection}{Foundations of Decision Theory}

Decision Theory is much younger than the Probability Calculus, and its
foundations probably still needs to be tightened here and there. Here
are old and recent works on its foundations:

\begin{itemize}
\item
  J. von~Neumann, O. Morgenstern (1953):
  \href{https://archive.org/details/in.ernet.dli.2015.215284}{\emph{Theory
  of Games and Economic Behavior}}
\item
  D. Luce, H. Raiffa (1957):
  \href{https://archive.org/details/img-1907_202109}{\emph{Games and
  Decisions: introduction and critical survey}}
\item
  L. J. Savage (1972):
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{The
  Foundations of Statistics}}
\item
  E. Eells (1982):
  \href{https://hvl.instructure.com/courses/32045/modules}{\emph{Rational
  Decision and Causality}}
\item
  R. Pettigrew (2019):
  \href{https://plato.stanford.edu/archives/win2019/entries/epistemic-utility}{\emph{Epistemic
  Utility Arguments for Probabilism}}
\item
  R. A. Briggs (2019):
  \href{https://plato.stanford.edu/archives/fall2019/entries/rationality-normative-utility}{\emph{Normative
  Theories of Rational Choice: Expected Utility}}
\end{itemize}

\chapter*{\texorpdfstring{{Thanks}}{Thanks}}\label{thanks}
\addcontentsline{toc}{chapter}{{Thanks}}

\markboth{{Thanks}}{{Thanks}}

\providecommand{\ul}{\uline}
\providecommand{\and}{\mathbin{\mkern-0.5mu,\mkern-0.5mu}}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\providecommand*{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand*{\sei}[1]{\mathsfit{\small #1}}

\providecommand{\cat}[1]{{\small\verb;#1;}}
\providecommand{\vec}[1]{\boldsymbol{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\providecommand*{\mo}[1][=]{\mathclose{}\mathord{\nonscript\mkern0mu\textrm{\small#1}\nonscript\mkern0mu}\mathopen{}}
\providecommand*{\yX}{\se{X}}
\providecommand*{\yY}{\se{Y}}
\providecommand*{\yI}{\se{I}}
\providecommand*{\yi}[1][]{\se{I}_{\text{#1}}}
\providecommand{\di}{\mathrm{d}}
\providecommand{\defd}{\coloneqq}
\providecommand{\blue}{\color[RGB]{68,119,170}}
\providecommand{\red}{\color[RGB]{238,102,119}}
\providecommand{\purple}{\color[RGB]{170,51,119}}
\providecommand{\green}{\color[RGB]{34,136,51}}
\providecommand{\yellow}{\color[RGB]{204,187,68}}
\providecommand{\lblue}{\color[RGB]{102,204,238}}
\providecommand{\grey}{\color[RGB]{187,187,187}}
\providecommand{\midgrey}{\color[RGB]{119,119,119}}
\providecommand{\black}{\color[RGB]{0,0,0}}
\providecommand{\e}{\mathrm{e}}
\providecommand{\pu}{\text{π}}
\providecommand{\RR}{\mathbf{R}}


\providecommand{\argmax}{\operatorname{argmax}}

We would like to thank, in unsystematic order:

\begin{itemize}
\item
  The {master students} of the first version of this course, for their
  enthusiasm and interest in the course goal and material, and for their
  constructive feedback. \textbf{You rock, guys!}\footnote{They were
    indeed all guys. We hope the coming years will bring more balanced
    gender statistics.}
\item
  The members of the \href{https://github.com/HVL-ML}{\emph{Artificial
  Intelligence Engineering}} group at the Western Norway University of
  Applied Sciences (HVL) for endorsement of the present course and
  encouragement during its construction.
\item
  {Soledad Gonzalo Cogno} and {Iván Davidovich} and their course
  \href{https://www.ntnu.edu/studies/courses/NEVR8011}{\emph{Concepts in
  Data Analysis}}, organized by the
  \href{https://www.ntnu.edu/kavli/gonzalo-cogno-group}{\emph{Gonzalo
  Cogno Group}} at the \href{https://www.ntnu.edu/kavli}{Kavli Institute
  for Systems Neuroscience} and at the Norwegian University of Science
  and Technology (NTNU), where some of the present course material was
  initially designed and tested.
\item
  The members of the
  {\emph{\href{https://mmiv.no/machinelearning/}{Medical AI}}} group at
  the \href{https://mmiv.no/}{Mohn Medical Imaging and Visualization
  Centre}, in particular Ingrid Rye, Alexandra Vik, Marek Kociński,
  Arvid Lundervold, Astri Lundervold, Alexander Lundervold, for the many
  group meetings, discussions, and projects where the core of the
  present course material was tested.
\item
  The {\emph{\href{https://bayesian.org/resources/bulletin/}{Bulletin}
  of the \href{https://bayesian.org/}{International Society for Bayesian
  Analysis}}} and its editor {Gregor Kastner} for kindly allowing us to
  share the present course in the ``Teaching Highlight'' section.
\item
  {Lars Michael Kristensen} for his great work on the
  \href{https://www.hvl.no/en/studies-at-hvl/study-programmes/ict-engineering-applied-computer-science-and-engineering/}{\emph{Master
  in Applied Computer Science}} at HVL, of which this course is part.
\item
  The developers and maintainers of {\href{https://quarto.org/}{Quarto}}
  for help in the customization of this course's web pages.
\item
  Our beloved, families, friends for their continuous encouragement and
  support.
\item
  PGLPM thanks Saitama for being a constant source of awe and
  inspiration.
\end{itemize}




\end{document}
