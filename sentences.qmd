# [Sentences]{.green} {#sec-sentences}
{{< include macros.qmd >}}

We have seen that an inference involves, at the very least, two things: the object of the inference (*proposal*), and the data, information, or hypotheses on which the inference is based (*conditional*).

We also observed that wildly different "things" can be the object of an inference or the information on which the inference is based: measurement results, decision outcomes, hypotheses, not-real events, assumptions, data and information of all kinds (for example, images). In fact, such variety in some cases can make it difficult to pinpoint what an inference is about or what it is based upon.

Is there a general, flexible, yet precise way of representing all these kinds of "things"?


## The central components of knowledge representation {#sec-central-comps}

When speaking of "data", what comes to mind to many people is numbers or collections of numbers. Maybe numbers, then, could be used to represent all the variety of "things" exemplified above? Well, this option turns out to be too restrictive.

I give you this number: "$8$", saying that it is "data". But what is it about? You, as an agent, can hardly call this number a piece of information, because you have no clue what to do with it.

Instead, if I tell you: "[The number of official planets in the solar system is 8](https://solarsystem.nasa.gov/planets/overview)", then we can say that I've given you data. You can do different things with this piece of information. For instance, if you had decided to send one probe to each official planet, now you know you have to build eight probes. Or maybe you can win at a pub quiz with it.

"Data" is therefore not just numbers. A number is not "data" unless there's an additional verbal and non-numeric context accompanying it -- even if only implicitly. Sure, we could represent this meta-data information as numbers too; but this move would only shift the problem one level up: we would need an auxiliary verbal context explaining what the meta-data numbers are about.

Data can, moreover, be completely non-numeric. A clinician saying "The patient has fully recovered from the disease" is giving us a piece of information that we could further use, for instance, to make prognoses about other, similar patients. The clinician's statement surely is "data", but is essentially non-numeric data. Sure, in some situations we could represent this data with numbers, say "1" for "recovered" and "0" for "not recovered". But the opposite or some other convention could also be used: "0" for "recovered" and "1" for "not recovered", or the numbers "0.3" and "174". These numbers have intrinsically nothing to do with the clinician's "recovery" data.

\

The examples above, however, actually reveal the answer to our needs! In the examples we expressed the data by means of *sentences*. Clearly any measurement result, decision outcome, hypothesis, not-real event, assumption, data, and any piece of information can be expressed by a sentence.

We shall therefore use [**sentences**]{.blue}, also called [**propositions**]{.blue} or **statements**,^[These three terms are not always equivalent in formal logic, but here we'll use them as synonyms.] to represent and communicate all the kinds of "things" that can be the proposal or the conditional of an inference. In some cases we can of course summarize a sentence by a number, as a shorthand, when the full meaning of the sentence is understood.
\
\

*Sentences are the central components of knowledge representation in AI agents*. For example they appear at the heart of automated control programs and fault-management systems in NASA spacecrafts -- we'll return to these later on.

::: {.callout-warning}
## {{< fa book >}} Study reading

[**Read**]{.lightblue} §7.1 in [*Artificial Intelligence*](references.html).

:::

## Identifying and working with sentences

But what is a sentence, more exactly? The everyday meaning of this word will work for us, even though there are more precise definitions -- and still a lot of research in logic an artificial intelligence on how to define and use sentences. We shall adopt this useful definition:

::::{.column-margin}
::: {.callout-tip}
## {{< fa rocket >}} For the extra curious
[Propositions](https://plato.stanford.edu/archives/win2020/entries/propositions)
:::
::::

[*A **sentence** is something for which an agent can determine, at least in principle, whether it is `true` or `false`.*]{.blue}

Let's make this definition clearer with some remarks:

:::{}
- [**{{< fa hand-point-right >}} A sentence doesn't have to contain only words**]{.blue}. It can contain pictures, sounds, and other non-verbal items. For example, the following:
    
    "[This: ![](saitama_transform.gif){height=3em} is an animated picture of Saitama.]{.midgrey}"
	
	is a sentence, even if it contains animated graphics, because we can say that it is `true`. Likewise, the following:
	
	"[[This link](iliketrafficlights.mp3){target="_blank"} leads to a song by Pink Floyd.]{.midgrey}"
	
	is also a sentence, even if it contains links and audio, because we can say that it is `false` (that's a song by Monty Python).


- [**{{< fa hand-point-right >}} A meaningful phrase may not be a sentence**]{.blue}. For instance, a phrase like "[Apples are much tastier than pears]{.midgrey}" may not be a sentence, because it's a matter of personal taste whether it's `true` or `false`.  Moreover, an agent's opinion about apples and pears might change from time to time.
    
    The phrase "[Jenny right now finds apples tastier than pears]{.midgrey}", on the other hand, could be a sentence; its truth being found by asking Jenny at that very moment.
	
	In an engineering context, the phrase "[This valve will operate for at least two months]{.midgrey}" is a sentence, even if its truth is unknown at the moment: one has to wait two months, and then its truth will be unambiguously known.
:::

- [**{{< fa hand-point-right >}} An expression involving technical terms may not be a sentence (and not meaningful either)**]{.blue}. For instance, in a data-science context the phrase "[This neural-network algorithm has better performance than that random-forest one]{.midgrey}" is *not* a sentence unless we have objectively specified what "better" means (higher accuracy? higher true-positive rate? faster?), for example by adopting a particular comparison metric.
    
    Some expressions involving technical terms may appear to be sentences at first; but a deeper analysis then reveals that they are not. A famous example is the sentence "[The two events (at different spatial locations) are simultaneous]{.midgrey}". Einstein showed that there's no physical way to determine whether such an expression is true or false. Its truth turns out to be a matter of convention. The Theory of Relativity was born from this observation.

::::{.column-margin}
::: {.callout-tip}
## {{< fa rocket >}} For the extra curious
[*On the electrodynamics of moving bodies*](https://einsteinpapers.press.princeton.edu/vol2-trans/154).
:::
::::

:::{.callout-important}
## 
{{< fa exclamation-circle >}} Be particularly careful when reading scientific and engineering papers with a lot of technical terms and phrases. Technical jargon often makes it especially difficult to see whether something true or at least meaningful is being said, or not!
:::

- [**{{< fa hand-point-right >}} A sentence can be expressed in different ways**]{.blue} by different phrases and in different languages. For instance, "[The temperature is 248.15 K]{.midgrey}", "[Temperaturen ligger på minus 25 grader]{.midgrey}", and "[25 °C is the value of the temperature]{.midgrey}" all represent the *same* sentence.

---

There are many advantages in working with sentences (rather than just numbers), and in keeping in mind that every inference is about sentences:

First, this point of view leads to **clarity** in engineering problems, and makes them more **goal-oriented**. A data engineer must acquire information and convey information. "Acquiring information" does not simply consist in making measurements or counting something: the engineer must understand *what* is being measured and *why*. If data is gathered from third parties, the engineer must ask what exactly the data mean and how they were acquired. In designing a solution, it is important to understand what information or outcomes the end user exactly wants. These "what", "why", "how" are expressed by sentences. A data engineer will often ask "*wait, what do you mean by that?*". This question is not just an unofficial parenthesis in the official data-transfer workflow between the engineer and someone else. It is an integral part of that workflow: it means that some information has not been completely transferred yet.

Second, this point of view is extremely important in AI and machine-learning design. A (human) engineer may proceed informally when drawing inferences, without worrying about "sentences" unless a need for disambiguation arises. A data engineer who's *designing* or *programming* an algorithm that will do inferences automatically, must instead be unambiguous and cover beforehand all possible cases that the algorithm will face.

\

We therefore agree that [*the proposal and the conditional of an inference have to be sentences*]{.blue}. This means that the proposal of the inference must be something that can be true or false.

Many inferences, especially when they concern numerical measurements, involve more than one sentence. For example, an inference about the result of rolling a die actually consists of the probabilities for six separate proposals:

$$
\begin{aligned}
&\pr{The result of the roll is 1}
\\
&\pr{The result of the roll is 2}
\\
&\dotso
\\
&\pr{The result of the roll is 6}
\end{aligned}
$$

Later on we shall see how to work with more complex inferences of this kind. In real applications it can be useful, on some occasions, to pause and reduce an inference to its basic set of `true`/`false` sentences. This analysis may reveal contradictions in our inference problem. A simple way to do this is to reduce the complex inference into a set of yes/no questions.

This kind of analysis is also important in information-theoretic situations: the [**information content**]{.blue} provided by an inference, when measured in *Shannons*, is related to the minimal amount of yes/no questions that the inference answers.

:::{.callout-caution}
## {{< fa user-edit >}} Exercise
Rewrite each inference scenario of [§@sec-inference-scenarios] in a formal way, as one or more inferences

$$
\textit{[proposal]}\ \pmb{\|[\Big]}\ \textit{[conditional]}
$$

where proposal and conditional are well-defined sentences.

In ambiguous cases, use your judgement and motivate your choices.
:::


## Notation and abbreviations {#sec-sentence-notation}

Writing full sentences would take up *a lot* of space. Even an expression such as "[The speed is 10 m/s]{.midgrey}" is not a sentence, strictly speaking, because it leaves unspecified the speed of what, when it was measured and in which frame of reference, what we mean by "speed", how the unit "m/s" is defined, and so on.

Typically we leave the full content of a sentence to be understood from the context, and we denote the sentence by a simple expression. Example:

$$
\prq{The speed is 10\,m/s}
$$

or even more compactly introducing physical symbols:

$$
v \mo 10\,\mathrm{m/s}
$$

where $v$ is a physical variable denoting the speed. Sometimes we may simply write

$$
10\,\mathrm{m/s}
$$

In some problems it's useful to introduce symbols to denote sentences. As mentioned before, in these notes we'll use sans-serif italic letters: $\se{A},\se{B},\se{a},\se{b},\dotsc$, possibly with sub- or super-scripts. For instance, the sentence "[The speed is 10 m/s]{.midgrey}" could be denoted by the symbol $\se{S}_{10}$. We express such a  definition like this:

$$
\se{S}_{10} \defd \pr{The speed is 10\,m/s}
$$

which means that the symbol $\se{S}_{10}$ is defined to be the sentence [$\pr{The speed is 10\,m/s}$]{.grey}.

::::{.callout-important}
## {{< fa exclamation-triangle >}} We must be wary of how much we shorten sentences
Consider these three sentences:

$$
\begin{aligned}
&\pr{The speed is measured to be 10\,m/s}
\\
&\pr{The speed is set to 10\,m/s}
\\
&\pr{The speed is reported, by a third party, to be 10\,m/s}
\end{aligned}
$$

The quantity "10 m/s" is the same in all three sentences, but their meanings are very different. They represent different kinds of data. The difference greatly affect any inference about or from these data. For instance, in the third case an engineer may not take the indirectly-reported speed "10 m/s" at face value, unlike in the first case. In a scenario where all three sentences can occur, it would be ambiguous to simply write "$v = 10\,\mathrm{m/s}$": would the equal-sign mean "measured", "set", or "indirectly reported"?
::::

:::{.callout-caution}
## {{< fa user-edit >}} Exercise
How would you denote the three sentences above, to make their differences clear?
:::

\

:::{.callout-note}
## Get familiar with abbreviations of sentences
To summarize, a sentence like

$$
\pr{The temperature $T$ has value $x$}
$$

could be abbreviated in these different ways:

- A symbol for the sentence (note the sans-serif font):

    $$
\se{S}
$$

- Some key word appearing in the sentence:

    $$
\prq{temperature}
$$

- An equality:

    $$
T\mo x
$$

- The quantity appearing in the sentence:

    $$
T
$$

- The value appearing in the sentence:

    $$
x
$$

Get familiar with these kinds of abbreviations because they are all very common. Some texts may even jump from one abbreviation to another in the same page or paragraph!
:::

\


## Connecting sentences {#sec-connecting-sentences}

### Atomic sentences

In analysing the measurement results, decision outcomes, hypotheses, assumptions, data and information that enter into an inference problem, it is convenient to find a collection of **basic sentences** or, using a more technical term, [**atomic sentences**]{.blue}, out of which all other sentences of interest can be constructed. These atomic sentences often represent elementary pieces of information in the problem.

Consider for instance the following composite sentence, which could appear in our assembly-line scenario:

> "The electronic component is still whole after the shock test and the subsequent heating test. The voltage reported in the final power test is either 90 mV or 110 mV."

<!-- In the assembly-line scenario, the statement above represents data, that is, it's the description of a factual situation. But keep in mind that in a different problem -- say, one where it need to be assessed whether the component is still whole -- the same statement could represent a hypothesis, that is, one possible state of affairs among other possible ones. -->

In this statement we can identify at least four atomic sentences, which we denote by these symbols:

$$\begin{aligned}
\se{s} &\defd \pr{The component is whole after the shock test}
\\
\se{h} &\defd \pr{The component is whole after the heating test}
\\
\se{v}_{90} &\defd \pr{The power-test voltage reading is 90\,mV}
\\
\se{v}_{110} &\defd \pr{The power-test voltage reading is 110\,mV}
\end{aligned}
$$

The inference may actually require additional atomic sentences. For example it might become necessary to consider atomic sentences with other values for the reported voltage, such as

$$\begin{aligned}
\se{v}_{110} &\defd \pr{The power-test voltage reading is 100\,mV}
\\
\se{v}_{80} &\defd \pr{The power-test voltage reading is 80\,mV}
\end{aligned}$$

and so on.


### Connectives

How do we construct composite sentences, like the one above, out of atomic sentences?

We consider three ways: one operation to change a sentence into another related to it, and two operations to combine two or more sentences together. These operations are called [**connectives**]{.blue}. You may have already encountered them in Boolean algebra. Our natural language offers many more operations to combine sentences, but these three connectives turn out to be all we need in virtually all engineering and data-science problems:

:::: {.callout-note style="font-size:120%"}
##  
:::{style="font-size:120%"}
[Not [(symbol]{.small}\ \ $\lnot$ [)]{.small}]{.blue}
: example:

$$\begin{aligned}
\se{s} &\defd \pr{The component is whole after the shock test}
\\[1ex]
\lnot \se{s} &= \pr{The component is broken after the shock test}
\end{aligned}$$


[And [(symbols]{.small}\ \ $\land$\ \ [also]{.small}\ \ $\and$ [)]{.small}]{.blue}
: example:

$$
\begin{aligned}
\se{s} &\defd \pr{The component is whole after the shock test}
\\
\se{h} &\defd \pr{The component is whole after the heating test}
\\[1ex]
\se{s} \land \se{h} &= \pr{The component is whole after the shock and heating tests}
\\
\se{s} \and \se{h} &= \pr{The component is whole after the shock and heating tests}
\end{aligned}
$$


[Or [(symbol]{.small}\ \ $\lor$ [)]{.small}]{.blue}
: example:

$$\begin{aligned}
\se{v}_{90} &\defd \pr{The power-test voltage reading is 90\,mV}
\\
\se{v}_{110} &\defd \pr{The power-test voltage reading is 110\,mV}
\\[1ex]
\se{v}_{90} \lor \se{v}_{110} &= \pr{The power-test voltage reading is 90\,mV, or 110\,mV, or both}
\end{aligned}$$

:::
::::

These connectives can be applied multiple times, to form increasingly more complex composite sentences.

The `and` connective appears very frequently in probability formulae. Using its standard symbol "$\land$" would consume a lot of horizontal space. For this reason a comma "$\and$" is often used as an alternative symbol. So the expressions $\se{s} \land \se{h}$ and $\se{s} \and \se{h}$ **are completely equivalent**.

:::{.callout-important} 
## {{< fa exclamation-triangle >}} Important subtleties of the connectives:
- There is *no strict correspondence* between the words "not", "and", "or" in natural language and the three connectives. The `and` connective may for instance correspond to the words "but" or "whereas", or just to a comma " , ".

- `Not` means not some kind of complementary quality, but the denial. For instance,\ \ $\lnot\pr{The chair is black}$\ \ generally does not mean\ \ $\pr{The chair is white}$ ,\ \  (although in some situations these two sentences could amount to the same thing).

    It's always best to *declare explicitly what the `not` of a sentence concretely means*. In our example we take
	
	$$
	\lnot\pr{The component is whole} \defd \pr{The component is broken}
	$$
	
	But in other examples the negation of "being whole" could comprise several different conditions. A good guideline is to always state the `not` of a sentence in *positive* terms.

- `Or` does not exclude that the sentences it connects can be both true. So in our example\ \ $\se{v}_{90} \lor \se{v}_{110}$\ \ does not exclude, a priori, that the reported voltage could be both 90 mV and 110 mV. (There is a connective for that: "exclusive-or", but it can be constructed out of the three we already have.)
:::

From the last remark we see that the sentence

$$
\pr{The power-test voltage reading is 90\,mV or 110\,mV}
$$

does *not* correspond to \ \ $\se{v}_{90} \lor \se{v}_{110}$ .\ \ It is implicitly understood that a voltage reading cannot yield two different values at the same time. Convince yourself that the correct way to write that sentence is this:

$$
(\se{v}_{90} \lor \se{v}_{110})
\land
\lnot(\se{v}_{90} \land \se{v}_{110})
$$

Finally, the full composite sentence of the present example can be written in symbols as follows:

> "[The electronic component is still whole after the shock test]{.lightblue} and [the subsequent heating test]{.green}. [The voltage reported in the final power test is]{.red} either [90 mV]{.red} or [110 mV]{.purple}."

$$
\textcolor[RGB]{102,204,238}{\se{s}} \land \textcolor[RGB]{34,136,51}{\se{h}} \land
(\textcolor[RGB]{238,102,119}{\se{v}_{90}} \lor \textcolor[RGB]{170,51,119}{\se{v}_{110}})
\land
\lnot
(\textcolor[RGB]{238,102,119}{\se{v}_{90}} \land \textcolor[RGB]{170,51,119}{\se{v}_{110}})
$$

\


::: {.callout-warning}
## {{< fa book >}} Study reading
[**Skim through**]{.lightblue} §7.4.1 in [*Artificial Intelligence*](references.html) and note the similarities with what we've just learned. In these notes we follow a faster approach leading directly to probability logic.
:::


## "If... then..."

Sentences expressing data and information in natural language also appear connected with *if... then...*. For instance: "[If the voltage reading is 200 mV, then the component is defective]{.midgrey}". This kind of expression actually indicates that the following inference

$$
\pr{The component is defective} \pmb{\|[\big]} \pr{The voltage reading is 200\,mV}
$$

is `true`.

This kind of information is very important because it is often the starting point of our inferences. We shall discuss this point in more detail in the next sections.

:::{.callout-important}
## {{< fa exclamation-triangle >}} Careful
There is a connective in logic, called "[material conditional](https://plato.stanford.edu/entries/logic-propositional/#MateCond)", which is also often translated as "if... then...". But it is not the same as the inference relation discussed above. "If... then..." in natural language usually denotes an inference rather than a material conditional.

Research is still ongoing on these topics. If you are curious and in for a headache, look over [*The logic of conditionals*](https://plato.stanford.edu/entries/logic-conditionals).
:::

## Actual implementation

As we said at the beginning, *sentences are the central components of knowledge representation in AI agents*. But how are sentences and their relationships actually *implemented* in a concrete AI agent?

The notation and symbols we discussed above are tools that we, humans, use to study and discuss about sentences. These symbols and tools are independent of technology; there also lies their usefulness. But we cannot expect a concrete AI agent to work with "letters" or similar symbols internally.

Knowledge representation is a whole AI field in itself, and unfortunately we don't have time to delve into its present-day state and concrete implementations. Also because, remember, we're trying to adopt a view that's technology-independent, a view that allows us to see potential in new technologies.

But it's good to get a glimpse of present-day implementations knowledge representations. Here are examples from NASA:

:::{.column-margin}
![](SMART.png){width=100%}
(From the *SMART* paper)
:::

::: {.callout-warning}
## {{< fa book >}} Study reading

[**Skim through**]{.lightblue}:

- Ono & al. 2015: [*SMART: A propositional logic-based trade analysis and risk assessment tool for a complex mission*](references.html)
- around p. 22 in Ingham 2012: [*No More Band-Aids: Integrating FM into the Onboard Execution Architecture*](references.html)

<!-- - §2.1 in [*Deliberation for autonomous robots: A survey*](http://doi.org/10.1016/j.artint.2014.11.003) -->

- part IV in Williams & al. 2003: [*Model-based programming of intelligent embedded systems and robotic space explorers*](references.html)
:::

\

---

We are now equipped with all the notions and symbolic notation to deal with our next task: learning the rules for drawing correct inferences.

\

[@@ TODO: add connections to large language models (Gödel & Co.).]{.small .grey}
