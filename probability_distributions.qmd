# [Probability distributions]{.green} {#sec-prob-distribs}
{{< include macros.qmd >}}

## [Motivation for the "Inference II" part]{.green} {.unnumbered}

In the "[Data I]{.yellow}" part we developed a language, that is, particular kinds of sentences, to approach inferences and probability calculations typical of data-science and engineering problems.

In the present part we focus on probability calculations that often occur with this kind of sentences and data. We also focus on how to visually represent such probabilities in useful ways. 

Always keep in mind that at bottom we're just using the [four fundamental rules of inference](probability_inference.html#sec-fundamental) over and over again -- nothing more than that!

----

\

## Distribution of probability among values {#sec-distribute-prob}

When an agent is uncertain about the value of a quantity, its uncertainty is expressed and quantified by assigning a degree of belief, conditional on the agent's knowledge, to all the possible cases -- all the possible values that could be the true one.

For a temperature measurement, for instance, the cases could be "[The temperature is measured to have value 271 K]{.green}", "[The temperature is measured to have value 272 K]{.green}", and so on up to 275 K. These cases are expressed by mutually exclusive and exhaustive sentences. Denoting the temperature with $T$, these sentences can be abbreviated as

$$
{\green T = 271\,\mathrm{K}} \ , \quad
{\green T = 272\,\mathrm{K} \ ,} \quad
{\green T = 273\,\mathrm{K} \ ,} \quad
{\green T = 274\,\mathrm{K} \ ,} \quad
{\green T = 275\,\mathrm{K}} \ .
$$

The agent's belief about the quantity is then expressed by the [probabilities]{.purple} about these five sentences, conditional on the agent's state of knowledge, which we may denote by the letter ${\yellow\yI}$. These probabilities could be, for instance,
<!-- 4 10 18 28 40 -->

$$\begin{aligned}
\P({\green T \mo 271\,\mathrm{K}} \| {\yellow\yI}) &= {\purple0.04} \\[1ex]
\P({\green T \mo 272\,\mathrm{K}} \| {\yellow\yI}) &= {\purple0.10} \\[1ex]
\P({\green T \mo 273\,\mathrm{K}} \| {\yellow\yI}) &= {\purple0.18} \\[1ex]
\P({\green T \mo 274\,\mathrm{K}} \| {\yellow\yI}) &= {\purple0.28} \\[1ex]
\P({\green T \mo 275\,\mathrm{K}} \| {\yellow\yI}) &= {\purple0.40}
\end{aligned}
$$

Note that they sum up to one:

$$
\begin{aligned}
&\quad\P({\green T \mo 271\,\mathrm{K}} \| {\yellow\yI}) +
\dotsb +
\P({\green T \mo 275\,\mathrm{K}} \| {\yellow\yI}) 
\\[1ex]
&= 
{\purple0.04}+{\purple0.10}+{\purple0.18}+{\purple0.28}+{\purple0.40} 
\\[1ex]
&=
{\purple1}
\end{aligned}$$

This collection of probabilities is called a [**probability distribution**]{.blue}, because we are distributing the probability among the possible alternatives.

:::{.callout-important}
## {{< fa exclamation-triangle >}} What's "distributed"?
The *probability* is distributed among the possible values, as illustrated in the side picture. The quantity cannot be "distributed": it has one, definite value, which is however unknown to the agent.
:::

::::{.column-margin}
![](illustration_prob_distr2.png)
::::


:::{.callout-caution}
## {{< fa user-edit >}} Exercise
Consider three sentences $\yX_1, \yX_2, \yX_3$ that are mutually exclusive and exhaustive on conditional $\yI$, that is:

$$
\begin{gathered}
\P(\yX_1 \land \yX_2 \| \yI) =
\P(\yX_1 \land \yX_3 \| \yI) =
\P(\yX_2 \land \yX_3 \| \yI) = 0
\\
\P(\yX_1 \lor \yX_2 \lor \yX_3 \| \yI) = 1
\end{gathered}
$$

Prove, using the fundamental rules of inferences and any derived rules from [§@sec-probability], that we must then have

$$
\P(\yX_1 \| \yI) + \P(\yX_2 \| \yI) + \P(\yX_3 \| \yI) = 1
$$
:::

\
Let's see how probability distributions can be represented and visualized for the basic types of quantities discussed in [§@sec-quantities-types-basic].

We start with probability distributions over discrete domains.

## Discrete probability distributions {#sec-discr-prob-distr}

### Tables and functions

A probability distribution over a discrete domain can obviously be displayed as a table of values and their probabilities. For instance

| [*value*]{.green}      | [271 K]{.green} | [272 K]{.green} | [273 K]{.green} | [274 K]{.green} | [275 K]{.green} |
|------------------------|:---------------:|:---------------:|:---------------:|:---------------:|-----------------|
|[*probability*]{.purple}| [0.04]{.purple} | [0.10]{.purple} | [0.18]{.purple} | [0.28]{.purple} | [0.40]{.purple} |

In the case of ordinal or interval quantities it is sometimes possible to express the probability as a *function* of the value. For instance, the probability distribution above could be summarized by this function of the value ${\green t}$:

$$
\P({\green T\mo t} \| {\yellow\yI}) = 
{\purple\frac{({\green t}/\textrm{\small K} - 269)^2}{90}}
\quad\text{\small (rounded to two decimals)}
$$

\


A graphical representation is often helpful to detect features, peculiarities, and even inconsistencies in one or more probability distributions.

### Histograms and area-based representations

A probability distribution for a nominal, ordinal, or discrete-interval quantity can be neatly represented by a [**histogram**]{.blue}.

:::{.column-margin}
![Histogram for the probability distribution over possible component failures](example_histogram.png){width=100%}
:::

The possible values are placed on a line. For an ordinal or interval quantity, the sequence of values on the line should correspond to their natural order. For a nominal quantity the order is irrelevant.

A rectangle is then drawn above each value. The rectangles might be contiguous or not. The bases of the rectangles are all equal, and the [*areas*]{.blue} of the rectangles are proportional to the probabilities. Since the bases are equal, this implies that the heights of the rectangles are also proportional to the probabilities.

Such kind of drawing can of course be horizontal, vertical, upside-down, and so on, depending on convenience.

Since the probabilities must sum to one, the total area of the rectangles represents an area equal to 1. So in principle there is no need of writing probability values on some vertical axis, or grid, or similar visual device, because the probability value can be visually read as the ratio of a rectangle area to the total area. An axis or grid can nevertheless be helpful. Alternatively the probabilities can be reported above or below each rectangle.

Nominal quantities do not have any specific order, so their values do not need to be ordered on a line. Other area-based representations, such as pie charts, can also be used for these quantities.



### Line-based representations

Histograms give faithful representations of discrete probability distributions. Their graphical bulkiness, however, can be a disadvantage in some situations, for instance when we want to have a clearer idea of how the probability varies across values for ordinal or interval quantities; or when we want to compare several different probability distributions over the same values.

In these cases we can use standard line plots, or variations thereof. Compare the following example.

A technician wonders which component of a laptop failed first (only one can fail at a time), with seven possible alternatives: $\set{\cat{hard-drive}, \cat{motherboard}, \cat{CPU}, \cat{keyboard}, \cat{screen}, \cat{graphics-card}, \cat{PCI}}$. This is a [nominal quantity](quantities_types.html#nominal).

Before examining the laptop, the technician's belief about which component failed first is distributed among the seven alternatives as shown by the [blue histogram with solid borders]{.blue}. After a first inspection of the laptop, the technician's belief has a new distribution, shown by the [red histogram with dashed borders]{.red}:

![](example_histogram_double.png){width=100%}

It requires some concentration to tell the two probability distributions apart, for example to understand where their peaks are. Let us represent them by two line plots instead: [solid blue with circles]{.blue} for the pre-inspection belief distribution, and [dashed red with squares]{.red} for the post-inspection one:

![](example_curve_double.png){width=100%}

this line plot displays more cleanly the differences between the two distributions. We see that at first the technician most strongly believed the $\cat{keyboard}$ to be the faulty candidate, the second strongest belief being for the $\cat{PCI}$. After the preliminary inspection, the technician most strongly believes the $\cat{PCI}$ to be the faulty candidate, followed by the $\cat{graphics card}$.


<!-- ## Probability distributions over infinite discrete values -->

<!-- [@@ TODO]{.small .grey} -->


## Probability densities {#sec-prob-densities}

Distributions of probability over continuous domains present several counter-intuitive aspects, which essentially arise because we are dealing with uncountable infinities -- while often using linguistic expressions that make only sense for countable infinities. Here we follow a practical and realistic approach for working with such distributions.

Consider a quantity [$X$]{.green} with a continuous domain. When we say that this quantity has some value\ \ [$x$]{.green}\ \ we really mean that it has a value somewhere in the range\ \  [$x -\epsilon/2$\ \ to\ \ $x+\epsilon/2$]{.green},\ \  where the width $\epsilon$ is usually extremely small, because we never have infinite precision. For example, for [double-precision](https://rdrr.io/r/base/double.html) values stored in a computer, the width^[more precisely the relative width] must be at least $\epsilon \approx 2\cdot 10^{-16}$ . You can check indeed that your computer might not distinguish between two numbers that differ in their 16th decimal digit:

```r
#### R code
## difference in 15th decimal digit
> 1.234567890123456 == 1.234567890123455
[1] FALSE

## difference in 16th decimal digit
> 1.2345678901234567 == 1.2345678901234566
[1] TRUE
```

The value `1.3` really represents a range between
[`1.29999999999999982236431605997495353221893310546875`]{.small} and [`1.300000000000000266453525910037569701671600341796875`]{.small}, this range coming from the internal binary representation of `1.3`. Often the width $\epsilon$ is much larger than the computer's precision, and comes from the precision with which the value is *experimentally* measured.

When we consider a distribution of probability for a continuous quantity, the probabilities are therefore distributed among such small ranges, not among single values.

Since these ranges are very small, they are also very numerous. But the total probability assigned to all of them must still sum up to $1$. This means that each small range receives an extremely small amount of probability. A standard Gaussian distribution for a real-valued quantity, for instance, assigns a probability of approximately $8\cdot 10^{-17}$, or [$0.000 000 000 000 000 08$]{.small}, to a range of width $2\cdot 10^{-16}$ around the value $0$. All other ranges are assigned even smaller probabilities.

In would be impractical to work with such small probabilities. We use [**probability densities**]{.blue} instead. As implied by the term "[density](https://www.nist.gov/pml/special-publication-811/nist-guide-si-chapter-8)", a probability density is the amount of probability $P$ assigned to a standard range of width $\epsilon$, *divided* by that width. For example, if the probability assigned to a range of width\ \ $\epsilon=2\cdot10^{-16}$\ \ around the value $0$ is\ \ $P=7.97885\cdot10^{-17}$,\ \ then the
*probability density* around $0$ is

$$
\frac{P}{\epsilon} =
\frac{7.97885\cdot10^{-17}}{2\cdot10^{-16}} = 0.398942
$$

which is a more convenient number to work with.

Probability densities are convenient because they usually do not depend on the range width $\epsilon$, if it's small enough. Owing to physics reasons, we don't expect a situation where $X$ is between [$0.9999999999999999$]{.small} and [$1.0000000000000001$]{.small} to be very different from one where $X$ is between [$1.0000000000000001$]{.small} and [$1.0000000000000003$]{.small}. The probabilities assigned to these two small ranges of width $\epsilon=2\cdot 10^{-16}$ will therefore be approximately equal, let's say $P$ each. Now if we use a small range of width $\epsilon$ around $X=1$, the probability is $P$, and the probability *density* is $P/\epsilon$. If we consider a range of double width $2\,\epsilon$ around $X=1$, then the probability is $P+P$ instead, but the probability density is still

$$\frac{P+P}{2\,\epsilon} =
\frac{1.59577\cdot10^{-16}}{4\cdot10^{-16}}
= 0.398942 \ .
$$

As you see, even if we consider a range with double the width as before, the probability density is still the same.

\

In these notes we'll denote probability densities with a [*lowercase* $\p$]{.blue}, with the following notation:

$$
\underbracket[0pt]{\p}_{\mathrlap{\midgrey\!\uparrow\ \textit{lowercase}}}(X\mo x \| \yI) \defd
\frac{
\overbracket[0pt]{\P}^{\mathrlap{\midgrey\!\downarrow\ \textit{uppercase}}}(\pr{\(X\) has value between \(x-\epsilon/2\) and \(x+\epsilon/2\)} \| \yI)
}{\epsilon}
$$

This definition works even if we don't specify the exact value of $\epsilon$, as long as it's small enough.

:::{.callout-important}
## {{< fa exclamation-triangle >}} Probability densities are not probabilities

If $X$ is a continuous quantity, the expression "$\p(X\mo 2.5 \| \yI)=0.3$" does *not* mean "There is a $0.3$  probability that $X\mo 2.5$["]{.div}. The probability that $X\mo 2.5$ *exactly* is, if anything, zero.

That expression instead means "There is a\ \ $0.3\cdot \epsilon$\ \  probability that $X$ is between $2.5-\epsilon/2$ and $2.5+\epsilon/2$, for any $\epsilon$ small enough[”]{.div}.

In fact, **probability densities can be larger than 1**, because they are obtained by dividing by a number, the width, that is in principle arbitrary. This fact shows that they cannot be probabilities.

It is important not to mix up probabilities and probability *densities*. We shall see later that densities have very different properties, for example with respect to maxima and averages.
:::

A helpful practice (though followed by few texts) is to always write a probability density as

$$\p(X\mo x \| \yI)\,\di X$$

where "$\di X$" stands for the width of a small range around $x$. This notation is also helpful with integrals. Unfortunately it becomes a little cumbersome when we are dealing with more than one quantity.

### Physical dimensions and units

In the [International System of Units (SI)](https://www.nist.gov/pml/owm/metric-si/si-units), "Degree of belief" is considered to be a dimensionless quantity, or more precisely a quantity of dimension "1". This is why we don't write units such as "metres" ($\mathrm{m}$), "kilograms" ($\mathrm{kg}$) or similar together with a probability value.^[See also the material at the [International Bureau of Weights and Measures (BIPM)](https://www.bipm.org/en/measurement-units)]

A probability *density*, however, is defined as the ratio of a probability amount and an interval $\epsilon$ of some quantity. This latter quantity might well have physical dimensions, say "metres" $\mathrm{m}$. Then the ratio, which is the probability density, has dimensions $1/\mathrm{m}$. So [*probability densities in general have physical dimensions*]{.blue}.

As another example, suppose that an agent with background knowledge $\yI$ assigns a degree of belief $0.00012$ to an interval of temperature of width $0.0001\,\mathrm{°C}$, around the temperature $T = 20\,\mathrm{°C}$. Then the probability *density* at $20\,\mathrm{°C}$ is equal to

$$
\p(T \mo 20\mathrm{°C} \| \yI) =
\frac{0.00012}{0.0001\,\mathrm{°C}} = 1.2\,\mathrm{°C^{-1}}
$$

It is an error to report probability densities without their correct physical units. In fact, keeping track of these units is often useful for consistency checks and finding errors in calculations, just like in other engineering or physics calculations.

On the other hand, if we write probability densities as previously suggested, in this case as "$\p(T \mo 20\mathrm{°C} \| \yI)\,\di T$", then the density written this way does not need any units: the units "$\mathrm{°C^{-1}}$" disappear because multiplied by $\di T$, which has the inverse units "$\mathrm{°C}$".



## Representation of probability densities {#sec-represent-dens}

### Line-based representations

The histogram and the line representations become indistinguishable for a probability density.

If we represent the probability $P$ assigned to a small range of width $\epsilon$ as the area of a rectangle, and the width of the rectangle is equal to $\epsilon$, then the height $P/\epsilon$ of the rectangle is numerically equal to the probability density. The difference from histograms for discrete quantities lies in the values reported on the vertical axis: for discrete quantities the values are *probabilities* (the *areas* of the rectangles), but for continuous quantities they are probability *densities* (the *heights* of the rectangles). This is also evident from the fact that the values reported on the vertical axis can be larger than 1, as in the example plots shown in the margin.

The rectangles, however, are so thin (usually thinner than a pixel on a screen) that they appear just as vertical lines, and together they look just like a curve delimiting a coloured area. If we don't colour the area underneath the curve, then we just have a line-based, or rather curve-based, representation of the probability density.

:::{.column-margin}
![](example_histo_density_0.08.png){width=100%}
![](example_histo_density_0.01.png){width=100%}
![](example_curve_density.png){width=100%}
As the width $\epsilon$ of the small ranges is decreased, a histogram based on these widths become indistinguishable from a line plot
:::

Keep in mind that the curve representing the probability density is *not quite a function*. In fact it's best to call it a "density" or a "density function". There are important reasons for keeping this distinction, which have also consequences for probability calculations, but we shall not delve into them for the moment.

### Scatter plots {#sec-scatter-plot}

Line plots of a probability density are very informative, but they can also be slightly deceiving. Try the following experiment.

Consider a continuous quantity $X$ with the following probability density:

![](example_curve_density.png){width=100%}

We want to represent the amount of probability in any small range, say between $X\mo 0$ and $X\mo 0.1$, by drawing in that range a number of short thin lines, the number being proportional to the probability. So a range containing 10 lines has twice the probability of a range containing 5 lines. The probability density around a value is therefore roughly represented by the density of the lines around that value.

Suppose that we have 50 lines available to distribute this way. Where should we place them?

::::{.column-page-right}
:::{.callout-caution}
## {{< fa user-edit >}} Exercise
:::::{style="font-size:110%;"}
Which of these plots shows the correct placement of the 50 lines? [(NB: the position of the correct answer is determined by a pseudorandom-number generator.)]{.small}

::::::{layout-nrow=2}
![(A)](example_scatter_densityd_p50.png)

![(B)](example_scatter_densitya_p50.png)

![(C)](example_scatter_densityb_p50.png)

![(D)](example_scatter_densityf_p50.png)
::::::
:::::
:::
::::

In a [**scatter plot**]{.blue}, the probability density is (approximately) represented by density of lines, or points, or similar objects, as in the examples above (only one of the examples above, though, correctly matches the density represented by the curve).

As the experiment and exercise above may have demonstrated, line plots sometimes give us slightly misleading ideas of how the probability is distributed across the domain. For example, peaks at some values make us overestimate the probability density around those values. Scatter plots often give a less misleading representation of the probability density.

Scatter plots are also useful for representing probability densities in more than one dimension -- sometimes even in infinite dimensions! They can moreover be easier to produce computationally than line plots.

[@@ TODO Behaviour of representations under transformations of data.]{.small .grey}

\

::: {.callout-warning}
## {{< fa book >}} Study reading
- §§5.3.0--5.3.1 of Fenton & Neil: [*Risk Assessment and Decision Analysis with Bayesian Networks*](references.html)
:::




## Combined probabilities {#sec-combined-probs}

A probability distribution is defined over a set of mutually exclusive and exhaustive sentences. In some inference problems, however, we do not need the probability of those sentences, but of some other sentence that can be obtained from them by an `or` operation. The probability of this sentence can then be obtained by a sum, according to the `or`-rule of inference. We can call this a *combined probability*. Let's explain this procedure with an example.

Back to our initial assembly-line scenario from [Ch. @sec-intro], the inference problem was to predict whether a specific component would fail within a year or not. Consider the time when the component will fail (if it's sold), and represent it by the quantity $T$ with the following 24 different values, where "$\mathrm{mo}$" stands for "months":

$$\begin{aligned}
&\pr{The component will fail during it 1st month of use}\\
&\pr{The component will fail during it 2nd month of use}\\
&\dotsc \\
&\pr{The component will fail during it 23rd month of use}\\
&\pr{The component will fail during it 24th month of use or after}
\end{aligned}$$

which we can shorten to\ \ $T\mo 1 \and T\mo 2 \and \dotsc \and T\mo 24$; note the slightly different meaning of the last value.

:::{.callout-caution}
## {{< fa user-edit >}} Exercise
What is the basic type of the quantity $T$? Which other characteristics does it have? for instance discrete? unbounded? rounded? uncensored?
:::

Suppose that the inspection device -- our agent -- has internally calculated a probability distribution for $T$, conditional on its internal programming and the results of the tests on the component, collectively denoted $\yI$. The probabilities, compactly written, are

$$
\P(T\mo1 \|\yI), \quad
\P(T\mo2 \|\yI), \quad
\dotsc, \quad
\P(T\mo24 \|\yI)
$$

Their values are stored in the file [`failure_probability.csv`](datasets/failure_probability.csv) and plotted in the histogram on the side.

:::{.column-margin}
![](failure_probabilities.png){width=100%}
:::

What's important for the agent's decision about rejecting or accepting the component, is not the exact time when it will fail, but only whether it will fail within the first year or not. That is, the agent needs the probability of the sentence $\pr{The component will fail within a year of use}$. But this sentence is just the `or` of the first 12 sentences expressing the values of $T$:

$$
\begin{aligned}
&\pr{The component will fail within a year of use}
\\[1ex]
&\qquad\qquad{}\equiv
\pr{The component will fail during it 1st month of use}
\lor{}
\\&\qquad\qquad\qquad
\pr{The component will fail during it 2nd month of use}
\lor \dotsb
\\&\qquad\qquad\qquad
\dotsb \lor
\pr{The component will fail during it 12th month of use}
\\[1ex]&\qquad\qquad{}\equiv
(T\mo 1) \lor (T\mo 2) \lor \dotsb \lor (T\mo 12)
\end{aligned}
$$

The probability needed by the agent is therefore

$$
\P(T\mo1 \lor T\mo2 \lor \dotsb \lor T\mo12\| \yI )
$$

which can be calculated using the `or`-rule, considering that the sentences involved are mutually exclusive:

$$
\begin{aligned}
&\P(\pr{The component will fail within a year of use} \| \yI) 
\\[1ex]&\qquad{}=
\P(T\mo1 \lor T\mo2 \lor \dotsb \lor T\mo12\| \yI )
\\[1ex]&\qquad{}=
\P(T\mo1 \|\yI) + \P(T\mo2 \|\yI) + \dotsb + \P(T\mo12 \|\yI)
\\[1ex]&\qquad{}= \sum_{t=1}^{12} \P(T\mo t \| \yI)
\end{aligned}
$$



:::{.callout-note}
## Sum notation
We shall often use the $\sum$-notation for sums, as in the example above. A notation like "$\displaystyle\sum_{i=5}^{20}$" means: write multiple copies of what's written on its right side, and in each copy replace the symbol "$i$" with values from $5$ to $20$, in turn; then sum up these copies. The symbol "$i$" is called the *index* of the sum. Sometimes the initial and final values, $5$ and $20$ in the example, are omitted if they are understood from the context, and the sum is written simply "$\displaystyle\sum_{i}$".
:::



:::{.callout-caution}
## {{< fa user-edit >}} Exercise
Using your favourite programming language:

- Load the file [`failure_probability.csv`](datasets/failure_probability.csv) containing the probabilities.
- Inspect this file, find the headers of its columns and so on.
- Calculate the probability that the component will fail within a year of use.
- Calculate the probability that the component will fail "within two months of use, or after a year of use".
:::


